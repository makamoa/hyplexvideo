{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch import nn\n",
    "import pickle\n",
    "import warnings\n",
    "import pandas as pd\n",
    "from scipy import ndimage as ndi\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import models\n",
    "from torchsummary import summary\n",
    "import torch \n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "gpu_id = [0] # only modify if you machine has more than one GPU card"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3666"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import skimage\n",
    "SPECIM = '/home/makam0a/Dropbox/Pixeltra/Datasets/Demo1/'\n",
    "realfake_label = pd.read_csv(SPECIM + \"NPY_data/\" + 'realfake_label.csv')\n",
    "realfake_label['folder'] = 'realfakelabel/'\n",
    "real_label = pd.read_csv(SPECIM + \"NPY_data/\" + 'real_label.csv')\n",
    "real_label['folder'] = 'reallabel/'\n",
    "fake_label = pd.read_csv(SPECIM + \"NPY_data/\" + 'fake_label.csv')\n",
    "fake_label['folder'] = 'fakelabel/'\n",
    "frames = [frame[1:-4] for frame in os.listdir(SPECIM + \"NPY_data/\" + \"background\")][:1]\n",
    "bg_label = pd.DataFrame({'frame' : frames})\n",
    "bg_label['right'] = 0\n",
    "bg_label['left'] = 0\n",
    "bg_label = bg_label.reindex(columns=['left', 'right', 'frame'])\n",
    "bg_label['folder'] = 'background/'\n",
    "data = pd.concat([bg_label, fake_label, real_label, realfake_label], ignore_index=True)\n",
    "data = data.sample(frac=1).reset_index(drop=True)\n",
    "data.loc[0].frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>left</th>\n",
       "      <th>right</th>\n",
       "      <th>frame</th>\n",
       "      <th>folder</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>4120</td>\n",
       "      <td>fakelabel/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1195</td>\n",
       "      <td>background/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>6657</td>\n",
       "      <td>realfakelabel/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4808</td>\n",
       "      <td>fakelabel/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>472</td>\n",
       "      <td>background/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>2800</td>\n",
       "      <td>fakelabel/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3933</td>\n",
       "      <td>fakelabel/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>4684</td>\n",
       "      <td>fakelabel/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4730</td>\n",
       "      <td>background/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>5248</td>\n",
       "      <td>realfakelabel/</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>155 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     left  right  frame          folder\n",
       "0       6      6   4120      fakelabel/\n",
       "1       0      0   1195     background/\n",
       "2       6      3   6657  realfakelabel/\n",
       "3       4      4   4808      fakelabel/\n",
       "4       0      0    472     background/\n",
       "..    ...    ...    ...             ...\n",
       "150     5      4   2800      fakelabel/\n",
       "151     5      4   3933      fakelabel/\n",
       "152     4      5   4684      fakelabel/\n",
       "153     0      0   4730     background/\n",
       "154     2      1   5248  realfakelabel/\n",
       "\n",
       "[155 rows x 4 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#data.to_csv('data.csv')\n",
    "pd.read_csv('data.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>left</th>\n",
       "      <th>right</th>\n",
       "      <th>frame</th>\n",
       "      <th>folder</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3666</td>\n",
       "      <td>realfakelabel/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1468</td>\n",
       "      <td>reallabel/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>5096</td>\n",
       "      <td>fakelabel/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3933</td>\n",
       "      <td>fakelabel/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>1770</td>\n",
       "      <td>fakelabel/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3677</td>\n",
       "      <td>reallabel/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1552</td>\n",
       "      <td>realfakelabel/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>8150</td>\n",
       "      <td>realfakelabel/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>6680</td>\n",
       "      <td>fakelabel/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>2316</td>\n",
       "      <td>realfakelabel/</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>126 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     left  right frame          folder\n",
       "0       5      4  3666  realfakelabel/\n",
       "1       2      1  1468      reallabel/\n",
       "2       6      5  5096      fakelabel/\n",
       "3       5      4  3933      fakelabel/\n",
       "4       5      6  1770      fakelabel/\n",
       "..    ...    ...   ...             ...\n",
       "121     1      1  3677      reallabel/\n",
       "122     1      4  1552  realfakelabel/\n",
       "123     1      4  8150  realfakelabel/\n",
       "124     5      6  6680      fakelabel/\n",
       "125     1      6  2316  realfakelabel/\n",
       "\n",
       "[126 rows x 4 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "REALFAKE = np.load(SPECIM + 'NPY_data/' + 'realfake.npy')\n",
    "FAKE = np.load(SPECIM + 'NPY_data/' + 'fake.npy')\n",
    "REAL = np.load(SPECIM + 'NPY_data/' + 'real.npy')\n",
    "BACKGROUND = np.load(SPECIM + 'NPY_data/' + 'background.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'REALFAKE' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_36832/3652734311.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m121\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mread_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m122\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mread_label\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_36832/3652734311.py\u001b[0m in \u001b[0;36mread_image\u001b[0;34m(idx)\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mBACKGROUND\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfolder\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'realfakelabel/'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mREALFAKE\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfolder\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'reallabel/'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mREAL\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'REALFAKE' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "NX = 48\n",
    "NY = 56\n",
    "BACKGROUND_LABEL = np.zeros((NX,NY))\n",
    "\n",
    "def read_label(idx):\n",
    "    sample = data.loc[idx]\n",
    "    if sample.folder == 'background/':\n",
    "        return BACKGROUND_LABEL\n",
    "    else:\n",
    "        fname = SPECIM + 'NPY_data/' + sample.folder + str(sample.frame) + '.npy'\n",
    "        return np.load(fname)\n",
    "\n",
    "def read_image(idx):\n",
    "    sample = data.loc[idx]\n",
    "    if sample.folder == 'background/':\n",
    "        idx = np.random.choice(len(BACKGROUND))\n",
    "        return BACKGROUND[idx]\n",
    "    elif sample.folder == 'realfakelabel/':\n",
    "        return REALFAKE[sample.frame]\n",
    "    elif sample.folder == 'reallabel/':\n",
    "        return REAL[sample.frame]\n",
    "    elif sample.folder == 'fakelabel/':\n",
    "        return FAKE[sample.frame]\n",
    "    else:\n",
    "        raise ValueError('frame not found')\n",
    "    \n",
    "for i in range(len(data)):\n",
    "    plt.subplot(121)\n",
    "    plt.imshow(read_image(i)[:,:,0])\n",
    "    plt.subplot(122)\n",
    "    plt.imshow(read_label(i))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import os\n",
    "import glob\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from skimage import io, transform\n",
    "from torchvision import transforms\n",
    "from torchvision.utils import make_grid\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "\n",
    "\n",
    "normalize = transforms.Normalize((0.5)*34, (0.5)*34)\n",
    "VALIDATION_SPLIT = 0.01\n",
    "CHANNELS = 9\n",
    "\n",
    "class Resize(object):\n",
    "    def __init__(self, target_size=(256,256)):\n",
    "        self.target_size = target_size\n",
    "    def __call__(self, sample):\n",
    "        target_size = self.target_size\n",
    "        x = sample['image']\n",
    "        y = sample['label']\n",
    "        sample['image'] = transform.resize(x, (target_size[0], target_size[1]))\n",
    "        sample['label'] = transform.resize(y, (target_size[0], target_size[1]),\n",
    "                                           anti_aliasing=False,\n",
    "                                           preserve_range=True,\n",
    "                                          order=0).astype(int)\n",
    "        return sample\n",
    "\n",
    "class RandomHorizontalFlip():\n",
    "    def __init__(self, prob=0.5):\n",
    "        self.prob = prob\n",
    "    \n",
    "    def __call__(self, sample):\n",
    "        x = sample['image']\n",
    "        y = sample['label']\n",
    "        if np.random.rand(1) < self.prob:\n",
    "            sample['image'] = torch.flip(x,dims=(-1,))\n",
    "            sample['label'] = torch.flip(y,dims=(-1,))\n",
    "        return sample\n",
    "    \n",
    "class ImageNormalize(object):\n",
    "    def __call__(self, sample):\n",
    "        x = sample['image']\n",
    "        sample['image'] = normalize(x)\n",
    "        return sample\n",
    "    \n",
    "class Clamp():\n",
    "    def __call__(self, sample):\n",
    "        x = sample['image']\n",
    "        sample['image'] = torch.clamp(sample['image'],0.0,1.0)\n",
    "        return sample\n",
    "    \n",
    "class RandomHorizontalFlip():\n",
    "    def __init__(self, prob=0.5):\n",
    "        self.prob = prob\n",
    "    \n",
    "    def __call__(self, sample):\n",
    "        x = sample['image']\n",
    "        y = sample['label']\n",
    "        if np.random.rand(1) < self.prob:\n",
    "            sample['image'] = torch.flip(x,dims=(-1,))\n",
    "            sample['label'] = torch.flip(y,dims=(-1,))\n",
    "        return sample\n",
    "\n",
    "    \n",
    "class SegIdentityTransform(object):\n",
    "    # Hint: Note that our transforms work on dicts. This is an example of a transform that works\n",
    "    # on a dict whose elements can be converted to np.arrays, and are then converted to torch.tensors\n",
    "    # This performs the scaling of the RGB by division by 255, and puts channels first by performing the permute\n",
    "    # for the label, we convert to long, datatype to let torch know that this is a discrete label.\n",
    "    # You might want to change this or write different transforms depending on how you read data.\n",
    "    def __call__(self, sample):\n",
    "        return {'image': torch.tensor(np.array(sample['image'])).permute(2,0,1),\n",
    "                'label': torch.tensor(np.array(sample['label'])).long()}\n",
    "    \n",
    "class RandomCrop():\n",
    "    def __init__(self, target_size=(256,256), edge=10):\n",
    "        self.target_size = target_size\n",
    "        self.edge = edge\n",
    "    def __call__(self, sample):\n",
    "        if min(sample['label'].shape) < max(self.target_size) + 2*self.edge:\n",
    "            sample = Resize(self.target_size)(sample)\n",
    "            return sample\n",
    "        wx, wy = self.target_size\n",
    "        wx0 , wy0 = sample['label'].shape\n",
    "        try:\n",
    "            center_x = np.random.randint(self.edge+wx//2,wx0 - self.edge - wx//2)\n",
    "            center_y = np.random.randint(self.edge+wy//2,wy0 - self.edge - wy//2)\n",
    "        except:\n",
    "            print(sample['label'].shape)\n",
    "        crop_x_0 = center_x - wx // 2\n",
    "        crop_x_1 = center_x + wx // 2\n",
    "        crop_y_0 = center_y - wy // 2\n",
    "        crop_y_1 = center_y + wy // 2\n",
    "        sample['image'] = sample['image'][crop_x_0:crop_x_1,crop_y_0:crop_y_1].astype(float)\n",
    "        sample['label'] = sample['label'][crop_x_0:crop_x_1,crop_y_0:crop_y_1].astype(int)\n",
    "        return sample\n",
    "    \n",
    "class RandomCropHoriz():\n",
    "    def __init__(self, target_size=(256,256), edge=10, shift=170):\n",
    "        self.target_size = target_size\n",
    "        self.edge = edge\n",
    "        self.shift = shift\n",
    "    def __call__(self, sample):\n",
    "        if min(sample['label'].shape) < max(self.target_size) + 2*self.edge:\n",
    "            sample = Resize(self.target_size)(sample)\n",
    "            return sample\n",
    "        wx, wy = self.target_size\n",
    "        wx0 , wy0 = sample['label'].shape\n",
    "        try:\n",
    "            center_x = np.random.randint(self.edge+wx//2,wx0 - self.edge - wx//2)\n",
    "            center_y = np.random.randint(self.edge+wy//2,wy0 - self.edge - wy//2)\n",
    "        except:\n",
    "            print(sample['label'].shape)\n",
    "        crop_x_0 = center_x - wx // 2\n",
    "        crop_x_1 = center_x + wx // 2\n",
    "        crop_y_0 = center_y - wy // 2\n",
    "        crop_y_1 = center_y + wy // 2\n",
    "        sample['image'] = sample['image'][self.shift:self.shift+self.target_size[0],crop_y_0:crop_y_1].astype(float)\n",
    "        sample['label'] = sample['label'][self.shift:self.shift+self.target_size[0],crop_y_0:crop_y_1].astype(int)\n",
    "        return sample\n",
    "    \n",
    "class_names = ['bg,',\n",
    "                    'real apple',\n",
    "                    'real pepper',\n",
    "                    'real grape',\n",
    "                    'fake apple',\n",
    "                    'fake pepper',\n",
    "                    'fake grape']\n",
    "\n",
    "def get_labels():\n",
    "    \"\"\"Load the mapping that associates pascal classes with label colors\n",
    "    Returns:\n",
    "        np.ndarray with dimensions (21, 3)\n",
    "    \"\"\"\n",
    "    return np.asarray([[0, 0, 0],\n",
    "                       [128, 0, 0],\n",
    "                       [0, 128, 0],\n",
    "                       [128, 128, 0],\n",
    "                       [0, 0, 128],\n",
    "                       [128, 0, 128],\n",
    "                       [0, 128, 128]])\n",
    "\n",
    "def encode_segmap(mask):\n",
    "    \"\"\"Encode segmentation label images as pascal classes\n",
    "    Args:\n",
    "        mask (np.ndarray): raw segmentation label image of dimension\n",
    "          (M, N, 3), in which the Pascal classes are encoded as colours.\n",
    "    Returns:\n",
    "        (np.ndarray): class map with dimensions (M,N), where the value at\n",
    "        a given location is the integer denoting the class index.\n",
    "    \"\"\"\n",
    "\n",
    "    mask = mask.astype(int)\n",
    "    label_mask = np.zeros((mask.shape[0], mask.shape[1]), dtype=np.int32)\n",
    "    for i, label in enumerate(get_labels()):\n",
    "        label_mask[np.where(np.all(mask==label, axis=-1))[:2]] = i\n",
    "    return label_mask\n",
    "\n",
    "def decode_segmap(mask, unk_label=255):\n",
    "    \"\"\"Decode segmentation label prediction as RGB images\n",
    "    Args:\n",
    "        mask (torch.tensor): class map with dimensions (B, M,N), where the value at\n",
    "        a given location is the integer denoting the class index.\n",
    "    Returns:\n",
    "        (np.ndarray): colored image of shape (BM, BN, 3)\n",
    "    \"\"\"\n",
    "    mask[mask == unk_label] == 0\n",
    "    mask = mask.numpy()\n",
    "    cmap = get_labels()\n",
    "    cmap_exp = cmap[..., None]\n",
    "    colored = cmap[mask].squeeze()\n",
    "    grid = make_grid(torch.tensor(colored).permute(0, 3, 1, 2))\n",
    "    return np.transpose(grid, (1, 2, 0))\n",
    "    \n",
    "class HySpecSegmentation(Dataset):\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        self.transform = transform \n",
    "        self.image_files = os.listdir(root_dir)\n",
    "        self.root_dir = root_dir\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "    \n",
    "    def read_image(self, idx):\n",
    "        filename = self.root_dir + self.image_files[idx]\n",
    "        with h5py.File(filename, \"r\") as f:\n",
    "            # List all groups\n",
    "            a_group_key = list(f.keys())[0]\n",
    "            # Get the data\n",
    "            data = list(f[a_group_key])\n",
    "        return np.stack(data,axis=-1)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = self.read_image(idx)       \n",
    "        sample = {'image': image, 'label': image}    \n",
    "        return self.transform(sample) if self.transform else sample\n",
    "    \n",
    "class CameraSegmentation(Dataset):\n",
    "    def __init__(self, root_dir, datafile='data.csv', transform=None):\n",
    "        self.data = pd.read_csv(datafile, index_col=0)\n",
    "        self.transform = transform \n",
    "        self.root_dir = root_dir\n",
    "        self.class_names = ['bg,',\n",
    "                    'real apple',\n",
    "                    'real pepper',\n",
    "                    'real grape',\n",
    "                    'fake apple',\n",
    "                    'fake pepper',\n",
    "                    'fake grape']\n",
    "        self.num_classes = len(self.class_names)\n",
    "    \n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def read_label(self, idx):\n",
    "        sample = self.data.loc[idx]\n",
    "        if sample.folder == 'background/':\n",
    "            return BACKGROUND_LABEL\n",
    "        else:\n",
    "            fname = SPECIM + 'NPY_data/' + sample.folder + str(sample.frame) + '.npy'\n",
    "            return np.load(fname)\n",
    "\n",
    "    def read_image(self, idx):\n",
    "        sample = self.data.loc[idx]\n",
    "        if sample.folder == 'background/':\n",
    "            idx = np.random.choice(len(BACKGROUND))\n",
    "            return BACKGROUND[idx]\n",
    "        elif sample.folder == 'realfakelabel/':\n",
    "            return REALFAKE[sample.frame]\n",
    "        elif sample.folder == 'reallabel/':\n",
    "            return REAL[sample.frame]\n",
    "        elif sample.folder == 'fakelabel/':\n",
    "            return FAKE[sample.frame]\n",
    "        else:\n",
    "            raise ValueError('frame not found')\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = self.read_image(idx)[:,:,:CHANNELS]\n",
    "        label = self.read_label(idx)  \n",
    "        sample = {'image': image, 'label': label}    \n",
    "        return self.transform(sample) if self.transform else sample\n",
    "    \n",
    "def prep_loaders(root_dir=None, hyspec=True, batch_size=1, workers=1):\n",
    "    # Load dataset\n",
    "    if hyspec:\n",
    "        image_depth_dataset = HySpecSegmentation(root_dir=root_dir, transform=transforms.Compose([RandomCropHoriz(),SegIdentityTransform(),RandomHorizontalFlip()]))\n",
    "    else:\n",
    "        image_depth_dataset = CameraSegmentation(root_dir=root_dir, transform=transforms.Compose([Resize(), SegIdentityTransform(), RandomHorizontalFlip()]))\n",
    "\n",
    "    # Split into training and validation sets\n",
    "    train_size = int((1-VALIDATION_SPLIT) * len(image_depth_dataset))\n",
    "    test_size = len(image_depth_dataset) - train_size\n",
    "    train_dataset, test_dataset = torch.utils.data.random_split(image_depth_dataset, [train_size, test_size])\n",
    "\n",
    "    # Prepare data loaders\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=workers)\n",
    "    valid_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=workers)\n",
    "    print('Dataset size (num. batches)', len(train_loader), len(valid_loader))\n",
    "    return train_loader, valid_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset size (num. batches) 16 1\n"
     ]
    }
   ],
   "source": [
    "batch_size=8\n",
    "workers = 1\n",
    "train_loader, valid_loader = prep_loaders(SPECIM, hyspec=False, batch_size=batch_size, workers=workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = iter(train_loader).next()\n",
    "# plt.subplots(121)\n",
    "# plt.imshow(sample['label'][3])\n",
    "# plt.subplots(122)\n",
    "# plt.imshow(sample['image'][3,0])\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x14f3ac4a29d0>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(sample['image'][6,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['bg,' 'real apple' 'real pepper' 'real grape' 'fake apple' 'fake pepper'\n",
      " 'fake grape']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x14f3ae62a5b0>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 648x648 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 648x648 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Examine training data\n",
    "%pylab inline\n",
    "import torchvision\n",
    "sample = iter(train_loader).next()\n",
    "print(np.array(class_names)[sample['label'].unique()])\n",
    "figure(figsize=(9,9)); imshow(torchvision.utils.make_grid(sample['image'][:,:3,:,:], padding=0).permute((1, 2, 0)))\n",
    "figure(figsize=(9,9)); imshow(torchvision.utils.make_grid(sample['label'][:,None,...], padding=0).permute((1, 2, 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_classes = len(class_names)\n",
    "n_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/makam0a/.cache/torch/hub/mateuszbuda_brain-segmentation-pytorch_master\n"
     ]
    }
   ],
   "source": [
    "model = torch.hub.load('mateuszbuda/brain-segmentation-pytorch', 'unet',\n",
    "    in_channels=CHANNELS, out_channels=n_classes, pretrained=False).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import Metrics\n",
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "train_pretrained=False\n",
    "epochs = 300\n",
    "batch_size = 8\n",
    "learning_rate = 1e-4\n",
    "workers = 1 # The number of parallel processes used to read data\n",
    "gpu_id = [0] # only modify if you machine has more than one GPU card"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training segmentation_rgb_gpu[0]_n300_bs8_lr0.0001_pretrainedFalse_loss_cross_entropy_time_22:12:11.271030\n",
      "\n",
      "Epoch: [0][0/16]\tTime 0.438 (0.438)\tETA 0:00:07\tTraining Loss 1.7591 (1.7591)\n",
      "\n",
      "Epoch: [0][1/16]\tTime 0.179 (0.616)\tETA 0:00:02\tTraining Loss 1.7570 (1.7581)\n",
      "\n",
      "Epoch: [0][2/16]\tTime 0.176 (0.792)\tETA 0:00:02\tTraining Loss 1.7461 (1.7541)\n",
      "\n",
      "Epoch: [0][3/16]\tTime 0.193 (0.985)\tETA 0:00:02\tTraining Loss 1.7527 (1.7537)\n",
      "\n",
      "Epoch: [0][4/16]\tTime 0.190 (1.175)\tETA 0:00:02\tTraining Loss 1.7494 (1.7528)\n",
      "\n",
      "Epoch: [0][5/16]\tTime 0.182 (1.357)\tETA 0:00:02\tTraining Loss 1.7502 (1.7524)\n",
      "\n",
      "Epoch: [0][6/16]\tTime 0.188 (1.545)\tETA 0:00:01\tTraining Loss 1.7389 (1.7505)\n",
      "\n",
      "Epoch: [0][7/16]\tTime 0.186 (1.731)\tETA 0:00:01\tTraining Loss 1.7557 (1.7511)\n",
      "\n",
      "Epoch: [0][8/16]\tTime 0.186 (1.917)\tETA 0:00:01\tTraining Loss 1.7522 (1.7513)\n",
      "\n",
      "Epoch: [0][9/16]\tTime 0.184 (2.101)\tETA 0:00:01\tTraining Loss 1.7413 (1.7503)\n",
      "\n",
      "Epoch: [0][10/16]\tTime 0.205 (2.306)\tETA 0:00:01\tTraining Loss 1.7443 (1.7497)\n",
      "\n",
      "Epoch: [0][11/16]\tTime 0.187 (2.493)\tETA 0:00:00\tTraining Loss 1.7409 (1.7490)\n",
      "\n",
      "Epoch: [0][12/16]\tTime 0.195 (2.689)\tETA 0:00:00\tTraining Loss 1.7418 (1.7484)\n",
      "\n",
      "Epoch: [0][13/16]\tTime 0.188 (2.877)\tETA 0:00:00\tTraining Loss 1.7551 (1.7489)\n",
      "\n",
      "Epoch: [0][14/16]\tTime 0.183 (3.060)\tETA 0:00:00\tTraining Loss 1.7427 (1.7485)\n",
      "\n",
      "Epoch: [0][15/16]\tTime 0.110 (3.170)\tETA 0:00:00\tTraining Loss 1.7426 (1.7483)\n",
      "_\n",
      "Validation stats                    IoU        F1      Prec    recall       Acc\n",
      "bg,          0.949100  0.973800  0.973200  0.974600  0.954600\n",
      "real apple   0.008900  0.017600  0.175400  0.009300  0.932000\n",
      "real pepper  0.000000  0.000000  0.000000  0.000000  1.000000\n",
      "real grape   0.001700  0.003400  0.037600  0.001800  0.932400\n",
      "fake apple   0.000000  0.000000  0.000000  0.000000  0.935200\n",
      "fake pepper  0.000000  0.000000  0.000000  0.000000  0.999000\n",
      "fake grape   0.000000  0.000000  0.000000  0.000000  0.943000\n",
      "total        0.137100  0.142114  0.169457  0.140814  0.956600\n",
      "total(-bg)   0.001767  0.003500  0.035500  0.001850  0.956933\n",
      "\n",
      "Epoch: [1][0/16]\tTime 0.486 (0.486)\tETA 0:00:07\tTraining Loss 1.7416 (1.7416)\n",
      "\n",
      "Epoch: [1][1/16]\tTime 0.173 (0.659)\tETA 0:00:02\tTraining Loss 1.7413 (1.7415)\n",
      "\n",
      "Epoch: [1][2/16]\tTime 0.194 (0.853)\tETA 0:00:02\tTraining Loss 1.7402 (1.7410)\n",
      "\n",
      "Epoch: [1][3/16]\tTime 0.183 (1.036)\tETA 0:00:02\tTraining Loss 1.7319 (1.7387)\n",
      "\n",
      "Epoch: [1][4/16]\tTime 0.194 (1.230)\tETA 0:00:02\tTraining Loss 1.7496 (1.7409)\n",
      "\n",
      "Epoch: [1][5/16]\tTime 0.183 (1.413)\tETA 0:00:02\tTraining Loss 1.7336 (1.7397)\n",
      "\n",
      "Epoch: [1][6/16]\tTime 0.196 (1.609)\tETA 0:00:01\tTraining Loss 1.7442 (1.7403)\n",
      "\n",
      "Epoch: [1][7/16]\tTime 0.198 (1.806)\tETA 0:00:01\tTraining Loss 1.7327 (1.7394)\n",
      "\n",
      "Epoch: [1][8/16]\tTime 0.191 (1.997)\tETA 0:00:01\tTraining Loss 1.7356 (1.7390)\n",
      "\n",
      "Epoch: [1][9/16]\tTime 0.184 (2.181)\tETA 0:00:01\tTraining Loss 1.7373 (1.7388)\n",
      "\n",
      "Epoch: [1][10/16]\tTime 0.190 (2.371)\tETA 0:00:01\tTraining Loss 1.7354 (1.7385)\n",
      "\n",
      "Epoch: [1][11/16]\tTime 0.195 (2.566)\tETA 0:00:00\tTraining Loss 1.7372 (1.7384)\n",
      "\n",
      "Epoch: [1][12/16]\tTime 0.183 (2.749)\tETA 0:00:00\tTraining Loss 1.7348 (1.7381)\n",
      "\n",
      "Epoch: [1][13/16]\tTime 0.185 (2.935)\tETA 0:00:00\tTraining Loss 1.7278 (1.7374)\n",
      "\n",
      "Epoch: [1][14/16]\tTime 0.193 (3.127)\tETA 0:00:00\tTraining Loss 1.7348 (1.7372)\n",
      "\n",
      "Epoch: [1][15/16]\tTime 0.118 (3.245)\tETA 0:00:00\tTraining Loss 1.7282 (1.7369)\n",
      "_\n",
      "Validation stats                    IoU        F1      Prec    recall       Acc\n",
      "bg,          0.944600  0.971500  0.980900  0.962300  0.950900\n",
      "real apple   0.007100  0.014000  0.123100  0.007400  0.931300\n",
      "real pepper  0.000000  0.000000  0.000000  0.000000  1.000000\n",
      "real grape   0.004200  0.008400  0.074500  0.004500  0.931900\n",
      "fake apple   0.000000  0.000000  0.000000  0.000000  0.930200\n",
      "fake pepper  0.000000  0.000000  0.000000  0.000000  0.999400\n",
      "fake grape   0.000000  0.000000  0.000000  0.000000  0.931300\n",
      "total        0.136557  0.141986  0.168357  0.139171  0.953571\n",
      "total(-bg)   0.001883  0.003733  0.032933  0.001983  0.954017\n",
      "\n",
      "Epoch: [2][0/16]\tTime 0.460 (0.460)\tETA 0:00:07\tTraining Loss 1.7302 (1.7302)\n",
      "\n",
      "Epoch: [2][1/16]\tTime 0.173 (0.633)\tETA 0:00:02\tTraining Loss 1.7363 (1.7332)\n",
      "\n",
      "Epoch: [2][2/16]\tTime 0.203 (0.836)\tETA 0:00:02\tTraining Loss 1.7208 (1.7291)\n",
      "\n",
      "Epoch: [2][3/16]\tTime 0.189 (1.024)\tETA 0:00:02\tTraining Loss 1.7314 (1.7297)\n",
      "\n",
      "Epoch: [2][4/16]\tTime 0.180 (1.205)\tETA 0:00:02\tTraining Loss 1.7325 (1.7302)\n",
      "\n",
      "Epoch: [2][5/16]\tTime 0.191 (1.396)\tETA 0:00:02\tTraining Loss 1.7312 (1.7304)\n",
      "\n",
      "Epoch: [2][6/16]\tTime 0.198 (1.593)\tETA 0:00:01\tTraining Loss 1.7314 (1.7305)\n",
      "\n",
      "Epoch: [2][7/16]\tTime 0.194 (1.787)\tETA 0:00:01\tTraining Loss 1.7244 (1.7298)\n",
      "\n",
      "Epoch: [2][8/16]\tTime 0.186 (1.973)\tETA 0:00:01\tTraining Loss 1.7170 (1.7283)\n",
      "\n",
      "Epoch: [2][9/16]\tTime 0.184 (2.157)\tETA 0:00:01\tTraining Loss 1.7316 (1.7287)\n",
      "\n",
      "Epoch: [2][10/16]\tTime 0.196 (2.353)\tETA 0:00:01\tTraining Loss 1.7265 (1.7285)\n",
      "\n",
      "Epoch: [2][11/16]\tTime 0.194 (2.547)\tETA 0:00:00\tTraining Loss 1.7198 (1.7277)\n",
      "\n",
      "Epoch: [2][12/16]\tTime 0.190 (2.736)\tETA 0:00:00\tTraining Loss 1.7091 (1.7263)\n",
      "\n",
      "Epoch: [2][13/16]\tTime 0.184 (2.920)\tETA 0:00:00\tTraining Loss 1.7199 (1.7259)\n",
      "\n",
      "Epoch: [2][14/16]\tTime 0.176 (3.096)\tETA 0:00:00\tTraining Loss 1.7187 (1.7254)\n",
      "\n",
      "Epoch: [2][15/16]\tTime 0.110 (3.206)\tETA 0:00:00\tTraining Loss 1.7236 (1.7253)\n",
      "_\n",
      "Validation stats                    IoU        F1      Prec    recall       Acc\n",
      "bg,          0.942000  0.970100  0.975100  0.965200  0.948300\n",
      "real apple   0.004200  0.008300  0.109500  0.004300  0.932300\n",
      "real pepper  0.000000  0.000000  0.000000  0.000000  1.000000\n",
      "real grape   0.006000  0.011900  0.094900  0.006400  0.931700\n",
      "fake apple   0.000000  0.000000  0.000000  0.000000  0.931900\n",
      "fake pepper  0.000000  0.000000  0.000000  0.000000  0.999900\n",
      "fake grape   0.000000  0.000000  0.000000  0.000000  0.935800\n",
      "total        0.136029  0.141471  0.168500  0.139414  0.954271\n",
      "total(-bg)   0.001700  0.003367  0.034067  0.001783  0.955267\n",
      "\n",
      "Epoch: [3][0/16]\tTime 0.459 (0.459)\tETA 0:00:07\tTraining Loss 1.7113 (1.7113)\n",
      "\n",
      "Epoch: [3][1/16]\tTime 0.175 (0.634)\tETA 0:00:02\tTraining Loss 1.7349 (1.7231)\n",
      "\n",
      "Epoch: [3][2/16]\tTime 0.197 (0.831)\tETA 0:00:02\tTraining Loss 1.7119 (1.7194)\n",
      "\n",
      "Epoch: [3][3/16]\tTime 0.181 (1.012)\tETA 0:00:02\tTraining Loss 1.7116 (1.7174)\n",
      "\n",
      "Epoch: [3][4/16]\tTime 0.189 (1.200)\tETA 0:00:02\tTraining Loss 1.7133 (1.7166)\n",
      "\n",
      "Epoch: [3][5/16]\tTime 0.184 (1.385)\tETA 0:00:02\tTraining Loss 1.7012 (1.7140)\n",
      "\n",
      "Epoch: [3][6/16]\tTime 0.187 (1.572)\tETA 0:00:01\tTraining Loss 1.7240 (1.7155)\n",
      "\n",
      "Epoch: [3][7/16]\tTime 0.181 (1.753)\tETA 0:00:01\tTraining Loss 1.7093 (1.7147)\n",
      "\n",
      "Epoch: [3][8/16]\tTime 0.185 (1.938)\tETA 0:00:01\tTraining Loss 1.7128 (1.7145)\n",
      "\n",
      "Epoch: [3][9/16]\tTime 0.190 (2.128)\tETA 0:00:01\tTraining Loss 1.7122 (1.7143)\n",
      "\n",
      "Epoch: [3][10/16]\tTime 0.187 (2.316)\tETA 0:00:01\tTraining Loss 1.7146 (1.7143)\n",
      "\n",
      "Epoch: [3][11/16]\tTime 0.184 (2.500)\tETA 0:00:00\tTraining Loss 1.7204 (1.7148)\n",
      "\n",
      "Epoch: [3][12/16]\tTime 0.189 (2.689)\tETA 0:00:00\tTraining Loss 1.7137 (1.7147)\n",
      "\n",
      "Epoch: [3][13/16]\tTime 0.187 (2.875)\tETA 0:00:00\tTraining Loss 1.7088 (1.7143)\n",
      "\n",
      "Epoch: [3][14/16]\tTime 0.196 (3.072)\tETA 0:00:00\tTraining Loss 1.7252 (1.7150)\n",
      "\n",
      "Epoch: [3][15/16]\tTime 0.108 (3.179)\tETA 0:00:00\tTraining Loss 1.7025 (1.7146)\n",
      "_\n",
      "Validation stats                    IoU        F1      Prec    recall       Acc\n",
      "bg,          0.943700  0.971000  0.981600  0.960700  0.950100\n",
      "real apple   0.004200  0.008300  0.124600  0.004300  0.932600\n",
      "real pepper  0.000000  0.000000  0.000000  0.000000  1.000000\n",
      "real grape   0.016300  0.032000  0.179500  0.017600  0.931200\n",
      "fake apple   0.000000  0.000000  0.000000  0.000000  0.930400\n",
      "fake pepper  0.000000  0.000000  0.000000  0.000000  0.999500\n",
      "fake grape   0.000000  0.000000  0.000000  0.000000  0.929700\n",
      "total        0.137743  0.144471  0.183671  0.140371  0.953357\n",
      "total(-bg)   0.003417  0.006717  0.050683  0.003650  0.953900\n",
      "\n",
      "Epoch: [4][0/16]\tTime 0.397 (0.397)\tETA 0:00:06\tTraining Loss 1.7088 (1.7088)\n",
      "\n",
      "Epoch: [4][1/16]\tTime 0.179 (0.577)\tETA 0:00:02\tTraining Loss 1.7003 (1.7046)\n",
      "\n",
      "Epoch: [4][2/16]\tTime 0.193 (0.769)\tETA 0:00:02\tTraining Loss 1.7100 (1.7064)\n",
      "\n",
      "Epoch: [4][3/16]\tTime 0.185 (0.955)\tETA 0:00:02\tTraining Loss 1.7050 (1.7060)\n",
      "\n",
      "Epoch: [4][4/16]\tTime 0.190 (1.145)\tETA 0:00:02\tTraining Loss 1.7099 (1.7068)\n",
      "\n",
      "Epoch: [4][5/16]\tTime 0.193 (1.339)\tETA 0:00:02\tTraining Loss 1.7130 (1.7078)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: [4][6/16]\tTime 0.210 (1.549)\tETA 0:00:02\tTraining Loss 1.7046 (1.7074)\n",
      "\n",
      "Epoch: [4][7/16]\tTime 0.192 (1.741)\tETA 0:00:01\tTraining Loss 1.6944 (1.7058)\n",
      "\n",
      "Epoch: [4][8/16]\tTime 0.186 (1.927)\tETA 0:00:01\tTraining Loss 1.7006 (1.7052)\n",
      "\n",
      "Epoch: [4][9/16]\tTime 0.185 (2.112)\tETA 0:00:01\tTraining Loss 1.6963 (1.7043)\n",
      "\n",
      "Epoch: [4][10/16]\tTime 0.190 (2.302)\tETA 0:00:01\tTraining Loss 1.6981 (1.7037)\n",
      "\n",
      "Epoch: [4][11/16]\tTime 0.190 (2.492)\tETA 0:00:00\tTraining Loss 1.7042 (1.7038)\n",
      "\n",
      "Epoch: [4][12/16]\tTime 0.185 (2.677)\tETA 0:00:00\tTraining Loss 1.7053 (1.7039)\n",
      "\n",
      "Epoch: [4][13/16]\tTime 0.193 (2.870)\tETA 0:00:00\tTraining Loss 1.6969 (1.7034)\n",
      "\n",
      "Epoch: [4][14/16]\tTime 0.195 (3.066)\tETA 0:00:00\tTraining Loss 1.7043 (1.7034)\n",
      "\n",
      "Epoch: [4][15/16]\tTime 0.112 (3.177)\tETA 0:00:00\tTraining Loss 1.6984 (1.7033)\n",
      "_\n",
      "Validation stats                    IoU        F1      Prec    recall       Acc\n",
      "bg,          0.939300  0.968700  0.978300  0.959300  0.946100\n",
      "real apple   0.008800  0.017400  0.166000  0.009200  0.931900\n",
      "real pepper  0.000000  0.000000  0.000000  0.000000  1.000000\n",
      "real grape   0.012400  0.024600  0.143800  0.013400  0.930900\n",
      "fake apple   0.000000  0.000000  0.000000  0.000000  0.939700\n",
      "fake pepper  0.000000  0.000000  0.000000  0.000000  0.998400\n",
      "fake grape   0.000000  0.000000  0.000000  0.000000  0.924300\n",
      "total        0.137214  0.144386  0.184014  0.140271  0.953043\n",
      "total(-bg)   0.003533  0.007000  0.051633  0.003767  0.954200\n",
      "\n",
      "Epoch: [5][0/16]\tTime 0.470 (0.470)\tETA 0:00:07\tTraining Loss 1.6950 (1.6950)\n",
      "\n",
      "Epoch: [5][1/16]\tTime 0.283 (0.753)\tETA 0:00:04\tTraining Loss 1.6965 (1.6958)\n",
      "\n",
      "Epoch: [5][2/16]\tTime 0.183 (0.936)\tETA 0:00:02\tTraining Loss 1.6968 (1.6961)\n",
      "\n",
      "Epoch: [5][3/16]\tTime 0.186 (1.122)\tETA 0:00:02\tTraining Loss 1.6964 (1.6962)\n",
      "\n",
      "Epoch: [5][4/16]\tTime 0.191 (1.313)\tETA 0:00:02\tTraining Loss 1.7021 (1.6974)\n",
      "\n",
      "Epoch: [5][5/16]\tTime 0.199 (1.512)\tETA 0:00:02\tTraining Loss 1.6900 (1.6961)\n",
      "\n",
      "Epoch: [5][6/16]\tTime 0.184 (1.696)\tETA 0:00:01\tTraining Loss 1.7059 (1.6975)\n",
      "\n",
      "Epoch: [5][7/16]\tTime 0.185 (1.881)\tETA 0:00:01\tTraining Loss 1.6885 (1.6964)\n",
      "\n",
      "Epoch: [5][8/16]\tTime 0.191 (2.072)\tETA 0:00:01\tTraining Loss 1.6924 (1.6960)\n",
      "\n",
      "Epoch: [5][9/16]\tTime 0.188 (2.259)\tETA 0:00:01\tTraining Loss 1.6924 (1.6956)\n",
      "\n",
      "Epoch: [5][10/16]\tTime 0.197 (2.457)\tETA 0:00:01\tTraining Loss 1.6991 (1.6959)\n",
      "\n",
      "Epoch: [5][11/16]\tTime 0.185 (2.642)\tETA 0:00:00\tTraining Loss 1.6862 (1.6951)\n",
      "\n",
      "Epoch: [5][12/16]\tTime 0.202 (2.844)\tETA 0:00:00\tTraining Loss 1.6913 (1.6948)\n",
      "\n",
      "Epoch: [5][13/16]\tTime 0.189 (3.033)\tETA 0:00:00\tTraining Loss 1.6937 (1.6947)\n",
      "\n",
      "Epoch: [5][14/16]\tTime 0.194 (3.227)\tETA 0:00:00\tTraining Loss 1.6963 (1.6948)\n",
      "\n",
      "Epoch: [5][15/16]\tTime 0.118 (3.344)\tETA 0:00:00\tTraining Loss 1.6810 (1.6944)\n",
      "_\n",
      "Validation stats                    IoU        F1      Prec    recall       Acc\n",
      "bg,          0.940100  0.969100  0.977700  0.960700  0.946800\n",
      "real apple   0.003600  0.007200  0.123100  0.003700  0.932800\n",
      "real pepper  0.000000  0.000000  0.000000  0.000000  1.000000\n",
      "real grape   0.009100  0.018000  0.100100  0.009900  0.930100\n",
      "fake apple   0.000000  0.000000  0.000000  0.000000  0.932600\n",
      "fake pepper  0.000000  0.000000  0.000000  0.000000  0.997800\n",
      "fake grape   0.000000  0.000000  0.000000  0.000000  0.932500\n",
      "total        0.136114  0.142043  0.171557  0.139186  0.953229\n",
      "total(-bg)   0.002117  0.004200  0.037200  0.002267  0.954300\n",
      "\n",
      "Epoch: [6][0/16]\tTime 0.534 (0.534)\tETA 0:00:08\tTraining Loss 1.6807 (1.6807)\n",
      "\n",
      "Epoch: [6][1/16]\tTime 0.221 (0.755)\tETA 0:00:03\tTraining Loss 1.6917 (1.6862)\n",
      "\n",
      "Epoch: [6][2/16]\tTime 0.202 (0.957)\tETA 0:00:02\tTraining Loss 1.6907 (1.6877)\n",
      "\n",
      "Epoch: [6][3/16]\tTime 0.188 (1.146)\tETA 0:00:02\tTraining Loss 1.7015 (1.6912)\n",
      "\n",
      "Epoch: [6][4/16]\tTime 0.188 (1.334)\tETA 0:00:02\tTraining Loss 1.6884 (1.6906)\n",
      "\n",
      "Epoch: [6][5/16]\tTime 0.183 (1.517)\tETA 0:00:02\tTraining Loss 1.6932 (1.6910)\n",
      "\n",
      "Epoch: [6][6/16]\tTime 0.188 (1.706)\tETA 0:00:01\tTraining Loss 1.6812 (1.6896)\n",
      "\n",
      "Epoch: [6][7/16]\tTime 0.192 (1.897)\tETA 0:00:01\tTraining Loss 1.6951 (1.6903)\n",
      "\n",
      "Epoch: [6][8/16]\tTime 0.193 (2.090)\tETA 0:00:01\tTraining Loss 1.6860 (1.6898)\n",
      "\n",
      "Epoch: [6][9/16]\tTime 0.195 (2.285)\tETA 0:00:01\tTraining Loss 1.6928 (1.6901)\n",
      "\n",
      "Epoch: [6][10/16]\tTime 0.210 (2.495)\tETA 0:00:01\tTraining Loss 1.6806 (1.6893)\n",
      "\n",
      "Epoch: [6][11/16]\tTime 0.188 (2.683)\tETA 0:00:00\tTraining Loss 1.6779 (1.6883)\n",
      "\n",
      "Epoch: [6][12/16]\tTime 0.193 (2.876)\tETA 0:00:00\tTraining Loss 1.6761 (1.6874)\n",
      "\n",
      "Epoch: [6][13/16]\tTime 0.192 (3.068)\tETA 0:00:00\tTraining Loss 1.6796 (1.6868)\n",
      "\n",
      "Epoch: [6][14/16]\tTime 0.189 (3.257)\tETA 0:00:00\tTraining Loss 1.6896 (1.6870)\n",
      "\n",
      "Epoch: [6][15/16]\tTime 0.114 (3.371)\tETA 0:00:00\tTraining Loss 1.6782 (1.6867)\n",
      "_\n",
      "Validation stats                    IoU        F1      Prec    recall       Acc\n",
      "bg,          0.942700  0.970500  0.980200  0.961100  0.949200\n",
      "real apple   0.004600  0.009100  0.098800  0.004800  0.931700\n",
      "real pepper  0.000000  0.000000  0.000000  0.000000  1.000000\n",
      "real grape   0.011400  0.022500  0.115500  0.012500  0.929900\n",
      "fake apple   0.000000  0.000000  0.000000  0.000000  0.930600\n",
      "fake pepper  0.000000  0.000000  0.000000  0.000000  0.996900\n",
      "fake grape   0.000000  0.000000  0.000000  0.000000  0.935300\n",
      "total        0.136957  0.143157  0.170643  0.139771  0.953371\n",
      "total(-bg)   0.002667  0.005267  0.035717  0.002883  0.954067\n",
      "\n",
      "Epoch: [7][0/16]\tTime 0.455 (0.455)\tETA 0:00:07\tTraining Loss 1.6789 (1.6789)\n",
      "\n",
      "Epoch: [7][1/16]\tTime 0.196 (0.651)\tETA 0:00:02\tTraining Loss 1.6792 (1.6791)\n",
      "\n",
      "Epoch: [7][2/16]\tTime 0.191 (0.841)\tETA 0:00:02\tTraining Loss 1.6817 (1.6800)\n",
      "\n",
      "Epoch: [7][3/16]\tTime 0.184 (1.025)\tETA 0:00:02\tTraining Loss 1.6851 (1.6813)\n",
      "\n",
      "Epoch: [7][4/16]\tTime 0.182 (1.207)\tETA 0:00:02\tTraining Loss 1.6855 (1.6821)\n",
      "\n",
      "Epoch: [7][5/16]\tTime 0.188 (1.396)\tETA 0:00:02\tTraining Loss 1.6703 (1.6801)\n",
      "\n",
      "Epoch: [7][6/16]\tTime 0.196 (1.592)\tETA 0:00:01\tTraining Loss 1.6846 (1.6808)\n",
      "\n",
      "Epoch: [7][7/16]\tTime 0.198 (1.790)\tETA 0:00:01\tTraining Loss 1.6768 (1.6803)\n",
      "\n",
      "Epoch: [7][8/16]\tTime 0.182 (1.972)\tETA 0:00:01\tTraining Loss 1.6766 (1.6799)\n",
      "\n",
      "Epoch: [7][9/16]\tTime 0.193 (2.165)\tETA 0:00:01\tTraining Loss 1.6768 (1.6796)\n",
      "\n",
      "Epoch: [7][10/16]\tTime 0.188 (2.353)\tETA 0:00:01\tTraining Loss 1.6717 (1.6789)\n",
      "\n",
      "Epoch: [7][11/16]\tTime 0.182 (2.535)\tETA 0:00:00\tTraining Loss 1.6913 (1.6799)\n",
      "\n",
      "Epoch: [7][12/16]\tTime 0.202 (2.737)\tETA 0:00:00\tTraining Loss 1.6809 (1.6800)\n",
      "\n",
      "Epoch: [7][13/16]\tTime 0.189 (2.927)\tETA 0:00:00\tTraining Loss 1.6742 (1.6796)\n",
      "\n",
      "Epoch: [7][14/16]\tTime 0.196 (3.123)\tETA 0:00:00\tTraining Loss 1.6698 (1.6789)\n",
      "\n",
      "Epoch: [7][15/16]\tTime 0.113 (3.235)\tETA 0:00:00\tTraining Loss 1.6684 (1.6786)\n",
      "_\n",
      "Validation stats                    IoU        F1      Prec    recall       Acc\n",
      "bg,          0.945300  0.971800  0.979800  0.964000  0.951500\n",
      "real apple   0.007900  0.015600  0.296100  0.008000  0.933600\n",
      "real pepper  0.000000  0.000000  0.000000  0.000000  1.000000\n",
      "real grape   0.007400  0.014700  0.093700  0.008000  0.930700\n",
      "fake apple   0.000000  0.000000  0.000000  0.000000  0.929800\n",
      "fake pepper  0.000000  0.000000  0.000000  0.000000  0.997000\n",
      "fake grape   0.000000  0.000000  0.000000  0.000000  0.936000\n",
      "total        0.137229  0.143157  0.195657  0.140000  0.954086\n",
      "total(-bg)   0.002550  0.005050  0.064967  0.002667  0.954517\n",
      "\n",
      "Epoch: [8][0/16]\tTime 0.476 (0.476)\tETA 0:00:07\tTraining Loss 1.6682 (1.6682)\n",
      "\n",
      "Epoch: [8][1/16]\tTime 0.185 (0.661)\tETA 0:00:02\tTraining Loss 1.6799 (1.6741)\n",
      "\n",
      "Epoch: [8][2/16]\tTime 0.192 (0.853)\tETA 0:00:02\tTraining Loss 1.6722 (1.6734)\n",
      "\n",
      "Epoch: [8][3/16]\tTime 0.179 (1.032)\tETA 0:00:02\tTraining Loss 1.6720 (1.6731)\n",
      "\n",
      "Epoch: [8][4/16]\tTime 0.181 (1.213)\tETA 0:00:02\tTraining Loss 1.6662 (1.6717)\n",
      "\n",
      "Epoch: [8][5/16]\tTime 0.187 (1.399)\tETA 0:00:02\tTraining Loss 1.6754 (1.6723)\n",
      "\n",
      "Epoch: [8][6/16]\tTime 0.183 (1.583)\tETA 0:00:01\tTraining Loss 1.6655 (1.6713)\n",
      "\n",
      "Epoch: [8][7/16]\tTime 0.168 (1.750)\tETA 0:00:01\tTraining Loss 1.6851 (1.6731)\n",
      "\n",
      "Epoch: [8][8/16]\tTime 0.192 (1.942)\tETA 0:00:01\tTraining Loss 1.6750 (1.6733)\n",
      "\n",
      "Epoch: [8][9/16]\tTime 0.186 (2.128)\tETA 0:00:01\tTraining Loss 1.6648 (1.6724)\n",
      "\n",
      "Epoch: [8][10/16]\tTime 0.181 (2.309)\tETA 0:00:01\tTraining Loss 1.6692 (1.6721)\n",
      "\n",
      "Epoch: [8][11/16]\tTime 0.192 (2.501)\tETA 0:00:00\tTraining Loss 1.6686 (1.6718)\n",
      "\n",
      "Epoch: [8][12/16]\tTime 0.178 (2.679)\tETA 0:00:00\tTraining Loss 1.6666 (1.6714)\n",
      "\n",
      "Epoch: [8][13/16]\tTime 0.184 (2.863)\tETA 0:00:00\tTraining Loss 1.6684 (1.6712)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: [8][14/16]\tTime 0.184 (3.047)\tETA 0:00:00\tTraining Loss 1.6751 (1.6715)\n",
      "\n",
      "Epoch: [8][15/16]\tTime 0.114 (3.161)\tETA 0:00:00\tTraining Loss 1.6606 (1.6711)\n",
      "_\n",
      "Validation stats                    IoU      F1      Prec    recall       Acc\n",
      "bg,          0.935000  0.9664  0.980800  0.952500  0.942500\n",
      "real apple   0.002800  0.0055  0.193500  0.002800  0.933700\n",
      "real pepper  0.000000  0.0000  0.000000  0.000000  1.000000\n",
      "real grape   0.011200  0.0221  0.072700  0.013100  0.925300\n",
      "fake apple   0.000000  0.0000  0.000000  0.000000  0.942000\n",
      "fake pepper  0.000000  0.0000  0.000000  0.000000  0.996200\n",
      "fake grape   0.000000  0.0000  0.000000  0.000000  0.918800\n",
      "total        0.135571  0.1420  0.178143  0.138343  0.951214\n",
      "total(-bg)   0.002333  0.0046  0.044367  0.002650  0.952667\n",
      "\n",
      "Epoch: [9][0/16]\tTime 0.474 (0.474)\tETA 0:00:07\tTraining Loss 1.6650 (1.6650)\n",
      "\n",
      "Epoch: [9][1/16]\tTime 0.183 (0.657)\tETA 0:00:02\tTraining Loss 1.6644 (1.6647)\n",
      "\n",
      "Epoch: [9][2/16]\tTime 0.183 (0.840)\tETA 0:00:02\tTraining Loss 1.6707 (1.6667)\n",
      "\n",
      "Epoch: [9][3/16]\tTime 0.191 (1.030)\tETA 0:00:02\tTraining Loss 1.6630 (1.6658)\n",
      "\n",
      "Epoch: [9][4/16]\tTime 0.184 (1.214)\tETA 0:00:02\tTraining Loss 1.6637 (1.6654)\n",
      "\n",
      "Epoch: [9][5/16]\tTime 0.181 (1.395)\tETA 0:00:01\tTraining Loss 1.6542 (1.6635)\n",
      "\n",
      "Epoch: [9][6/16]\tTime 0.190 (1.585)\tETA 0:00:01\tTraining Loss 1.6697 (1.6644)\n",
      "\n",
      "Epoch: [9][7/16]\tTime 0.188 (1.773)\tETA 0:00:01\tTraining Loss 1.6700 (1.6651)\n",
      "\n",
      "Epoch: [9][8/16]\tTime 0.182 (1.955)\tETA 0:00:01\tTraining Loss 1.6520 (1.6636)\n",
      "\n",
      "Epoch: [9][9/16]\tTime 0.187 (2.142)\tETA 0:00:01\tTraining Loss 1.6563 (1.6629)\n",
      "\n",
      "Epoch: [9][10/16]\tTime 0.185 (2.327)\tETA 0:00:01\tTraining Loss 1.6651 (1.6631)\n",
      "\n",
      "Epoch: [9][11/16]\tTime 0.191 (2.518)\tETA 0:00:00\tTraining Loss 1.6623 (1.6631)\n",
      "\n",
      "Epoch: [9][12/16]\tTime 0.185 (2.703)\tETA 0:00:00\tTraining Loss 1.6562 (1.6625)\n",
      "\n",
      "Epoch: [9][13/16]\tTime 0.188 (2.891)\tETA 0:00:00\tTraining Loss 1.6648 (1.6627)\n",
      "\n",
      "Epoch: [9][14/16]\tTime 0.194 (3.085)\tETA 0:00:00\tTraining Loss 1.6647 (1.6628)\n",
      "\n",
      "Epoch: [9][15/16]\tTime 0.111 (3.196)\tETA 0:00:00\tTraining Loss 1.6651 (1.6629)\n",
      "_\n",
      "Validation stats                    IoU        F1      Prec    recall       Acc\n",
      "bg,          0.944800  0.971500  0.978300  0.964900  0.950900\n",
      "real apple   0.002300  0.004500  0.109900  0.002300  0.933200\n",
      "real pepper  0.000000  0.000000  0.000000  0.000000  1.000000\n",
      "real grape   0.026900  0.052400  0.378200  0.028200  0.934100\n",
      "fake apple   0.000000  0.000000  0.000000  0.000000  0.930400\n",
      "fake pepper  0.000000  0.000000  0.000000  0.000000  0.996500\n",
      "fake grape   0.000000  0.000000  0.000000  0.000000  0.936900\n",
      "total        0.139143  0.146914  0.209486  0.142200  0.954571\n",
      "total(-bg)   0.004867  0.009483  0.081350  0.005083  0.955183\n",
      "\n",
      "Epoch: [10][0/16]\tTime 0.393 (0.393)\tETA 0:00:06\tTraining Loss 1.6664 (1.6664)\n",
      "\n",
      "Epoch: [10][1/16]\tTime 0.195 (0.588)\tETA 0:00:02\tTraining Loss 1.6662 (1.6663)\n",
      "\n",
      "Epoch: [10][2/16]\tTime 0.172 (0.760)\tETA 0:00:02\tTraining Loss 1.6659 (1.6662)\n",
      "\n",
      "Epoch: [10][3/16]\tTime 0.184 (0.944)\tETA 0:00:02\tTraining Loss 1.6559 (1.6636)\n",
      "\n",
      "Epoch: [10][4/16]\tTime 0.187 (1.131)\tETA 0:00:02\tTraining Loss 1.6529 (1.6615)\n",
      "\n",
      "Epoch: [10][5/16]\tTime 0.186 (1.317)\tETA 0:00:02\tTraining Loss 1.6639 (1.6619)\n",
      "\n",
      "Epoch: [10][6/16]\tTime 0.188 (1.505)\tETA 0:00:01\tTraining Loss 1.6530 (1.6606)\n",
      "\n",
      "Epoch: [10][7/16]\tTime 0.185 (1.690)\tETA 0:00:01\tTraining Loss 1.6487 (1.6591)\n",
      "\n",
      "Epoch: [10][8/16]\tTime 0.182 (1.872)\tETA 0:00:01\tTraining Loss 1.6547 (1.6586)\n",
      "\n",
      "Epoch: [10][9/16]\tTime 0.190 (2.061)\tETA 0:00:01\tTraining Loss 1.6522 (1.6580)\n",
      "\n",
      "Epoch: [10][10/16]\tTime 0.189 (2.251)\tETA 0:00:01\tTraining Loss 1.6589 (1.6581)\n",
      "\n",
      "Epoch: [10][11/16]\tTime 0.188 (2.439)\tETA 0:00:00\tTraining Loss 1.6438 (1.6569)\n",
      "\n",
      "Epoch: [10][12/16]\tTime 0.186 (2.624)\tETA 0:00:00\tTraining Loss 1.6581 (1.6570)\n",
      "\n",
      "Epoch: [10][13/16]\tTime 0.184 (2.809)\tETA 0:00:00\tTraining Loss 1.6555 (1.6569)\n",
      "\n",
      "Epoch: [10][14/16]\tTime 0.185 (2.993)\tETA 0:00:00\tTraining Loss 1.6507 (1.6565)\n",
      "\n",
      "Epoch: [10][15/16]\tTime 0.114 (3.107)\tETA 0:00:00\tTraining Loss 1.6457 (1.6561)\n",
      "_\n",
      "Validation stats                    IoU        F1      Prec    recall       Acc\n",
      "bg,          0.929200  0.963200  0.977500  0.949400  0.937000\n",
      "real apple   0.002000  0.004100  0.090000  0.002100  0.933000\n",
      "real pepper  0.000000  0.000000  0.000000  0.000000  1.000000\n",
      "real grape   0.005100  0.010200  0.033200  0.006000  0.924300\n",
      "fake apple   0.000000  0.000000  0.000000  0.000000  0.933200\n",
      "fake pepper  0.000000  0.000000  0.000000  0.000000  0.995800\n",
      "fake grape   0.000000  0.000000  0.000000  0.000000  0.928700\n",
      "total        0.133757  0.139643  0.157243  0.136786  0.950286\n",
      "total(-bg)   0.001183  0.002383  0.020533  0.001350  0.952500\n",
      "\n",
      "Epoch: [11][0/16]\tTime 0.368 (0.368)\tETA 0:00:05\tTraining Loss 1.6462 (1.6462)\n",
      "\n",
      "Epoch: [11][1/16]\tTime 0.182 (0.550)\tETA 0:00:02\tTraining Loss 1.6475 (1.6469)\n",
      "\n",
      "Epoch: [11][2/16]\tTime 0.179 (0.729)\tETA 0:00:02\tTraining Loss 1.6484 (1.6474)\n",
      "\n",
      "Epoch: [11][3/16]\tTime 0.190 (0.918)\tETA 0:00:02\tTraining Loss 1.6652 (1.6518)\n",
      "\n",
      "Epoch: [11][4/16]\tTime 0.195 (1.113)\tETA 0:00:02\tTraining Loss 1.6489 (1.6512)\n",
      "\n",
      "Epoch: [11][5/16]\tTime 0.186 (1.299)\tETA 0:00:02\tTraining Loss 1.6413 (1.6496)\n",
      "\n",
      "Epoch: [11][6/16]\tTime 0.183 (1.482)\tETA 0:00:01\tTraining Loss 1.6455 (1.6490)\n",
      "\n",
      "Epoch: [11][7/16]\tTime 0.191 (1.673)\tETA 0:00:01\tTraining Loss 1.6484 (1.6489)\n",
      "\n",
      "Epoch: [11][8/16]\tTime 0.180 (1.853)\tETA 0:00:01\tTraining Loss 1.6472 (1.6487)\n",
      "\n",
      "Epoch: [11][9/16]\tTime 0.186 (2.039)\tETA 0:00:01\tTraining Loss 1.6429 (1.6482)\n",
      "\n",
      "Epoch: [11][10/16]\tTime 0.194 (2.234)\tETA 0:00:01\tTraining Loss 1.6392 (1.6473)\n",
      "\n",
      "Epoch: [11][11/16]\tTime 0.188 (2.422)\tETA 0:00:00\tTraining Loss 1.6434 (1.6470)\n",
      "\n",
      "Epoch: [11][12/16]\tTime 0.192 (2.613)\tETA 0:00:00\tTraining Loss 1.6408 (1.6465)\n",
      "\n",
      "Epoch: [11][13/16]\tTime 0.189 (2.803)\tETA 0:00:00\tTraining Loss 1.6524 (1.6470)\n",
      "\n",
      "Epoch: [11][14/16]\tTime 0.191 (2.993)\tETA 0:00:00\tTraining Loss 1.6472 (1.6470)\n",
      "\n",
      "Epoch: [11][15/16]\tTime 0.116 (3.109)\tETA 0:00:00\tTraining Loss 1.6570 (1.6473)\n",
      "_\n",
      "Validation stats                    IoU        F1      Prec    recall       Acc\n",
      "bg,          0.945200  0.971800  0.982600  0.961300  0.951500\n",
      "real apple   0.001100  0.002300  0.090100  0.001200  0.933600\n",
      "real pepper  0.000000  0.000000  0.000000  0.000000  1.000000\n",
      "real grape   0.073700  0.137300  0.435500  0.081500  0.933700\n",
      "fake apple   0.000000  0.000000  0.000000  0.000000  0.927700\n",
      "fake pepper  0.000000  0.000000  0.000000  0.000000  0.995600\n",
      "fake grape   0.000000  0.000000  0.000000  0.000000  0.940400\n",
      "total        0.145714  0.158771  0.215457  0.149143  0.954643\n",
      "total(-bg)   0.012467  0.023267  0.087600  0.013783  0.955167\n",
      "\n",
      "Epoch: [12][0/16]\tTime 0.526 (0.526)\tETA 0:00:08\tTraining Loss 1.6387 (1.6387)\n",
      "\n",
      "Epoch: [12][1/16]\tTime 0.183 (0.709)\tETA 0:00:02\tTraining Loss 1.6375 (1.6381)\n",
      "\n",
      "Epoch: [12][2/16]\tTime 0.184 (0.893)\tETA 0:00:02\tTraining Loss 1.6486 (1.6416)\n",
      "\n",
      "Epoch: [12][3/16]\tTime 0.195 (1.088)\tETA 0:00:02\tTraining Loss 1.6398 (1.6412)\n",
      "\n",
      "Epoch: [12][4/16]\tTime 0.193 (1.280)\tETA 0:00:02\tTraining Loss 1.6385 (1.6406)\n",
      "\n",
      "Epoch: [12][5/16]\tTime 0.188 (1.469)\tETA 0:00:02\tTraining Loss 1.6431 (1.6410)\n",
      "\n",
      "Epoch: [12][6/16]\tTime 0.208 (1.677)\tETA 0:00:02\tTraining Loss 1.6407 (1.6410)\n",
      "\n",
      "Epoch: [12][7/16]\tTime 0.187 (1.864)\tETA 0:00:01\tTraining Loss 1.6432 (1.6413)\n",
      "\n",
      "Epoch: [12][8/16]\tTime 0.194 (2.058)\tETA 0:00:01\tTraining Loss 1.6411 (1.6412)\n",
      "\n",
      "Epoch: [12][9/16]\tTime 0.183 (2.241)\tETA 0:00:01\tTraining Loss 1.6517 (1.6423)\n",
      "\n",
      "Epoch: [12][10/16]\tTime 0.187 (2.428)\tETA 0:00:01\tTraining Loss 1.6379 (1.6419)\n",
      "\n",
      "Epoch: [12][11/16]\tTime 0.182 (2.611)\tETA 0:00:00\tTraining Loss 1.6305 (1.6409)\n",
      "\n",
      "Epoch: [12][12/16]\tTime 0.188 (2.798)\tETA 0:00:00\tTraining Loss 1.6303 (1.6401)\n",
      "\n",
      "Epoch: [12][13/16]\tTime 0.182 (2.981)\tETA 0:00:00\tTraining Loss 1.6271 (1.6392)\n",
      "\n",
      "Epoch: [12][14/16]\tTime 0.186 (3.167)\tETA 0:00:00\tTraining Loss 1.6380 (1.6391)\n",
      "\n",
      "Epoch: [12][15/16]\tTime 0.112 (3.279)\tETA 0:00:00\tTraining Loss 1.6588 (1.6397)\n",
      "_\n",
      "Validation stats                    IoU        F1      Prec    recall       Acc\n",
      "bg,          0.934600  0.966200  0.979800  0.953000  0.942000\n",
      "real apple   0.002700  0.005500  0.150900  0.002800  0.933400\n",
      "real pepper  0.000000  0.000000  0.000000  0.000000  1.000000\n",
      "real grape   0.048700  0.092900  0.294900  0.055100  0.930300\n",
      "fake apple   0.000000  0.000000  0.000000  0.000000  0.932600\n",
      "fake pepper  0.000000  0.000000  0.000000  0.000000  0.997600\n",
      "fake grape   0.000000  0.000000  0.000000  0.000000  0.928900\n",
      "total        0.140857  0.152086  0.203657  0.144414  0.952114\n",
      "total(-bg)   0.008567  0.016400  0.074300  0.009650  0.953800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: [13][0/16]\tTime 0.415 (0.415)\tETA 0:00:06\tTraining Loss 1.6396 (1.6396)\n",
      "\n",
      "Epoch: [13][1/16]\tTime 0.194 (0.608)\tETA 0:00:02\tTraining Loss 1.6279 (1.6338)\n",
      "\n",
      "Epoch: [13][2/16]\tTime 0.189 (0.798)\tETA 0:00:02\tTraining Loss 1.6433 (1.6370)\n",
      "\n",
      "Epoch: [13][3/16]\tTime 0.196 (0.994)\tETA 0:00:02\tTraining Loss 1.6292 (1.6350)\n",
      "\n",
      "Epoch: [13][4/16]\tTime 0.191 (1.184)\tETA 0:00:02\tTraining Loss 1.6313 (1.6343)\n",
      "\n",
      "Epoch: [13][5/16]\tTime 0.192 (1.376)\tETA 0:00:02\tTraining Loss 1.6289 (1.6334)\n",
      "\n",
      "Epoch: [13][6/16]\tTime 0.189 (1.565)\tETA 0:00:01\tTraining Loss 1.6433 (1.6348)\n",
      "\n",
      "Epoch: [13][7/16]\tTime 0.188 (1.753)\tETA 0:00:01\tTraining Loss 1.6360 (1.6350)\n",
      "\n",
      "Epoch: [13][8/16]\tTime 0.192 (1.945)\tETA 0:00:01\tTraining Loss 1.6260 (1.6340)\n",
      "\n",
      "Epoch: [13][9/16]\tTime 0.199 (2.143)\tETA 0:00:01\tTraining Loss 1.6223 (1.6328)\n",
      "\n",
      "Epoch: [13][10/16]\tTime 0.197 (2.340)\tETA 0:00:01\tTraining Loss 1.6302 (1.6326)\n",
      "\n",
      "Epoch: [13][11/16]\tTime 0.195 (2.536)\tETA 0:00:00\tTraining Loss 1.6313 (1.6325)\n",
      "\n",
      "Epoch: [13][12/16]\tTime 0.196 (2.731)\tETA 0:00:00\tTraining Loss 1.6325 (1.6325)\n",
      "\n",
      "Epoch: [13][13/16]\tTime 0.183 (2.914)\tETA 0:00:00\tTraining Loss 1.6516 (1.6338)\n",
      "\n",
      "Epoch: [13][14/16]\tTime 0.191 (3.105)\tETA 0:00:00\tTraining Loss 1.6302 (1.6336)\n",
      "\n",
      "Epoch: [13][15/16]\tTime 0.112 (3.217)\tETA 0:00:00\tTraining Loss 1.6334 (1.6336)\n",
      "_\n",
      "Validation stats                    IoU        F1      Prec    recall       Acc\n",
      "bg,          0.939200  0.968600  0.979800  0.957800  0.946100\n",
      "real apple   0.000800  0.001600  0.095900  0.000800  0.933800\n",
      "real pepper  0.000000  0.000000  0.000000  0.000000  1.000000\n",
      "real grape   0.187400  0.315600  0.661500  0.207300  0.941800\n",
      "fake apple   0.000000  0.000000  0.000000  0.000000  0.937300\n",
      "fake pepper  0.000000  0.000000  0.000000  0.000000  0.990400\n",
      "fake grape   0.000000  0.000000  0.000000  0.000000  0.943000\n",
      "total        0.161057  0.183686  0.248171  0.166557  0.956057\n",
      "total(-bg)   0.031367  0.052867  0.126233  0.034683  0.957717\n",
      "\n",
      "Epoch: [14][0/16]\tTime 0.410 (0.410)\tETA 0:00:06\tTraining Loss 1.6217 (1.6217)\n",
      "\n",
      "Epoch: [14][1/16]\tTime 0.193 (0.603)\tETA 0:00:02\tTraining Loss 1.6211 (1.6214)\n",
      "\n",
      "Epoch: [14][2/16]\tTime 0.186 (0.789)\tETA 0:00:02\tTraining Loss 1.6377 (1.6269)\n",
      "\n",
      "Epoch: [14][3/16]\tTime 0.187 (0.976)\tETA 0:00:02\tTraining Loss 1.6397 (1.6301)\n",
      "\n",
      "Epoch: [14][4/16]\tTime 0.187 (1.162)\tETA 0:00:02\tTraining Loss 1.6382 (1.6317)\n",
      "\n",
      "Epoch: [14][5/16]\tTime 0.190 (1.352)\tETA 0:00:02\tTraining Loss 1.6364 (1.6325)\n",
      "\n",
      "Epoch: [14][6/16]\tTime 0.190 (1.542)\tETA 0:00:01\tTraining Loss 1.6411 (1.6337)\n",
      "\n",
      "Epoch: [14][7/16]\tTime 0.197 (1.739)\tETA 0:00:01\tTraining Loss 1.6280 (1.6330)\n",
      "\n",
      "Epoch: [14][8/16]\tTime 0.194 (1.933)\tETA 0:00:01\tTraining Loss 1.6320 (1.6329)\n",
      "\n",
      "Epoch: [14][9/16]\tTime 0.189 (2.123)\tETA 0:00:01\tTraining Loss 1.6224 (1.6318)\n",
      "\n",
      "Epoch: [14][10/16]\tTime 0.189 (2.312)\tETA 0:00:01\tTraining Loss 1.6203 (1.6308)\n",
      "\n",
      "Epoch: [14][11/16]\tTime 0.211 (2.523)\tETA 0:00:01\tTraining Loss 1.6257 (1.6304)\n",
      "\n",
      "Epoch: [14][12/16]\tTime 0.183 (2.706)\tETA 0:00:00\tTraining Loss 1.6213 (1.6297)\n",
      "\n",
      "Epoch: [14][13/16]\tTime 0.184 (2.890)\tETA 0:00:00\tTraining Loss 1.6219 (1.6291)\n",
      "\n",
      "Epoch: [14][14/16]\tTime 0.197 (3.087)\tETA 0:00:00\tTraining Loss 1.6277 (1.6290)\n",
      "\n",
      "Epoch: [14][15/16]\tTime 0.114 (3.201)\tETA 0:00:00\tTraining Loss 1.6318 (1.6291)\n",
      "_\n",
      "Validation stats                    IoU        F1      Prec    recall      Acc\n",
      "bg,          0.937800  0.967800  0.981600  0.954500  0.94490\n",
      "real apple   0.000900  0.001800  0.057600  0.000900  0.93330\n",
      "real pepper  0.000000  0.000000  0.000000  0.000000  1.00000\n",
      "real grape   0.076400  0.142000  0.455400  0.084100  0.93420\n",
      "fake apple   0.000000  0.000000  0.000000  0.000000  0.91930\n",
      "fake pepper  0.000000  0.000000  0.000000  0.000000  0.99160\n",
      "fake grape   0.000000  0.000000  0.000000  0.000000  0.94770\n",
      "total        0.145014  0.158800  0.213514  0.148500  0.95300\n",
      "total(-bg)   0.012883  0.023967  0.085500  0.014167  0.95435\n",
      "\n",
      "Epoch: [15][0/16]\tTime 0.410 (0.410)\tETA 0:00:06\tTraining Loss 1.6288 (1.6288)\n",
      "\n",
      "Epoch: [15][1/16]\tTime 0.190 (0.600)\tETA 0:00:02\tTraining Loss 1.6181 (1.6234)\n",
      "\n",
      "Epoch: [15][2/16]\tTime 0.188 (0.787)\tETA 0:00:02\tTraining Loss 1.6137 (1.6202)\n",
      "\n",
      "Epoch: [15][3/16]\tTime 0.191 (0.978)\tETA 0:00:02\tTraining Loss 1.6262 (1.6217)\n",
      "\n",
      "Epoch: [15][4/16]\tTime 0.186 (1.164)\tETA 0:00:02\tTraining Loss 1.6113 (1.6196)\n",
      "\n",
      "Epoch: [15][5/16]\tTime 0.197 (1.361)\tETA 0:00:02\tTraining Loss 1.6313 (1.6216)\n",
      "\n",
      "Epoch: [15][6/16]\tTime 0.193 (1.553)\tETA 0:00:01\tTraining Loss 1.6252 (1.6221)\n",
      "\n",
      "Epoch: [15][7/16]\tTime 0.195 (1.748)\tETA 0:00:01\tTraining Loss 1.6143 (1.6211)\n",
      "\n",
      "Epoch: [15][8/16]\tTime 0.192 (1.940)\tETA 0:00:01\tTraining Loss 1.6093 (1.6198)\n",
      "\n",
      "Epoch: [15][9/16]\tTime 0.195 (2.135)\tETA 0:00:01\tTraining Loss 1.6213 (1.6199)\n",
      "\n",
      "Epoch: [15][10/16]\tTime 0.192 (2.327)\tETA 0:00:01\tTraining Loss 1.6202 (1.6200)\n",
      "\n",
      "Epoch: [15][11/16]\tTime 0.189 (2.517)\tETA 0:00:00\tTraining Loss 1.6138 (1.6195)\n",
      "\n",
      "Epoch: [15][12/16]\tTime 0.212 (2.729)\tETA 0:00:00\tTraining Loss 1.6160 (1.6192)\n",
      "\n",
      "Epoch: [15][13/16]\tTime 0.192 (2.921)\tETA 0:00:00\tTraining Loss 1.6178 (1.6191)\n",
      "\n",
      "Epoch: [15][14/16]\tTime 0.187 (3.108)\tETA 0:00:00\tTraining Loss 1.6182 (1.6190)\n",
      "\n",
      "Epoch: [15][15/16]\tTime 0.112 (3.220)\tETA 0:00:00\tTraining Loss 1.6336 (1.6195)\n",
      "_\n",
      "Validation stats                    IoU        F1      Prec    recall       Acc\n",
      "bg,          0.936300  0.967100  0.977200  0.957300  0.943400\n",
      "real apple   0.001400  0.002800  0.142900  0.001400  0.933800\n",
      "real pepper  0.000000  0.000000  0.000000  0.000000  1.000000\n",
      "real grape   0.228700  0.372200  0.710700  0.252200  0.944900\n",
      "fake apple   0.000000  0.000000  0.000000  0.000000  0.934900\n",
      "fake pepper  0.000000  0.000000  0.000000  0.000000  0.990400\n",
      "fake grape   0.000000  0.000000  0.000000  0.000000  0.950100\n",
      "total        0.166629  0.191729  0.261543  0.172986  0.956786\n",
      "total(-bg)   0.038350  0.062500  0.142267  0.042267  0.959017\n",
      "\n",
      "Epoch: [16][0/16]\tTime 0.481 (0.481)\tETA 0:00:07\tTraining Loss 1.6158 (1.6158)\n",
      "\n",
      "Epoch: [16][1/16]\tTime 0.184 (0.666)\tETA 0:00:02\tTraining Loss 1.6186 (1.6172)\n",
      "\n",
      "Epoch: [16][2/16]\tTime 0.184 (0.850)\tETA 0:00:02\tTraining Loss 1.6300 (1.6215)\n",
      "\n",
      "Epoch: [16][3/16]\tTime 0.188 (1.037)\tETA 0:00:02\tTraining Loss 1.6102 (1.6186)\n",
      "\n",
      "Epoch: [16][4/16]\tTime 0.183 (1.221)\tETA 0:00:02\tTraining Loss 1.6148 (1.6179)\n",
      "\n",
      "Epoch: [16][5/16]\tTime 0.185 (1.406)\tETA 0:00:02\tTraining Loss 1.6118 (1.6169)\n",
      "\n",
      "Epoch: [16][6/16]\tTime 0.187 (1.593)\tETA 0:00:01\tTraining Loss 1.6139 (1.6164)\n",
      "\n",
      "Epoch: [16][7/16]\tTime 0.189 (1.781)\tETA 0:00:01\tTraining Loss 1.6171 (1.6165)\n",
      "\n",
      "Epoch: [16][8/16]\tTime 0.183 (1.964)\tETA 0:00:01\tTraining Loss 1.6107 (1.6159)\n",
      "\n",
      "Epoch: [16][9/16]\tTime 0.184 (2.148)\tETA 0:00:01\tTraining Loss 1.6061 (1.6149)\n",
      "\n",
      "Epoch: [16][10/16]\tTime 0.188 (2.336)\tETA 0:00:01\tTraining Loss 1.6067 (1.6142)\n",
      "\n",
      "Epoch: [16][11/16]\tTime 0.189 (2.525)\tETA 0:00:00\tTraining Loss 1.6109 (1.6139)\n",
      "\n",
      "Epoch: [16][12/16]\tTime 0.189 (2.715)\tETA 0:00:00\tTraining Loss 1.6211 (1.6144)\n",
      "\n",
      "Epoch: [16][13/16]\tTime 0.190 (2.905)\tETA 0:00:00\tTraining Loss 1.6133 (1.6144)\n",
      "\n",
      "Epoch: [16][14/16]\tTime 0.187 (3.092)\tETA 0:00:00\tTraining Loss 1.6079 (1.6139)\n",
      "\n",
      "Epoch: [16][15/16]\tTime 0.113 (3.205)\tETA 0:00:00\tTraining Loss 1.6034 (1.6136)\n",
      "_\n",
      "Validation stats                    IoU        F1      Prec    recall       Acc\n",
      "bg,          0.944300  0.971300  0.979500  0.963400  0.950600\n",
      "real apple   0.000000  0.000000  0.000000  0.000000  0.933600\n",
      "real pepper  0.000000  0.000000  0.000000  0.000000  1.000000\n",
      "real grape   0.095200  0.173900  0.548500  0.103300  0.936400\n",
      "fake apple   0.000000  0.000000  0.000000  0.000000  0.936200\n",
      "fake pepper  0.000000  0.000000  0.000000  0.000000  0.988900\n",
      "fake grape   0.000000  0.000000  0.000000  0.000000  0.943100\n",
      "total        0.148500  0.163600  0.218286  0.152386  0.955543\n",
      "total(-bg)   0.015867  0.028983  0.091417  0.017217  0.956367\n",
      "\n",
      "Epoch: [17][0/16]\tTime 0.428 (0.428)\tETA 0:00:06\tTraining Loss 1.6030 (1.6030)\n",
      "\n",
      "Epoch: [17][1/16]\tTime 0.184 (0.612)\tETA 0:00:02\tTraining Loss 1.6188 (1.6109)\n",
      "\n",
      "Epoch: [17][2/16]\tTime 0.186 (0.798)\tETA 0:00:02\tTraining Loss 1.6043 (1.6087)\n",
      "\n",
      "Epoch: [17][3/16]\tTime 0.185 (0.983)\tETA 0:00:02\tTraining Loss 1.6155 (1.6104)\n",
      "\n",
      "Epoch: [17][4/16]\tTime 0.184 (1.168)\tETA 0:00:02\tTraining Loss 1.6069 (1.6097)\n",
      "\n",
      "Epoch: [17][5/16]\tTime 0.188 (1.356)\tETA 0:00:02\tTraining Loss 1.5987 (1.6079)\n",
      "\n",
      "Epoch: [17][6/16]\tTime 0.189 (1.545)\tETA 0:00:01\tTraining Loss 1.6061 (1.6076)\n",
      "\n",
      "Epoch: [17][7/16]\tTime 0.187 (1.731)\tETA 0:00:01\tTraining Loss 1.6047 (1.6073)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: [17][8/16]\tTime 0.189 (1.920)\tETA 0:00:01\tTraining Loss 1.6056 (1.6071)\n",
      "\n",
      "Epoch: [17][9/16]\tTime 0.194 (2.114)\tETA 0:00:01\tTraining Loss 1.6180 (1.6082)\n",
      "\n",
      "Epoch: [17][10/16]\tTime 0.194 (2.308)\tETA 0:00:01\tTraining Loss 1.6091 (1.6083)\n",
      "\n",
      "Epoch: [17][11/16]\tTime 0.185 (2.493)\tETA 0:00:00\tTraining Loss 1.5900 (1.6067)\n",
      "\n",
      "Epoch: [17][12/16]\tTime 0.194 (2.687)\tETA 0:00:00\tTraining Loss 1.6026 (1.6064)\n",
      "\n",
      "Epoch: [17][13/16]\tTime 0.186 (2.873)\tETA 0:00:00\tTraining Loss 1.6028 (1.6062)\n",
      "\n",
      "Epoch: [17][14/16]\tTime 0.186 (3.059)\tETA 0:00:00\tTraining Loss 1.5993 (1.6057)\n",
      "\n",
      "Epoch: [17][15/16]\tTime 0.111 (3.170)\tETA 0:00:00\tTraining Loss 1.5930 (1.6053)\n",
      "_\n",
      "Validation stats                    IoU        F1      Prec    recall       Acc\n",
      "bg,          0.940800  0.969500  0.981200  0.958100  0.947600\n",
      "real apple   0.000500  0.000900  0.055600  0.000500  0.933800\n",
      "real pepper  0.000000  0.000000  0.000000  0.000000  1.000000\n",
      "real grape   0.061700  0.116300  0.402100  0.068000  0.933100\n",
      "fake apple   0.000000  0.000000  0.000000  0.000000  0.938100\n",
      "fake pepper  0.000000  0.000000  0.000000  0.000000  0.990100\n",
      "fake grape   0.000000  0.000000  0.000000  0.000000  0.932300\n",
      "total        0.143286  0.155243  0.205557  0.146657  0.953571\n",
      "total(-bg)   0.010367  0.019533  0.076283  0.011417  0.954567\n",
      "\n",
      "Epoch: [18][0/16]\tTime 0.483 (0.483)\tETA 0:00:07\tTraining Loss 1.6106 (1.6106)\n",
      "\n",
      "Epoch: [18][1/16]\tTime 0.200 (0.683)\tETA 0:00:03\tTraining Loss 1.6026 (1.6066)\n",
      "\n",
      "Epoch: [18][2/16]\tTime 0.170 (0.853)\tETA 0:00:02\tTraining Loss 1.6071 (1.6068)\n",
      "\n",
      "Epoch: [18][3/16]\tTime 0.180 (1.033)\tETA 0:00:02\tTraining Loss 1.6036 (1.6060)\n",
      "\n",
      "Epoch: [18][4/16]\tTime 0.183 (1.216)\tETA 0:00:02\tTraining Loss 1.5927 (1.6033)\n",
      "\n",
      "Epoch: [18][5/16]\tTime 0.181 (1.397)\tETA 0:00:01\tTraining Loss 1.5892 (1.6010)\n",
      "\n",
      "Epoch: [18][6/16]\tTime 0.186 (1.583)\tETA 0:00:01\tTraining Loss 1.5955 (1.6002)\n",
      "\n",
      "Epoch: [18][7/16]\tTime 0.192 (1.775)\tETA 0:00:01\tTraining Loss 1.6003 (1.6002)\n",
      "\n",
      "Epoch: [18][8/16]\tTime 0.181 (1.956)\tETA 0:00:01\tTraining Loss 1.6013 (1.6003)\n",
      "\n",
      "Epoch: [18][9/16]\tTime 0.186 (2.141)\tETA 0:00:01\tTraining Loss 1.5924 (1.5995)\n",
      "\n",
      "Epoch: [18][10/16]\tTime 0.184 (2.326)\tETA 0:00:01\tTraining Loss 1.6027 (1.5998)\n",
      "\n",
      "Epoch: [18][11/16]\tTime 0.190 (2.516)\tETA 0:00:00\tTraining Loss 1.5908 (1.5991)\n",
      "\n",
      "Epoch: [18][12/16]\tTime 0.178 (2.694)\tETA 0:00:00\tTraining Loss 1.5884 (1.5983)\n",
      "\n",
      "Epoch: [18][13/16]\tTime 0.172 (2.866)\tETA 0:00:00\tTraining Loss 1.5900 (1.5977)\n",
      "\n",
      "Epoch: [18][14/16]\tTime 0.194 (3.060)\tETA 0:00:00\tTraining Loss 1.5911 (1.5972)\n",
      "\n",
      "Epoch: [18][15/16]\tTime 0.117 (3.177)\tETA 0:00:00\tTraining Loss 1.6072 (1.5976)\n",
      "_\n",
      "Validation stats                    IoU        F1      Prec    recall       Acc\n",
      "bg,          0.941500  0.969800  0.980500  0.959500  0.948200\n",
      "real apple   0.000300  0.000700  0.039500  0.000300  0.933700\n",
      "real pepper  0.000000  0.000000  0.000000  0.000000  1.000000\n",
      "real grape   0.227000  0.369900  0.779800  0.242500  0.946500\n",
      "fake apple   0.000000  0.000000  0.000000  0.000000  0.932900\n",
      "fake pepper  0.000000  0.000000  0.000000  0.000000  0.982800\n",
      "fake grape   0.000000  0.000000  0.000000  0.000000  0.955900\n",
      "total        0.166971  0.191486  0.257114  0.171757  0.957143\n",
      "total(-bg)   0.037883  0.061767  0.136550  0.040467  0.958633\n",
      "\n",
      "Epoch: [19][0/16]\tTime 0.370 (0.370)\tETA 0:00:05\tTraining Loss 1.5887 (1.5887)\n",
      "\n",
      "Epoch: [19][1/16]\tTime 0.176 (0.545)\tETA 0:00:02\tTraining Loss 1.6009 (1.5948)\n",
      "\n",
      "Epoch: [19][2/16]\tTime 0.188 (0.733)\tETA 0:00:02\tTraining Loss 1.5865 (1.5920)\n",
      "\n",
      "Epoch: [19][3/16]\tTime 0.188 (0.921)\tETA 0:00:02\tTraining Loss 1.5967 (1.5932)\n",
      "\n",
      "Epoch: [19][4/16]\tTime 0.179 (1.100)\tETA 0:00:02\tTraining Loss 1.5831 (1.5912)\n",
      "\n",
      "Epoch: [19][5/16]\tTime 0.185 (1.285)\tETA 0:00:02\tTraining Loss 1.6084 (1.5940)\n",
      "\n",
      "Epoch: [19][6/16]\tTime 0.176 (1.461)\tETA 0:00:01\tTraining Loss 1.5909 (1.5936)\n",
      "\n",
      "Epoch: [19][7/16]\tTime 0.188 (1.649)\tETA 0:00:01\tTraining Loss 1.5863 (1.5927)\n",
      "\n",
      "Epoch: [19][8/16]\tTime 0.188 (1.836)\tETA 0:00:01\tTraining Loss 1.5931 (1.5927)\n",
      "\n",
      "Epoch: [19][9/16]\tTime 0.188 (2.024)\tETA 0:00:01\tTraining Loss 1.5869 (1.5921)\n",
      "\n",
      "Epoch: [19][10/16]\tTime 0.184 (2.208)\tETA 0:00:01\tTraining Loss 1.5888 (1.5918)\n",
      "\n",
      "Epoch: [19][11/16]\tTime 0.193 (2.401)\tETA 0:00:00\tTraining Loss 1.5859 (1.5913)\n",
      "\n",
      "Epoch: [19][12/16]\tTime 0.191 (2.592)\tETA 0:00:00\tTraining Loss 1.5849 (1.5908)\n",
      "\n",
      "Epoch: [19][13/16]\tTime 0.185 (2.777)\tETA 0:00:00\tTraining Loss 1.5879 (1.5906)\n",
      "\n",
      "Epoch: [19][14/16]\tTime 0.181 (2.958)\tETA 0:00:00\tTraining Loss 1.5921 (1.5907)\n",
      "\n",
      "Epoch: [19][15/16]\tTime 0.111 (3.069)\tETA 0:00:00\tTraining Loss 1.6033 (1.5911)\n",
      "_\n",
      "Validation stats                   IoU        F1     Prec    recall       Acc\n",
      "bg,          0.94320  0.970700  0.97870  0.963000  0.949600\n",
      "real apple   0.00120  0.002300  0.14710  0.001200  0.933900\n",
      "real pepper  0.00000  0.000000  0.00000  0.000000  1.000000\n",
      "real grape   0.31350  0.477300  0.80060  0.340000  0.951800\n",
      "fake apple   0.00000  0.000000  0.00000  0.000000  0.934400\n",
      "fake pepper  0.00000  0.000000  0.00000  0.000000  0.981000\n",
      "fake grape   0.00000  0.000000  0.00000  0.000000  0.968300\n",
      "total        0.17970  0.207186  0.27520  0.186314  0.959857\n",
      "total(-bg)   0.05245  0.079933  0.15795  0.056867  0.961567\n",
      "\n",
      "Epoch: [20][0/16]\tTime 0.489 (0.489)\tETA 0:00:07\tTraining Loss 1.5844 (1.5844)\n",
      "\n",
      "Epoch: [20][1/16]\tTime 0.183 (0.672)\tETA 0:00:02\tTraining Loss 1.5863 (1.5853)\n",
      "\n",
      "Epoch: [20][2/16]\tTime 0.186 (0.858)\tETA 0:00:02\tTraining Loss 1.5864 (1.5857)\n",
      "\n",
      "Epoch: [20][3/16]\tTime 0.191 (1.049)\tETA 0:00:02\tTraining Loss 1.5846 (1.5854)\n",
      "\n",
      "Epoch: [20][4/16]\tTime 0.183 (1.232)\tETA 0:00:02\tTraining Loss 1.5886 (1.5861)\n",
      "\n",
      "Epoch: [20][5/16]\tTime 0.183 (1.415)\tETA 0:00:02\tTraining Loss 1.5878 (1.5863)\n",
      "\n",
      "Epoch: [20][6/16]\tTime 0.191 (1.606)\tETA 0:00:01\tTraining Loss 1.6013 (1.5885)\n",
      "\n",
      "Epoch: [20][7/16]\tTime 0.187 (1.793)\tETA 0:00:01\tTraining Loss 1.5817 (1.5876)\n",
      "\n",
      "Epoch: [20][8/16]\tTime 0.190 (1.983)\tETA 0:00:01\tTraining Loss 1.5891 (1.5878)\n",
      "\n",
      "Epoch: [20][9/16]\tTime 0.178 (2.161)\tETA 0:00:01\tTraining Loss 1.5845 (1.5875)\n",
      "\n",
      "Epoch: [20][10/16]\tTime 0.187 (2.348)\tETA 0:00:01\tTraining Loss 1.5868 (1.5874)\n",
      "\n",
      "Epoch: [20][11/16]\tTime 0.182 (2.531)\tETA 0:00:00\tTraining Loss 1.5873 (1.5874)\n",
      "\n",
      "Epoch: [20][12/16]\tTime 0.187 (2.717)\tETA 0:00:00\tTraining Loss 1.5732 (1.5863)\n",
      "\n",
      "Epoch: [20][13/16]\tTime 0.186 (2.904)\tETA 0:00:00\tTraining Loss 1.5732 (1.5854)\n",
      "\n",
      "Epoch: [20][14/16]\tTime 0.191 (3.094)\tETA 0:00:00\tTraining Loss 1.5748 (1.5847)\n",
      "\n",
      "Epoch: [20][15/16]\tTime 0.114 (3.209)\tETA 0:00:00\tTraining Loss 1.5848 (1.5847)\n",
      "_\n",
      "Validation stats                    IoU        F1      Prec    recall       Acc\n",
      "bg,          0.943800  0.971000  0.980000  0.962300  0.950200\n",
      "real apple   0.000300  0.000700  0.056600  0.000300  0.933900\n",
      "real pepper  0.000000  0.000000  0.000000  0.000000  1.000000\n",
      "real grape   0.041500  0.079800  0.330800  0.045400  0.932200\n",
      "fake apple   0.000000  0.000000  0.000000  0.000000  0.928200\n",
      "fake pepper  0.000000  0.000000  0.000000  0.000000  0.987100\n",
      "fake grape   0.000000  0.000000  0.000000  0.000000  0.947800\n",
      "total        0.140800  0.150214  0.195343  0.144000  0.954200\n",
      "total(-bg)   0.006967  0.013417  0.064567  0.007617  0.954867\n",
      "\n",
      "Epoch: [21][0/16]\tTime 0.497 (0.497)\tETA 0:00:07\tTraining Loss 1.5798 (1.5798)\n",
      "\n",
      "Epoch: [21][1/16]\tTime 0.174 (0.671)\tETA 0:00:02\tTraining Loss 1.5843 (1.5820)\n",
      "\n",
      "Epoch: [21][2/16]\tTime 0.184 (0.855)\tETA 0:00:02\tTraining Loss 1.5841 (1.5827)\n",
      "\n",
      "Epoch: [21][3/16]\tTime 0.180 (1.035)\tETA 0:00:02\tTraining Loss 1.5810 (1.5823)\n",
      "\n",
      "Epoch: [21][4/16]\tTime 0.177 (1.212)\tETA 0:00:02\tTraining Loss 1.5754 (1.5809)\n",
      "\n",
      "Epoch: [21][5/16]\tTime 0.192 (1.404)\tETA 0:00:02\tTraining Loss 1.5817 (1.5811)\n",
      "\n",
      "Epoch: [21][6/16]\tTime 0.194 (1.598)\tETA 0:00:01\tTraining Loss 1.5783 (1.5807)\n",
      "\n",
      "Epoch: [21][7/16]\tTime 0.176 (1.774)\tETA 0:00:01\tTraining Loss 1.5770 (1.5802)\n",
      "\n",
      "Epoch: [21][8/16]\tTime 0.186 (1.961)\tETA 0:00:01\tTraining Loss 1.5798 (1.5802)\n",
      "\n",
      "Epoch: [21][9/16]\tTime 0.181 (2.141)\tETA 0:00:01\tTraining Loss 1.5840 (1.5806)\n",
      "\n",
      "Epoch: [21][10/16]\tTime 0.187 (2.329)\tETA 0:00:01\tTraining Loss 1.5829 (1.5808)\n",
      "\n",
      "Epoch: [21][11/16]\tTime 0.206 (2.535)\tETA 0:00:01\tTraining Loss 1.5725 (1.5801)\n",
      "\n",
      "Epoch: [21][12/16]\tTime 0.178 (2.713)\tETA 0:00:00\tTraining Loss 1.5715 (1.5794)\n",
      "\n",
      "Epoch: [21][13/16]\tTime 0.188 (2.900)\tETA 0:00:00\tTraining Loss 1.5774 (1.5793)\n",
      "\n",
      "Epoch: [21][14/16]\tTime 0.176 (3.076)\tETA 0:00:00\tTraining Loss 1.5714 (1.5787)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: [21][15/16]\tTime 0.114 (3.190)\tETA 0:00:00\tTraining Loss 1.5837 (1.5789)\n",
      "_\n",
      "Validation stats                    IoU        F1      Prec    recall       Acc\n",
      "bg,          0.944000  0.971200  0.980500  0.962100  0.950400\n",
      "real apple   0.000000  0.000000  0.000000  0.000000  0.933700\n",
      "real pepper  0.000000  0.000000  0.000000  0.000000  1.000000\n",
      "real grape   0.192400  0.322600  0.707100  0.209000  0.943200\n",
      "fake apple   0.000000  0.000000  0.000000  0.000000  0.943300\n",
      "fake pepper  0.000000  0.000000  0.000000  0.000000  0.983300\n",
      "fake grape   0.000000  0.000000  0.000000  0.000000  0.946300\n",
      "total        0.162343  0.184829  0.241086  0.167300  0.957171\n",
      "total(-bg)   0.032067  0.053767  0.117850  0.034833  0.958300\n",
      "\n",
      "Epoch: [22][0/16]\tTime 0.473 (0.473)\tETA 0:00:07\tTraining Loss 1.5712 (1.5712)\n",
      "\n",
      "Epoch: [22][1/16]\tTime 0.195 (0.668)\tETA 0:00:02\tTraining Loss 1.5695 (1.5704)\n",
      "\n",
      "Epoch: [22][2/16]\tTime 0.184 (0.853)\tETA 0:00:02\tTraining Loss 1.5699 (1.5702)\n",
      "\n",
      "Epoch: [22][3/16]\tTime 0.192 (1.045)\tETA 0:00:02\tTraining Loss 1.5814 (1.5730)\n",
      "\n",
      "Epoch: [22][4/16]\tTime 0.193 (1.238)\tETA 0:00:02\tTraining Loss 1.5654 (1.5715)\n",
      "\n",
      "Epoch: [22][5/16]\tTime 0.194 (1.431)\tETA 0:00:02\tTraining Loss 1.5627 (1.5700)\n",
      "\n",
      "Epoch: [22][6/16]\tTime 0.198 (1.629)\tETA 0:00:01\tTraining Loss 1.5672 (1.5696)\n",
      "\n",
      "Epoch: [22][7/16]\tTime 0.188 (1.818)\tETA 0:00:01\tTraining Loss 1.5724 (1.5700)\n",
      "\n",
      "Epoch: [22][8/16]\tTime 0.186 (2.004)\tETA 0:00:01\tTraining Loss 1.5713 (1.5701)\n",
      "\n",
      "Epoch: [22][9/16]\tTime 0.200 (2.204)\tETA 0:00:01\tTraining Loss 1.5671 (1.5698)\n",
      "\n",
      "Epoch: [22][10/16]\tTime 0.192 (2.396)\tETA 0:00:01\tTraining Loss 1.5709 (1.5699)\n",
      "\n",
      "Epoch: [22][11/16]\tTime 0.200 (2.596)\tETA 0:00:01\tTraining Loss 1.5615 (1.5692)\n",
      "\n",
      "Epoch: [22][12/16]\tTime 0.188 (2.784)\tETA 0:00:00\tTraining Loss 1.5752 (1.5697)\n",
      "\n",
      "Epoch: [22][13/16]\tTime 0.196 (2.980)\tETA 0:00:00\tTraining Loss 1.5705 (1.5697)\n",
      "\n",
      "Epoch: [22][14/16]\tTime 0.189 (3.169)\tETA 0:00:00\tTraining Loss 1.5769 (1.5702)\n",
      "\n",
      "Epoch: [22][15/16]\tTime 0.115 (3.284)\tETA 0:00:00\tTraining Loss 1.5777 (1.5705)\n",
      "_\n",
      "Validation stats                    IoU        F1      Prec    recall       Acc\n",
      "bg,          0.944900  0.971600  0.979300  0.964100  0.951100\n",
      "real apple   0.000300  0.000700  0.120000  0.000300  0.934100\n",
      "real pepper  0.000000  0.000000  0.000000  0.000000  1.000000\n",
      "real grape   0.018800  0.037000  0.198600  0.020400  0.931200\n",
      "fake apple   0.000000  0.000000  0.000000  0.000000  0.947400\n",
      "fake pepper  0.000000  0.000000  0.000000  0.000000  0.974000\n",
      "fake grape   0.000000  0.000000  0.000000  0.000000  0.941500\n",
      "total        0.137714  0.144186  0.185414  0.140686  0.954186\n",
      "total(-bg)   0.003183  0.006283  0.053100  0.003450  0.954700\n",
      "\n",
      "Epoch: [23][0/16]\tTime 0.398 (0.398)\tETA 0:00:06\tTraining Loss 1.5708 (1.5708)\n",
      "\n",
      "Epoch: [23][1/16]\tTime 0.190 (0.587)\tETA 0:00:02\tTraining Loss 1.5618 (1.5663)\n",
      "\n",
      "Epoch: [23][2/16]\tTime 0.193 (0.780)\tETA 0:00:02\tTraining Loss 1.5711 (1.5679)\n",
      "\n",
      "Epoch: [23][3/16]\tTime 0.194 (0.975)\tETA 0:00:02\tTraining Loss 1.5629 (1.5666)\n",
      "\n",
      "Epoch: [23][4/16]\tTime 0.193 (1.168)\tETA 0:00:02\tTraining Loss 1.5658 (1.5665)\n",
      "\n",
      "Epoch: [23][5/16]\tTime 0.188 (1.356)\tETA 0:00:02\tTraining Loss 1.5747 (1.5678)\n",
      "\n",
      "Epoch: [23][6/16]\tTime 0.187 (1.543)\tETA 0:00:01\tTraining Loss 1.5624 (1.5671)\n",
      "\n",
      "Epoch: [23][7/16]\tTime 0.197 (1.740)\tETA 0:00:01\tTraining Loss 1.5604 (1.5662)\n",
      "\n",
      "Epoch: [23][8/16]\tTime 0.185 (1.925)\tETA 0:00:01\tTraining Loss 1.5586 (1.5654)\n",
      "\n",
      "Epoch: [23][9/16]\tTime 0.209 (2.134)\tETA 0:00:01\tTraining Loss 1.5658 (1.5654)\n",
      "\n",
      "Epoch: [23][10/16]\tTime 0.193 (2.327)\tETA 0:00:01\tTraining Loss 1.5659 (1.5655)\n",
      "\n",
      "Epoch: [23][11/16]\tTime 0.186 (2.512)\tETA 0:00:00\tTraining Loss 1.5643 (1.5654)\n",
      "\n",
      "Epoch: [23][12/16]\tTime 0.196 (2.709)\tETA 0:00:00\tTraining Loss 1.5749 (1.5661)\n",
      "\n",
      "Epoch: [23][13/16]\tTime 0.175 (2.884)\tETA 0:00:00\tTraining Loss 1.5595 (1.5656)\n",
      "\n",
      "Epoch: [23][14/16]\tTime 0.192 (3.076)\tETA 0:00:00\tTraining Loss 1.5643 (1.5655)\n",
      "\n",
      "Epoch: [23][15/16]\tTime 0.115 (3.190)\tETA 0:00:00\tTraining Loss 1.5518 (1.5651)\n",
      "_\n",
      "Validation stats                    IoU        F1      Prec    recall       Acc\n",
      "bg,          0.938900  0.968400  0.976600  0.960500  0.945600\n",
      "real apple   0.000000  0.000000  0.000000  0.000000  0.934300\n",
      "real pepper  0.000000  0.000000  0.000000  0.000000  1.000000\n",
      "real grape   0.411200  0.582700  0.732700  0.483800  0.955100\n",
      "fake apple   0.000000  0.000000  0.000000  0.000000  0.948200\n",
      "fake pepper  0.000000  0.000000  0.000000  0.000000  0.986700\n",
      "fake grape   0.000000  0.000000  0.000000  0.000000  0.963100\n",
      "total        0.192871  0.221586  0.244186  0.206329  0.961857\n",
      "total(-bg)   0.068533  0.097117  0.122117  0.080633  0.964567\n",
      "\n",
      "Epoch: [24][0/16]\tTime 0.459 (0.459)\tETA 0:00:07\tTraining Loss 1.5670 (1.5670)\n",
      "\n",
      "Epoch: [24][1/16]\tTime 0.183 (0.642)\tETA 0:00:02\tTraining Loss 1.5565 (1.5618)\n",
      "\n",
      "Epoch: [24][2/16]\tTime 0.186 (0.828)\tETA 0:00:02\tTraining Loss 1.5601 (1.5612)\n",
      "\n",
      "Epoch: [24][3/16]\tTime 0.183 (1.011)\tETA 0:00:02\tTraining Loss 1.5593 (1.5607)\n",
      "\n",
      "Epoch: [24][4/16]\tTime 0.185 (1.196)\tETA 0:00:02\tTraining Loss 1.5544 (1.5595)\n",
      "\n",
      "Epoch: [24][5/16]\tTime 0.195 (1.392)\tETA 0:00:02\tTraining Loss 1.5596 (1.5595)\n",
      "\n",
      "Epoch: [24][6/16]\tTime 0.192 (1.584)\tETA 0:00:01\tTraining Loss 1.5699 (1.5610)\n",
      "\n",
      "Epoch: [24][7/16]\tTime 0.188 (1.772)\tETA 0:00:01\tTraining Loss 1.5534 (1.5600)\n",
      "\n",
      "Epoch: [24][8/16]\tTime 0.193 (1.965)\tETA 0:00:01\tTraining Loss 1.5555 (1.5595)\n",
      "\n",
      "Epoch: [24][9/16]\tTime 0.189 (2.154)\tETA 0:00:01\tTraining Loss 1.5513 (1.5587)\n",
      "\n",
      "Epoch: [24][10/16]\tTime 0.189 (2.343)\tETA 0:00:01\tTraining Loss 1.5504 (1.5579)\n",
      "\n",
      "Epoch: [24][11/16]\tTime 0.180 (2.523)\tETA 0:00:00\tTraining Loss 1.5623 (1.5583)\n",
      "\n",
      "Epoch: [24][12/16]\tTime 0.195 (2.718)\tETA 0:00:00\tTraining Loss 1.5701 (1.5592)\n",
      "\n",
      "Epoch: [24][13/16]\tTime 0.181 (2.899)\tETA 0:00:00\tTraining Loss 1.5584 (1.5592)\n",
      "\n",
      "Epoch: [24][14/16]\tTime 0.187 (3.087)\tETA 0:00:00\tTraining Loss 1.5550 (1.5589)\n",
      "\n",
      "Epoch: [24][15/16]\tTime 0.113 (3.200)\tETA 0:00:00\tTraining Loss 1.5582 (1.5589)\n",
      "_\n",
      "Validation stats                    IoU        F1      Prec    recall       Acc\n",
      "bg,          0.944000  0.971100  0.979200  0.963400  0.950300\n",
      "real apple   0.000100  0.000200  0.090900  0.000100  0.934200\n",
      "real pepper  0.000000  0.000000  0.000000  0.000000  1.000000\n",
      "real grape   0.143400  0.250800  0.649100  0.155400  0.939900\n",
      "fake apple   0.000000  0.000000  0.000000  0.000000  0.939400\n",
      "fake pepper  0.000000  0.000000  0.000000  0.000000  0.981700\n",
      "fake grape   0.000000  0.000000  0.000000  0.000000  0.950000\n",
      "total        0.155357  0.174586  0.245600  0.159843  0.956500\n",
      "total(-bg)   0.023917  0.041833  0.123333  0.025917  0.957533\n",
      "\n",
      "Epoch: [25][0/16]\tTime 0.466 (0.466)\tETA 0:00:07\tTraining Loss 1.5494 (1.5494)\n",
      "\n",
      "Epoch: [25][1/16]\tTime 0.182 (0.649)\tETA 0:00:02\tTraining Loss 1.5618 (1.5556)\n",
      "\n",
      "Epoch: [25][2/16]\tTime 0.184 (0.833)\tETA 0:00:02\tTraining Loss 1.5511 (1.5541)\n",
      "\n",
      "Epoch: [25][3/16]\tTime 0.188 (1.021)\tETA 0:00:02\tTraining Loss 1.5574 (1.5549)\n",
      "\n",
      "Epoch: [25][4/16]\tTime 0.180 (1.201)\tETA 0:00:02\tTraining Loss 1.5473 (1.5534)\n",
      "\n",
      "Epoch: [25][5/16]\tTime 0.188 (1.388)\tETA 0:00:02\tTraining Loss 1.5523 (1.5532)\n",
      "\n",
      "Epoch: [25][6/16]\tTime 0.198 (1.587)\tETA 0:00:01\tTraining Loss 1.5478 (1.5525)\n",
      "\n",
      "Epoch: [25][7/16]\tTime 0.197 (1.784)\tETA 0:00:01\tTraining Loss 1.5461 (1.5517)\n",
      "\n",
      "Epoch: [25][8/16]\tTime 0.181 (1.965)\tETA 0:00:01\tTraining Loss 1.5547 (1.5520)\n",
      "\n",
      "Epoch: [25][9/16]\tTime 0.184 (2.149)\tETA 0:00:01\tTraining Loss 1.5456 (1.5514)\n",
      "\n",
      "Epoch: [25][10/16]\tTime 0.202 (2.351)\tETA 0:00:01\tTraining Loss 1.5436 (1.5507)\n",
      "\n",
      "Epoch: [25][11/16]\tTime 0.190 (2.541)\tETA 0:00:00\tTraining Loss 1.5699 (1.5523)\n",
      "\n",
      "Epoch: [25][12/16]\tTime 0.183 (2.723)\tETA 0:00:00\tTraining Loss 1.5458 (1.5518)\n",
      "\n",
      "Epoch: [25][13/16]\tTime 0.182 (2.905)\tETA 0:00:00\tTraining Loss 1.5419 (1.5511)\n",
      "\n",
      "Epoch: [25][14/16]\tTime 0.193 (3.098)\tETA 0:00:00\tTraining Loss 1.5547 (1.5513)\n",
      "\n",
      "Epoch: [25][15/16]\tTime 0.114 (3.212)\tETA 0:00:00\tTraining Loss 1.5507 (1.5513)\n",
      "_\n",
      "Validation stats                    IoU        F1      Prec    recall       Acc\n",
      "bg,          0.947700  0.973100  0.981300  0.965200  0.953700\n",
      "real apple   0.000000  0.000000  0.000000  0.000000  0.934000\n",
      "real pepper  0.000000  0.000000  0.000000  0.000000  1.000000\n",
      "real grape   0.128400  0.227500  0.631300  0.138800  0.939000\n",
      "fake apple   0.000000  0.000000  0.000000  0.000000  0.949200\n",
      "fake pepper  0.000000  0.000000  0.000000  0.000000  0.976100\n",
      "fake grape   0.000000  0.000000  0.000000  0.000000  0.944500\n",
      "total        0.153729  0.171514  0.230371  0.157714  0.956643\n",
      "total(-bg)   0.021400  0.037917  0.105217  0.023133  0.957133\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: [26][0/16]\tTime 0.464 (0.464)\tETA 0:00:07\tTraining Loss 1.5520 (1.5520)\n",
      "\n",
      "Epoch: [26][1/16]\tTime 0.176 (0.640)\tETA 0:00:02\tTraining Loss 1.5464 (1.5492)\n",
      "\n",
      "Epoch: [26][2/16]\tTime 0.190 (0.831)\tETA 0:00:02\tTraining Loss 1.5514 (1.5499)\n",
      "\n",
      "Epoch: [26][3/16]\tTime 0.189 (1.020)\tETA 0:00:02\tTraining Loss 1.5441 (1.5485)\n",
      "\n",
      "Epoch: [26][4/16]\tTime 0.194 (1.213)\tETA 0:00:02\tTraining Loss 1.5406 (1.5469)\n",
      "\n",
      "Epoch: [26][5/16]\tTime 0.178 (1.391)\tETA 0:00:01\tTraining Loss 1.5430 (1.5463)\n",
      "\n",
      "Epoch: [26][6/16]\tTime 0.179 (1.570)\tETA 0:00:01\tTraining Loss 1.5468 (1.5463)\n",
      "\n",
      "Epoch: [26][7/16]\tTime 0.197 (1.767)\tETA 0:00:01\tTraining Loss 1.5477 (1.5465)\n",
      "\n",
      "Epoch: [26][8/16]\tTime 0.180 (1.947)\tETA 0:00:01\tTraining Loss 1.5401 (1.5458)\n",
      "\n",
      "Epoch: [26][9/16]\tTime 0.174 (2.122)\tETA 0:00:01\tTraining Loss 1.5394 (1.5452)\n",
      "\n",
      "Epoch: [26][10/16]\tTime 0.189 (2.311)\tETA 0:00:01\tTraining Loss 1.5513 (1.5457)\n",
      "\n",
      "Epoch: [26][11/16]\tTime 0.183 (2.494)\tETA 0:00:00\tTraining Loss 1.5580 (1.5467)\n",
      "\n",
      "Epoch: [26][12/16]\tTime 0.174 (2.668)\tETA 0:00:00\tTraining Loss 1.5441 (1.5465)\n",
      "\n",
      "Epoch: [26][13/16]\tTime 0.186 (2.855)\tETA 0:00:00\tTraining Loss 1.5423 (1.5462)\n",
      "\n",
      "Epoch: [26][14/16]\tTime 0.198 (3.052)\tETA 0:00:00\tTraining Loss 1.5508 (1.5465)\n",
      "\n",
      "Epoch: [26][15/16]\tTime 0.111 (3.164)\tETA 0:00:00\tTraining Loss 1.5471 (1.5466)\n",
      "_\n",
      "Validation stats                    IoU        F1      Prec    recall       Acc\n",
      "bg,          0.933200  0.965400  0.978700  0.952500  0.940700\n",
      "real apple   0.000000  0.000000  0.000000  0.000000  0.934200\n",
      "real pepper  0.000000  0.000000  0.000000  0.000000  1.000000\n",
      "real grape   0.165200  0.283500  0.684900  0.178700  0.941500\n",
      "fake apple   0.000000  0.000000  0.000000  0.000000  0.940300\n",
      "fake pepper  0.000000  0.000000  0.000000  0.000000  0.974300\n",
      "fake grape   0.000000  0.000000  0.000000  0.000000  0.948700\n",
      "total        0.156914  0.178414  0.237657  0.161600  0.954243\n",
      "total(-bg)   0.027533  0.047250  0.114150  0.029783  0.956500\n",
      "\n",
      "Epoch: [27][0/16]\tTime 0.461 (0.461)\tETA 0:00:07\tTraining Loss 1.5394 (1.5394)\n",
      "\n",
      "Epoch: [27][1/16]\tTime 0.197 (0.659)\tETA 0:00:02\tTraining Loss 1.5520 (1.5457)\n",
      "\n",
      "Epoch: [27][2/16]\tTime 0.281 (0.939)\tETA 0:00:03\tTraining Loss 1.5325 (1.5413)\n",
      "\n",
      "Epoch: [27][3/16]\tTime 0.202 (1.141)\tETA 0:00:02\tTraining Loss 1.5426 (1.5416)\n",
      "\n",
      "Epoch: [27][4/16]\tTime 0.172 (1.314)\tETA 0:00:02\tTraining Loss 1.5369 (1.5407)\n",
      "\n",
      "Epoch: [27][5/16]\tTime 0.181 (1.495)\tETA 0:00:01\tTraining Loss 1.5458 (1.5415)\n",
      "\n",
      "Epoch: [27][6/16]\tTime 0.190 (1.685)\tETA 0:00:01\tTraining Loss 1.5335 (1.5404)\n",
      "\n",
      "Epoch: [27][7/16]\tTime 0.186 (1.871)\tETA 0:00:01\tTraining Loss 1.5306 (1.5391)\n",
      "\n",
      "Epoch: [27][8/16]\tTime 0.183 (2.054)\tETA 0:00:01\tTraining Loss 1.5405 (1.5393)\n",
      "\n",
      "Epoch: [27][9/16]\tTime 0.197 (2.250)\tETA 0:00:01\tTraining Loss 1.5431 (1.5397)\n",
      "\n",
      "Epoch: [27][10/16]\tTime 0.185 (2.435)\tETA 0:00:01\tTraining Loss 1.5303 (1.5388)\n",
      "\n",
      "Epoch: [27][11/16]\tTime 0.187 (2.622)\tETA 0:00:00\tTraining Loss 1.5360 (1.5386)\n",
      "\n",
      "Epoch: [27][12/16]\tTime 0.179 (2.801)\tETA 0:00:00\tTraining Loss 1.5474 (1.5393)\n",
      "\n",
      "Epoch: [27][13/16]\tTime 0.188 (2.989)\tETA 0:00:00\tTraining Loss 1.5384 (1.5392)\n",
      "\n",
      "Epoch: [27][14/16]\tTime 0.186 (3.175)\tETA 0:00:00\tTraining Loss 1.5427 (1.5394)\n",
      "\n",
      "Epoch: [27][15/16]\tTime 0.123 (3.298)\tETA 0:00:00\tTraining Loss 1.5282 (1.5391)\n",
      "_\n",
      "Validation stats                    IoU        F1    Prec    recall      Acc\n",
      "bg,          0.944800  0.971600  0.9815  0.961900  0.95110\n",
      "real apple   0.000000  0.000000  0.0000  0.000000  0.93430\n",
      "real pepper  0.000000  0.000000  0.0000  0.000000  1.00000\n",
      "real grape   0.588500  0.740900  0.8700  0.645200  0.97080\n",
      "fake apple   0.000000  0.000000  0.0000  0.000000  0.95120\n",
      "fake pepper  0.000000  0.000000  0.0000  0.000000  0.97660\n",
      "fake grape   0.000000  0.000000  0.0000  0.000000  0.97240\n",
      "total        0.219043  0.244643  0.2645  0.229586  0.96520\n",
      "total(-bg)   0.098083  0.123483  0.1450  0.107533  0.96755\n",
      "\n",
      "Epoch: [28][0/16]\tTime 0.486 (0.486)\tETA 0:00:07\tTraining Loss 1.5337 (1.5337)\n",
      "\n",
      "Epoch: [28][1/16]\tTime 0.184 (0.670)\tETA 0:00:02\tTraining Loss 1.5305 (1.5321)\n",
      "\n",
      "Epoch: [28][2/16]\tTime 0.185 (0.855)\tETA 0:00:02\tTraining Loss 1.5292 (1.5311)\n",
      "\n",
      "Epoch: [28][3/16]\tTime 0.185 (1.041)\tETA 0:00:02\tTraining Loss 1.5317 (1.5313)\n",
      "\n",
      "Epoch: [28][4/16]\tTime 0.184 (1.225)\tETA 0:00:02\tTraining Loss 1.5573 (1.5365)\n",
      "\n",
      "Epoch: [28][5/16]\tTime 0.183 (1.407)\tETA 0:00:02\tTraining Loss 1.5384 (1.5368)\n",
      "\n",
      "Epoch: [28][6/16]\tTime 0.188 (1.595)\tETA 0:00:01\tTraining Loss 1.5397 (1.5372)\n",
      "\n",
      "Epoch: [28][7/16]\tTime 0.176 (1.772)\tETA 0:00:01\tTraining Loss 1.5322 (1.5366)\n",
      "\n",
      "Epoch: [28][8/16]\tTime 0.197 (1.969)\tETA 0:00:01\tTraining Loss 1.5280 (1.5356)\n",
      "\n",
      "Epoch: [28][9/16]\tTime 0.189 (2.159)\tETA 0:00:01\tTraining Loss 1.5298 (1.5351)\n",
      "\n",
      "Epoch: [28][10/16]\tTime 0.185 (2.343)\tETA 0:00:01\tTraining Loss 1.5336 (1.5349)\n",
      "\n",
      "Epoch: [28][11/16]\tTime 0.185 (2.528)\tETA 0:00:00\tTraining Loss 1.5266 (1.5342)\n",
      "\n",
      "Epoch: [28][12/16]\tTime 0.197 (2.726)\tETA 0:00:00\tTraining Loss 1.5351 (1.5343)\n",
      "\n",
      "Epoch: [28][13/16]\tTime 0.191 (2.916)\tETA 0:00:00\tTraining Loss 1.5547 (1.5358)\n",
      "\n",
      "Epoch: [28][14/16]\tTime 0.181 (3.098)\tETA 0:00:00\tTraining Loss 1.5303 (1.5354)\n",
      "\n",
      "Epoch: [28][15/16]\tTime 0.113 (3.210)\tETA 0:00:00\tTraining Loss 1.5283 (1.5352)\n",
      "_\n",
      "Validation stats                  IoU        F1      Prec    recall       Acc\n",
      "bg,          0.9408  0.969400  0.980400  0.958700  0.947500\n",
      "real apple   0.0000  0.000000  0.000000  0.000000  0.934200\n",
      "real pepper  0.0000  0.000000  0.000000  0.000000  1.000000\n",
      "real grape   0.2730  0.428900  0.736200  0.302600  0.947800\n",
      "fake apple   0.0000  0.000000  0.000000  0.000000  0.952700\n",
      "fake pepper  0.0000  0.000000  0.000000  0.000000  0.975900\n",
      "fake grape   0.0000  0.000000  0.000000  0.000000  0.948300\n",
      "total        0.1734  0.199757  0.245229  0.180186  0.958057\n",
      "total(-bg)   0.0455  0.071483  0.122700  0.050433  0.959817\n",
      "\n",
      "Epoch: [29][0/16]\tTime 0.477 (0.477)\tETA 0:00:07\tTraining Loss 1.5334 (1.5334)\n",
      "\n",
      "Epoch: [29][1/16]\tTime 0.181 (0.659)\tETA 0:00:02\tTraining Loss 1.5299 (1.5317)\n",
      "\n",
      "Epoch: [29][2/16]\tTime 0.185 (0.844)\tETA 0:00:02\tTraining Loss 1.5259 (1.5297)\n",
      "\n",
      "Epoch: [29][3/16]\tTime 0.193 (1.037)\tETA 0:00:02\tTraining Loss 1.5242 (1.5284)\n",
      "\n",
      "Epoch: [29][4/16]\tTime 0.185 (1.222)\tETA 0:00:02\tTraining Loss 1.5277 (1.5282)\n",
      "\n",
      "Epoch: [29][5/16]\tTime 0.177 (1.399)\tETA 0:00:01\tTraining Loss 1.5294 (1.5284)\n",
      "\n",
      "Epoch: [29][6/16]\tTime 0.190 (1.589)\tETA 0:00:01\tTraining Loss 1.5329 (1.5291)\n",
      "\n",
      "Epoch: [29][7/16]\tTime 0.181 (1.770)\tETA 0:00:01\tTraining Loss 1.5318 (1.5294)\n",
      "\n",
      "Epoch: [29][8/16]\tTime 0.193 (1.962)\tETA 0:00:01\tTraining Loss 1.5213 (1.5285)\n",
      "\n",
      "Epoch: [29][9/16]\tTime 0.186 (2.148)\tETA 0:00:01\tTraining Loss 1.5302 (1.5287)\n",
      "\n",
      "Epoch: [29][10/16]\tTime 0.194 (2.342)\tETA 0:00:01\tTraining Loss 1.5217 (1.5280)\n",
      "\n",
      "Epoch: [29][11/16]\tTime 0.198 (2.540)\tETA 0:00:00\tTraining Loss 1.5290 (1.5281)\n",
      "\n",
      "Epoch: [29][12/16]\tTime 0.183 (2.723)\tETA 0:00:00\tTraining Loss 1.5238 (1.5278)\n",
      "\n",
      "Epoch: [29][13/16]\tTime 0.188 (2.911)\tETA 0:00:00\tTraining Loss 1.5191 (1.5272)\n",
      "\n",
      "Epoch: [29][14/16]\tTime 0.190 (3.100)\tETA 0:00:00\tTraining Loss 1.5232 (1.5269)\n",
      "\n",
      "Epoch: [29][15/16]\tTime 0.114 (3.214)\tETA 0:00:00\tTraining Loss 1.5141 (1.5265)\n",
      "_\n",
      "Validation stats                    IoU        F1      Prec    recall       Acc\n",
      "bg,          0.942900  0.970500  0.979600  0.961800  0.949300\n",
      "real apple   0.000000  0.000000  0.000000  0.000000  0.934200\n",
      "real pepper  0.000000  0.000000  0.000000  0.000000  1.000000\n",
      "real grape   0.041800  0.080200  0.325500  0.045700  0.932100\n",
      "fake apple   0.000000  0.000000  0.000000  0.000000  0.943500\n",
      "fake pepper  0.000000  0.000000  0.000000  0.000000  0.973000\n",
      "fake grape   0.000000  0.000000  0.000000  0.000000  0.946400\n",
      "total        0.140671  0.150100  0.186443  0.143929  0.954071\n",
      "total(-bg)   0.006967  0.013367  0.054250  0.007617  0.954867\n",
      "\n",
      "Epoch: [30][0/16]\tTime 0.416 (0.416)\tETA 0:00:06\tTraining Loss 1.5149 (1.5149)\n",
      "\n",
      "Epoch: [30][1/16]\tTime 0.181 (0.597)\tETA 0:00:02\tTraining Loss 1.5219 (1.5184)\n",
      "\n",
      "Epoch: [30][2/16]\tTime 0.196 (0.792)\tETA 0:00:02\tTraining Loss 1.5147 (1.5171)\n",
      "\n",
      "Epoch: [30][3/16]\tTime 0.180 (0.973)\tETA 0:00:02\tTraining Loss 1.5162 (1.5169)\n",
      "\n",
      "Epoch: [30][4/16]\tTime 0.191 (1.164)\tETA 0:00:02\tTraining Loss 1.5161 (1.5167)\n",
      "\n",
      "Epoch: [30][5/16]\tTime 0.189 (1.353)\tETA 0:00:02\tTraining Loss 1.5203 (1.5173)\n",
      "\n",
      "Epoch: [30][6/16]\tTime 0.192 (1.545)\tETA 0:00:01\tTraining Loss 1.5227 (1.5181)\n",
      "\n",
      "Epoch: [30][7/16]\tTime 0.188 (1.733)\tETA 0:00:01\tTraining Loss 1.5264 (1.5191)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: [30][8/16]\tTime 0.182 (1.915)\tETA 0:00:01\tTraining Loss 1.5185 (1.5191)\n",
      "\n",
      "Epoch: [30][9/16]\tTime 0.191 (2.106)\tETA 0:00:01\tTraining Loss 1.5141 (1.5186)\n",
      "\n",
      "Epoch: [30][10/16]\tTime 0.196 (2.302)\tETA 0:00:01\tTraining Loss 1.5096 (1.5177)\n",
      "\n",
      "Epoch: [30][11/16]\tTime 0.186 (2.488)\tETA 0:00:00\tTraining Loss 1.5221 (1.5181)\n",
      "\n",
      "Epoch: [30][12/16]\tTime 0.192 (2.680)\tETA 0:00:00\tTraining Loss 1.5212 (1.5183)\n",
      "\n",
      "Epoch: [30][13/16]\tTime 0.189 (2.869)\tETA 0:00:00\tTraining Loss 1.5153 (1.5181)\n",
      "\n",
      "Epoch: [30][14/16]\tTime 0.190 (3.059)\tETA 0:00:00\tTraining Loss 1.5280 (1.5188)\n",
      "\n",
      "Epoch: [30][15/16]\tTime 0.112 (3.171)\tETA 0:00:00\tTraining Loss 1.5169 (1.5187)\n",
      "_\n",
      "Validation stats                    IoU        F1      Prec    recall       Acc\n",
      "bg,          0.944700  0.971500  0.977900  0.965300  0.950800\n",
      "real apple   0.000000  0.000000  0.000000  0.000000  0.934200\n",
      "real pepper  0.000000  0.000000  0.000000  0.000000  1.000000\n",
      "real grape   0.376700  0.547200  0.878200  0.397400  0.957400\n",
      "fake apple   0.000000  0.000000  0.000000  0.000000  0.956800\n",
      "fake pepper  0.000000  0.000000  0.000000  0.000000  0.974900\n",
      "fake grape   0.000000  0.000000  0.000000  0.000000  0.956000\n",
      "total        0.188771  0.216957  0.265157  0.194671  0.961443\n",
      "total(-bg)   0.062783  0.091200  0.146367  0.066233  0.963217\n",
      "\n",
      "Epoch: [31][0/16]\tTime 0.530 (0.530)\tETA 0:00:08\tTraining Loss 1.5091 (1.5091)\n",
      "\n",
      "Epoch: [31][1/16]\tTime 0.220 (0.751)\tETA 0:00:03\tTraining Loss 1.5069 (1.5080)\n",
      "\n",
      "Epoch: [31][2/16]\tTime 0.196 (0.946)\tETA 0:00:02\tTraining Loss 1.5180 (1.5113)\n",
      "\n",
      "Epoch: [31][3/16]\tTime 0.194 (1.141)\tETA 0:00:02\tTraining Loss 1.5130 (1.5117)\n",
      "\n",
      "Epoch: [31][4/16]\tTime 0.187 (1.328)\tETA 0:00:02\tTraining Loss 1.5128 (1.5120)\n",
      "\n",
      "Epoch: [31][5/16]\tTime 0.191 (1.519)\tETA 0:00:02\tTraining Loss 1.5141 (1.5123)\n",
      "\n",
      "Epoch: [31][6/16]\tTime 0.215 (1.734)\tETA 0:00:02\tTraining Loss 1.5148 (1.5127)\n",
      "\n",
      "Epoch: [31][7/16]\tTime 0.189 (1.923)\tETA 0:00:01\tTraining Loss 1.5216 (1.5138)\n",
      "\n",
      "Epoch: [31][8/16]\tTime 0.184 (2.107)\tETA 0:00:01\tTraining Loss 1.5216 (1.5146)\n",
      "\n",
      "Epoch: [31][9/16]\tTime 0.187 (2.294)\tETA 0:00:01\tTraining Loss 1.5119 (1.5144)\n",
      "\n",
      "Epoch: [31][10/16]\tTime 0.192 (2.486)\tETA 0:00:01\tTraining Loss 1.5300 (1.5158)\n",
      "\n",
      "Epoch: [31][11/16]\tTime 0.177 (2.663)\tETA 0:00:00\tTraining Loss 1.5155 (1.5158)\n",
      "\n",
      "Epoch: [31][12/16]\tTime 0.193 (2.856)\tETA 0:00:00\tTraining Loss 1.5064 (1.5150)\n",
      "\n",
      "Epoch: [31][13/16]\tTime 0.185 (3.042)\tETA 0:00:00\tTraining Loss 1.5040 (1.5142)\n",
      "\n",
      "Epoch: [31][14/16]\tTime 0.190 (3.232)\tETA 0:00:00\tTraining Loss 1.5062 (1.5137)\n",
      "\n",
      "Epoch: [31][15/16]\tTime 0.111 (3.344)\tETA 0:00:00\tTraining Loss 1.5053 (1.5134)\n",
      "_\n",
      "Validation stats                    IoU        F1      Prec    recall       Acc\n",
      "bg,          0.940100  0.969000  0.978700  0.959700  0.946800\n",
      "real apple   0.000100  0.000200  0.333300  0.000100  0.934300\n",
      "real pepper  0.000000  0.000000  0.000000  0.000000  1.000000\n",
      "real grape   0.135100  0.238100  0.701400  0.143400  0.940600\n",
      "fake apple   0.000000  0.000000  0.000000  0.000000  0.954500\n",
      "fake pepper  0.000000  0.000000  0.000000  0.000000  0.975000\n",
      "fake grape   0.000000  0.000000  0.000000  0.000000  0.936400\n",
      "total        0.153614  0.172471  0.287629  0.157600  0.955371\n",
      "total(-bg)   0.022533  0.039717  0.172450  0.023917  0.956800\n",
      "\n",
      "Epoch: [32][0/16]\tTime 0.463 (0.463)\tETA 0:00:07\tTraining Loss 1.5058 (1.5058)\n",
      "\n",
      "Epoch: [32][1/16]\tTime 0.189 (0.651)\tETA 0:00:02\tTraining Loss 1.5043 (1.5050)\n",
      "\n",
      "Epoch: [32][2/16]\tTime 0.182 (0.834)\tETA 0:00:02\tTraining Loss 1.5055 (1.5052)\n",
      "\n",
      "Epoch: [32][3/16]\tTime 0.180 (1.014)\tETA 0:00:02\tTraining Loss 1.5054 (1.5052)\n",
      "\n",
      "Epoch: [32][4/16]\tTime 0.187 (1.201)\tETA 0:00:02\tTraining Loss 1.5076 (1.5057)\n",
      "\n",
      "Epoch: [32][5/16]\tTime 0.186 (1.387)\tETA 0:00:02\tTraining Loss 1.5066 (1.5059)\n",
      "\n",
      "Epoch: [32][6/16]\tTime 0.184 (1.571)\tETA 0:00:01\tTraining Loss 1.5066 (1.5060)\n",
      "\n",
      "Epoch: [32][7/16]\tTime 0.179 (1.750)\tETA 0:00:01\tTraining Loss 1.5153 (1.5071)\n",
      "\n",
      "Epoch: [32][8/16]\tTime 0.188 (1.938)\tETA 0:00:01\tTraining Loss 1.5052 (1.5069)\n",
      "\n",
      "Epoch: [32][9/16]\tTime 0.183 (2.121)\tETA 0:00:01\tTraining Loss 1.5024 (1.5064)\n",
      "\n",
      "Epoch: [32][10/16]\tTime 0.189 (2.310)\tETA 0:00:01\tTraining Loss 1.5036 (1.5062)\n",
      "\n",
      "Epoch: [32][11/16]\tTime 0.181 (2.492)\tETA 0:00:00\tTraining Loss 1.5095 (1.5065)\n",
      "\n",
      "Epoch: [32][12/16]\tTime 0.192 (2.683)\tETA 0:00:00\tTraining Loss 1.5007 (1.5060)\n",
      "\n",
      "Epoch: [32][13/16]\tTime 0.186 (2.870)\tETA 0:00:00\tTraining Loss 1.4976 (1.5054)\n",
      "\n",
      "Epoch: [32][14/16]\tTime 0.191 (3.060)\tETA 0:00:00\tTraining Loss 1.4974 (1.5049)\n",
      "\n",
      "Epoch: [32][15/16]\tTime 0.124 (3.184)\tETA 0:00:00\tTraining Loss 1.5047 (1.5049)\n",
      "_\n",
      "Validation stats                    IoU        F1      Prec    recall       Acc\n",
      "bg,          0.945000  0.971700  0.978300  0.965200  0.951200\n",
      "real apple   0.000100  0.000200  0.058800  0.000100  0.934200\n",
      "real pepper  0.000000  0.000000  0.000000  0.000000  1.000000\n",
      "real grape   0.310600  0.474000  0.836200  0.330700  0.952500\n",
      "fake apple   0.000000  0.000000  0.000000  0.000000  0.951000\n",
      "fake pepper  0.000000  0.000000  0.000000  0.000000  0.974800\n",
      "fake grape   0.000000  0.000000  0.000000  0.000000  0.957900\n",
      "total        0.179386  0.206557  0.267614  0.185143  0.960229\n",
      "total(-bg)   0.051783  0.079033  0.149167  0.055133  0.961733\n",
      "\n",
      "Epoch: [33][0/16]\tTime 0.503 (0.503)\tETA 0:00:08\tTraining Loss 1.5033 (1.5033)\n",
      "\n",
      "Epoch: [33][1/16]\tTime 0.170 (0.674)\tETA 0:00:02\tTraining Loss 1.5006 (1.5020)\n",
      "\n",
      "Epoch: [33][2/16]\tTime 0.187 (0.861)\tETA 0:00:02\tTraining Loss 1.5012 (1.5017)\n",
      "\n",
      "Epoch: [33][3/16]\tTime 0.184 (1.045)\tETA 0:00:02\tTraining Loss 1.4990 (1.5010)\n",
      "\n",
      "Epoch: [33][4/16]\tTime 0.188 (1.233)\tETA 0:00:02\tTraining Loss 1.5078 (1.5024)\n",
      "\n",
      "Epoch: [33][5/16]\tTime 0.187 (1.420)\tETA 0:00:02\tTraining Loss 1.4968 (1.5015)\n",
      "\n",
      "Epoch: [33][6/16]\tTime 0.193 (1.612)\tETA 0:00:01\tTraining Loss 1.5023 (1.5016)\n",
      "\n",
      "Epoch: [33][7/16]\tTime 0.177 (1.789)\tETA 0:00:01\tTraining Loss 1.5021 (1.5016)\n",
      "\n",
      "Epoch: [33][8/16]\tTime 0.192 (1.981)\tETA 0:00:01\tTraining Loss 1.5013 (1.5016)\n",
      "\n",
      "Epoch: [33][9/16]\tTime 0.188 (2.170)\tETA 0:00:01\tTraining Loss 1.4967 (1.5011)\n",
      "\n",
      "Epoch: [33][10/16]\tTime 0.191 (2.361)\tETA 0:00:01\tTraining Loss 1.4975 (1.5008)\n",
      "\n",
      "Epoch: [33][11/16]\tTime 0.187 (2.548)\tETA 0:00:00\tTraining Loss 1.4922 (1.5001)\n",
      "\n",
      "Epoch: [33][12/16]\tTime 0.183 (2.731)\tETA 0:00:00\tTraining Loss 1.4941 (1.4996)\n",
      "\n",
      "Epoch: [33][13/16]\tTime 0.182 (2.913)\tETA 0:00:00\tTraining Loss 1.4959 (1.4993)\n",
      "\n",
      "Epoch: [33][14/16]\tTime 0.184 (3.097)\tETA 0:00:00\tTraining Loss 1.4965 (1.4992)\n",
      "\n",
      "Epoch: [33][15/16]\tTime 0.117 (3.214)\tETA 0:00:00\tTraining Loss 1.4882 (1.4988)\n",
      "_\n",
      "Validation stats                    IoU        F1      Prec    recall       Acc\n",
      "bg,          0.943600  0.970900  0.977500  0.964600  0.949900\n",
      "real apple   0.000000  0.000000  0.000000  0.000000  0.934200\n",
      "real pepper  0.000000  0.000000  0.000000  0.000000  1.000000\n",
      "real grape   0.410400  0.581900  0.893200  0.431600  0.959900\n",
      "fake apple   0.000000  0.000000  0.000000  0.000000  0.951900\n",
      "fake pepper  0.000000  0.000000  0.000000  0.000000  0.982300\n",
      "fake grape   0.000000  0.000000  0.000000  0.000000  0.955200\n",
      "total        0.193429  0.221829  0.267243  0.199457  0.961914\n",
      "total(-bg)   0.068400  0.096983  0.148867  0.071933  0.963917\n",
      "\n",
      "Epoch: [34][0/16]\tTime 0.485 (0.485)\tETA 0:00:07\tTraining Loss 1.4956 (1.4956)\n",
      "\n",
      "Epoch: [34][1/16]\tTime 0.186 (0.671)\tETA 0:00:02\tTraining Loss 1.4972 (1.4964)\n",
      "\n",
      "Epoch: [34][2/16]\tTime 0.193 (0.864)\tETA 0:00:02\tTraining Loss 1.4951 (1.4959)\n",
      "\n",
      "Epoch: [34][3/16]\tTime 0.183 (1.047)\tETA 0:00:02\tTraining Loss 1.4935 (1.4953)\n",
      "\n",
      "Epoch: [34][4/16]\tTime 0.184 (1.231)\tETA 0:00:02\tTraining Loss 1.4958 (1.4954)\n",
      "\n",
      "Epoch: [34][5/16]\tTime 0.187 (1.418)\tETA 0:00:02\tTraining Loss 1.4901 (1.4945)\n",
      "\n",
      "Epoch: [34][6/16]\tTime 0.183 (1.601)\tETA 0:00:01\tTraining Loss 1.4832 (1.4929)\n",
      "\n",
      "Epoch: [34][7/16]\tTime 0.186 (1.787)\tETA 0:00:01\tTraining Loss 1.4929 (1.4929)\n",
      "\n",
      "Epoch: [34][8/16]\tTime 0.184 (1.971)\tETA 0:00:01\tTraining Loss 1.4930 (1.4929)\n",
      "\n",
      "Epoch: [34][9/16]\tTime 0.186 (2.157)\tETA 0:00:01\tTraining Loss 1.4946 (1.4931)\n",
      "\n",
      "Epoch: [34][10/16]\tTime 0.190 (2.347)\tETA 0:00:01\tTraining Loss 1.4962 (1.4934)\n",
      "\n",
      "Epoch: [34][11/16]\tTime 0.196 (2.543)\tETA 0:00:00\tTraining Loss 1.4894 (1.4931)\n",
      "\n",
      "Epoch: [34][12/16]\tTime 0.193 (2.736)\tETA 0:00:00\tTraining Loss 1.4891 (1.4927)\n",
      "\n",
      "Epoch: [34][13/16]\tTime 0.181 (2.916)\tETA 0:00:00\tTraining Loss 1.4921 (1.4927)\n",
      "\n",
      "Epoch: [34][14/16]\tTime 0.203 (3.119)\tETA 0:00:00\tTraining Loss 1.5002 (1.4932)\n",
      "\n",
      "Epoch: [34][15/16]\tTime 0.109 (3.229)\tETA 0:00:00\tTraining Loss 1.4928 (1.4932)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_\n",
      "Validation stats                    IoU        F1      Prec    recall       Acc\n",
      "bg,          0.946900  0.972700  0.979000  0.966600  0.952900\n",
      "real apple   0.000000  0.000000  0.000000  0.000000  0.934300\n",
      "real pepper  0.000000  0.000000  0.000000  0.000000  1.000000\n",
      "real grape   0.329200  0.495300  0.842600  0.350800  0.953700\n",
      "fake apple   0.000000  0.000000  0.000000  0.000000  0.962700\n",
      "fake pepper  0.000000  0.000000  0.000000  0.000000  0.971500\n",
      "fake grape   0.000000  0.000000  0.000000  0.000000  0.951300\n",
      "total        0.182300  0.209714  0.260229  0.188200  0.960914\n",
      "total(-bg)   0.054867  0.082550  0.140433  0.058467  0.962250\n",
      "\n",
      "Epoch: [35][0/16]\tTime 0.466 (0.466)\tETA 0:00:07\tTraining Loss 1.4914 (1.4914)\n",
      "\n",
      "Epoch: [35][1/16]\tTime 0.192 (0.658)\tETA 0:00:02\tTraining Loss 1.4925 (1.4920)\n",
      "\n",
      "Epoch: [35][2/16]\tTime 0.185 (0.842)\tETA 0:00:02\tTraining Loss 1.4847 (1.4895)\n",
      "\n",
      "Epoch: [35][3/16]\tTime 0.182 (1.024)\tETA 0:00:02\tTraining Loss 1.4851 (1.4884)\n",
      "\n",
      "Epoch: [35][4/16]\tTime 0.186 (1.210)\tETA 0:00:02\tTraining Loss 1.4883 (1.4884)\n",
      "\n",
      "Epoch: [35][5/16]\tTime 0.183 (1.394)\tETA 0:00:02\tTraining Loss 1.4956 (1.4896)\n",
      "\n",
      "Epoch: [35][6/16]\tTime 0.188 (1.582)\tETA 0:00:01\tTraining Loss 1.4958 (1.4905)\n",
      "\n",
      "Epoch: [35][7/16]\tTime 0.180 (1.762)\tETA 0:00:01\tTraining Loss 1.4887 (1.4903)\n",
      "\n",
      "Epoch: [35][8/16]\tTime 0.189 (1.951)\tETA 0:00:01\tTraining Loss 1.4813 (1.4893)\n",
      "\n",
      "Epoch: [35][9/16]\tTime 0.185 (2.136)\tETA 0:00:01\tTraining Loss 1.4823 (1.4886)\n",
      "\n",
      "Epoch: [35][10/16]\tTime 0.182 (2.318)\tETA 0:00:01\tTraining Loss 1.4809 (1.4879)\n",
      "\n",
      "Epoch: [35][11/16]\tTime 0.183 (2.501)\tETA 0:00:00\tTraining Loss 1.4823 (1.4874)\n",
      "\n",
      "Epoch: [35][12/16]\tTime 0.187 (2.688)\tETA 0:00:00\tTraining Loss 1.4888 (1.4875)\n",
      "\n",
      "Epoch: [35][13/16]\tTime 0.186 (2.874)\tETA 0:00:00\tTraining Loss 1.4794 (1.4869)\n",
      "\n",
      "Epoch: [35][14/16]\tTime 0.183 (3.057)\tETA 0:00:00\tTraining Loss 1.4850 (1.4868)\n",
      "\n",
      "Epoch: [35][15/16]\tTime 0.116 (3.173)\tETA 0:00:00\tTraining Loss 1.4906 (1.4869)\n",
      "_\n",
      "Validation stats                    IoU        F1      Prec    recall       Acc\n",
      "bg,          0.941800  0.970000  0.975200  0.965000  0.948200\n",
      "real apple   0.000000  0.000000  0.000000  0.000000  0.934200\n",
      "real pepper  0.000000  0.000000  0.000000  0.000000  1.000000\n",
      "real grape   0.126300  0.224300  0.726000  0.132700  0.940600\n",
      "fake apple   0.000000  0.000000  0.000000  0.000000  0.926800\n",
      "fake pepper  0.000000  0.000000  0.000000  0.000000  0.978100\n",
      "fake grape   0.000000  0.000000  0.000000  0.000000  0.967400\n",
      "total        0.152586  0.170614  0.243029  0.156814  0.956471\n",
      "total(-bg)   0.021050  0.037383  0.121000  0.022117  0.957850\n",
      "\n",
      "Epoch: [36][0/16]\tTime 0.485 (0.485)\tETA 0:00:07\tTraining Loss 1.4848 (1.4848)\n",
      "\n",
      "Epoch: [36][1/16]\tTime 0.180 (0.665)\tETA 0:00:02\tTraining Loss 1.4824 (1.4836)\n",
      "\n",
      "Epoch: [36][2/16]\tTime 0.184 (0.849)\tETA 0:00:02\tTraining Loss 1.4820 (1.4831)\n",
      "\n",
      "Epoch: [36][3/16]\tTime 0.180 (1.029)\tETA 0:00:02\tTraining Loss 1.4860 (1.4838)\n",
      "\n",
      "Epoch: [36][4/16]\tTime 0.185 (1.214)\tETA 0:00:02\tTraining Loss 1.4751 (1.4821)\n",
      "\n",
      "Epoch: [36][5/16]\tTime 0.187 (1.400)\tETA 0:00:02\tTraining Loss 1.4791 (1.4816)\n",
      "\n",
      "Epoch: [36][6/16]\tTime 0.183 (1.583)\tETA 0:00:01\tTraining Loss 1.4935 (1.4833)\n",
      "\n",
      "Epoch: [36][7/16]\tTime 0.180 (1.763)\tETA 0:00:01\tTraining Loss 1.4773 (1.4825)\n",
      "\n",
      "Epoch: [36][8/16]\tTime 0.187 (1.950)\tETA 0:00:01\tTraining Loss 1.4834 (1.4826)\n",
      "\n",
      "Epoch: [36][9/16]\tTime 0.178 (2.128)\tETA 0:00:01\tTraining Loss 1.4755 (1.4819)\n",
      "\n",
      "Epoch: [36][10/16]\tTime 0.183 (2.311)\tETA 0:00:01\tTraining Loss 1.4793 (1.4817)\n",
      "\n",
      "Epoch: [36][11/16]\tTime 0.180 (2.490)\tETA 0:00:00\tTraining Loss 1.4806 (1.4816)\n",
      "\n",
      "Epoch: [36][12/16]\tTime 0.185 (2.676)\tETA 0:00:00\tTraining Loss 1.4732 (1.4809)\n",
      "\n",
      "Epoch: [36][13/16]\tTime 0.180 (2.856)\tETA 0:00:00\tTraining Loss 1.4745 (1.4805)\n",
      "\n",
      "Epoch: [36][14/16]\tTime 0.176 (3.031)\tETA 0:00:00\tTraining Loss 1.4858 (1.4808)\n",
      "\n",
      "Epoch: [36][15/16]\tTime 0.114 (3.145)\tETA 0:00:00\tTraining Loss 1.4780 (1.4807)\n",
      "_\n",
      "Validation stats                    IoU        F1     Prec    recall       Acc\n",
      "bg,          0.940800  0.969500  0.97590  0.963200  0.947300\n",
      "real apple   0.000000  0.000000  0.00000  0.000000  0.934200\n",
      "real pepper  0.000000  0.000000  0.00000  0.000000  1.000000\n",
      "real grape   0.166400  0.285300  0.73350  0.177100  0.942600\n",
      "fake apple   0.000000  0.000000  0.00000  0.000000  0.941100\n",
      "fake pepper  0.000000  0.000000  0.00000  0.000000  0.995600\n",
      "fake grape   0.000000  0.000000  0.00000  0.000000  0.937300\n",
      "total        0.158171  0.179257  0.24420  0.162900  0.956871\n",
      "total(-bg)   0.027733  0.047550  0.12225  0.029517  0.958467\n",
      "\n",
      "Epoch: [37][0/16]\tTime 0.492 (0.492)\tETA 0:00:07\tTraining Loss 1.4754 (1.4754)\n",
      "\n",
      "Epoch: [37][1/16]\tTime 0.180 (0.672)\tETA 0:00:02\tTraining Loss 1.4740 (1.4747)\n",
      "\n",
      "Epoch: [37][2/16]\tTime 0.183 (0.855)\tETA 0:00:02\tTraining Loss 1.4790 (1.4761)\n",
      "\n",
      "Epoch: [37][3/16]\tTime 0.184 (1.038)\tETA 0:00:02\tTraining Loss 1.4774 (1.4765)\n",
      "\n",
      "Epoch: [37][4/16]\tTime 0.195 (1.234)\tETA 0:00:02\tTraining Loss 1.4805 (1.4773)\n",
      "\n",
      "Epoch: [37][5/16]\tTime 0.174 (1.408)\tETA 0:00:01\tTraining Loss 1.4832 (1.4782)\n",
      "\n",
      "Epoch: [37][6/16]\tTime 0.186 (1.594)\tETA 0:00:01\tTraining Loss 1.4693 (1.4770)\n",
      "\n",
      "Epoch: [37][7/16]\tTime 0.192 (1.786)\tETA 0:00:01\tTraining Loss 1.4777 (1.4771)\n",
      "\n",
      "Epoch: [37][8/16]\tTime 0.180 (1.967)\tETA 0:00:01\tTraining Loss 1.4747 (1.4768)\n",
      "\n",
      "Epoch: [37][9/16]\tTime 0.196 (2.163)\tETA 0:00:01\tTraining Loss 1.4747 (1.4766)\n",
      "\n",
      "Epoch: [37][10/16]\tTime 0.192 (2.355)\tETA 0:00:01\tTraining Loss 1.4823 (1.4771)\n",
      "\n",
      "Epoch: [37][11/16]\tTime 0.181 (2.536)\tETA 0:00:00\tTraining Loss 1.4717 (1.4767)\n",
      "\n",
      "Epoch: [37][12/16]\tTime 0.176 (2.712)\tETA 0:00:00\tTraining Loss 1.4806 (1.4770)\n",
      "\n",
      "Epoch: [37][13/16]\tTime 0.195 (2.907)\tETA 0:00:00\tTraining Loss 1.4720 (1.4766)\n",
      "\n",
      "Epoch: [37][14/16]\tTime 0.305 (3.212)\tETA 0:00:00\tTraining Loss 1.4799 (1.4768)\n",
      "\n",
      "Epoch: [37][15/16]\tTime 0.114 (3.326)\tETA 0:00:00\tTraining Loss 1.4685 (1.4766)\n",
      "_\n",
      "Validation stats                    IoU        F1      Prec    recall       Acc\n",
      "bg,          0.939100  0.968500  0.980500  0.957000  0.946000\n",
      "real apple   0.000200  0.000500  0.333300  0.000200  0.934300\n",
      "real pepper  0.000000  0.000000  0.000000  0.000000  1.000000\n",
      "real grape   0.528300  0.691300  0.897500  0.562300  0.967500\n",
      "fake apple   0.000000  0.000000  0.000000  0.000000  0.942900\n",
      "fake pepper  0.000000  0.000000  0.000000  0.000000  0.979700\n",
      "fake grape   0.000000  0.000000  0.000000  0.000000  0.966600\n",
      "total        0.209657  0.237186  0.315900  0.217071  0.962429\n",
      "total(-bg)   0.088083  0.115300  0.205133  0.093750  0.965167\n",
      "\n",
      "Epoch: [38][0/16]\tTime 0.432 (0.432)\tETA 0:00:06\tTraining Loss 1.4726 (1.4726)\n",
      "\n",
      "Epoch: [38][1/16]\tTime 0.190 (0.622)\tETA 0:00:02\tTraining Loss 1.4653 (1.4690)\n",
      "\n",
      "Epoch: [38][2/16]\tTime 0.186 (0.808)\tETA 0:00:02\tTraining Loss 1.4712 (1.4697)\n",
      "\n",
      "Epoch: [38][3/16]\tTime 0.184 (0.992)\tETA 0:00:02\tTraining Loss 1.4692 (1.4696)\n",
      "\n",
      "Epoch: [38][4/16]\tTime 0.186 (1.178)\tETA 0:00:02\tTraining Loss 1.4746 (1.4706)\n",
      "\n",
      "Epoch: [38][5/16]\tTime 0.190 (1.368)\tETA 0:00:02\tTraining Loss 1.4710 (1.4706)\n",
      "\n",
      "Epoch: [38][6/16]\tTime 0.185 (1.552)\tETA 0:00:01\tTraining Loss 1.4748 (1.4712)\n",
      "\n",
      "Epoch: [38][7/16]\tTime 0.180 (1.732)\tETA 0:00:01\tTraining Loss 1.4680 (1.4708)\n",
      "\n",
      "Epoch: [38][8/16]\tTime 0.185 (1.917)\tETA 0:00:01\tTraining Loss 1.4669 (1.4704)\n",
      "\n",
      "Epoch: [38][9/16]\tTime 0.182 (2.099)\tETA 0:00:01\tTraining Loss 1.4789 (1.4713)\n",
      "\n",
      "Epoch: [38][10/16]\tTime 0.192 (2.291)\tETA 0:00:01\tTraining Loss 1.4682 (1.4710)\n",
      "\n",
      "Epoch: [38][11/16]\tTime 0.189 (2.480)\tETA 0:00:00\tTraining Loss 1.4638 (1.4704)\n",
      "\n",
      "Epoch: [38][12/16]\tTime 0.192 (2.672)\tETA 0:00:00\tTraining Loss 1.4632 (1.4698)\n",
      "\n",
      "Epoch: [38][13/16]\tTime 0.182 (2.854)\tETA 0:00:00\tTraining Loss 1.4631 (1.4693)\n",
      "\n",
      "Epoch: [38][14/16]\tTime 0.186 (3.040)\tETA 0:00:00\tTraining Loss 1.4823 (1.4702)\n",
      "\n",
      "Epoch: [38][15/16]\tTime 0.113 (3.153)\tETA 0:00:00\tTraining Loss 1.4691 (1.4702)\n",
      "_\n",
      "Validation stats                    IoU        F1      Prec    recall       Acc\n",
      "bg,          0.938900  0.968500  0.978400  0.958900  0.945800\n",
      "real apple   0.000000  0.000000  0.000000  0.000000  0.934200\n",
      "real pepper  0.000000  0.000000  0.000000  0.000000  1.000000\n",
      "real grape   0.536200  0.698000  0.892200  0.573300  0.967900\n",
      "fake apple   0.000000  0.000000  0.000000  0.000000  0.956300\n",
      "fake pepper  0.000000  0.000000  0.000000  0.000000  0.970700\n",
      "fake grape   0.000000  0.000000  0.000000  0.000000  0.966900\n",
      "total        0.210729  0.238071  0.267229  0.218886  0.963114\n",
      "total(-bg)   0.089367  0.116333  0.148700  0.095550  0.966000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: [39][0/16]\tTime 0.458 (0.458)\tETA 0:00:07\tTraining Loss 1.4701 (1.4701)\n",
      "\n",
      "Epoch: [39][1/16]\tTime 0.183 (0.640)\tETA 0:00:02\tTraining Loss 1.4779 (1.4740)\n",
      "\n",
      "Epoch: [39][2/16]\tTime 0.192 (0.832)\tETA 0:00:02\tTraining Loss 1.4659 (1.4713)\n",
      "\n",
      "Epoch: [39][3/16]\tTime 0.189 (1.022)\tETA 0:00:02\tTraining Loss 1.4655 (1.4698)\n",
      "\n",
      "Epoch: [39][4/16]\tTime 0.187 (1.209)\tETA 0:00:02\tTraining Loss 1.4688 (1.4696)\n",
      "\n",
      "Epoch: [39][5/16]\tTime 0.184 (1.393)\tETA 0:00:02\tTraining Loss 1.4641 (1.4687)\n",
      "\n",
      "Epoch: [39][6/16]\tTime 0.188 (1.581)\tETA 0:00:01\tTraining Loss 1.4639 (1.4680)\n",
      "\n",
      "Epoch: [39][7/16]\tTime 0.180 (1.761)\tETA 0:00:01\tTraining Loss 1.4632 (1.4674)\n",
      "\n",
      "Epoch: [39][8/16]\tTime 0.183 (1.944)\tETA 0:00:01\tTraining Loss 1.4595 (1.4665)\n",
      "\n",
      "Epoch: [39][9/16]\tTime 0.188 (2.132)\tETA 0:00:01\tTraining Loss 1.4646 (1.4664)\n",
      "\n",
      "Epoch: [39][10/16]\tTime 0.193 (2.325)\tETA 0:00:01\tTraining Loss 1.4659 (1.4663)\n",
      "\n",
      "Epoch: [39][11/16]\tTime 0.181 (2.506)\tETA 0:00:00\tTraining Loss 1.4665 (1.4663)\n",
      "\n",
      "Epoch: [39][12/16]\tTime 0.185 (2.690)\tETA 0:00:00\tTraining Loss 1.4557 (1.4655)\n",
      "\n",
      "Epoch: [39][13/16]\tTime 0.189 (2.879)\tETA 0:00:00\tTraining Loss 1.4608 (1.4652)\n",
      "\n",
      "Epoch: [39][14/16]\tTime 0.182 (3.061)\tETA 0:00:00\tTraining Loss 1.4669 (1.4653)\n",
      "\n",
      "Epoch: [39][15/16]\tTime 0.113 (3.174)\tETA 0:00:00\tTraining Loss 1.4606 (1.4651)\n",
      "_\n",
      "Validation stats                    IoU        F1      Prec    recall       Acc\n",
      "bg,          0.941100  0.969600  0.977100  0.962400  0.947600\n",
      "real apple   0.000000  0.000000  0.000000  0.000000  0.934300\n",
      "real pepper  0.000000  0.000000  0.000000  0.000000  1.000000\n",
      "real grape   0.353000  0.521800  0.907400  0.366200  0.956500\n",
      "fake apple   0.000000  0.000000  0.000000  0.000000  0.958400\n",
      "fake pepper  0.000000  0.000000  0.000000  0.000000  0.971200\n",
      "fake grape   0.000000  0.000000  0.000000  0.000000  0.952900\n",
      "total        0.184871  0.213057  0.269214  0.189800  0.960129\n",
      "total(-bg)   0.058833  0.086967  0.151233  0.061033  0.962217\n",
      "\n",
      "Epoch: [40][0/16]\tTime 0.479 (0.479)\tETA 0:00:07\tTraining Loss 1.4578 (1.4578)\n",
      "\n",
      "Epoch: [40][1/16]\tTime 0.185 (0.665)\tETA 0:00:02\tTraining Loss 1.4646 (1.4612)\n",
      "\n",
      "Epoch: [40][2/16]\tTime 0.192 (0.857)\tETA 0:00:02\tTraining Loss 1.4544 (1.4589)\n",
      "\n",
      "Epoch: [40][3/16]\tTime 0.194 (1.051)\tETA 0:00:02\tTraining Loss 1.4511 (1.4570)\n",
      "\n",
      "Epoch: [40][4/16]\tTime 0.180 (1.231)\tETA 0:00:02\tTraining Loss 1.4609 (1.4577)\n",
      "\n",
      "Epoch: [40][5/16]\tTime 0.182 (1.413)\tETA 0:00:01\tTraining Loss 1.4543 (1.4572)\n",
      "\n",
      "Epoch: [40][6/16]\tTime 0.192 (1.605)\tETA 0:00:01\tTraining Loss 1.4583 (1.4573)\n",
      "\n",
      "Epoch: [40][7/16]\tTime 0.188 (1.793)\tETA 0:00:01\tTraining Loss 1.4563 (1.4572)\n",
      "\n",
      "Epoch: [40][8/16]\tTime 0.186 (1.979)\tETA 0:00:01\tTraining Loss 1.4522 (1.4567)\n",
      "\n",
      "Epoch: [40][9/16]\tTime 0.181 (2.160)\tETA 0:00:01\tTraining Loss 1.4586 (1.4568)\n",
      "\n",
      "Epoch: [40][10/16]\tTime 0.186 (2.346)\tETA 0:00:01\tTraining Loss 1.4579 (1.4569)\n",
      "\n",
      "Epoch: [40][11/16]\tTime 0.192 (2.538)\tETA 0:00:00\tTraining Loss 1.4781 (1.4587)\n",
      "\n",
      "Epoch: [40][12/16]\tTime 0.187 (2.725)\tETA 0:00:00\tTraining Loss 1.4554 (1.4584)\n",
      "\n",
      "Epoch: [40][13/16]\tTime 0.181 (2.906)\tETA 0:00:00\tTraining Loss 1.4496 (1.4578)\n",
      "\n",
      "Epoch: [40][14/16]\tTime 0.184 (3.090)\tETA 0:00:00\tTraining Loss 1.4582 (1.4578)\n",
      "\n",
      "Epoch: [40][15/16]\tTime 0.113 (3.202)\tETA 0:00:00\tTraining Loss 1.4605 (1.4579)\n",
      "_\n",
      "Validation stats                    IoU        F1      Prec    recall       Acc\n",
      "bg,          0.934000  0.965800  0.978500  0.953500  0.941400\n",
      "real apple   0.000200  0.000500  0.105300  0.000200  0.934200\n",
      "real pepper  0.000000  0.000000  0.000000  0.000000  1.000000\n",
      "real grape   0.451700  0.622300  0.861900  0.487000  0.961700\n",
      "fake apple   0.000000  0.000000  0.000000  0.000000  0.951900\n",
      "fake pepper  0.000000  0.000000  0.000000  0.000000  0.977600\n",
      "fake grape   0.000000  0.000000  0.000000  0.000000  0.954600\n",
      "total        0.197986  0.226943  0.277957  0.205814  0.960200\n",
      "total(-bg)   0.075317  0.103800  0.161200  0.081200  0.963333\n",
      "\n",
      "Epoch: [41][0/16]\tTime 0.441 (0.441)\tETA 0:00:07\tTraining Loss 1.4483 (1.4483)\n",
      "\n",
      "Epoch: [41][1/16]\tTime 0.184 (0.625)\tETA 0:00:02\tTraining Loss 1.4536 (1.4510)\n",
      "\n",
      "Epoch: [41][2/16]\tTime 0.188 (0.813)\tETA 0:00:02\tTraining Loss 1.4564 (1.4528)\n",
      "\n",
      "Epoch: [41][3/16]\tTime 0.183 (0.997)\tETA 0:00:02\tTraining Loss 1.4511 (1.4523)\n",
      "\n",
      "Epoch: [41][4/16]\tTime 0.187 (1.183)\tETA 0:00:02\tTraining Loss 1.4507 (1.4520)\n",
      "\n",
      "Epoch: [41][5/16]\tTime 0.186 (1.369)\tETA 0:00:02\tTraining Loss 1.4507 (1.4518)\n",
      "\n",
      "Epoch: [41][6/16]\tTime 0.187 (1.556)\tETA 0:00:01\tTraining Loss 1.4496 (1.4515)\n",
      "\n",
      "Epoch: [41][7/16]\tTime 0.194 (1.750)\tETA 0:00:01\tTraining Loss 1.4503 (1.4513)\n",
      "\n",
      "Epoch: [41][8/16]\tTime 0.183 (1.933)\tETA 0:00:01\tTraining Loss 1.4531 (1.4515)\n",
      "\n",
      "Epoch: [41][9/16]\tTime 0.189 (2.122)\tETA 0:00:01\tTraining Loss 1.4475 (1.4511)\n",
      "\n",
      "Epoch: [41][10/16]\tTime 0.184 (2.306)\tETA 0:00:01\tTraining Loss 1.4492 (1.4510)\n",
      "\n",
      "Epoch: [41][11/16]\tTime 0.191 (2.497)\tETA 0:00:00\tTraining Loss 1.4525 (1.4511)\n",
      "\n",
      "Epoch: [41][12/16]\tTime 0.185 (2.683)\tETA 0:00:00\tTraining Loss 1.4500 (1.4510)\n",
      "\n",
      "Epoch: [41][13/16]\tTime 0.187 (2.870)\tETA 0:00:00\tTraining Loss 1.4443 (1.4505)\n",
      "\n",
      "Epoch: [41][14/16]\tTime 0.190 (3.059)\tETA 0:00:00\tTraining Loss 1.4473 (1.4503)\n",
      "\n",
      "Epoch: [41][15/16]\tTime 0.113 (3.173)\tETA 0:00:00\tTraining Loss 1.4546 (1.4504)\n",
      "_\n",
      "Validation stats                    IoU        F1      Prec    recall       Acc\n",
      "bg,          0.948700  0.973600  0.978300  0.969100  0.954400\n",
      "real apple   0.000100  0.000200  0.076900  0.000100  0.934200\n",
      "real pepper  0.000000  0.000000  0.000000  0.000000  1.000000\n",
      "real grape   0.559500  0.717500  0.892800  0.599700  0.969400\n",
      "fake apple   0.000000  0.000000  0.000000  0.000000  0.946700\n",
      "fake pepper  0.000000  0.000000  0.000000  0.000000  0.987300\n",
      "fake grape   0.000000  0.000000  0.000000  0.000000  0.971000\n",
      "total        0.215471  0.241614  0.278286  0.224129  0.966143\n",
      "total(-bg)   0.093267  0.119617  0.161617  0.099967  0.968100\n",
      "\n",
      "Epoch: [42][0/16]\tTime 0.481 (0.481)\tETA 0:00:07\tTraining Loss 1.4459 (1.4459)\n",
      "\n",
      "Epoch: [42][1/16]\tTime 0.187 (0.669)\tETA 0:00:02\tTraining Loss 1.4469 (1.4464)\n",
      "\n",
      "Epoch: [42][2/16]\tTime 0.191 (0.859)\tETA 0:00:02\tTraining Loss 1.4475 (1.4468)\n",
      "\n",
      "Epoch: [42][3/16]\tTime 0.184 (1.043)\tETA 0:00:02\tTraining Loss 1.4458 (1.4465)\n",
      "\n",
      "Epoch: [42][4/16]\tTime 0.190 (1.233)\tETA 0:00:02\tTraining Loss 1.4447 (1.4462)\n",
      "\n",
      "Epoch: [42][5/16]\tTime 0.185 (1.418)\tETA 0:00:02\tTraining Loss 1.4471 (1.4463)\n",
      "\n",
      "Epoch: [42][6/16]\tTime 0.188 (1.606)\tETA 0:00:01\tTraining Loss 1.4413 (1.4456)\n",
      "\n",
      "Epoch: [42][7/16]\tTime 0.179 (1.785)\tETA 0:00:01\tTraining Loss 1.4487 (1.4460)\n",
      "\n",
      "Epoch: [42][8/16]\tTime 0.192 (1.977)\tETA 0:00:01\tTraining Loss 1.4433 (1.4457)\n",
      "\n",
      "Epoch: [42][9/16]\tTime 0.183 (2.160)\tETA 0:00:01\tTraining Loss 1.4464 (1.4458)\n",
      "\n",
      "Epoch: [42][10/16]\tTime 0.189 (2.349)\tETA 0:00:01\tTraining Loss 1.4418 (1.4454)\n",
      "\n",
      "Epoch: [42][11/16]\tTime 0.190 (2.539)\tETA 0:00:00\tTraining Loss 1.4421 (1.4451)\n",
      "\n",
      "Epoch: [42][12/16]\tTime 0.184 (2.723)\tETA 0:00:00\tTraining Loss 1.4393 (1.4447)\n",
      "\n",
      "Epoch: [42][13/16]\tTime 0.188 (2.911)\tETA 0:00:00\tTraining Loss 1.4434 (1.4446)\n",
      "\n",
      "Epoch: [42][14/16]\tTime 0.182 (3.093)\tETA 0:00:00\tTraining Loss 1.4467 (1.4447)\n",
      "\n",
      "Epoch: [42][15/16]\tTime 0.117 (3.210)\tETA 0:00:00\tTraining Loss 1.4556 (1.4451)\n",
      "_\n",
      "Validation stats                    IoU        F1      Prec   recall       Acc\n",
      "bg,          0.941700  0.969900  0.974500  0.96550  0.948000\n",
      "real apple   0.000000  0.000000  0.000000  0.00000  0.934300\n",
      "real pepper  0.000000  0.000000  0.000000  0.00000  1.000000\n",
      "real grape   0.069700  0.130400  0.870500  0.07050  0.939100\n",
      "fake apple   0.000000  0.000000  0.000000  0.00000  0.942200\n",
      "fake pepper  0.000000  0.000000  0.000000  0.00000  0.990800\n",
      "fake grape   0.000000  0.000000  0.000000  0.00000  0.933800\n",
      "total        0.144486  0.157186  0.263571  0.14800  0.955457\n",
      "total(-bg)   0.011617  0.021733  0.145083  0.01175  0.956700\n",
      "\n",
      "Epoch: [43][0/16]\tTime 0.476 (0.476)\tETA 0:00:07\tTraining Loss 1.4420 (1.4420)\n",
      "\n",
      "Epoch: [43][1/16]\tTime 0.181 (0.658)\tETA 0:00:02\tTraining Loss 1.4436 (1.4428)\n",
      "\n",
      "Epoch: [43][2/16]\tTime 0.181 (0.838)\tETA 0:00:02\tTraining Loss 1.4373 (1.4410)\n",
      "\n",
      "Epoch: [43][3/16]\tTime 0.182 (1.021)\tETA 0:00:02\tTraining Loss 1.4534 (1.4441)\n",
      "\n",
      "Epoch: [43][4/16]\tTime 0.183 (1.203)\tETA 0:00:02\tTraining Loss 1.4397 (1.4432)\n",
      "\n",
      "Epoch: [43][5/16]\tTime 0.183 (1.386)\tETA 0:00:02\tTraining Loss 1.4399 (1.4427)\n",
      "\n",
      "Epoch: [43][6/16]\tTime 0.192 (1.578)\tETA 0:00:01\tTraining Loss 1.4441 (1.4429)\n",
      "\n",
      "Epoch: [43][7/16]\tTime 0.185 (1.763)\tETA 0:00:01\tTraining Loss 1.4378 (1.4422)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: [43][8/16]\tTime 0.191 (1.955)\tETA 0:00:01\tTraining Loss 1.4404 (1.4420)\n",
      "\n",
      "Epoch: [43][9/16]\tTime 0.183 (2.137)\tETA 0:00:01\tTraining Loss 1.4358 (1.4414)\n",
      "\n",
      "Epoch: [43][10/16]\tTime 0.190 (2.327)\tETA 0:00:01\tTraining Loss 1.4421 (1.4415)\n",
      "\n",
      "Epoch: [43][11/16]\tTime 0.205 (2.532)\tETA 0:00:01\tTraining Loss 1.4383 (1.4412)\n",
      "\n",
      "Epoch: [43][12/16]\tTime 0.177 (2.709)\tETA 0:00:00\tTraining Loss 1.4370 (1.4409)\n",
      "\n",
      "Epoch: [43][13/16]\tTime 0.185 (2.894)\tETA 0:00:00\tTraining Loss 1.4441 (1.4411)\n",
      "\n",
      "Epoch: [43][14/16]\tTime 0.177 (3.071)\tETA 0:00:00\tTraining Loss 1.4424 (1.4412)\n",
      "\n",
      "Epoch: [43][15/16]\tTime 0.114 (3.185)\tETA 0:00:00\tTraining Loss 1.4494 (1.4415)\n",
      "_\n",
      "Validation stats                    IoU        F1      Prec  recall     Acc\n",
      "bg,          0.945400  0.971900  0.976800  0.9671  0.9514\n",
      "real apple   0.000100  0.000200  0.250000  0.0001  0.9343\n",
      "real pepper  0.000000  0.000000  0.000000  0.0000  1.0000\n",
      "real grape   0.142900  0.250000  0.672700  0.1535  0.9404\n",
      "fake apple   0.000000  0.000000  0.000000  0.0000  0.9522\n",
      "fake pepper  0.000000  0.000000  0.000000  0.0000  0.9809\n",
      "fake grape   0.000000  0.000000  0.000000  0.0000  0.9426\n",
      "total        0.155486  0.174586  0.271357  0.1601  0.9574\n",
      "total(-bg)   0.023833  0.041700  0.153783  0.0256  0.9584\n",
      "\n",
      "Epoch: [44][0/16]\tTime 0.534 (0.534)\tETA 0:00:08\tTraining Loss 1.4350 (1.4350)\n",
      "\n",
      "Epoch: [44][1/16]\tTime 0.192 (0.726)\tETA 0:00:02\tTraining Loss 1.4436 (1.4393)\n",
      "\n",
      "Epoch: [44][2/16]\tTime 0.194 (0.921)\tETA 0:00:02\tTraining Loss 1.4366 (1.4384)\n",
      "\n",
      "Epoch: [44][3/16]\tTime 0.195 (1.115)\tETA 0:00:02\tTraining Loss 1.4422 (1.4393)\n",
      "\n",
      "Epoch: [44][4/16]\tTime 0.184 (1.299)\tETA 0:00:02\tTraining Loss 1.4415 (1.4398)\n",
      "\n",
      "Epoch: [44][5/16]\tTime 0.193 (1.492)\tETA 0:00:02\tTraining Loss 1.4309 (1.4383)\n",
      "\n",
      "Epoch: [44][6/16]\tTime 0.194 (1.686)\tETA 0:00:01\tTraining Loss 1.4347 (1.4378)\n",
      "\n",
      "Epoch: [44][7/16]\tTime 0.189 (1.875)\tETA 0:00:01\tTraining Loss 1.4343 (1.4374)\n",
      "\n",
      "Epoch: [44][8/16]\tTime 0.187 (2.062)\tETA 0:00:01\tTraining Loss 1.4371 (1.4373)\n",
      "\n",
      "Epoch: [44][9/16]\tTime 0.192 (2.254)\tETA 0:00:01\tTraining Loss 1.4423 (1.4378)\n",
      "\n",
      "Epoch: [44][10/16]\tTime 0.189 (2.443)\tETA 0:00:01\tTraining Loss 1.4356 (1.4376)\n",
      "\n",
      "Epoch: [44][11/16]\tTime 0.186 (2.629)\tETA 0:00:00\tTraining Loss 1.4340 (1.4373)\n",
      "\n",
      "Epoch: [44][12/16]\tTime 0.189 (2.818)\tETA 0:00:00\tTraining Loss 1.4306 (1.4368)\n",
      "\n",
      "Epoch: [44][13/16]\tTime 0.194 (3.012)\tETA 0:00:00\tTraining Loss 1.4374 (1.4369)\n",
      "\n",
      "Epoch: [44][14/16]\tTime 0.182 (3.194)\tETA 0:00:00\tTraining Loss 1.4351 (1.4367)\n",
      "\n",
      "Epoch: [44][15/16]\tTime 0.113 (3.307)\tETA 0:00:00\tTraining Loss 1.4449 (1.4370)\n",
      "_\n",
      "Validation stats                    IoU        F1      Prec    recall     Acc\n",
      "bg,          0.943200  0.970700  0.978100  0.963500  0.9495\n",
      "real apple   0.000200  0.000500  0.222200  0.000200  0.9342\n",
      "real pepper  0.000000  0.000000  0.000000  0.000000  1.0000\n",
      "real grape   0.588200  0.740600  0.921800  0.619100  0.9719\n",
      "fake apple   0.000000  0.000000  0.000000  0.000000  0.9527\n",
      "fake pepper  0.000000  0.000000  0.000000  0.000000  0.9780\n",
      "fake grape   0.000000  0.000000  0.000000  0.000000  0.9694\n",
      "total        0.218800  0.244543  0.303157  0.226114  0.9651\n",
      "total(-bg)   0.098067  0.123517  0.190667  0.103217  0.9677\n",
      "\n",
      "Epoch: [45][0/16]\tTime 0.403 (0.403)\tETA 0:00:06\tTraining Loss 1.4311 (1.4311)\n",
      "\n",
      "Epoch: [45][1/16]\tTime 0.192 (0.595)\tETA 0:00:02\tTraining Loss 1.4302 (1.4307)\n",
      "\n",
      "Epoch: [45][2/16]\tTime 0.191 (0.786)\tETA 0:00:02\tTraining Loss 1.4322 (1.4312)\n",
      "\n",
      "Epoch: [45][3/16]\tTime 0.184 (0.970)\tETA 0:00:02\tTraining Loss 1.4278 (1.4304)\n",
      "\n",
      "Epoch: [45][4/16]\tTime 0.191 (1.161)\tETA 0:00:02\tTraining Loss 1.4290 (1.4301)\n",
      "\n",
      "Epoch: [45][5/16]\tTime 0.190 (1.352)\tETA 0:00:02\tTraining Loss 1.4262 (1.4294)\n",
      "\n",
      "Epoch: [45][6/16]\tTime 0.194 (1.546)\tETA 0:00:01\tTraining Loss 1.4305 (1.4296)\n",
      "\n",
      "Epoch: [45][7/16]\tTime 0.186 (1.731)\tETA 0:00:01\tTraining Loss 1.4323 (1.4299)\n",
      "\n",
      "Epoch: [45][8/16]\tTime 0.200 (1.931)\tETA 0:00:01\tTraining Loss 1.4301 (1.4300)\n",
      "\n",
      "Epoch: [45][9/16]\tTime 0.184 (2.115)\tETA 0:00:01\tTraining Loss 1.4374 (1.4307)\n",
      "\n",
      "Epoch: [45][10/16]\tTime 0.196 (2.312)\tETA 0:00:01\tTraining Loss 1.4352 (1.4311)\n",
      "\n",
      "Epoch: [45][11/16]\tTime 0.197 (2.508)\tETA 0:00:00\tTraining Loss 1.4263 (1.4307)\n",
      "\n",
      "Epoch: [45][12/16]\tTime 0.190 (2.699)\tETA 0:00:00\tTraining Loss 1.4287 (1.4306)\n",
      "\n",
      "Epoch: [45][13/16]\tTime 0.187 (2.886)\tETA 0:00:00\tTraining Loss 1.4307 (1.4306)\n",
      "\n",
      "Epoch: [45][14/16]\tTime 0.197 (3.083)\tETA 0:00:00\tTraining Loss 1.4270 (1.4303)\n",
      "\n",
      "Epoch: [45][15/16]\tTime 0.110 (3.194)\tETA 0:00:00\tTraining Loss 1.4231 (1.4301)\n",
      "_\n",
      "Validation stats                    IoU        F1      Prec    recall       Acc\n",
      "bg,          0.942700  0.970500  0.978900  0.962300  0.949200\n",
      "real apple   0.000000  0.000000  0.000000  0.000000  0.934300\n",
      "real pepper  0.000000  0.000000  0.000000  0.000000  1.000000\n",
      "real grape   0.491500  0.659000  0.880300  0.526700  0.964700\n",
      "fake apple   0.000000  0.000000  0.000000  0.000000  0.948100\n",
      "fake pepper  0.000000  0.000000  0.000000  0.000000  0.982300\n",
      "fake grape   0.000000  0.000000  0.000000  0.000000  0.963200\n",
      "total        0.204886  0.232786  0.265600  0.212714  0.963114\n",
      "total(-bg)   0.081917  0.109833  0.146717  0.087783  0.965433\n",
      "\n",
      "Epoch: [46][0/16]\tTime 0.482 (0.482)\tETA 0:00:07\tTraining Loss 1.4268 (1.4268)\n",
      "\n",
      "Epoch: [46][1/16]\tTime 0.183 (0.665)\tETA 0:00:02\tTraining Loss 1.4300 (1.4284)\n",
      "\n",
      "Epoch: [46][2/16]\tTime 0.191 (0.856)\tETA 0:00:02\tTraining Loss 1.4381 (1.4316)\n",
      "\n",
      "Epoch: [46][3/16]\tTime 0.182 (1.038)\tETA 0:00:02\tTraining Loss 1.4198 (1.4287)\n",
      "\n",
      "Epoch: [46][4/16]\tTime 0.184 (1.222)\tETA 0:00:02\tTraining Loss 1.4273 (1.4284)\n",
      "\n",
      "Epoch: [46][5/16]\tTime 0.187 (1.409)\tETA 0:00:02\tTraining Loss 1.4218 (1.4273)\n",
      "\n",
      "Epoch: [46][6/16]\tTime 0.185 (1.594)\tETA 0:00:01\tTraining Loss 1.4229 (1.4267)\n",
      "\n",
      "Epoch: [46][7/16]\tTime 0.180 (1.774)\tETA 0:00:01\tTraining Loss 1.4186 (1.4257)\n",
      "\n",
      "Epoch: [46][8/16]\tTime 0.188 (1.962)\tETA 0:00:01\tTraining Loss 1.4211 (1.4252)\n",
      "\n",
      "Epoch: [46][9/16]\tTime 0.186 (2.148)\tETA 0:00:01\tTraining Loss 1.4250 (1.4252)\n",
      "\n",
      "Epoch: [46][10/16]\tTime 0.190 (2.338)\tETA 0:00:01\tTraining Loss 1.4247 (1.4251)\n",
      "\n",
      "Epoch: [46][11/16]\tTime 0.192 (2.530)\tETA 0:00:00\tTraining Loss 1.4260 (1.4252)\n",
      "\n",
      "Epoch: [46][12/16]\tTime 0.179 (2.709)\tETA 0:00:00\tTraining Loss 1.4237 (1.4251)\n",
      "\n",
      "Epoch: [46][13/16]\tTime 0.198 (2.908)\tETA 0:00:00\tTraining Loss 1.4181 (1.4246)\n",
      "\n",
      "Epoch: [46][14/16]\tTime 0.186 (3.094)\tETA 0:00:00\tTraining Loss 1.4256 (1.4246)\n",
      "\n",
      "Epoch: [46][15/16]\tTime 0.112 (3.207)\tETA 0:00:00\tTraining Loss 1.4193 (1.4245)\n",
      "_\n",
      "Validation stats                    IoU        F1      Prec    recall       Acc\n",
      "bg,          0.949000  0.973800  0.975300  0.972300  0.954500\n",
      "real apple   0.005200  0.010400  0.918400  0.005200  0.934600\n",
      "real pepper  0.000000  0.000000  0.000000  0.000000  1.000000\n",
      "real grape   0.769400  0.869600  0.921900  0.823000  0.984000\n",
      "fake apple   0.000000  0.000000  0.000000  0.000000  0.951300\n",
      "fake pepper  0.000000  0.000000  0.000000  0.000000  0.984900\n",
      "fake grape   0.000000  0.000000  0.000000  0.000000  0.988800\n",
      "total        0.246229  0.264829  0.402229  0.257214  0.971157\n",
      "total(-bg)   0.129100  0.146667  0.306717  0.138033  0.973933\n",
      "\n",
      "Epoch: [47][0/16]\tTime 0.441 (0.441)\tETA 0:00:07\tTraining Loss 1.4232 (1.4232)\n",
      "\n",
      "Epoch: [47][1/16]\tTime 0.182 (0.623)\tETA 0:00:02\tTraining Loss 1.4323 (1.4277)\n",
      "\n",
      "Epoch: [47][2/16]\tTime 0.193 (0.816)\tETA 0:00:02\tTraining Loss 1.4202 (1.4252)\n",
      "\n",
      "Epoch: [47][3/16]\tTime 0.185 (1.001)\tETA 0:00:02\tTraining Loss 1.4176 (1.4233)\n",
      "\n",
      "Epoch: [47][4/16]\tTime 0.180 (1.181)\tETA 0:00:02\tTraining Loss 1.4157 (1.4218)\n",
      "\n",
      "Epoch: [47][5/16]\tTime 0.190 (1.371)\tETA 0:00:02\tTraining Loss 1.4197 (1.4214)\n",
      "\n",
      "Epoch: [47][6/16]\tTime 0.189 (1.561)\tETA 0:00:01\tTraining Loss 1.4210 (1.4214)\n",
      "\n",
      "Epoch: [47][7/16]\tTime 0.192 (1.753)\tETA 0:00:01\tTraining Loss 1.4221 (1.4215)\n",
      "\n",
      "Epoch: [47][8/16]\tTime 0.190 (1.942)\tETA 0:00:01\tTraining Loss 1.4276 (1.4221)\n",
      "\n",
      "Epoch: [47][9/16]\tTime 0.194 (2.136)\tETA 0:00:01\tTraining Loss 1.4253 (1.4225)\n",
      "\n",
      "Epoch: [47][10/16]\tTime 0.190 (2.326)\tETA 0:00:01\tTraining Loss 1.4257 (1.4228)\n",
      "\n",
      "Epoch: [47][11/16]\tTime 0.172 (2.498)\tETA 0:00:00\tTraining Loss 1.4151 (1.4221)\n",
      "\n",
      "Epoch: [47][12/16]\tTime 0.193 (2.691)\tETA 0:00:00\tTraining Loss 1.4150 (1.4216)\n",
      "\n",
      "Epoch: [47][13/16]\tTime 0.190 (2.881)\tETA 0:00:00\tTraining Loss 1.4146 (1.4211)\n",
      "\n",
      "Epoch: [47][14/16]\tTime 0.188 (3.069)\tETA 0:00:00\tTraining Loss 1.4150 (1.4207)\n",
      "\n",
      "Epoch: [47][15/16]\tTime 0.116 (3.184)\tETA 0:00:00\tTraining Loss 1.4221 (1.4207)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_\n",
      "Validation stats                    IoU        F1      Prec    recall       Acc\n",
      "bg,          0.943200  0.970700  0.980100  0.961700  0.949700\n",
      "real apple   0.018700  0.036700  0.760600  0.018800  0.935100\n",
      "real pepper  0.000000  0.000000  0.000000  0.000000  1.000000\n",
      "real grape   0.588300  0.740700  0.886100  0.636400  0.971200\n",
      "fake apple   0.000000  0.000000  0.000000  0.000000  0.939300\n",
      "fake pepper  0.000000  0.000000  0.000000  0.000000  0.995600\n",
      "fake grape   0.000000  0.000000  0.000000  0.000000  0.966400\n",
      "total        0.221457  0.249729  0.375257  0.230986  0.965329\n",
      "total(-bg)   0.101167  0.129567  0.274450  0.109200  0.967933\n",
      "\n",
      "Epoch: [48][0/16]\tTime 0.348 (0.348)\tETA 0:00:05\tTraining Loss 1.4141 (1.4141)\n",
      "\n",
      "Epoch: [48][1/16]\tTime 0.183 (0.530)\tETA 0:00:02\tTraining Loss 1.4210 (1.4175)\n",
      "\n",
      "Epoch: [48][2/16]\tTime 0.188 (0.719)\tETA 0:00:02\tTraining Loss 1.4178 (1.4176)\n",
      "\n",
      "Epoch: [48][3/16]\tTime 0.196 (0.915)\tETA 0:00:02\tTraining Loss 1.4142 (1.4168)\n",
      "\n",
      "Epoch: [48][4/16]\tTime 0.181 (1.096)\tETA 0:00:02\tTraining Loss 1.4139 (1.4162)\n",
      "\n",
      "Epoch: [48][5/16]\tTime 0.189 (1.285)\tETA 0:00:02\tTraining Loss 1.4095 (1.4151)\n",
      "\n",
      "Epoch: [48][6/16]\tTime 0.188 (1.473)\tETA 0:00:01\tTraining Loss 1.4197 (1.4158)\n",
      "\n",
      "Epoch: [48][7/16]\tTime 0.189 (1.662)\tETA 0:00:01\tTraining Loss 1.4098 (1.4150)\n",
      "\n",
      "Epoch: [48][8/16]\tTime 0.201 (1.863)\tETA 0:00:01\tTraining Loss 1.4109 (1.4146)\n",
      "\n",
      "Epoch: [48][9/16]\tTime 0.189 (2.052)\tETA 0:00:01\tTraining Loss 1.4184 (1.4150)\n",
      "\n",
      "Epoch: [48][10/16]\tTime 0.190 (2.243)\tETA 0:00:01\tTraining Loss 1.4208 (1.4155)\n",
      "\n",
      "Epoch: [48][11/16]\tTime 0.179 (2.422)\tETA 0:00:00\tTraining Loss 1.4149 (1.4154)\n",
      "\n",
      "Epoch: [48][12/16]\tTime 0.186 (2.608)\tETA 0:00:00\tTraining Loss 1.4175 (1.4156)\n",
      "\n",
      "Epoch: [48][13/16]\tTime 0.184 (2.792)\tETA 0:00:00\tTraining Loss 1.4175 (1.4157)\n",
      "\n",
      "Epoch: [48][14/16]\tTime 0.184 (2.976)\tETA 0:00:00\tTraining Loss 1.4117 (1.4155)\n",
      "\n",
      "Epoch: [48][15/16]\tTime 0.113 (3.089)\tETA 0:00:00\tTraining Loss 1.4132 (1.4154)\n",
      "_\n",
      "Validation stats                    IoU        F1      Prec    recall       Acc\n",
      "bg,          0.945300  0.971800  0.978300  0.965500  0.951400\n",
      "real apple   0.000000  0.000000  0.000000  0.000000  0.934200\n",
      "real pepper  0.000000  0.000000  0.000000  0.000000  1.000000\n",
      "real grape   0.583800  0.737200  0.867700  0.640900  0.970400\n",
      "fake apple   0.000000  0.000000  0.000000  0.000000  0.951400\n",
      "fake pepper  0.000000  0.000000  0.000000  0.000000  0.979000\n",
      "fake grape   0.000000  0.000000  0.000000  0.000000  0.975600\n",
      "total        0.218443  0.244143  0.263714  0.229486  0.966000\n",
      "total(-bg)   0.097300  0.122867  0.144617  0.106817  0.968433\n",
      "\n",
      "Epoch: [49][0/16]\tTime 0.531 (0.531)\tETA 0:00:08\tTraining Loss 1.4137 (1.4137)\n",
      "\n",
      "Epoch: [49][1/16]\tTime 0.192 (0.723)\tETA 0:00:02\tTraining Loss 1.4077 (1.4107)\n",
      "\n",
      "Epoch: [49][2/16]\tTime 0.194 (0.916)\tETA 0:00:02\tTraining Loss 1.4193 (1.4136)\n",
      "\n",
      "Epoch: [49][3/16]\tTime 0.186 (1.102)\tETA 0:00:02\tTraining Loss 1.4083 (1.4122)\n",
      "\n",
      "Epoch: [49][4/16]\tTime 0.190 (1.293)\tETA 0:00:02\tTraining Loss 1.4123 (1.4123)\n",
      "\n",
      "Epoch: [49][5/16]\tTime 0.190 (1.482)\tETA 0:00:02\tTraining Loss 1.4148 (1.4127)\n",
      "\n",
      "Epoch: [49][6/16]\tTime 0.194 (1.676)\tETA 0:00:01\tTraining Loss 1.4072 (1.4119)\n",
      "\n",
      "Epoch: [49][7/16]\tTime 0.196 (1.872)\tETA 0:00:01\tTraining Loss 1.4105 (1.4117)\n",
      "\n",
      "Epoch: [49][8/16]\tTime 0.193 (2.065)\tETA 0:00:01\tTraining Loss 1.4121 (1.4118)\n",
      "\n",
      "Epoch: [49][9/16]\tTime 0.186 (2.251)\tETA 0:00:01\tTraining Loss 1.4101 (1.4116)\n",
      "\n",
      "Epoch: [49][10/16]\tTime 0.190 (2.441)\tETA 0:00:01\tTraining Loss 1.4035 (1.4109)\n",
      "\n",
      "Epoch: [49][11/16]\tTime 0.198 (2.639)\tETA 0:00:00\tTraining Loss 1.4040 (1.4103)\n",
      "\n",
      "Epoch: [49][12/16]\tTime 0.184 (2.823)\tETA 0:00:00\tTraining Loss 1.4074 (1.4101)\n",
      "\n",
      "Epoch: [49][13/16]\tTime 0.199 (3.022)\tETA 0:00:00\tTraining Loss 1.4053 (1.4097)\n",
      "\n",
      "Epoch: [49][14/16]\tTime 0.195 (3.217)\tETA 0:00:00\tTraining Loss 1.4052 (1.4094)\n",
      "\n",
      "Epoch: [49][15/16]\tTime 0.116 (3.333)\tETA 0:00:00\tTraining Loss 1.4310 (1.4101)\n",
      "_\n",
      "Validation stats                    IoU        F1      Prec    recall       Acc\n",
      "bg,          0.947900  0.973200  0.978800  0.967800  0.953800\n",
      "real apple   0.038200  0.073500  0.901600  0.038300  0.936500\n",
      "real pepper  0.000000  0.000000  0.000000  0.000000  1.000000\n",
      "real grape   0.147900  0.257700  0.749300  0.155600  0.942000\n",
      "fake apple   0.000000  0.000000  0.000000  0.000000  0.940700\n",
      "fake pepper  0.000000  0.000000  0.000000  0.000000  0.986700\n",
      "fake grape   0.000000  0.000000  0.000000  0.000000  0.948600\n",
      "total        0.162000  0.186343  0.375671  0.165957  0.958329\n",
      "total(-bg)   0.031017  0.055200  0.275150  0.032317  0.959083\n",
      "\n",
      "Epoch: [50][0/16]\tTime 0.502 (0.502)\tETA 0:00:08\tTraining Loss 1.4050 (1.4050)\n",
      "\n",
      "Epoch: [50][1/16]\tTime 0.186 (0.687)\tETA 0:00:02\tTraining Loss 1.4065 (1.4057)\n",
      "\n",
      "Epoch: [50][2/16]\tTime 0.185 (0.873)\tETA 0:00:02\tTraining Loss 1.4094 (1.4070)\n",
      "\n",
      "Epoch: [50][3/16]\tTime 0.173 (1.045)\tETA 0:00:02\tTraining Loss 1.4144 (1.4088)\n",
      "\n",
      "Epoch: [50][4/16]\tTime 0.195 (1.240)\tETA 0:00:02\tTraining Loss 1.4078 (1.4086)\n",
      "\n",
      "Epoch: [50][5/16]\tTime 0.187 (1.428)\tETA 0:00:02\tTraining Loss 1.4072 (1.4084)\n",
      "\n",
      "Epoch: [50][6/16]\tTime 0.192 (1.619)\tETA 0:00:01\tTraining Loss 1.4066 (1.4081)\n",
      "\n",
      "Epoch: [50][7/16]\tTime 0.203 (1.822)\tETA 0:00:01\tTraining Loss 1.4097 (1.4083)\n",
      "\n",
      "Epoch: [50][8/16]\tTime 0.192 (2.014)\tETA 0:00:01\tTraining Loss 1.4097 (1.4085)\n",
      "\n",
      "Epoch: [50][9/16]\tTime 0.190 (2.204)\tETA 0:00:01\tTraining Loss 1.4035 (1.4080)\n",
      "\n",
      "Epoch: [50][10/16]\tTime 0.184 (2.389)\tETA 0:00:01\tTraining Loss 1.4019 (1.4074)\n",
      "\n",
      "Epoch: [50][11/16]\tTime 0.182 (2.571)\tETA 0:00:00\tTraining Loss 1.4036 (1.4071)\n",
      "\n",
      "Epoch: [50][12/16]\tTime 0.191 (2.762)\tETA 0:00:00\tTraining Loss 1.4046 (1.4069)\n",
      "\n",
      "Epoch: [50][13/16]\tTime 0.179 (2.941)\tETA 0:00:00\tTraining Loss 1.4020 (1.4066)\n",
      "\n",
      "Epoch: [50][14/16]\tTime 0.185 (3.126)\tETA 0:00:00\tTraining Loss 1.4022 (1.4063)\n",
      "\n",
      "Epoch: [50][15/16]\tTime 0.115 (3.241)\tETA 0:00:00\tTraining Loss 1.3959 (1.4060)\n",
      "_\n",
      "Validation stats                    IoU        F1      Prec    recall       Acc\n",
      "bg,          0.948400  0.973500  0.978000  0.969100  0.954200\n",
      "real apple   0.000100  0.000200  0.111100  0.000100  0.934200\n",
      "real pepper  0.000000  0.000000  0.000000  0.000000  1.000000\n",
      "real grape   0.707300  0.828500  0.919300  0.754100  0.979800\n",
      "fake apple   0.000000  0.000000  0.000000  0.000000  0.960300\n",
      "fake pepper  0.000000  0.000000  0.000000  0.000000  0.974000\n",
      "fake grape   0.000000  0.000000  0.000000  0.000000  0.980500\n",
      "total        0.236543  0.257457  0.286914  0.246186  0.969000\n",
      "total(-bg)   0.117900  0.138117  0.171733  0.125700  0.971467\n",
      "\n",
      "Epoch: [51][0/16]\tTime 0.531 (0.531)\tETA 0:00:08\tTraining Loss 1.4036 (1.4036)\n",
      "\n",
      "Epoch: [51][1/16]\tTime 0.196 (0.727)\tETA 0:00:02\tTraining Loss 1.4005 (1.4021)\n",
      "\n",
      "Epoch: [51][2/16]\tTime 0.197 (0.924)\tETA 0:00:02\tTraining Loss 1.4008 (1.4017)\n",
      "\n",
      "Epoch: [51][3/16]\tTime 0.191 (1.115)\tETA 0:00:02\tTraining Loss 1.3965 (1.4004)\n",
      "\n",
      "Epoch: [51][4/16]\tTime 0.193 (1.308)\tETA 0:00:02\tTraining Loss 1.3968 (1.3997)\n",
      "\n",
      "Epoch: [51][5/16]\tTime 0.181 (1.489)\tETA 0:00:01\tTraining Loss 1.4055 (1.4006)\n",
      "\n",
      "Epoch: [51][6/16]\tTime 0.193 (1.682)\tETA 0:00:01\tTraining Loss 1.4090 (1.4018)\n",
      "\n",
      "Epoch: [51][7/16]\tTime 0.183 (1.865)\tETA 0:00:01\tTraining Loss 1.3970 (1.4012)\n",
      "\n",
      "Epoch: [51][8/16]\tTime 0.195 (2.059)\tETA 0:00:01\tTraining Loss 1.4004 (1.4011)\n",
      "\n",
      "Epoch: [51][9/16]\tTime 0.197 (2.256)\tETA 0:00:01\tTraining Loss 1.3953 (1.4005)\n",
      "\n",
      "Epoch: [51][10/16]\tTime 0.202 (2.458)\tETA 0:00:01\tTraining Loss 1.4017 (1.4006)\n",
      "\n",
      "Epoch: [51][11/16]\tTime 0.172 (2.630)\tETA 0:00:00\tTraining Loss 1.4061 (1.4011)\n",
      "\n",
      "Epoch: [51][12/16]\tTime 0.197 (2.827)\tETA 0:00:00\tTraining Loss 1.4013 (1.4011)\n",
      "\n",
      "Epoch: [51][13/16]\tTime 0.188 (3.016)\tETA 0:00:00\tTraining Loss 1.3963 (1.4008)\n",
      "\n",
      "Epoch: [51][14/16]\tTime 0.188 (3.204)\tETA 0:00:00\tTraining Loss 1.3988 (1.4006)\n",
      "\n",
      "Epoch: [51][15/16]\tTime 0.117 (3.321)\tETA 0:00:00\tTraining Loss 1.3935 (1.4004)\n",
      "_\n",
      "Validation stats                    IoU        F1      Prec    recall       Acc\n",
      "bg,          0.945600  0.972000  0.976500  0.967600  0.951600\n",
      "real apple   0.003000  0.006000  0.812500  0.003000  0.934400\n",
      "real pepper  0.000000  0.000000  0.000000  0.000000  1.000000\n",
      "real grape   0.511300  0.676600  0.923400  0.534000  0.967000\n",
      "fake apple   0.000000  0.000000  0.000000  0.000000  0.957200\n",
      "fake pepper  0.000000  0.000000  0.000000  0.000000  0.973200\n",
      "fake grape   0.000000  0.000000  0.000000  0.000000  0.968900\n",
      "total        0.208557  0.236371  0.387486  0.214943  0.964614\n",
      "total(-bg)   0.085717  0.113767  0.289317  0.089500  0.966783\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: [52][0/16]\tTime 0.480 (0.480)\tETA 0:00:07\tTraining Loss 1.3981 (1.3981)\n",
      "\n",
      "Epoch: [52][1/16]\tTime 0.186 (0.666)\tETA 0:00:02\tTraining Loss 1.3969 (1.3975)\n",
      "\n",
      "Epoch: [52][2/16]\tTime 0.189 (0.855)\tETA 0:00:02\tTraining Loss 1.3980 (1.3977)\n",
      "\n",
      "Epoch: [52][3/16]\tTime 0.185 (1.041)\tETA 0:00:02\tTraining Loss 1.3972 (1.3976)\n",
      "\n",
      "Epoch: [52][4/16]\tTime 0.184 (1.225)\tETA 0:00:02\tTraining Loss 1.3994 (1.3979)\n",
      "\n",
      "Epoch: [52][5/16]\tTime 0.192 (1.417)\tETA 0:00:02\tTraining Loss 1.3970 (1.3978)\n",
      "\n",
      "Epoch: [52][6/16]\tTime 0.188 (1.605)\tETA 0:00:01\tTraining Loss 1.3979 (1.3978)\n",
      "\n",
      "Epoch: [52][7/16]\tTime 0.188 (1.793)\tETA 0:00:01\tTraining Loss 1.3923 (1.3971)\n",
      "\n",
      "Epoch: [52][8/16]\tTime 0.192 (1.985)\tETA 0:00:01\tTraining Loss 1.3958 (1.3970)\n",
      "\n",
      "Epoch: [52][9/16]\tTime 0.185 (2.170)\tETA 0:00:01\tTraining Loss 1.3907 (1.3963)\n",
      "\n",
      "Epoch: [52][10/16]\tTime 0.186 (2.356)\tETA 0:00:01\tTraining Loss 1.3943 (1.3961)\n",
      "\n",
      "Epoch: [52][11/16]\tTime 0.194 (2.551)\tETA 0:00:00\tTraining Loss 1.3886 (1.3955)\n",
      "\n",
      "Epoch: [52][12/16]\tTime 0.195 (2.746)\tETA 0:00:00\tTraining Loss 1.3966 (1.3956)\n",
      "\n",
      "Epoch: [52][13/16]\tTime 0.191 (2.937)\tETA 0:00:00\tTraining Loss 1.4046 (1.3962)\n",
      "\n",
      "Epoch: [52][14/16]\tTime 0.184 (3.121)\tETA 0:00:00\tTraining Loss 1.3938 (1.3961)\n",
      "\n",
      "Epoch: [52][15/16]\tTime 0.117 (3.238)\tETA 0:00:00\tTraining Loss 1.3952 (1.3960)\n",
      "_\n",
      "Validation stats                    IoU        F1      Prec    recall       Acc\n",
      "bg,          0.944900  0.971600  0.976200  0.967200  0.951000\n",
      "real apple   0.004200  0.008300  0.857100  0.004200  0.934500\n",
      "real pepper  0.000000  0.000000  0.000000  0.000000  1.000000\n",
      "real grape   0.536700  0.698400  0.905700  0.568400  0.968200\n",
      "fake apple   0.000000  0.000000  0.000000  0.000000  0.957500\n",
      "fake pepper  0.000000  0.000000  0.000000  0.000000  0.977100\n",
      "fake grape   0.000000  0.000000  0.000000  0.000000  0.967900\n",
      "total        0.212257  0.239757  0.391286  0.219971  0.965171\n",
      "total(-bg)   0.090150  0.117783  0.293800  0.095433  0.967533\n",
      "\n",
      "Epoch: [53][0/16]\tTime 0.482 (0.482)\tETA 0:00:07\tTraining Loss 1.3883 (1.3883)\n",
      "\n",
      "Epoch: [53][1/16]\tTime 0.183 (0.666)\tETA 0:00:02\tTraining Loss 1.4013 (1.3948)\n",
      "\n",
      "Epoch: [53][2/16]\tTime 0.186 (0.852)\tETA 0:00:02\tTraining Loss 1.3912 (1.3936)\n",
      "\n",
      "Epoch: [53][3/16]\tTime 0.185 (1.036)\tETA 0:00:02\tTraining Loss 1.3929 (1.3934)\n",
      "\n",
      "Epoch: [53][4/16]\tTime 0.185 (1.221)\tETA 0:00:02\tTraining Loss 1.3989 (1.3945)\n",
      "\n",
      "Epoch: [53][5/16]\tTime 0.197 (1.418)\tETA 0:00:02\tTraining Loss 1.3939 (1.3944)\n",
      "\n",
      "Epoch: [53][6/16]\tTime 0.184 (1.601)\tETA 0:00:01\tTraining Loss 1.3879 (1.3935)\n",
      "\n",
      "Epoch: [53][7/16]\tTime 0.191 (1.793)\tETA 0:00:01\tTraining Loss 1.3866 (1.3926)\n",
      "\n",
      "Epoch: [53][8/16]\tTime 0.182 (1.974)\tETA 0:00:01\tTraining Loss 1.3857 (1.3919)\n",
      "\n",
      "Epoch: [53][9/16]\tTime 0.193 (2.167)\tETA 0:00:01\tTraining Loss 1.3912 (1.3918)\n",
      "\n",
      "Epoch: [53][10/16]\tTime 0.178 (2.346)\tETA 0:00:01\tTraining Loss 1.3954 (1.3921)\n",
      "\n",
      "Epoch: [53][11/16]\tTime 0.185 (2.531)\tETA 0:00:00\tTraining Loss 1.3872 (1.3917)\n",
      "\n",
      "Epoch: [53][12/16]\tTime 0.188 (2.719)\tETA 0:00:00\tTraining Loss 1.3941 (1.3919)\n",
      "\n",
      "Epoch: [53][13/16]\tTime 0.182 (2.902)\tETA 0:00:00\tTraining Loss 1.3882 (1.3916)\n",
      "\n",
      "Epoch: [53][14/16]\tTime 0.190 (3.092)\tETA 0:00:00\tTraining Loss 1.3856 (1.3912)\n",
      "\n",
      "Epoch: [53][15/16]\tTime 0.111 (3.203)\tETA 0:00:00\tTraining Loss 1.3867 (1.3911)\n",
      "_\n",
      "Validation stats                    IoU        F1      Prec    recall       Acc\n",
      "bg,          0.944400  0.971400  0.977900  0.965000  0.950600\n",
      "real apple   0.010600  0.020900  0.947900  0.010600  0.934900\n",
      "real pepper  0.000000  0.000000  0.000000  0.000000  1.000000\n",
      "real grape   0.542100  0.703000  0.875200  0.587500  0.967900\n",
      "fake apple   0.000000  0.000000  0.000000  0.000000  0.951100\n",
      "fake pepper  0.000000  0.000000  0.000000  0.000000  0.981400\n",
      "fake grape   0.000000  0.000000  0.000000  0.000000  0.969800\n",
      "total        0.213871  0.242186  0.400143  0.223300  0.965100\n",
      "total(-bg)   0.092117  0.120650  0.303850  0.099683  0.967517\n",
      "\n",
      "Epoch: [54][0/16]\tTime 0.472 (0.472)\tETA 0:00:07\tTraining Loss 1.3888 (1.3888)\n",
      "\n",
      "Epoch: [54][1/16]\tTime 0.189 (0.662)\tETA 0:00:02\tTraining Loss 1.3817 (1.3853)\n",
      "\n",
      "Epoch: [54][2/16]\tTime 0.186 (0.848)\tETA 0:00:02\tTraining Loss 1.3963 (1.3889)\n",
      "\n",
      "Epoch: [54][3/16]\tTime 0.184 (1.032)\tETA 0:00:02\tTraining Loss 1.3841 (1.3877)\n",
      "\n",
      "Epoch: [54][4/16]\tTime 0.184 (1.215)\tETA 0:00:02\tTraining Loss 1.3834 (1.3869)\n",
      "\n",
      "Epoch: [54][5/16]\tTime 0.189 (1.404)\tETA 0:00:02\tTraining Loss 1.3910 (1.3875)\n",
      "\n",
      "Epoch: [54][6/16]\tTime 0.188 (1.592)\tETA 0:00:01\tTraining Loss 1.3941 (1.3885)\n",
      "\n",
      "Epoch: [54][7/16]\tTime 0.198 (1.790)\tETA 0:00:01\tTraining Loss 1.3904 (1.3887)\n",
      "\n",
      "Epoch: [54][8/16]\tTime 0.191 (1.981)\tETA 0:00:01\tTraining Loss 1.3822 (1.3880)\n",
      "\n",
      "Epoch: [54][9/16]\tTime 0.197 (2.178)\tETA 0:00:01\tTraining Loss 1.3852 (1.3877)\n",
      "\n",
      "Epoch: [54][10/16]\tTime 0.194 (2.372)\tETA 0:00:01\tTraining Loss 1.3916 (1.3881)\n",
      "\n",
      "Epoch: [54][11/16]\tTime 0.197 (2.569)\tETA 0:00:00\tTraining Loss 1.3803 (1.3874)\n",
      "\n",
      "Epoch: [54][12/16]\tTime 0.204 (2.772)\tETA 0:00:00\tTraining Loss 1.3828 (1.3871)\n",
      "\n",
      "Epoch: [54][13/16]\tTime 0.188 (2.960)\tETA 0:00:00\tTraining Loss 1.3872 (1.3871)\n",
      "\n",
      "Epoch: [54][14/16]\tTime 0.194 (3.154)\tETA 0:00:00\tTraining Loss 1.3858 (1.3870)\n",
      "\n",
      "Epoch: [54][15/16]\tTime 0.118 (3.273)\tETA 0:00:00\tTraining Loss 1.3929 (1.3872)\n",
      "_\n",
      "Validation stats                    IoU       F1      Prec    recall       Acc\n",
      "bg,          0.941700  0.96990  0.977300  0.962800  0.948200\n",
      "real apple   0.033300  0.06450  0.847500  0.033600  0.936100\n",
      "real pepper  0.000000  0.00000  0.000000  0.000000  1.000000\n",
      "real grape   0.674000  0.80520  0.898300  0.729700  0.977100\n",
      "fake apple   0.000000  0.00000  0.000000  0.000000  0.947900\n",
      "fake pepper  0.000000  0.00000  0.000000  0.000000  0.985800\n",
      "fake grape   0.000000  0.00000  0.000000  0.000000  0.978100\n",
      "total        0.235571  0.26280  0.389014  0.246586  0.967600\n",
      "total(-bg)   0.117883  0.14495  0.290967  0.127217  0.970833\n",
      "\n",
      "Epoch: [55][0/16]\tTime 0.487 (0.487)\tETA 0:00:07\tTraining Loss 1.3836 (1.3836)\n",
      "\n",
      "Epoch: [55][1/16]\tTime 0.186 (0.673)\tETA 0:00:02\tTraining Loss 1.3841 (1.3839)\n",
      "\n",
      "Epoch: [55][2/16]\tTime 0.184 (0.857)\tETA 0:00:02\tTraining Loss 1.3847 (1.3841)\n",
      "\n",
      "Epoch: [55][3/16]\tTime 0.189 (1.045)\tETA 0:00:02\tTraining Loss 1.3854 (1.3845)\n",
      "\n",
      "Epoch: [55][4/16]\tTime 0.199 (1.244)\tETA 0:00:02\tTraining Loss 1.3823 (1.3840)\n",
      "\n",
      "Epoch: [55][5/16]\tTime 0.178 (1.423)\tETA 0:00:01\tTraining Loss 1.3834 (1.3839)\n",
      "\n",
      "Epoch: [55][6/16]\tTime 0.193 (1.615)\tETA 0:00:01\tTraining Loss 1.3789 (1.3832)\n",
      "\n",
      "Epoch: [55][7/16]\tTime 0.204 (1.820)\tETA 0:00:01\tTraining Loss 1.3831 (1.3832)\n",
      "\n",
      "Epoch: [55][8/16]\tTime 0.180 (2.000)\tETA 0:00:01\tTraining Loss 1.3817 (1.3830)\n",
      "\n",
      "Epoch: [55][9/16]\tTime 0.196 (2.196)\tETA 0:00:01\tTraining Loss 1.3875 (1.3835)\n",
      "\n",
      "Epoch: [55][10/16]\tTime 0.191 (2.387)\tETA 0:00:01\tTraining Loss 1.3815 (1.3833)\n",
      "\n",
      "Epoch: [55][11/16]\tTime 0.202 (2.589)\tETA 0:00:01\tTraining Loss 1.3804 (1.3830)\n",
      "\n",
      "Epoch: [55][12/16]\tTime 0.184 (2.773)\tETA 0:00:00\tTraining Loss 1.3860 (1.3833)\n",
      "\n",
      "Epoch: [55][13/16]\tTime 0.189 (2.961)\tETA 0:00:00\tTraining Loss 1.3860 (1.3835)\n",
      "\n",
      "Epoch: [55][14/16]\tTime 0.186 (3.147)\tETA 0:00:00\tTraining Loss 1.3769 (1.3830)\n",
      "\n",
      "Epoch: [55][15/16]\tTime 0.117 (3.263)\tETA 0:00:00\tTraining Loss 1.3790 (1.3829)\n",
      "_\n",
      "Validation stats                    IoU        F1      Prec   recall       Acc\n",
      "bg,          0.948000  0.973300  0.976100  0.97050  0.953700\n",
      "real apple   0.009900  0.019700  0.716700  0.01000  0.934700\n",
      "real pepper  0.000000  0.000000  0.000000  0.00000  0.999800\n",
      "real grape   0.415100  0.586600  0.883400  0.43910  0.959900\n",
      "fake apple   0.000000  0.000000  0.000000  0.00000  0.943500\n",
      "fake pepper  0.000000  0.000000  0.000000  0.00000  0.997400\n",
      "fake grape   0.000000  0.000000  0.000000  0.00000  0.957000\n",
      "total        0.196143  0.225657  0.368029  0.20280  0.963714\n",
      "total(-bg)   0.070833  0.101050  0.266683  0.07485  0.965383\n",
      "\n",
      "Epoch: [56][0/16]\tTime 0.477 (0.477)\tETA 0:00:07\tTraining Loss 1.3854 (1.3854)\n",
      "\n",
      "Epoch: [56][1/16]\tTime 0.189 (0.667)\tETA 0:00:02\tTraining Loss 1.3809 (1.3831)\n",
      "\n",
      "Epoch: [56][2/16]\tTime 0.199 (0.866)\tETA 0:00:02\tTraining Loss 1.3942 (1.3868)\n",
      "\n",
      "Epoch: [56][3/16]\tTime 0.188 (1.053)\tETA 0:00:02\tTraining Loss 1.3891 (1.3874)\n",
      "\n",
      "Epoch: [56][4/16]\tTime 0.188 (1.242)\tETA 0:00:02\tTraining Loss 1.3819 (1.3863)\n",
      "\n",
      "Epoch: [56][5/16]\tTime 0.196 (1.438)\tETA 0:00:02\tTraining Loss 1.3791 (1.3851)\n",
      "\n",
      "Epoch: [56][6/16]\tTime 0.191 (1.629)\tETA 0:00:01\tTraining Loss 1.3779 (1.3841)\n",
      "\n",
      "Epoch: [56][7/16]\tTime 0.183 (1.812)\tETA 0:00:01\tTraining Loss 1.3817 (1.3838)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: [56][8/16]\tTime 0.185 (1.997)\tETA 0:00:01\tTraining Loss 1.3787 (1.3832)\n",
      "\n",
      "Epoch: [56][9/16]\tTime 0.186 (2.183)\tETA 0:00:01\tTraining Loss 1.3879 (1.3837)\n",
      "\n",
      "Epoch: [56][10/16]\tTime 0.205 (2.389)\tETA 0:00:01\tTraining Loss 1.3815 (1.3835)\n",
      "\n",
      "Epoch: [56][11/16]\tTime 0.190 (2.579)\tETA 0:00:00\tTraining Loss 1.3770 (1.3829)\n",
      "\n",
      "Epoch: [56][12/16]\tTime 0.181 (2.759)\tETA 0:00:00\tTraining Loss 1.3755 (1.3823)\n",
      "\n",
      "Epoch: [56][13/16]\tTime 0.197 (2.956)\tETA 0:00:00\tTraining Loss 1.3789 (1.3821)\n",
      "\n",
      "Epoch: [56][14/16]\tTime 0.193 (3.149)\tETA 0:00:00\tTraining Loss 1.3766 (1.3817)\n",
      "\n",
      "Epoch: [56][15/16]\tTime 0.116 (3.265)\tETA 0:00:00\tTraining Loss 1.3768 (1.3816)\n",
      "_\n",
      "Validation stats                    IoU        F1      Prec   recall       Acc\n",
      "bg,          0.929400  0.963400  0.977500  0.94980  0.937300\n",
      "real apple   0.015300  0.030200  1.000000  0.01530  0.935300\n",
      "real pepper  0.000000  0.000000  0.000000  0.00000  1.000000\n",
      "real grape   0.472300  0.641500  0.899300  0.49860  0.963900\n",
      "fake apple   0.000000  0.000000  0.000000  0.00000  0.943400\n",
      "fake pepper  0.000000  0.000000  0.000000  0.00000  0.975800\n",
      "fake grape   0.000000  0.000000  0.000000  0.00000  0.962600\n",
      "total        0.202429  0.233586  0.410971  0.20910  0.959757\n",
      "total(-bg)   0.081267  0.111950  0.316550  0.08565  0.963500\n",
      "\n",
      "Epoch: [57][0/16]\tTime 0.548 (0.548)\tETA 0:00:08\tTraining Loss 1.3798 (1.3798)\n",
      "\n",
      "Epoch: [57][1/16]\tTime 0.189 (0.736)\tETA 0:00:02\tTraining Loss 1.3718 (1.3758)\n",
      "\n",
      "Epoch: [57][2/16]\tTime 0.186 (0.923)\tETA 0:00:02\tTraining Loss 1.3767 (1.3761)\n",
      "\n",
      "Epoch: [57][3/16]\tTime 0.187 (1.109)\tETA 0:00:02\tTraining Loss 1.3789 (1.3768)\n",
      "\n",
      "Epoch: [57][4/16]\tTime 0.199 (1.309)\tETA 0:00:02\tTraining Loss 1.3810 (1.3777)\n",
      "\n",
      "Epoch: [57][5/16]\tTime 0.189 (1.498)\tETA 0:00:02\tTraining Loss 1.3794 (1.3779)\n",
      "\n",
      "Epoch: [57][6/16]\tTime 0.187 (1.685)\tETA 0:00:01\tTraining Loss 1.3742 (1.3774)\n",
      "\n",
      "Epoch: [57][7/16]\tTime 0.192 (1.877)\tETA 0:00:01\tTraining Loss 1.3692 (1.3764)\n",
      "\n",
      "Epoch: [57][8/16]\tTime 0.190 (2.066)\tETA 0:00:01\tTraining Loss 1.3893 (1.3778)\n",
      "\n",
      "Epoch: [57][9/16]\tTime 0.189 (2.255)\tETA 0:00:01\tTraining Loss 1.3825 (1.3783)\n",
      "\n",
      "Epoch: [57][10/16]\tTime 0.198 (2.453)\tETA 0:00:01\tTraining Loss 1.3752 (1.3780)\n",
      "\n",
      "Epoch: [57][11/16]\tTime 0.195 (2.648)\tETA 0:00:00\tTraining Loss 1.3757 (1.3778)\n",
      "\n",
      "Epoch: [57][12/16]\tTime 0.191 (2.839)\tETA 0:00:00\tTraining Loss 1.3722 (1.3774)\n",
      "\n",
      "Epoch: [57][13/16]\tTime 0.191 (3.030)\tETA 0:00:00\tTraining Loss 1.3711 (1.3769)\n",
      "\n",
      "Epoch: [57][14/16]\tTime 0.191 (3.221)\tETA 0:00:00\tTraining Loss 1.3794 (1.3771)\n",
      "\n",
      "Epoch: [57][15/16]\tTime 0.116 (3.337)\tETA 0:00:00\tTraining Loss 1.3699 (1.3769)\n",
      "_\n",
      "Validation stats                    IoU        F1      Prec    recall       Acc\n",
      "bg,          0.943300  0.970800  0.976600  0.965100  0.949500\n",
      "real apple   0.164700  0.282700  0.840900  0.170000  0.943300\n",
      "real pepper  0.000000  0.000000  0.000000  0.000000  0.998000\n",
      "real grape   0.377300  0.547800  0.886700  0.396400  0.957600\n",
      "fake apple   0.000000  0.000000  0.000000  0.000000  0.939500\n",
      "fake pepper  0.000000  0.000000  0.000000  0.000000  0.992400\n",
      "fake grape   0.000000  0.000000  0.000000  0.000000  0.971600\n",
      "total        0.212186  0.257329  0.386314  0.218786  0.964557\n",
      "total(-bg)   0.090333  0.138417  0.287933  0.094400  0.967067\n",
      "\n",
      "Epoch: [58][0/16]\tTime 0.477 (0.477)\tETA 0:00:07\tTraining Loss 1.3755 (1.3755)\n",
      "\n",
      "Epoch: [58][1/16]\tTime 0.180 (0.657)\tETA 0:00:02\tTraining Loss 1.3698 (1.3726)\n",
      "\n",
      "Epoch: [58][2/16]\tTime 0.193 (0.850)\tETA 0:00:02\tTraining Loss 1.3707 (1.3720)\n",
      "\n",
      "Epoch: [58][3/16]\tTime 0.180 (1.031)\tETA 0:00:02\tTraining Loss 1.3687 (1.3711)\n",
      "\n",
      "Epoch: [58][4/16]\tTime 0.188 (1.219)\tETA 0:00:02\tTraining Loss 1.3683 (1.3706)\n",
      "\n",
      "Epoch: [58][5/16]\tTime 0.185 (1.404)\tETA 0:00:02\tTraining Loss 1.3745 (1.3712)\n",
      "\n",
      "Epoch: [58][6/16]\tTime 0.185 (1.589)\tETA 0:00:01\tTraining Loss 1.3777 (1.3721)\n",
      "\n",
      "Epoch: [58][7/16]\tTime 0.185 (1.774)\tETA 0:00:01\tTraining Loss 1.3690 (1.3717)\n",
      "\n",
      "Epoch: [58][8/16]\tTime 0.186 (1.959)\tETA 0:00:01\tTraining Loss 1.3665 (1.3712)\n",
      "\n",
      "Epoch: [58][9/16]\tTime 0.172 (2.131)\tETA 0:00:01\tTraining Loss 1.3763 (1.3717)\n",
      "\n",
      "Epoch: [58][10/16]\tTime 0.191 (2.322)\tETA 0:00:01\tTraining Loss 1.3712 (1.3716)\n",
      "\n",
      "Epoch: [58][11/16]\tTime 0.177 (2.499)\tETA 0:00:00\tTraining Loss 1.3765 (1.3720)\n",
      "\n",
      "Epoch: [58][12/16]\tTime 0.194 (2.693)\tETA 0:00:00\tTraining Loss 1.3661 (1.3716)\n",
      "\n",
      "Epoch: [58][13/16]\tTime 0.181 (2.875)\tETA 0:00:00\tTraining Loss 1.3702 (1.3715)\n",
      "\n",
      "Epoch: [58][14/16]\tTime 0.185 (3.059)\tETA 0:00:00\tTraining Loss 1.3783 (1.3719)\n",
      "\n",
      "Epoch: [58][15/16]\tTime 0.113 (3.172)\tETA 0:00:00\tTraining Loss 1.3981 (1.3728)\n",
      "_\n",
      "Validation stats                   IoU        F1      Prec    recall       Acc\n",
      "bg,          0.94840  0.973500  0.980000  0.967100  0.954300\n",
      "real apple   0.11710  0.209600  0.801100  0.120600  0.940200\n",
      "real pepper  0.00000  0.000000  0.000000  0.000000  0.995900\n",
      "real grape   0.59420  0.745400  0.941400  0.617100  0.972700\n",
      "fake apple   0.00000  0.000000  0.000000  0.000000  0.944000\n",
      "fake pepper  0.00000  0.000000  0.000000  0.000000  0.990700\n",
      "fake grape   0.00000  0.000000  0.000000  0.000000  0.979800\n",
      "total        0.23710  0.275500  0.388929  0.243543  0.968229\n",
      "total(-bg)   0.11855  0.159167  0.290417  0.122950  0.970550\n",
      "\n",
      "Epoch: [59][0/16]\tTime 0.475 (0.475)\tETA 0:00:07\tTraining Loss 1.3722 (1.3722)\n",
      "\n",
      "Epoch: [59][1/16]\tTime 0.172 (0.647)\tETA 0:00:02\tTraining Loss 1.3746 (1.3734)\n",
      "\n",
      "Epoch: [59][2/16]\tTime 0.182 (0.829)\tETA 0:00:02\tTraining Loss 1.3748 (1.3739)\n",
      "\n",
      "Epoch: [59][3/16]\tTime 0.179 (1.009)\tETA 0:00:02\tTraining Loss 1.3714 (1.3733)\n",
      "\n",
      "Epoch: [59][4/16]\tTime 0.187 (1.195)\tETA 0:00:02\tTraining Loss 1.3717 (1.3729)\n",
      "\n",
      "Epoch: [59][5/16]\tTime 0.186 (1.381)\tETA 0:00:02\tTraining Loss 1.3667 (1.3719)\n",
      "\n",
      "Epoch: [59][6/16]\tTime 0.184 (1.565)\tETA 0:00:01\tTraining Loss 1.3659 (1.3710)\n",
      "\n",
      "Epoch: [59][7/16]\tTime 0.188 (1.753)\tETA 0:00:01\tTraining Loss 1.3660 (1.3704)\n",
      "\n",
      "Epoch: [59][8/16]\tTime 0.187 (1.940)\tETA 0:00:01\tTraining Loss 1.3770 (1.3711)\n",
      "\n",
      "Epoch: [59][9/16]\tTime 0.188 (2.128)\tETA 0:00:01\tTraining Loss 1.3666 (1.3707)\n",
      "\n",
      "Epoch: [59][10/16]\tTime 0.201 (2.329)\tETA 0:00:01\tTraining Loss 1.3702 (1.3707)\n",
      "\n",
      "Epoch: [59][11/16]\tTime 0.181 (2.510)\tETA 0:00:00\tTraining Loss 1.3735 (1.3709)\n",
      "\n",
      "Epoch: [59][12/16]\tTime 0.179 (2.689)\tETA 0:00:00\tTraining Loss 1.3678 (1.3707)\n",
      "\n",
      "Epoch: [59][13/16]\tTime 0.181 (2.870)\tETA 0:00:00\tTraining Loss 1.3632 (1.3701)\n",
      "\n",
      "Epoch: [59][14/16]\tTime 0.180 (3.050)\tETA 0:00:00\tTraining Loss 1.3667 (1.3699)\n",
      "\n",
      "Epoch: [59][15/16]\tTime 0.114 (3.164)\tETA 0:00:00\tTraining Loss 1.3635 (1.3697)\n",
      "_\n",
      "Validation stats                    IoU      F1      Prec    recall       Acc\n",
      "bg,          0.948700  0.9736  0.978900  0.968500  0.954500\n",
      "real apple   0.000800  0.0016  0.388900  0.000800  0.934200\n",
      "real pepper  0.000000  0.0000  0.000000  0.000000  1.000000\n",
      "real grape   0.397600  0.5690  0.879100  0.420600  0.958700\n",
      "fake apple   0.000000  0.0000  0.000000  0.000000  0.949000\n",
      "fake pepper  0.000000  0.0000  0.000000  0.000000  0.978500\n",
      "fake grape   0.000000  0.0000  0.000000  0.000000  0.964000\n",
      "total        0.192443  0.2206  0.320986  0.198557  0.962700\n",
      "total(-bg)   0.066400  0.0951  0.211333  0.070233  0.964067\n",
      "\n",
      "Epoch: [60][0/16]\tTime 0.487 (0.487)\tETA 0:00:07\tTraining Loss 1.3657 (1.3657)\n",
      "\n",
      "Epoch: [60][1/16]\tTime 0.175 (0.662)\tETA 0:00:02\tTraining Loss 1.3591 (1.3624)\n",
      "\n",
      "Epoch: [60][2/16]\tTime 0.200 (0.862)\tETA 0:00:02\tTraining Loss 1.3644 (1.3630)\n",
      "\n",
      "Epoch: [60][3/16]\tTime 0.180 (1.041)\tETA 0:00:02\tTraining Loss 1.3691 (1.3646)\n",
      "\n",
      "Epoch: [60][4/16]\tTime 0.187 (1.229)\tETA 0:00:02\tTraining Loss 1.3669 (1.3650)\n",
      "\n",
      "Epoch: [60][5/16]\tTime 0.184 (1.413)\tETA 0:00:02\tTraining Loss 1.3606 (1.3643)\n",
      "\n",
      "Epoch: [60][6/16]\tTime 0.199 (1.612)\tETA 0:00:01\tTraining Loss 1.3639 (1.3642)\n",
      "\n",
      "Epoch: [60][7/16]\tTime 0.191 (1.803)\tETA 0:00:01\tTraining Loss 1.3649 (1.3643)\n",
      "\n",
      "Epoch: [60][8/16]\tTime 0.185 (1.988)\tETA 0:00:01\tTraining Loss 1.3579 (1.3636)\n",
      "\n",
      "Epoch: [60][9/16]\tTime 0.195 (2.183)\tETA 0:00:01\tTraining Loss 1.3628 (1.3635)\n",
      "\n",
      "Epoch: [60][10/16]\tTime 0.182 (2.365)\tETA 0:00:01\tTraining Loss 1.3760 (1.3647)\n",
      "\n",
      "Epoch: [60][11/16]\tTime 0.187 (2.552)\tETA 0:00:00\tTraining Loss 1.3677 (1.3649)\n",
      "\n",
      "Epoch: [60][12/16]\tTime 0.200 (2.751)\tETA 0:00:00\tTraining Loss 1.3609 (1.3646)\n",
      "\n",
      "Epoch: [60][13/16]\tTime 0.180 (2.931)\tETA 0:00:00\tTraining Loss 1.3602 (1.3643)\n",
      "\n",
      "Epoch: [60][14/16]\tTime 0.196 (3.127)\tETA 0:00:00\tTraining Loss 1.3652 (1.3643)\n",
      "\n",
      "Epoch: [60][15/16]\tTime 0.112 (3.239)\tETA 0:00:00\tTraining Loss 1.3612 (1.3642)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_\n",
      "Validation stats                    IoU        F1      Prec    recall       Acc\n",
      "bg,          0.951300  0.975000  0.978000  0.972100  0.956700\n",
      "real apple   0.090900  0.166600  0.858500  0.092300  0.939300\n",
      "real pepper  0.000000  0.000000  0.000000  0.000000  1.000000\n",
      "real grape   0.558300  0.716500  0.914100  0.589300  0.969800\n",
      "fake apple   0.000000  0.000000  0.000000  0.000000  0.948500\n",
      "fake pepper  0.000000  0.000000  0.000000  0.000000  0.995400\n",
      "fake grape   0.000000  0.000000  0.000000  0.000000  0.969200\n",
      "total        0.228643  0.265443  0.392943  0.236243  0.968414\n",
      "total(-bg)   0.108200  0.147183  0.295433  0.113600  0.970367\n",
      "\n",
      "Epoch: [61][0/16]\tTime 0.435 (0.435)\tETA 0:00:06\tTraining Loss 1.3585 (1.3585)\n",
      "\n",
      "Epoch: [61][1/16]\tTime 0.187 (0.622)\tETA 0:00:02\tTraining Loss 1.3556 (1.3570)\n",
      "\n",
      "Epoch: [61][2/16]\tTime 0.184 (0.806)\tETA 0:00:02\tTraining Loss 1.3590 (1.3577)\n",
      "\n",
      "Epoch: [61][3/16]\tTime 0.185 (0.991)\tETA 0:00:02\tTraining Loss 1.3696 (1.3607)\n",
      "\n",
      "Epoch: [61][4/16]\tTime 0.188 (1.178)\tETA 0:00:02\tTraining Loss 1.3580 (1.3601)\n",
      "\n",
      "Epoch: [61][5/16]\tTime 0.191 (1.370)\tETA 0:00:02\tTraining Loss 1.3608 (1.3602)\n",
      "\n",
      "Epoch: [61][6/16]\tTime 0.183 (1.553)\tETA 0:00:01\tTraining Loss 1.3560 (1.3596)\n",
      "\n",
      "Epoch: [61][7/16]\tTime 0.178 (1.730)\tETA 0:00:01\tTraining Loss 1.3638 (1.3601)\n",
      "\n",
      "Epoch: [61][8/16]\tTime 0.195 (1.925)\tETA 0:00:01\tTraining Loss 1.3677 (1.3610)\n",
      "\n",
      "Epoch: [61][9/16]\tTime 0.178 (2.103)\tETA 0:00:01\tTraining Loss 1.3625 (1.3611)\n",
      "\n",
      "Epoch: [61][10/16]\tTime 0.183 (2.286)\tETA 0:00:01\tTraining Loss 1.3704 (1.3620)\n",
      "\n",
      "Epoch: [61][11/16]\tTime 0.310 (2.596)\tETA 0:00:01\tTraining Loss 1.3640 (1.3621)\n",
      "\n",
      "Epoch: [61][12/16]\tTime 0.185 (2.781)\tETA 0:00:00\tTraining Loss 1.3559 (1.3617)\n",
      "\n",
      "Epoch: [61][13/16]\tTime 0.185 (2.966)\tETA 0:00:00\tTraining Loss 1.3540 (1.3611)\n",
      "\n",
      "Epoch: [61][14/16]\tTime 0.189 (3.155)\tETA 0:00:00\tTraining Loss 1.3587 (1.3610)\n",
      "\n",
      "Epoch: [61][15/16]\tTime 0.114 (3.268)\tETA 0:00:00\tTraining Loss 1.3613 (1.3610)\n",
      "_\n",
      "Validation stats                    IoU        F1      Prec    recall       Acc\n",
      "bg,          0.946100  0.972300  0.977000  0.967700  0.952100\n",
      "real apple   0.076000  0.141200  0.950800  0.076300  0.939000\n",
      "real pepper  0.000000  0.000000  0.000000  0.000000  1.000000\n",
      "real grape   0.792100  0.884000  0.919900  0.850800  0.985500\n",
      "fake apple   0.000000  0.000000  0.000000  0.000000  0.954400\n",
      "fake pepper  0.000000  0.000000  0.000000  0.000000  0.981200\n",
      "fake grape   0.000000  0.000000  0.000000  0.000000  0.990800\n",
      "total        0.259171  0.285357  0.406814  0.270686  0.971857\n",
      "total(-bg)   0.144683  0.170867  0.311783  0.154517  0.975150\n",
      "\n",
      "Epoch: [62][0/16]\tTime 0.461 (0.461)\tETA 0:00:07\tTraining Loss 1.3553 (1.3553)\n",
      "\n",
      "Epoch: [62][1/16]\tTime 0.176 (0.637)\tETA 0:00:02\tTraining Loss 1.3538 (1.3546)\n",
      "\n",
      "Epoch: [62][2/16]\tTime 0.194 (0.831)\tETA 0:00:02\tTraining Loss 1.3609 (1.3567)\n",
      "\n",
      "Epoch: [62][3/16]\tTime 0.185 (1.015)\tETA 0:00:02\tTraining Loss 1.3555 (1.3564)\n",
      "\n",
      "Epoch: [62][4/16]\tTime 0.190 (1.205)\tETA 0:00:02\tTraining Loss 1.3618 (1.3575)\n",
      "\n",
      "Epoch: [62][5/16]\tTime 0.182 (1.387)\tETA 0:00:02\tTraining Loss 1.3611 (1.3581)\n",
      "\n",
      "Epoch: [62][6/16]\tTime 0.186 (1.573)\tETA 0:00:01\tTraining Loss 1.3583 (1.3581)\n",
      "\n",
      "Epoch: [62][7/16]\tTime 0.191 (1.765)\tETA 0:00:01\tTraining Loss 1.3517 (1.3573)\n",
      "\n",
      "Epoch: [62][8/16]\tTime 0.185 (1.950)\tETA 0:00:01\tTraining Loss 1.3531 (1.3568)\n",
      "\n",
      "Epoch: [62][9/16]\tTime 0.196 (2.145)\tETA 0:00:01\tTraining Loss 1.3572 (1.3569)\n",
      "\n",
      "Epoch: [62][10/16]\tTime 0.195 (2.340)\tETA 0:00:01\tTraining Loss 1.3533 (1.3565)\n",
      "\n",
      "Epoch: [62][11/16]\tTime 0.200 (2.540)\tETA 0:00:01\tTraining Loss 1.3513 (1.3561)\n",
      "\n",
      "Epoch: [62][12/16]\tTime 0.178 (2.718)\tETA 0:00:00\tTraining Loss 1.3511 (1.3557)\n",
      "\n",
      "Epoch: [62][13/16]\tTime 0.171 (2.889)\tETA 0:00:00\tTraining Loss 1.3557 (1.3557)\n",
      "\n",
      "Epoch: [62][14/16]\tTime 0.197 (3.086)\tETA 0:00:00\tTraining Loss 1.3633 (1.3562)\n",
      "\n",
      "Epoch: [62][15/16]\tTime 0.118 (3.204)\tETA 0:00:00\tTraining Loss 1.3518 (1.3561)\n",
      "_\n",
      "Validation stats                    IoU        F1      Prec   recall       Acc\n",
      "bg,          0.947400  0.972900  0.975300  0.97070  0.953100\n",
      "real apple   0.077800  0.144300  0.840500  0.07890  0.938500\n",
      "real pepper  0.000000  0.000000  0.000000  0.00000  0.999800\n",
      "real grape   0.563800  0.721000  0.907400  0.59820  0.970000\n",
      "fake apple   0.000000  0.000000  0.000000  0.00000  0.955200\n",
      "fake pepper  0.000000  0.000000  0.000000  0.00000  0.989300\n",
      "fake grape   0.000000  0.000000  0.000000  0.00000  0.970000\n",
      "total        0.227000  0.262600  0.389029  0.23540  0.967986\n",
      "total(-bg)   0.106933  0.144217  0.291317  0.11285  0.970467\n",
      "\n",
      "Epoch: [63][0/16]\tTime 0.477 (0.477)\tETA 0:00:07\tTraining Loss 1.3560 (1.3560)\n",
      "\n",
      "Epoch: [63][1/16]\tTime 0.183 (0.660)\tETA 0:00:02\tTraining Loss 1.3535 (1.3547)\n",
      "\n",
      "Epoch: [63][2/16]\tTime 0.181 (0.841)\tETA 0:00:02\tTraining Loss 1.3501 (1.3532)\n",
      "\n",
      "Epoch: [63][3/16]\tTime 0.190 (1.031)\tETA 0:00:02\tTraining Loss 1.3497 (1.3523)\n",
      "\n",
      "Epoch: [63][4/16]\tTime 0.181 (1.212)\tETA 0:00:02\tTraining Loss 1.3537 (1.3526)\n",
      "\n",
      "Epoch: [63][5/16]\tTime 0.183 (1.395)\tETA 0:00:02\tTraining Loss 1.3476 (1.3517)\n",
      "\n",
      "Epoch: [63][6/16]\tTime 0.179 (1.574)\tETA 0:00:01\tTraining Loss 1.3556 (1.3523)\n",
      "\n",
      "Epoch: [63][7/16]\tTime 0.185 (1.759)\tETA 0:00:01\tTraining Loss 1.3488 (1.3519)\n",
      "\n",
      "Epoch: [63][8/16]\tTime 0.184 (1.943)\tETA 0:00:01\tTraining Loss 1.3505 (1.3517)\n",
      "\n",
      "Epoch: [63][9/16]\tTime 0.191 (2.134)\tETA 0:00:01\tTraining Loss 1.3494 (1.3515)\n",
      "\n",
      "Epoch: [63][10/16]\tTime 0.181 (2.315)\tETA 0:00:01\tTraining Loss 1.3487 (1.3512)\n",
      "\n",
      "Epoch: [63][11/16]\tTime 0.186 (2.502)\tETA 0:00:00\tTraining Loss 1.3521 (1.3513)\n",
      "\n",
      "Epoch: [63][12/16]\tTime 0.185 (2.687)\tETA 0:00:00\tTraining Loss 1.3544 (1.3515)\n",
      "\n",
      "Epoch: [63][13/16]\tTime 0.185 (2.871)\tETA 0:00:00\tTraining Loss 1.3532 (1.3517)\n",
      "\n",
      "Epoch: [63][14/16]\tTime 0.188 (3.060)\tETA 0:00:00\tTraining Loss 1.3523 (1.3517)\n",
      "\n",
      "Epoch: [63][15/16]\tTime 0.113 (3.172)\tETA 0:00:00\tTraining Loss 1.3574 (1.3519)\n",
      "_\n",
      "Validation stats                    IoU        F1      Prec    recall       Acc\n",
      "bg,          0.946000  0.972200  0.976500  0.968000  0.952000\n",
      "real apple   0.021300  0.041600  0.832600  0.021400  0.935400\n",
      "real pepper  0.000000  0.000000  0.000000  0.000000  1.000000\n",
      "real grape   0.589900  0.742000  0.933100  0.616000  0.972300\n",
      "fake apple   0.000000  0.000000  0.000000  0.000000  0.949100\n",
      "fake pepper  0.000000  0.000000  0.000000  0.000000  0.983700\n",
      "fake grape   0.000000  0.000000  0.000000  0.000000  0.973600\n",
      "total        0.222457  0.250829  0.391743  0.229343  0.966586\n",
      "total(-bg)   0.101867  0.130600  0.294283  0.106233  0.969017\n",
      "\n",
      "Epoch: [64][0/16]\tTime 0.430 (0.430)\tETA 0:00:06\tTraining Loss 1.3506 (1.3506)\n",
      "\n",
      "Epoch: [64][1/16]\tTime 0.190 (0.619)\tETA 0:00:02\tTraining Loss 1.3516 (1.3511)\n",
      "\n",
      "Epoch: [64][2/16]\tTime 0.188 (0.807)\tETA 0:00:02\tTraining Loss 1.3483 (1.3502)\n",
      "\n",
      "Epoch: [64][3/16]\tTime 0.183 (0.990)\tETA 0:00:02\tTraining Loss 1.3434 (1.3485)\n",
      "\n",
      "Epoch: [64][4/16]\tTime 0.194 (1.184)\tETA 0:00:02\tTraining Loss 1.3457 (1.3479)\n",
      "\n",
      "Epoch: [64][5/16]\tTime 0.187 (1.371)\tETA 0:00:02\tTraining Loss 1.3536 (1.3489)\n",
      "\n",
      "Epoch: [64][6/16]\tTime 0.184 (1.554)\tETA 0:00:01\tTraining Loss 1.3513 (1.3492)\n",
      "\n",
      "Epoch: [64][7/16]\tTime 0.197 (1.751)\tETA 0:00:01\tTraining Loss 1.3496 (1.3492)\n",
      "\n",
      "Epoch: [64][8/16]\tTime 0.181 (1.932)\tETA 0:00:01\tTraining Loss 1.3473 (1.3490)\n",
      "\n",
      "Epoch: [64][9/16]\tTime 0.184 (2.115)\tETA 0:00:01\tTraining Loss 1.3480 (1.3489)\n",
      "\n",
      "Epoch: [64][10/16]\tTime 0.183 (2.298)\tETA 0:00:01\tTraining Loss 1.3435 (1.3484)\n",
      "\n",
      "Epoch: [64][11/16]\tTime 0.194 (2.492)\tETA 0:00:00\tTraining Loss 1.3448 (1.3481)\n",
      "\n",
      "Epoch: [64][12/16]\tTime 0.182 (2.674)\tETA 0:00:00\tTraining Loss 1.3474 (1.3481)\n",
      "\n",
      "Epoch: [64][13/16]\tTime 0.187 (2.861)\tETA 0:00:00\tTraining Loss 1.3432 (1.3477)\n",
      "\n",
      "Epoch: [64][14/16]\tTime 0.188 (3.049)\tETA 0:00:00\tTraining Loss 1.3478 (1.3477)\n",
      "\n",
      "Epoch: [64][15/16]\tTime 0.117 (3.167)\tETA 0:00:00\tTraining Loss 1.3489 (1.3478)\n",
      "_\n",
      "Validation stats                    IoU        F1      Prec    recall       Acc\n",
      "bg,          0.947600  0.973000  0.977900  0.968300  0.953400\n",
      "real apple   0.068300  0.127900  0.767600  0.069800  0.937500\n",
      "real pepper  0.000000  0.000000  0.000000  0.000000  1.000000\n",
      "real grape   0.656900  0.792800  0.919900  0.696700  0.976400\n",
      "fake apple   0.000000  0.000000  0.000000  0.000000  0.956900\n",
      "fake pepper  0.000000  0.000000  0.000000  0.000000  0.984900\n",
      "fake grape   0.000000  0.000000  0.000000  0.000000  0.974100\n",
      "total        0.238971  0.270529  0.380771  0.247829  0.969029\n",
      "total(-bg)   0.120867  0.153450  0.281250  0.127750  0.971633\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: [65][0/16]\tTime 0.369 (0.369)\tETA 0:00:05\tTraining Loss 1.3447 (1.3447)\n",
      "\n",
      "Epoch: [65][1/16]\tTime 0.184 (0.554)\tETA 0:00:02\tTraining Loss 1.3440 (1.3443)\n",
      "\n",
      "Epoch: [65][2/16]\tTime 0.188 (0.741)\tETA 0:00:02\tTraining Loss 1.3446 (1.3444)\n",
      "\n",
      "Epoch: [65][3/16]\tTime 0.183 (0.925)\tETA 0:00:02\tTraining Loss 1.3607 (1.3485)\n",
      "\n",
      "Epoch: [65][4/16]\tTime 0.188 (1.112)\tETA 0:00:02\tTraining Loss 1.3435 (1.3475)\n",
      "\n",
      "Epoch: [65][5/16]\tTime 0.182 (1.295)\tETA 0:00:02\tTraining Loss 1.3579 (1.3492)\n",
      "\n",
      "Epoch: [65][6/16]\tTime 0.188 (1.483)\tETA 0:00:01\tTraining Loss 1.3498 (1.3493)\n",
      "\n",
      "Epoch: [65][7/16]\tTime 0.186 (1.669)\tETA 0:00:01\tTraining Loss 1.3454 (1.3488)\n",
      "\n",
      "Epoch: [65][8/16]\tTime 0.207 (1.876)\tETA 0:00:01\tTraining Loss 1.3429 (1.3482)\n",
      "\n",
      "Epoch: [65][9/16]\tTime 0.189 (2.065)\tETA 0:00:01\tTraining Loss 1.3417 (1.3475)\n",
      "\n",
      "Epoch: [65][10/16]\tTime 0.185 (2.250)\tETA 0:00:01\tTraining Loss 1.3492 (1.3477)\n",
      "\n",
      "Epoch: [65][11/16]\tTime 0.183 (2.433)\tETA 0:00:00\tTraining Loss 1.3428 (1.3473)\n",
      "\n",
      "Epoch: [65][12/16]\tTime 0.186 (2.619)\tETA 0:00:00\tTraining Loss 1.3420 (1.3469)\n",
      "\n",
      "Epoch: [65][13/16]\tTime 0.185 (2.804)\tETA 0:00:00\tTraining Loss 1.3421 (1.3465)\n",
      "\n",
      "Epoch: [65][14/16]\tTime 0.183 (2.987)\tETA 0:00:00\tTraining Loss 1.3393 (1.3460)\n",
      "\n",
      "Epoch: [65][15/16]\tTime 0.113 (3.099)\tETA 0:00:00\tTraining Loss 1.3488 (1.3461)\n",
      "_\n",
      "Validation stats                    IoU        F1      Prec    recall       Acc\n",
      "bg,          0.947700  0.973100  0.977300  0.969100  0.953500\n",
      "real apple   0.004500  0.009000  0.780000  0.004500  0.934500\n",
      "real pepper  0.000000  0.000000  0.000000  0.000000  1.000000\n",
      "real grape   0.540100  0.701300  0.937900  0.560200  0.969100\n",
      "fake apple   0.000000  0.000000  0.000000  0.000000  0.959200\n",
      "fake pepper  0.000000  0.000000  0.000000  0.000000  0.974100\n",
      "fake grape   0.000000  0.000000  0.000000  0.000000  0.968000\n",
      "total        0.213186  0.240486  0.385029  0.219114  0.965486\n",
      "total(-bg)   0.090767  0.118383  0.286317  0.094117  0.967483\n",
      "\n",
      "Epoch: [66][0/16]\tTime 0.473 (0.473)\tETA 0:00:07\tTraining Loss 1.3418 (1.3418)\n",
      "\n",
      "Epoch: [66][1/16]\tTime 0.184 (0.657)\tETA 0:00:02\tTraining Loss 1.3434 (1.3426)\n",
      "\n",
      "Epoch: [66][2/16]\tTime 0.188 (0.844)\tETA 0:00:02\tTraining Loss 1.3422 (1.3425)\n",
      "\n",
      "Epoch: [66][3/16]\tTime 0.179 (1.024)\tETA 0:00:02\tTraining Loss 1.3565 (1.3460)\n",
      "\n",
      "Epoch: [66][4/16]\tTime 0.188 (1.212)\tETA 0:00:02\tTraining Loss 1.3467 (1.3461)\n",
      "\n",
      "Epoch: [66][5/16]\tTime 0.188 (1.400)\tETA 0:00:02\tTraining Loss 1.3375 (1.3447)\n",
      "\n",
      "Epoch: [66][6/16]\tTime 0.183 (1.583)\tETA 0:00:01\tTraining Loss 1.3395 (1.3439)\n",
      "\n",
      "Epoch: [66][7/16]\tTime 0.189 (1.772)\tETA 0:00:01\tTraining Loss 1.3354 (1.3429)\n",
      "\n",
      "Epoch: [66][8/16]\tTime 0.185 (1.957)\tETA 0:00:01\tTraining Loss 1.3385 (1.3424)\n",
      "\n",
      "Epoch: [66][9/16]\tTime 0.187 (2.144)\tETA 0:00:01\tTraining Loss 1.3411 (1.3423)\n",
      "\n",
      "Epoch: [66][10/16]\tTime 0.194 (2.339)\tETA 0:00:01\tTraining Loss 1.3407 (1.3421)\n",
      "\n",
      "Epoch: [66][11/16]\tTime 0.183 (2.522)\tETA 0:00:00\tTraining Loss 1.3371 (1.3417)\n",
      "\n",
      "Epoch: [66][12/16]\tTime 0.192 (2.714)\tETA 0:00:00\tTraining Loss 1.3394 (1.3415)\n",
      "\n",
      "Epoch: [66][13/16]\tTime 0.183 (2.896)\tETA 0:00:00\tTraining Loss 1.3523 (1.3423)\n",
      "\n",
      "Epoch: [66][14/16]\tTime 0.189 (3.085)\tETA 0:00:00\tTraining Loss 1.3426 (1.3423)\n",
      "\n",
      "Epoch: [66][15/16]\tTime 0.114 (3.200)\tETA 0:00:00\tTraining Loss 1.3423 (1.3423)\n",
      "_\n",
      "Validation stats                    IoU        F1      Prec    recall       Acc\n",
      "bg,          0.948500  0.973500  0.976800  0.970300  0.954200\n",
      "real apple   0.091700  0.167900  0.886800  0.092800  0.939600\n",
      "real pepper  0.000000  0.000000  0.000000  0.000000  1.000000\n",
      "real grape   0.556600  0.715100  0.885100  0.600000  0.969100\n",
      "fake apple   0.000000  0.000000  0.000000  0.000000  0.957000\n",
      "fake pepper  0.000000  0.000000  0.000000  0.000000  0.986500\n",
      "fake grape   0.000000  0.000000  0.000000  0.000000  0.971000\n",
      "total        0.228114  0.265214  0.392671  0.237586  0.968200\n",
      "total(-bg)   0.108050  0.147167  0.295317  0.115467  0.970533\n",
      "\n",
      "Epoch: [67][0/16]\tTime 0.367 (0.367)\tETA 0:00:05\tTraining Loss 1.3409 (1.3409)\n",
      "\n",
      "Epoch: [67][1/16]\tTime 0.185 (0.552)\tETA 0:00:02\tTraining Loss 1.3460 (1.3434)\n",
      "\n",
      "Epoch: [67][2/16]\tTime 0.184 (0.736)\tETA 0:00:02\tTraining Loss 1.3416 (1.3428)\n",
      "\n",
      "Epoch: [67][3/16]\tTime 0.184 (0.920)\tETA 0:00:02\tTraining Loss 1.3468 (1.3438)\n",
      "\n",
      "Epoch: [67][4/16]\tTime 0.183 (1.104)\tETA 0:00:02\tTraining Loss 1.3372 (1.3425)\n",
      "\n",
      "Epoch: [67][5/16]\tTime 0.182 (1.285)\tETA 0:00:02\tTraining Loss 1.3381 (1.3418)\n",
      "\n",
      "Epoch: [67][6/16]\tTime 0.186 (1.471)\tETA 0:00:01\tTraining Loss 1.3424 (1.3418)\n",
      "\n",
      "Epoch: [67][7/16]\tTime 0.185 (1.656)\tETA 0:00:01\tTraining Loss 1.3382 (1.3414)\n",
      "\n",
      "Epoch: [67][8/16]\tTime 0.182 (1.839)\tETA 0:00:01\tTraining Loss 1.3354 (1.3407)\n",
      "\n",
      "Epoch: [67][9/16]\tTime 0.203 (2.042)\tETA 0:00:01\tTraining Loss 1.3415 (1.3408)\n",
      "\n",
      "Epoch: [67][10/16]\tTime 0.185 (2.226)\tETA 0:00:01\tTraining Loss 1.3368 (1.3404)\n",
      "\n",
      "Epoch: [67][11/16]\tTime 0.182 (2.409)\tETA 0:00:00\tTraining Loss 1.3451 (1.3408)\n",
      "\n",
      "Epoch: [67][12/16]\tTime 0.190 (2.599)\tETA 0:00:00\tTraining Loss 1.3379 (1.3406)\n",
      "\n",
      "Epoch: [67][13/16]\tTime 0.188 (2.787)\tETA 0:00:00\tTraining Loss 1.3391 (1.3405)\n",
      "\n",
      "Epoch: [67][14/16]\tTime 0.183 (2.970)\tETA 0:00:00\tTraining Loss 1.3340 (1.3401)\n",
      "\n",
      "Epoch: [67][15/16]\tTime 0.119 (3.089)\tETA 0:00:00\tTraining Loss 1.3474 (1.3403)\n",
      "_\n",
      "Validation stats                    IoU        F1      Prec    recall       Acc\n",
      "bg,          0.949900  0.974300  0.976700  0.972000  0.955500\n",
      "real apple   0.034600  0.066800  0.977000  0.034600  0.936500\n",
      "real pepper  0.000000  0.000000  0.000000  0.000000  1.000000\n",
      "real grape   0.542000  0.702900  0.903600  0.575200  0.968500\n",
      "fake apple   0.000000  0.000000  0.000000  0.000000  0.956500\n",
      "fake pepper  0.000000  0.000000  0.000000  0.000000  0.981300\n",
      "fake grape   0.000000  0.000000  0.000000  0.000000  0.971100\n",
      "total        0.218071  0.249143  0.408186  0.225971  0.967057\n",
      "total(-bg)   0.096100  0.128283  0.313433  0.101633  0.968983\n",
      "\n",
      "Epoch: [68][0/16]\tTime 0.443 (0.443)\tETA 0:00:07\tTraining Loss 1.3389 (1.3389)\n",
      "\n",
      "Epoch: [68][1/16]\tTime 0.186 (0.629)\tETA 0:00:02\tTraining Loss 1.3473 (1.3431)\n",
      "\n",
      "Epoch: [68][2/16]\tTime 0.185 (0.815)\tETA 0:00:02\tTraining Loss 1.3336 (1.3399)\n",
      "\n",
      "Epoch: [68][3/16]\tTime 0.180 (0.995)\tETA 0:00:02\tTraining Loss 1.3381 (1.3395)\n",
      "\n",
      "Epoch: [68][4/16]\tTime 0.185 (1.180)\tETA 0:00:02\tTraining Loss 1.3394 (1.3395)\n",
      "\n",
      "Epoch: [68][5/16]\tTime 0.190 (1.370)\tETA 0:00:02\tTraining Loss 1.3371 (1.3391)\n",
      "\n",
      "Epoch: [68][6/16]\tTime 0.187 (1.557)\tETA 0:00:01\tTraining Loss 1.3329 (1.3382)\n",
      "\n",
      "Epoch: [68][7/16]\tTime 0.191 (1.748)\tETA 0:00:01\tTraining Loss 1.3344 (1.3377)\n",
      "\n",
      "Epoch: [68][8/16]\tTime 0.188 (1.937)\tETA 0:00:01\tTraining Loss 1.3340 (1.3373)\n",
      "\n",
      "Epoch: [68][9/16]\tTime 0.181 (2.118)\tETA 0:00:01\tTraining Loss 1.3316 (1.3367)\n",
      "\n",
      "Epoch: [68][10/16]\tTime 0.189 (2.307)\tETA 0:00:01\tTraining Loss 1.3370 (1.3367)\n",
      "\n",
      "Epoch: [68][11/16]\tTime 0.203 (2.510)\tETA 0:00:01\tTraining Loss 1.3313 (1.3363)\n",
      "\n",
      "Epoch: [68][12/16]\tTime 0.174 (2.684)\tETA 0:00:00\tTraining Loss 1.3320 (1.3360)\n",
      "\n",
      "Epoch: [68][13/16]\tTime 0.185 (2.869)\tETA 0:00:00\tTraining Loss 1.3321 (1.3357)\n",
      "\n",
      "Epoch: [68][14/16]\tTime 0.185 (3.054)\tETA 0:00:00\tTraining Loss 1.3412 (1.3361)\n",
      "\n",
      "Epoch: [68][15/16]\tTime 0.117 (3.171)\tETA 0:00:00\tTraining Loss 1.3363 (1.3361)\n",
      "_\n",
      "Validation stats                    IoU        F1      Prec    recall       Acc\n",
      "bg,          0.951400  0.975000  0.977700  0.972500  0.956800\n",
      "real apple   0.174000  0.296300  0.897300  0.177500  0.944600\n",
      "real pepper  0.000000  0.000000  0.000000  0.000000  1.000000\n",
      "real grape   0.803800  0.891200  0.917600  0.866300  0.986300\n",
      "fake apple   0.000000  0.000000  0.000000  0.000000  0.955500\n",
      "fake pepper  0.000000  0.000000  0.000000  0.000000  0.993000\n",
      "fake grape   0.000000  0.000000  0.000000  0.000000  0.990500\n",
      "total        0.275600  0.308929  0.398943  0.288043  0.975243\n",
      "total(-bg)   0.162967  0.197917  0.302483  0.173967  0.978317\n",
      "\n",
      "Epoch: [69][0/16]\tTime 0.479 (0.479)\tETA 0:00:07\tTraining Loss 1.3357 (1.3357)\n",
      "\n",
      "Epoch: [69][1/16]\tTime 0.188 (0.667)\tETA 0:00:02\tTraining Loss 1.3417 (1.3387)\n",
      "\n",
      "Epoch: [69][2/16]\tTime 0.189 (0.856)\tETA 0:00:02\tTraining Loss 1.3342 (1.3372)\n",
      "\n",
      "Epoch: [69][3/16]\tTime 0.181 (1.037)\tETA 0:00:02\tTraining Loss 1.3307 (1.3356)\n",
      "\n",
      "Epoch: [69][4/16]\tTime 0.183 (1.220)\tETA 0:00:02\tTraining Loss 1.3298 (1.3344)\n",
      "\n",
      "Epoch: [69][5/16]\tTime 0.185 (1.404)\tETA 0:00:02\tTraining Loss 1.3315 (1.3339)\n",
      "\n",
      "Epoch: [69][6/16]\tTime 0.182 (1.586)\tETA 0:00:01\tTraining Loss 1.3315 (1.3336)\n",
      "\n",
      "Epoch: [69][7/16]\tTime 0.192 (1.778)\tETA 0:00:01\tTraining Loss 1.3301 (1.3331)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: [69][8/16]\tTime 0.182 (1.961)\tETA 0:00:01\tTraining Loss 1.3319 (1.3330)\n",
      "\n",
      "Epoch: [69][9/16]\tTime 0.187 (2.148)\tETA 0:00:01\tTraining Loss 1.3399 (1.3337)\n",
      "\n",
      "Epoch: [69][10/16]\tTime 0.199 (2.346)\tETA 0:00:01\tTraining Loss 1.3276 (1.3331)\n",
      "\n",
      "Epoch: [69][11/16]\tTime 0.186 (2.533)\tETA 0:00:00\tTraining Loss 1.3331 (1.3331)\n",
      "\n",
      "Epoch: [69][12/16]\tTime 0.186 (2.718)\tETA 0:00:00\tTraining Loss 1.3403 (1.3337)\n",
      "\n",
      "Epoch: [69][13/16]\tTime 0.186 (2.904)\tETA 0:00:00\tTraining Loss 1.3340 (1.3337)\n",
      "\n",
      "Epoch: [69][14/16]\tTime 0.182 (3.086)\tETA 0:00:00\tTraining Loss 1.3356 (1.3338)\n",
      "\n",
      "Epoch: [69][15/16]\tTime 0.116 (3.202)\tETA 0:00:00\tTraining Loss 1.3353 (1.3339)\n",
      "_\n",
      "Validation stats                    IoU        F1     Prec    recall       Acc\n",
      "bg,          0.944000  0.971200  0.97730  0.965100  0.950200\n",
      "real apple   0.097400  0.177500  0.95360  0.097900  0.940400\n",
      "real pepper  0.000000  0.000000  0.00000  0.000000  1.000000\n",
      "real grape   0.662600  0.797000  0.89710  0.717100  0.976400\n",
      "fake apple   0.000000  0.000000  0.00000  0.000000  0.953000\n",
      "fake pepper  0.000000  0.000000  0.00000  0.000000  0.983500\n",
      "fake grape   0.000000  0.000000  0.00000  0.000000  0.980600\n",
      "total        0.243429  0.277957  0.40400  0.254300  0.969157\n",
      "total(-bg)   0.126667  0.162417  0.30845  0.135833  0.972317\n",
      "\n",
      "Epoch: [70][0/16]\tTime 0.378 (0.378)\tETA 0:00:06\tTraining Loss 1.3271 (1.3271)\n",
      "\n",
      "Epoch: [70][1/16]\tTime 0.182 (0.561)\tETA 0:00:02\tTraining Loss 1.3355 (1.3313)\n",
      "\n",
      "Epoch: [70][2/16]\tTime 0.185 (0.745)\tETA 0:00:02\tTraining Loss 1.3232 (1.3286)\n",
      "\n",
      "Epoch: [70][3/16]\tTime 0.189 (0.934)\tETA 0:00:02\tTraining Loss 1.3286 (1.3286)\n",
      "\n",
      "Epoch: [70][4/16]\tTime 0.184 (1.119)\tETA 0:00:02\tTraining Loss 1.3331 (1.3295)\n",
      "\n",
      "Epoch: [70][5/16]\tTime 0.189 (1.308)\tETA 0:00:02\tTraining Loss 1.3295 (1.3295)\n",
      "\n",
      "Epoch: [70][6/16]\tTime 0.187 (1.495)\tETA 0:00:01\tTraining Loss 1.3297 (1.3295)\n",
      "\n",
      "Epoch: [70][7/16]\tTime 0.183 (1.678)\tETA 0:00:01\tTraining Loss 1.3312 (1.3297)\n",
      "\n",
      "Epoch: [70][8/16]\tTime 0.187 (1.865)\tETA 0:00:01\tTraining Loss 1.3285 (1.3296)\n",
      "\n",
      "Epoch: [70][9/16]\tTime 0.179 (2.044)\tETA 0:00:01\tTraining Loss 1.3303 (1.3297)\n",
      "\n",
      "Epoch: [70][10/16]\tTime 0.196 (2.241)\tETA 0:00:01\tTraining Loss 1.3388 (1.3305)\n",
      "\n",
      "Epoch: [70][11/16]\tTime 0.186 (2.426)\tETA 0:00:00\tTraining Loss 1.3345 (1.3308)\n",
      "\n",
      "Epoch: [70][12/16]\tTime 0.177 (2.603)\tETA 0:00:00\tTraining Loss 1.3255 (1.3304)\n",
      "\n",
      "Epoch: [70][13/16]\tTime 0.182 (2.785)\tETA 0:00:00\tTraining Loss 1.3283 (1.3303)\n",
      "\n",
      "Epoch: [70][14/16]\tTime 0.195 (2.980)\tETA 0:00:00\tTraining Loss 1.3265 (1.3300)\n",
      "\n",
      "Epoch: [70][15/16]\tTime 0.113 (3.093)\tETA 0:00:00\tTraining Loss 1.3348 (1.3302)\n",
      "_\n",
      "Validation stats                    IoU        F1      Prec    recall       Acc\n",
      "bg,          0.950400  0.974500  0.975900  0.973200  0.955800\n",
      "real apple   0.325300  0.490900  0.926800  0.333900  0.954500\n",
      "real pepper  0.000000  0.000000  0.000000  0.000000  0.996800\n",
      "real grape   0.840200  0.913100  0.898200  0.928600  0.988600\n",
      "fake apple   0.000000  0.000000  0.000000  0.000000  0.975600\n",
      "fake pepper  0.000000  0.000000  0.000000  0.000000  0.993700\n",
      "fake grape   0.000000  0.000000  0.000000  0.000000  0.991600\n",
      "total        0.302271  0.339786  0.400129  0.319386  0.979514\n",
      "total(-bg)   0.194250  0.234000  0.304167  0.210417  0.983467\n",
      "\n",
      "Epoch: [71][0/16]\tTime 0.372 (0.372)\tETA 0:00:05\tTraining Loss 1.3301 (1.3301)\n",
      "\n",
      "Epoch: [71][1/16]\tTime 0.182 (0.554)\tETA 0:00:02\tTraining Loss 1.3283 (1.3292)\n",
      "\n",
      "Epoch: [71][2/16]\tTime 0.191 (0.745)\tETA 0:00:02\tTraining Loss 1.3305 (1.3296)\n",
      "\n",
      "Epoch: [71][3/16]\tTime 0.188 (0.933)\tETA 0:00:02\tTraining Loss 1.3262 (1.3288)\n",
      "\n",
      "Epoch: [71][4/16]\tTime 0.190 (1.123)\tETA 0:00:02\tTraining Loss 1.3239 (1.3278)\n",
      "\n",
      "Epoch: [71][5/16]\tTime 0.175 (1.297)\tETA 0:00:01\tTraining Loss 1.3241 (1.3272)\n",
      "\n",
      "Epoch: [71][6/16]\tTime 0.189 (1.487)\tETA 0:00:01\tTraining Loss 1.3274 (1.3272)\n",
      "\n",
      "Epoch: [71][7/16]\tTime 0.187 (1.673)\tETA 0:00:01\tTraining Loss 1.3256 (1.3270)\n",
      "\n",
      "Epoch: [71][8/16]\tTime 0.189 (1.862)\tETA 0:00:01\tTraining Loss 1.3310 (1.3275)\n",
      "\n",
      "Epoch: [71][9/16]\tTime 0.184 (2.047)\tETA 0:00:01\tTraining Loss 1.3243 (1.3271)\n",
      "\n",
      "Epoch: [71][10/16]\tTime 0.187 (2.234)\tETA 0:00:01\tTraining Loss 1.3284 (1.3273)\n",
      "\n",
      "Epoch: [71][11/16]\tTime 0.191 (2.425)\tETA 0:00:00\tTraining Loss 1.3266 (1.3272)\n",
      "\n",
      "Epoch: [71][12/16]\tTime 0.193 (2.619)\tETA 0:00:00\tTraining Loss 1.3635 (1.3300)\n",
      "\n",
      "Epoch: [71][13/16]\tTime 0.186 (2.804)\tETA 0:00:00\tTraining Loss 1.3288 (1.3299)\n",
      "\n",
      "Epoch: [71][14/16]\tTime 0.191 (2.995)\tETA 0:00:00\tTraining Loss 1.3280 (1.3298)\n",
      "\n",
      "Epoch: [71][15/16]\tTime 0.116 (3.111)\tETA 0:00:00\tTraining Loss 1.3357 (1.3300)\n",
      "_\n",
      "Validation stats                    IoU        F1      Prec    recall       Acc\n",
      "bg,          0.945200  0.971800  0.976800  0.966900  0.951300\n",
      "real apple   0.177000  0.300700  0.849000  0.182700  0.944200\n",
      "real pepper  0.000000  0.000000  0.000000  0.000000  1.000000\n",
      "real grape   0.854100  0.921200  0.883400  0.962500  0.989300\n",
      "fake apple   0.000000  0.000000  0.000000  0.000000  0.957000\n",
      "fake pepper  0.000000  0.000000  0.000000  0.000000  0.991100\n",
      "fake grape   0.000000  0.000000  0.000000  0.000000  0.997300\n",
      "total        0.282329  0.313386  0.387029  0.301729  0.975743\n",
      "total(-bg)   0.171850  0.203650  0.288733  0.190867  0.979817\n",
      "\n",
      "Epoch: [72][0/16]\tTime 0.485 (0.485)\tETA 0:00:07\tTraining Loss 1.3332 (1.3332)\n",
      "\n",
      "Epoch: [72][1/16]\tTime 0.196 (0.681)\tETA 0:00:02\tTraining Loss 1.3264 (1.3298)\n",
      "\n",
      "Epoch: [72][2/16]\tTime 0.185 (0.865)\tETA 0:00:02\tTraining Loss 1.3317 (1.3304)\n",
      "\n",
      "Epoch: [72][3/16]\tTime 0.183 (1.048)\tETA 0:00:02\tTraining Loss 1.3296 (1.3302)\n",
      "\n",
      "Epoch: [72][4/16]\tTime 0.186 (1.234)\tETA 0:00:02\tTraining Loss 1.3242 (1.3290)\n",
      "\n",
      "Epoch: [72][5/16]\tTime 0.186 (1.420)\tETA 0:00:02\tTraining Loss 1.3425 (1.3313)\n",
      "\n",
      "Epoch: [72][6/16]\tTime 0.186 (1.606)\tETA 0:00:01\tTraining Loss 1.3270 (1.3307)\n",
      "\n",
      "Epoch: [72][7/16]\tTime 0.195 (1.801)\tETA 0:00:01\tTraining Loss 1.3233 (1.3298)\n",
      "\n",
      "Epoch: [72][8/16]\tTime 0.187 (1.988)\tETA 0:00:01\tTraining Loss 1.3209 (1.3288)\n",
      "\n",
      "Epoch: [72][9/16]\tTime 0.191 (2.180)\tETA 0:00:01\tTraining Loss 1.3265 (1.3286)\n",
      "\n",
      "Epoch: [72][10/16]\tTime 0.185 (2.365)\tETA 0:00:01\tTraining Loss 1.3307 (1.3287)\n",
      "\n",
      "Epoch: [72][11/16]\tTime 0.183 (2.548)\tETA 0:00:00\tTraining Loss 1.3316 (1.3290)\n",
      "\n",
      "Epoch: [72][12/16]\tTime 0.184 (2.732)\tETA 0:00:00\tTraining Loss 1.3310 (1.3291)\n",
      "\n",
      "Epoch: [72][13/16]\tTime 0.184 (2.917)\tETA 0:00:00\tTraining Loss 1.3235 (1.3287)\n",
      "\n",
      "Epoch: [72][14/16]\tTime 0.188 (3.104)\tETA 0:00:00\tTraining Loss 1.3349 (1.3291)\n",
      "\n",
      "Epoch: [72][15/16]\tTime 0.114 (3.218)\tETA 0:00:00\tTraining Loss 1.3288 (1.3291)\n",
      "_\n",
      "Validation stats                    IoU        F1      Prec    recall       Acc\n",
      "bg,          0.954000  0.976400  0.977100  0.975800  0.959100\n",
      "real apple   0.104800  0.189700  0.865200  0.106600  0.940200\n",
      "real pepper  0.000000  0.000000  0.000000  0.000000  0.999800\n",
      "real grape   0.531400  0.694000  0.965800  0.541700  0.969100\n",
      "fake apple   0.000000  0.000000  0.000000  0.000000  0.959100\n",
      "fake pepper  0.000000  0.000000  0.000000  0.000000  0.990500\n",
      "fake grape   0.000000  0.000000  0.000000  0.000000  0.963300\n",
      "total        0.227171  0.265729  0.401157  0.232014  0.968729\n",
      "total(-bg)   0.106033  0.147283  0.305167  0.108050  0.970333\n",
      "\n",
      "Epoch: [73][0/16]\tTime 0.482 (0.482)\tETA 0:00:07\tTraining Loss 1.3228 (1.3228)\n",
      "\n",
      "Epoch: [73][1/16]\tTime 0.178 (0.660)\tETA 0:00:02\tTraining Loss 1.3284 (1.3256)\n",
      "\n",
      "Epoch: [73][2/16]\tTime 0.183 (0.843)\tETA 0:00:02\tTraining Loss 1.3192 (1.3235)\n",
      "\n",
      "Epoch: [73][3/16]\tTime 0.181 (1.024)\tETA 0:00:02\tTraining Loss 1.3265 (1.3242)\n",
      "\n",
      "Epoch: [73][4/16]\tTime 0.194 (1.217)\tETA 0:00:02\tTraining Loss 1.3202 (1.3234)\n",
      "\n",
      "Epoch: [73][5/16]\tTime 0.186 (1.404)\tETA 0:00:02\tTraining Loss 1.3229 (1.3234)\n",
      "\n",
      "Epoch: [73][6/16]\tTime 0.181 (1.584)\tETA 0:00:01\tTraining Loss 1.3289 (1.3241)\n",
      "\n",
      "Epoch: [73][7/16]\tTime 0.188 (1.772)\tETA 0:00:01\tTraining Loss 1.3200 (1.3236)\n",
      "\n",
      "Epoch: [73][8/16]\tTime 0.193 (1.965)\tETA 0:00:01\tTraining Loss 1.3288 (1.3242)\n",
      "\n",
      "Epoch: [73][9/16]\tTime 0.183 (2.148)\tETA 0:00:01\tTraining Loss 1.3242 (1.3242)\n",
      "\n",
      "Epoch: [73][10/16]\tTime 0.182 (2.330)\tETA 0:00:01\tTraining Loss 1.3182 (1.3237)\n",
      "\n",
      "Epoch: [73][11/16]\tTime 0.190 (2.520)\tETA 0:00:00\tTraining Loss 1.3279 (1.3240)\n",
      "\n",
      "Epoch: [73][12/16]\tTime 0.183 (2.703)\tETA 0:00:00\tTraining Loss 1.3205 (1.3237)\n",
      "\n",
      "Epoch: [73][13/16]\tTime 0.187 (2.890)\tETA 0:00:00\tTraining Loss 1.3248 (1.3238)\n",
      "\n",
      "Epoch: [73][14/16]\tTime 0.190 (3.080)\tETA 0:00:00\tTraining Loss 1.3248 (1.3239)\n",
      "\n",
      "Epoch: [73][15/16]\tTime 0.112 (3.192)\tETA 0:00:00\tTraining Loss 1.3218 (1.3238)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_\n",
      "Validation stats                    IoU        F1      Prec    recall       Acc\n",
      "bg,          0.953000  0.975900  0.976700  0.975200  0.958200\n",
      "real apple   0.039800  0.076500  0.910100  0.039900  0.936600\n",
      "real pepper  0.000000  0.000000  0.000000  0.000000  1.000000\n",
      "real grape   0.679300  0.809000  0.944500  0.707600  0.978400\n",
      "fake apple   0.000000  0.000000  0.000000  0.000000  0.957700\n",
      "fake pepper  0.000000  0.000000  0.000000  0.000000  0.983800\n",
      "fake grape   0.000000  0.000000  0.000000  0.000000  0.978100\n",
      "total        0.238871  0.265914  0.404471  0.246100  0.970400\n",
      "total(-bg)   0.119850  0.147583  0.309100  0.124583  0.972433\n",
      "\n",
      "Epoch: [74][0/16]\tTime 0.474 (0.474)\tETA 0:00:07\tTraining Loss 1.3175 (1.3175)\n",
      "\n",
      "Epoch: [74][1/16]\tTime 0.184 (0.658)\tETA 0:00:02\tTraining Loss 1.3201 (1.3188)\n",
      "\n",
      "Epoch: [74][2/16]\tTime 0.190 (0.848)\tETA 0:00:02\tTraining Loss 1.3225 (1.3200)\n",
      "\n",
      "Epoch: [74][3/16]\tTime 0.185 (1.032)\tETA 0:00:02\tTraining Loss 1.3249 (1.3212)\n",
      "\n",
      "Epoch: [74][4/16]\tTime 0.189 (1.222)\tETA 0:00:02\tTraining Loss 1.3151 (1.3200)\n",
      "\n",
      "Epoch: [74][5/16]\tTime 0.189 (1.410)\tETA 0:00:02\tTraining Loss 1.3224 (1.3204)\n",
      "\n",
      "Epoch: [74][6/16]\tTime 0.188 (1.598)\tETA 0:00:01\tTraining Loss 1.3201 (1.3203)\n",
      "\n",
      "Epoch: [74][7/16]\tTime 0.196 (1.793)\tETA 0:00:01\tTraining Loss 1.3234 (1.3207)\n",
      "\n",
      "Epoch: [74][8/16]\tTime 0.193 (1.987)\tETA 0:00:01\tTraining Loss 1.3171 (1.3203)\n",
      "\n",
      "Epoch: [74][9/16]\tTime 0.180 (2.166)\tETA 0:00:01\tTraining Loss 1.3221 (1.3205)\n",
      "\n",
      "Epoch: [74][10/16]\tTime 0.190 (2.356)\tETA 0:00:01\tTraining Loss 1.3208 (1.3205)\n",
      "\n",
      "Epoch: [74][11/16]\tTime 0.184 (2.540)\tETA 0:00:00\tTraining Loss 1.3154 (1.3201)\n",
      "\n",
      "Epoch: [74][12/16]\tTime 0.201 (2.742)\tETA 0:00:00\tTraining Loss 1.3151 (1.3197)\n",
      "\n",
      "Epoch: [74][13/16]\tTime 0.188 (2.930)\tETA 0:00:00\tTraining Loss 1.3259 (1.3202)\n",
      "\n",
      "Epoch: [74][14/16]\tTime 0.191 (3.120)\tETA 0:00:00\tTraining Loss 1.3234 (1.3204)\n",
      "\n",
      "Epoch: [74][15/16]\tTime 0.114 (3.235)\tETA 0:00:00\tTraining Loss 1.3131 (1.3201)\n",
      "_\n",
      "Validation stats                    IoU        F1      Prec    recall       Acc\n",
      "bg,          0.952800  0.975800  0.975600  0.976100  0.958000\n",
      "real apple   0.143700  0.251200  0.873500  0.146700  0.942500\n",
      "real pepper  0.000000  0.000000  0.000000  0.000000  0.999800\n",
      "real grape   0.584900  0.738100  0.923200  0.614800  0.971700\n",
      "fake apple   0.000000  0.000000  0.000000  0.000000  0.959300\n",
      "fake pepper  0.000000  0.000000  0.000000  0.000000  0.993200\n",
      "fake grape   0.000000  0.000000  0.000000  0.000000  0.971900\n",
      "total        0.240200  0.280729  0.396043  0.248229  0.970914\n",
      "total(-bg)   0.121433  0.164883  0.299450  0.126917  0.973067\n",
      "\n",
      "Epoch: [75][0/16]\tTime 0.404 (0.404)\tETA 0:00:06\tTraining Loss 1.3173 (1.3173)\n",
      "\n",
      "Epoch: [75][1/16]\tTime 0.179 (0.584)\tETA 0:00:02\tTraining Loss 1.3235 (1.3204)\n",
      "\n",
      "Epoch: [75][2/16]\tTime 0.197 (0.780)\tETA 0:00:02\tTraining Loss 1.3157 (1.3188)\n",
      "\n",
      "Epoch: [75][3/16]\tTime 0.189 (0.970)\tETA 0:00:02\tTraining Loss 1.3186 (1.3188)\n",
      "\n",
      "Epoch: [75][4/16]\tTime 0.196 (1.166)\tETA 0:00:02\tTraining Loss 1.3165 (1.3183)\n",
      "\n",
      "Epoch: [75][5/16]\tTime 0.191 (1.356)\tETA 0:00:02\tTraining Loss 1.3138 (1.3176)\n",
      "\n",
      "Epoch: [75][6/16]\tTime 0.195 (1.551)\tETA 0:00:01\tTraining Loss 1.3194 (1.3178)\n",
      "\n",
      "Epoch: [75][7/16]\tTime 0.179 (1.730)\tETA 0:00:01\tTraining Loss 1.3141 (1.3174)\n",
      "\n",
      "Epoch: [75][8/16]\tTime 0.197 (1.927)\tETA 0:00:01\tTraining Loss 1.3222 (1.3179)\n",
      "\n",
      "Epoch: [75][9/16]\tTime 0.189 (2.117)\tETA 0:00:01\tTraining Loss 1.3136 (1.3175)\n",
      "\n",
      "Epoch: [75][10/16]\tTime 0.187 (2.304)\tETA 0:00:01\tTraining Loss 1.3237 (1.3180)\n",
      "\n",
      "Epoch: [75][11/16]\tTime 0.188 (2.491)\tETA 0:00:00\tTraining Loss 1.3172 (1.3180)\n",
      "\n",
      "Epoch: [75][12/16]\tTime 0.192 (2.684)\tETA 0:00:00\tTraining Loss 1.3186 (1.3180)\n",
      "\n",
      "Epoch: [75][13/16]\tTime 0.193 (2.876)\tETA 0:00:00\tTraining Loss 1.3179 (1.3180)\n",
      "\n",
      "Epoch: [75][14/16]\tTime 0.184 (3.061)\tETA 0:00:00\tTraining Loss 1.3117 (1.3176)\n",
      "\n",
      "Epoch: [75][15/16]\tTime 0.113 (3.174)\tETA 0:00:00\tTraining Loss 1.3236 (1.3178)\n",
      "_\n",
      "Validation stats                    IoU        F1      Prec    recall       Acc\n",
      "bg,          0.951800  0.975300  0.978100  0.972600  0.957200\n",
      "real apple   0.181600  0.307300  0.897700  0.185400  0.945100\n",
      "real pepper  0.000000  0.000000  0.000000  0.000000  1.000000\n",
      "real grape   0.787300  0.880900  0.925600  0.840500  0.985300\n",
      "fake apple   0.000000  0.000000  0.000000  0.000000  0.957500\n",
      "fake pepper  0.000000  0.000000  0.000000  0.000000  0.991800\n",
      "fake grape   0.000000  0.000000  0.000000  0.000000  0.987800\n",
      "total        0.274386  0.309071  0.400200  0.285500  0.974957\n",
      "total(-bg)   0.161483  0.198033  0.303883  0.170983  0.977917\n",
      "\n",
      "Epoch: [76][0/16]\tTime 0.510 (0.510)\tETA 0:00:08\tTraining Loss 1.3162 (1.3162)\n",
      "\n",
      "Epoch: [76][1/16]\tTime 0.167 (0.677)\tETA 0:00:02\tTraining Loss 1.3198 (1.3180)\n",
      "\n",
      "Epoch: [76][2/16]\tTime 0.193 (0.870)\tETA 0:00:02\tTraining Loss 1.3177 (1.3179)\n",
      "\n",
      "Epoch: [76][3/16]\tTime 0.174 (1.044)\tETA 0:00:02\tTraining Loss 1.3263 (1.3200)\n",
      "\n",
      "Epoch: [76][4/16]\tTime 0.200 (1.245)\tETA 0:00:02\tTraining Loss 1.3112 (1.3182)\n",
      "\n",
      "Epoch: [76][5/16]\tTime 0.186 (1.431)\tETA 0:00:02\tTraining Loss 1.3242 (1.3192)\n",
      "\n",
      "Epoch: [76][6/16]\tTime 0.194 (1.624)\tETA 0:00:01\tTraining Loss 1.3182 (1.3191)\n",
      "\n",
      "Epoch: [76][7/16]\tTime 0.193 (1.817)\tETA 0:00:01\tTraining Loss 1.3119 (1.3182)\n",
      "\n",
      "Epoch: [76][8/16]\tTime 0.188 (2.006)\tETA 0:00:01\tTraining Loss 1.3104 (1.3173)\n",
      "\n",
      "Epoch: [76][9/16]\tTime 0.197 (2.203)\tETA 0:00:01\tTraining Loss 1.3313 (1.3187)\n",
      "\n",
      "Epoch: [76][10/16]\tTime 0.184 (2.387)\tETA 0:00:01\tTraining Loss 1.3125 (1.3182)\n",
      "\n",
      "Epoch: [76][11/16]\tTime 0.190 (2.577)\tETA 0:00:00\tTraining Loss 1.3137 (1.3178)\n",
      "\n",
      "Epoch: [76][12/16]\tTime 0.182 (2.759)\tETA 0:00:00\tTraining Loss 1.3086 (1.3171)\n",
      "\n",
      "Epoch: [76][13/16]\tTime 0.186 (2.945)\tETA 0:00:00\tTraining Loss 1.3113 (1.3167)\n",
      "\n",
      "Epoch: [76][14/16]\tTime 0.184 (3.130)\tETA 0:00:00\tTraining Loss 1.3156 (1.3166)\n",
      "\n",
      "Epoch: [76][15/16]\tTime 0.113 (3.243)\tETA 0:00:00\tTraining Loss 1.3093 (1.3164)\n",
      "_\n",
      "Validation stats                    IoU        F1      Prec    recall       Acc\n",
      "bg,          0.952800  0.975800  0.979300  0.972400  0.958100\n",
      "real apple   0.257200  0.409100  0.882300  0.266300  0.949400\n",
      "real pepper  0.000000  0.000000  0.000000  0.000000  1.000000\n",
      "real grape   0.701300  0.824400  0.892700  0.765900  0.978900\n",
      "fake apple   0.000000  0.000000  0.000000  0.000000  0.959800\n",
      "fake pepper  0.000000  0.000000  0.000000  0.000000  0.995800\n",
      "fake grape   0.000000  0.000000  0.000000  0.000000  0.983100\n",
      "total        0.273043  0.315614  0.393471  0.286371  0.975014\n",
      "total(-bg)   0.159750  0.205583  0.295833  0.172033  0.977833\n",
      "\n",
      "Epoch: [77][0/16]\tTime 0.484 (0.484)\tETA 0:00:07\tTraining Loss 1.3215 (1.3215)\n",
      "\n",
      "Epoch: [77][1/16]\tTime 0.188 (0.672)\tETA 0:00:02\tTraining Loss 1.3159 (1.3187)\n",
      "\n",
      "Epoch: [77][2/16]\tTime 0.189 (0.861)\tETA 0:00:02\tTraining Loss 1.3165 (1.3179)\n",
      "\n",
      "Epoch: [77][3/16]\tTime 0.187 (1.048)\tETA 0:00:02\tTraining Loss 1.3119 (1.3164)\n",
      "\n",
      "Epoch: [77][4/16]\tTime 0.191 (1.239)\tETA 0:00:02\tTraining Loss 1.3112 (1.3154)\n",
      "\n",
      "Epoch: [77][5/16]\tTime 0.193 (1.432)\tETA 0:00:02\tTraining Loss 1.3101 (1.3145)\n",
      "\n",
      "Epoch: [77][6/16]\tTime 0.185 (1.618)\tETA 0:00:01\tTraining Loss 1.3097 (1.3138)\n",
      "\n",
      "Epoch: [77][7/16]\tTime 0.187 (1.804)\tETA 0:00:01\tTraining Loss 1.3174 (1.3143)\n",
      "\n",
      "Epoch: [77][8/16]\tTime 0.190 (1.994)\tETA 0:00:01\tTraining Loss 1.3172 (1.3146)\n",
      "\n",
      "Epoch: [77][9/16]\tTime 0.179 (2.174)\tETA 0:00:01\tTraining Loss 1.3084 (1.3140)\n",
      "\n",
      "Epoch: [77][10/16]\tTime 0.192 (2.366)\tETA 0:00:01\tTraining Loss 1.3101 (1.3136)\n",
      "\n",
      "Epoch: [77][11/16]\tTime 0.192 (2.557)\tETA 0:00:00\tTraining Loss 1.3101 (1.3133)\n",
      "\n",
      "Epoch: [77][12/16]\tTime 0.192 (2.750)\tETA 0:00:00\tTraining Loss 1.3139 (1.3134)\n",
      "\n",
      "Epoch: [77][13/16]\tTime 0.188 (2.938)\tETA 0:00:00\tTraining Loss 1.3064 (1.3129)\n",
      "\n",
      "Epoch: [77][14/16]\tTime 0.183 (3.121)\tETA 0:00:00\tTraining Loss 1.3123 (1.3128)\n",
      "\n",
      "Epoch: [77][15/16]\tTime 0.112 (3.233)\tETA 0:00:00\tTraining Loss 1.3144 (1.3129)\n",
      "_\n",
      "Validation stats                    IoU        F1      Prec    recall       Acc\n",
      "bg,          0.944800  0.971600  0.977800  0.965500  0.951000\n",
      "real apple   0.005100  0.010100  0.619700  0.005100  0.934400\n",
      "real pepper  0.000000  0.000000  0.000000  0.000000  0.999300\n",
      "real grape   0.610400  0.758000  0.936600  0.636700  0.973700\n",
      "fake apple   0.000000  0.000000  0.000000  0.000000  0.956100\n",
      "fake pepper  0.000000  0.000000  0.000000  0.000000  0.971600\n",
      "fake grape   0.000000  0.000000  0.000000  0.000000  0.976200\n",
      "total        0.222900  0.248529  0.362014  0.229614  0.966043\n",
      "total(-bg)   0.102583  0.128017  0.259383  0.106967  0.968550\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: [78][0/16]\tTime 0.360 (0.360)\tETA 0:00:05\tTraining Loss 1.3063 (1.3063)\n",
      "\n",
      "Epoch: [78][1/16]\tTime 0.183 (0.543)\tETA 0:00:02\tTraining Loss 1.3063 (1.3063)\n",
      "\n",
      "Epoch: [78][2/16]\tTime 0.187 (0.730)\tETA 0:00:02\tTraining Loss 1.3182 (1.3102)\n",
      "\n",
      "Epoch: [78][3/16]\tTime 0.186 (0.916)\tETA 0:00:02\tTraining Loss 1.3142 (1.3112)\n",
      "\n",
      "Epoch: [78][4/16]\tTime 0.184 (1.100)\tETA 0:00:02\tTraining Loss 1.3076 (1.3105)\n",
      "\n",
      "Epoch: [78][5/16]\tTime 0.195 (1.295)\tETA 0:00:02\tTraining Loss 1.3092 (1.3103)\n",
      "\n",
      "Epoch: [78][6/16]\tTime 0.180 (1.475)\tETA 0:00:01\tTraining Loss 1.3106 (1.3103)\n",
      "\n",
      "Epoch: [78][7/16]\tTime 0.194 (1.668)\tETA 0:00:01\tTraining Loss 1.3068 (1.3099)\n",
      "\n",
      "Epoch: [78][8/16]\tTime 0.184 (1.852)\tETA 0:00:01\tTraining Loss 1.3073 (1.3096)\n",
      "\n",
      "Epoch: [78][9/16]\tTime 0.186 (2.038)\tETA 0:00:01\tTraining Loss 1.3085 (1.3095)\n",
      "\n",
      "Epoch: [78][10/16]\tTime 0.192 (2.230)\tETA 0:00:01\tTraining Loss 1.3084 (1.3094)\n",
      "\n",
      "Epoch: [78][11/16]\tTime 0.194 (2.424)\tETA 0:00:00\tTraining Loss 1.3077 (1.3092)\n",
      "\n",
      "Epoch: [78][12/16]\tTime 0.186 (2.610)\tETA 0:00:00\tTraining Loss 1.3074 (1.3091)\n",
      "\n",
      "Epoch: [78][13/16]\tTime 0.191 (2.801)\tETA 0:00:00\tTraining Loss 1.3099 (1.3092)\n",
      "\n",
      "Epoch: [78][14/16]\tTime 0.202 (3.003)\tETA 0:00:00\tTraining Loss 1.3040 (1.3088)\n",
      "\n",
      "Epoch: [78][15/16]\tTime 0.113 (3.116)\tETA 0:00:00\tTraining Loss 1.3191 (1.3091)\n",
      "_\n",
      "Validation stats                    IoU      F1      Prec    recall       Acc\n",
      "bg,          0.949200  0.9739  0.978500  0.969400  0.954900\n",
      "real apple   0.024900  0.0487  0.827600  0.025100  0.935600\n",
      "real pepper  0.000000  0.0000  0.000000  0.000000  0.999800\n",
      "real grape   0.767000  0.8681  0.937700  0.808200  0.984100\n",
      "fake apple   0.000000  0.0000  0.000000  0.000000  0.956300\n",
      "fake pepper  0.000000  0.0000  0.000000  0.000000  0.975100\n",
      "fake grape   0.000000  0.0000  0.000000  0.000000  0.988100\n",
      "total        0.248729  0.2701  0.391971  0.257529  0.970557\n",
      "total(-bg)   0.131983  0.1528  0.294217  0.138883  0.973167\n",
      "\n",
      "Epoch: [79][0/16]\tTime 0.472 (0.472)\tETA 0:00:07\tTraining Loss 1.3153 (1.3153)\n",
      "\n",
      "Epoch: [79][1/16]\tTime 0.194 (0.667)\tETA 0:00:02\tTraining Loss 1.3055 (1.3104)\n",
      "\n",
      "Epoch: [79][2/16]\tTime 0.203 (0.869)\tETA 0:00:02\tTraining Loss 1.3080 (1.3096)\n",
      "\n",
      "Epoch: [79][3/16]\tTime 0.181 (1.050)\tETA 0:00:02\tTraining Loss 1.3114 (1.3101)\n",
      "\n",
      "Epoch: [79][4/16]\tTime 0.199 (1.250)\tETA 0:00:02\tTraining Loss 1.3076 (1.3096)\n",
      "\n",
      "Epoch: [79][5/16]\tTime 0.184 (1.434)\tETA 0:00:02\tTraining Loss 1.3065 (1.3091)\n",
      "\n",
      "Epoch: [79][6/16]\tTime 0.183 (1.617)\tETA 0:00:01\tTraining Loss 1.3042 (1.3084)\n",
      "\n",
      "Epoch: [79][7/16]\tTime 0.195 (1.812)\tETA 0:00:01\tTraining Loss 1.3046 (1.3079)\n",
      "\n",
      "Epoch: [79][8/16]\tTime 0.191 (2.004)\tETA 0:00:01\tTraining Loss 1.3059 (1.3077)\n",
      "\n",
      "Epoch: [79][9/16]\tTime 0.185 (2.189)\tETA 0:00:01\tTraining Loss 1.3032 (1.3072)\n",
      "\n",
      "Epoch: [79][10/16]\tTime 0.203 (2.391)\tETA 0:00:01\tTraining Loss 1.3013 (1.3067)\n",
      "\n",
      "Epoch: [79][11/16]\tTime 0.186 (2.577)\tETA 0:00:00\tTraining Loss 1.3040 (1.3065)\n",
      "\n",
      "Epoch: [79][12/16]\tTime 0.187 (2.764)\tETA 0:00:00\tTraining Loss 1.3223 (1.3077)\n",
      "\n",
      "Epoch: [79][13/16]\tTime 0.185 (2.949)\tETA 0:00:00\tTraining Loss 1.3016 (1.3073)\n",
      "\n",
      "Epoch: [79][14/16]\tTime 0.189 (3.138)\tETA 0:00:00\tTraining Loss 1.3049 (1.3071)\n",
      "\n",
      "Epoch: [79][15/16]\tTime 0.122 (3.261)\tETA 0:00:00\tTraining Loss 1.2997 (1.3069)\n",
      "_\n",
      "Validation stats                    IoU        F1      Prec    recall       Acc\n",
      "bg,          0.949800  0.974200  0.976800  0.971700  0.955400\n",
      "real apple   0.069200  0.129400  0.837700  0.070100  0.938000\n",
      "real pepper  0.000000  0.000000  0.000000  0.000000  1.000000\n",
      "real grape   0.843500  0.915100  0.915100  0.915200  0.989000\n",
      "fake apple   0.000000  0.000000  0.000000  0.000000  0.962000\n",
      "fake pepper  0.000000  0.000000  0.000000  0.000000  0.978100\n",
      "fake grape   0.000000  0.000000  0.000000  0.000000  0.995100\n",
      "total        0.266071  0.288386  0.389943  0.279571  0.973943\n",
      "total(-bg)   0.152117  0.174083  0.292133  0.164217  0.977033\n",
      "\n",
      "Epoch: [80][0/16]\tTime 0.498 (0.498)\tETA 0:00:07\tTraining Loss 1.3058 (1.3058)\n",
      "\n",
      "Epoch: [80][1/16]\tTime 0.181 (0.679)\tETA 0:00:02\tTraining Loss 1.3008 (1.3033)\n",
      "\n",
      "Epoch: [80][2/16]\tTime 0.186 (0.865)\tETA 0:00:02\tTraining Loss 1.3034 (1.3033)\n",
      "\n",
      "Epoch: [80][3/16]\tTime 0.184 (1.049)\tETA 0:00:02\tTraining Loss 1.3103 (1.3051)\n",
      "\n",
      "Epoch: [80][4/16]\tTime 0.192 (1.241)\tETA 0:00:02\tTraining Loss 1.3078 (1.3056)\n",
      "\n",
      "Epoch: [80][5/16]\tTime 0.183 (1.424)\tETA 0:00:02\tTraining Loss 1.3010 (1.3048)\n",
      "\n",
      "Epoch: [80][6/16]\tTime 0.190 (1.614)\tETA 0:00:01\tTraining Loss 1.3071 (1.3052)\n",
      "\n",
      "Epoch: [80][7/16]\tTime 0.194 (1.807)\tETA 0:00:01\tTraining Loss 1.3059 (1.3053)\n",
      "\n",
      "Epoch: [80][8/16]\tTime 0.187 (1.994)\tETA 0:00:01\tTraining Loss 1.3047 (1.3052)\n",
      "\n",
      "Epoch: [80][9/16]\tTime 0.183 (2.177)\tETA 0:00:01\tTraining Loss 1.3000 (1.3047)\n",
      "\n",
      "Epoch: [80][10/16]\tTime 0.196 (2.373)\tETA 0:00:01\tTraining Loss 1.3028 (1.3045)\n",
      "\n",
      "Epoch: [80][11/16]\tTime 0.192 (2.565)\tETA 0:00:00\tTraining Loss 1.3084 (1.3048)\n",
      "\n",
      "Epoch: [80][12/16]\tTime 0.188 (2.753)\tETA 0:00:00\tTraining Loss 1.3010 (1.3045)\n",
      "\n",
      "Epoch: [80][13/16]\tTime 0.179 (2.932)\tETA 0:00:00\tTraining Loss 1.3024 (1.3044)\n",
      "\n",
      "Epoch: [80][14/16]\tTime 0.190 (3.122)\tETA 0:00:00\tTraining Loss 1.3057 (1.3045)\n",
      "\n",
      "Epoch: [80][15/16]\tTime 0.114 (3.236)\tETA 0:00:00\tTraining Loss 1.3001 (1.3043)\n",
      "_\n",
      "Validation stats                   IoU        F1      Prec    recall       Acc\n",
      "bg,          0.95150  0.975100  0.978800  0.971500  0.956900\n",
      "real apple   0.05870  0.110800  0.821800  0.059400  0.937300\n",
      "real pepper  0.00000  0.000000  0.000000  0.000000  1.000000\n",
      "real grape   0.73000  0.843900  0.913200  0.784500  0.981200\n",
      "fake apple   0.00000  0.000000  0.000000  0.000000  0.953500\n",
      "fake pepper  0.00000  0.000000  0.000000  0.000000  0.984900\n",
      "fake grape   0.00000  0.000000  0.000000  0.000000  0.985000\n",
      "total        0.24860  0.275686  0.387686  0.259343  0.971257\n",
      "total(-bg)   0.13145  0.159117  0.289167  0.140650  0.973650\n",
      "\n",
      "Epoch: [81][0/16]\tTime 0.360 (0.360)\tETA 0:00:05\tTraining Loss 1.3099 (1.3099)\n",
      "\n",
      "Epoch: [81][1/16]\tTime 0.192 (0.552)\tETA 0:00:02\tTraining Loss 1.3049 (1.3074)\n",
      "\n",
      "Epoch: [81][2/16]\tTime 0.190 (0.743)\tETA 0:00:02\tTraining Loss 1.3115 (1.3088)\n",
      "\n",
      "Epoch: [81][3/16]\tTime 0.175 (0.918)\tETA 0:00:02\tTraining Loss 1.3034 (1.3074)\n",
      "\n",
      "Epoch: [81][4/16]\tTime 0.182 (1.100)\tETA 0:00:02\tTraining Loss 1.2996 (1.3059)\n",
      "\n",
      "Epoch: [81][5/16]\tTime 0.184 (1.284)\tETA 0:00:02\tTraining Loss 1.3008 (1.3050)\n",
      "\n",
      "Epoch: [81][6/16]\tTime 0.185 (1.468)\tETA 0:00:01\tTraining Loss 1.2997 (1.3043)\n",
      "\n",
      "Epoch: [81][7/16]\tTime 0.183 (1.652)\tETA 0:00:01\tTraining Loss 1.3003 (1.3038)\n",
      "\n",
      "Epoch: [81][8/16]\tTime 0.181 (1.832)\tETA 0:00:01\tTraining Loss 1.3036 (1.3038)\n",
      "\n",
      "Epoch: [81][9/16]\tTime 0.188 (2.020)\tETA 0:00:01\tTraining Loss 1.3035 (1.3037)\n",
      "\n",
      "Epoch: [81][10/16]\tTime 0.186 (2.206)\tETA 0:00:01\tTraining Loss 1.3082 (1.3041)\n",
      "\n",
      "Epoch: [81][11/16]\tTime 0.191 (2.397)\tETA 0:00:00\tTraining Loss 1.2998 (1.3038)\n",
      "\n",
      "Epoch: [81][12/16]\tTime 0.191 (2.588)\tETA 0:00:00\tTraining Loss 1.3023 (1.3037)\n",
      "\n",
      "Epoch: [81][13/16]\tTime 0.187 (2.776)\tETA 0:00:00\tTraining Loss 1.3006 (1.3034)\n",
      "\n",
      "Epoch: [81][14/16]\tTime 0.187 (2.963)\tETA 0:00:00\tTraining Loss 1.3004 (1.3032)\n",
      "\n",
      "Epoch: [81][15/16]\tTime 0.112 (3.075)\tETA 0:00:00\tTraining Loss 1.3036 (1.3033)\n",
      "_\n",
      "Validation stats                    IoU        F1     Prec    recall       Acc\n",
      "bg,          0.950100  0.974400  0.97710  0.971800  0.955700\n",
      "real apple   0.052200  0.099200  0.79030  0.052900  0.936800\n",
      "real pepper  0.000000  0.000000  0.00000  0.000000  0.999600\n",
      "real grape   0.580900  0.734900  0.90800  0.617300  0.971200\n",
      "fake apple   0.000000  0.000000  0.00000  0.000000  0.955600\n",
      "fake pepper  0.000000  0.000000  0.00000  0.000000  0.980100\n",
      "fake grape   0.000000  0.000000  0.00000  0.000000  0.978000\n",
      "total        0.226171  0.258357  0.38220  0.234571  0.968143\n",
      "total(-bg)   0.105517  0.139017  0.28305  0.111700  0.970217\n",
      "\n",
      "Epoch: [82][0/16]\tTime 0.432 (0.432)\tETA 0:00:06\tTraining Loss 1.3000 (1.3000)\n",
      "\n",
      "Epoch: [82][1/16]\tTime 0.180 (0.612)\tETA 0:00:02\tTraining Loss 1.2996 (1.2998)\n",
      "\n",
      "Epoch: [82][2/16]\tTime 0.179 (0.792)\tETA 0:00:02\tTraining Loss 1.2983 (1.2993)\n",
      "\n",
      "Epoch: [82][3/16]\tTime 0.186 (0.977)\tETA 0:00:02\tTraining Loss 1.3038 (1.3004)\n",
      "\n",
      "Epoch: [82][4/16]\tTime 0.191 (1.169)\tETA 0:00:02\tTraining Loss 1.3001 (1.3004)\n",
      "\n",
      "Epoch: [82][5/16]\tTime 0.188 (1.357)\tETA 0:00:02\tTraining Loss 1.2973 (1.2998)\n",
      "\n",
      "Epoch: [82][6/16]\tTime 0.182 (1.539)\tETA 0:00:01\tTraining Loss 1.2986 (1.2997)\n",
      "\n",
      "Epoch: [82][7/16]\tTime 0.187 (1.726)\tETA 0:00:01\tTraining Loss 1.3014 (1.2999)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: [82][8/16]\tTime 0.191 (1.917)\tETA 0:00:01\tTraining Loss 1.3010 (1.3000)\n",
      "\n",
      "Epoch: [82][9/16]\tTime 0.194 (2.111)\tETA 0:00:01\tTraining Loss 1.2963 (1.2996)\n",
      "\n",
      "Epoch: [82][10/16]\tTime 0.188 (2.299)\tETA 0:00:01\tTraining Loss 1.2985 (1.2995)\n",
      "\n",
      "Epoch: [82][11/16]\tTime 0.181 (2.480)\tETA 0:00:00\tTraining Loss 1.3030 (1.2998)\n",
      "\n",
      "Epoch: [82][12/16]\tTime 0.189 (2.668)\tETA 0:00:00\tTraining Loss 1.2992 (1.2998)\n",
      "\n",
      "Epoch: [82][13/16]\tTime 0.191 (2.860)\tETA 0:00:00\tTraining Loss 1.2966 (1.2995)\n",
      "\n",
      "Epoch: [82][14/16]\tTime 0.187 (3.047)\tETA 0:00:00\tTraining Loss 1.2975 (1.2994)\n",
      "\n",
      "Epoch: [82][15/16]\tTime 0.114 (3.161)\tETA 0:00:00\tTraining Loss 1.3111 (1.2998)\n",
      "_\n",
      "Validation stats                    IoU        F1      Prec    recall      Acc\n",
      "bg,          0.948900  0.973700  0.976300  0.971300  0.95460\n",
      "real apple   0.032900  0.063800  0.979300  0.033000  0.93640\n",
      "real pepper  0.000000  0.000000  0.000000  0.000000  1.00000\n",
      "real grape   0.715300  0.834000  0.907600  0.771500  0.98010\n",
      "fake apple   0.000000  0.000000  0.000000  0.000000  0.96030\n",
      "fake pepper  0.000000  0.000000  0.000000  0.000000  0.97960\n",
      "fake grape   0.000000  0.000000  0.000000  0.000000  0.98250\n",
      "total        0.242443  0.267357  0.409029  0.253686  0.97050\n",
      "total(-bg)   0.124700  0.149633  0.314483  0.134083  0.97315\n",
      "\n",
      "Epoch: [83][0/16]\tTime 0.461 (0.461)\tETA 0:00:07\tTraining Loss 1.3020 (1.3020)\n",
      "\n",
      "Epoch: [83][1/16]\tTime 0.174 (0.635)\tETA 0:00:02\tTraining Loss 1.2961 (1.2990)\n",
      "\n",
      "Epoch: [83][2/16]\tTime 0.196 (0.831)\tETA 0:00:02\tTraining Loss 1.2988 (1.2990)\n",
      "\n",
      "Epoch: [83][3/16]\tTime 0.186 (1.017)\tETA 0:00:02\tTraining Loss 1.3012 (1.2995)\n",
      "\n",
      "Epoch: [83][4/16]\tTime 0.185 (1.202)\tETA 0:00:02\tTraining Loss 1.2925 (1.2981)\n",
      "\n",
      "Epoch: [83][5/16]\tTime 0.185 (1.387)\tETA 0:00:02\tTraining Loss 1.2987 (1.2982)\n",
      "\n",
      "Epoch: [83][6/16]\tTime 0.183 (1.570)\tETA 0:00:01\tTraining Loss 1.2945 (1.2977)\n",
      "\n",
      "Epoch: [83][7/16]\tTime 0.187 (1.757)\tETA 0:00:01\tTraining Loss 1.2994 (1.2979)\n",
      "\n",
      "Epoch: [83][8/16]\tTime 0.176 (1.933)\tETA 0:00:01\tTraining Loss 1.2924 (1.2973)\n",
      "\n",
      "Epoch: [83][9/16]\tTime 0.190 (2.124)\tETA 0:00:01\tTraining Loss 1.2960 (1.2972)\n",
      "\n",
      "Epoch: [83][10/16]\tTime 0.187 (2.311)\tETA 0:00:01\tTraining Loss 1.2961 (1.2971)\n",
      "\n",
      "Epoch: [83][11/16]\tTime 0.182 (2.493)\tETA 0:00:00\tTraining Loss 1.2936 (1.2968)\n",
      "\n",
      "Epoch: [83][12/16]\tTime 0.189 (2.682)\tETA 0:00:00\tTraining Loss 1.2953 (1.2967)\n",
      "\n",
      "Epoch: [83][13/16]\tTime 0.179 (2.861)\tETA 0:00:00\tTraining Loss 1.2911 (1.2963)\n",
      "\n",
      "Epoch: [83][14/16]\tTime 0.188 (3.049)\tETA 0:00:00\tTraining Loss 1.2918 (1.2960)\n",
      "\n",
      "Epoch: [83][15/16]\tTime 0.113 (3.162)\tETA 0:00:00\tTraining Loss 1.3126 (1.2965)\n",
      "_\n",
      "Validation stats                    IoU        F1      Prec    recall       Acc\n",
      "bg,          0.953900  0.976400  0.976000  0.976800  0.959000\n",
      "real apple   0.055800  0.105700  0.921800  0.056100  0.937700\n",
      "real pepper  0.000000  0.000000  0.000000  0.000000  1.000000\n",
      "real grape   0.663100  0.797400  0.935300  0.694900  0.977100\n",
      "fake apple   0.000000  0.000000  0.000000  0.000000  0.957700\n",
      "fake pepper  0.000000  0.000000  0.000000  0.000000  0.984600\n",
      "fake grape   0.000000  0.000000  0.000000  0.000000  0.980100\n",
      "total        0.238971  0.268500  0.404729  0.246829  0.970886\n",
      "total(-bg)   0.119817  0.150517  0.309517  0.125167  0.972867\n",
      "\n",
      "Epoch: [84][0/16]\tTime 0.529 (0.529)\tETA 0:00:08\tTraining Loss 1.2958 (1.2958)\n",
      "\n",
      "Epoch: [84][1/16]\tTime 0.194 (0.724)\tETA 0:00:02\tTraining Loss 1.2964 (1.2961)\n",
      "\n",
      "Epoch: [84][2/16]\tTime 0.193 (0.916)\tETA 0:00:02\tTraining Loss 1.2957 (1.2960)\n",
      "\n",
      "Epoch: [84][3/16]\tTime 0.187 (1.103)\tETA 0:00:02\tTraining Loss 1.2962 (1.2960)\n",
      "\n",
      "Epoch: [84][4/16]\tTime 0.188 (1.292)\tETA 0:00:02\tTraining Loss 1.2912 (1.2951)\n",
      "\n",
      "Epoch: [84][5/16]\tTime 0.197 (1.488)\tETA 0:00:02\tTraining Loss 1.2978 (1.2955)\n",
      "\n",
      "Epoch: [84][6/16]\tTime 0.203 (1.691)\tETA 0:00:02\tTraining Loss 1.2952 (1.2955)\n",
      "\n",
      "Epoch: [84][7/16]\tTime 0.193 (1.885)\tETA 0:00:01\tTraining Loss 1.2929 (1.2952)\n",
      "\n",
      "Epoch: [84][8/16]\tTime 0.188 (2.073)\tETA 0:00:01\tTraining Loss 1.2954 (1.2952)\n",
      "\n",
      "Epoch: [84][9/16]\tTime 0.187 (2.260)\tETA 0:00:01\tTraining Loss 1.2969 (1.2953)\n",
      "\n",
      "Epoch: [84][10/16]\tTime 0.186 (2.446)\tETA 0:00:01\tTraining Loss 1.2914 (1.2950)\n",
      "\n",
      "Epoch: [84][11/16]\tTime 0.184 (2.630)\tETA 0:00:00\tTraining Loss 1.2949 (1.2950)\n",
      "\n",
      "Epoch: [84][12/16]\tTime 0.181 (2.811)\tETA 0:00:00\tTraining Loss 1.2920 (1.2947)\n",
      "\n",
      "Epoch: [84][13/16]\tTime 0.184 (2.995)\tETA 0:00:00\tTraining Loss 1.2927 (1.2946)\n",
      "\n",
      "Epoch: [84][14/16]\tTime 0.189 (3.184)\tETA 0:00:00\tTraining Loss 1.2893 (1.2942)\n",
      "\n",
      "Epoch: [84][15/16]\tTime 0.116 (3.300)\tETA 0:00:00\tTraining Loss 1.3030 (1.2945)\n",
      "_\n",
      "Validation stats                    IoU        F1      Prec    recall       Acc\n",
      "bg,          0.950300  0.974500  0.975700  0.973300  0.955700\n",
      "real apple   0.192800  0.323300  0.956100  0.194600  0.946500\n",
      "real pepper  0.000000  0.000000  0.000000  0.000000  0.999500\n",
      "real grape   0.629900  0.772900  0.940700  0.655900  0.975000\n",
      "fake apple   0.000000  0.000000  0.000000  0.000000  0.960400\n",
      "fake pepper  0.000000  0.000000  0.000000  0.000000  0.989900\n",
      "fake grape   0.000000  0.000000  0.000000  0.000000  0.976100\n",
      "total        0.253286  0.295814  0.410357  0.260543  0.971871\n",
      "total(-bg)   0.137117  0.182700  0.316133  0.141750  0.974567\n",
      "\n",
      "Epoch: [85][0/16]\tTime 0.476 (0.476)\tETA 0:00:07\tTraining Loss 1.2902 (1.2902)\n",
      "\n",
      "Epoch: [85][1/16]\tTime 0.190 (0.666)\tETA 0:00:02\tTraining Loss 1.2880 (1.2891)\n",
      "\n",
      "Epoch: [85][2/16]\tTime 0.186 (0.852)\tETA 0:00:02\tTraining Loss 1.2947 (1.2910)\n",
      "\n",
      "Epoch: [85][3/16]\tTime 0.186 (1.038)\tETA 0:00:02\tTraining Loss 1.2933 (1.2916)\n",
      "\n",
      "Epoch: [85][4/16]\tTime 0.184 (1.222)\tETA 0:00:02\tTraining Loss 1.2949 (1.2922)\n",
      "\n",
      "Epoch: [85][5/16]\tTime 0.189 (1.411)\tETA 0:00:02\tTraining Loss 1.2899 (1.2918)\n",
      "\n",
      "Epoch: [85][6/16]\tTime 0.192 (1.603)\tETA 0:00:01\tTraining Loss 1.2977 (1.2927)\n",
      "\n",
      "Epoch: [85][7/16]\tTime 0.187 (1.790)\tETA 0:00:01\tTraining Loss 1.2921 (1.2926)\n",
      "\n",
      "Epoch: [85][8/16]\tTime 0.195 (1.985)\tETA 0:00:01\tTraining Loss 1.2922 (1.2926)\n",
      "\n",
      "Epoch: [85][9/16]\tTime 0.182 (2.168)\tETA 0:00:01\tTraining Loss 1.2967 (1.2930)\n",
      "\n",
      "Epoch: [85][10/16]\tTime 0.179 (2.346)\tETA 0:00:01\tTraining Loss 1.2930 (1.2930)\n",
      "\n",
      "Epoch: [85][11/16]\tTime 0.200 (2.546)\tETA 0:00:00\tTraining Loss 1.2917 (1.2929)\n",
      "\n",
      "Epoch: [85][12/16]\tTime 0.185 (2.731)\tETA 0:00:00\tTraining Loss 1.2938 (1.2929)\n",
      "\n",
      "Epoch: [85][13/16]\tTime 0.184 (2.916)\tETA 0:00:00\tTraining Loss 1.2926 (1.2929)\n",
      "\n",
      "Epoch: [85][14/16]\tTime 0.189 (3.105)\tETA 0:00:00\tTraining Loss 1.2974 (1.2932)\n",
      "\n",
      "Epoch: [85][15/16]\tTime 0.115 (3.220)\tETA 0:00:00\tTraining Loss 1.2930 (1.2932)\n",
      "_\n",
      "Validation stats                    IoU        F1      Prec    recall       Acc\n",
      "bg,          0.955800  0.977400  0.974200  0.980600  0.960600\n",
      "real apple   0.526500  0.689700  0.845000  0.582800  0.965600\n",
      "real pepper  0.000000  0.000000  0.000000  0.000000  0.999000\n",
      "real grape   0.546500  0.706800  0.924600  0.572100  0.969300\n",
      "fake apple   0.000000  0.000000  0.000000  0.000000  0.966600\n",
      "fake pepper  0.000000  0.000000  0.000000  0.000000  0.999000\n",
      "fake grape   0.000000  0.000000  0.000000  0.000000  0.996100\n",
      "total        0.289829  0.339129  0.391971  0.305071  0.979457\n",
      "total(-bg)   0.178833  0.232750  0.294933  0.192483  0.982600\n",
      "\n",
      "Epoch: [86][0/16]\tTime 0.531 (0.531)\tETA 0:00:08\tTraining Loss 1.2980 (1.2980)\n",
      "\n",
      "Epoch: [86][1/16]\tTime 0.189 (0.720)\tETA 0:00:02\tTraining Loss 1.2928 (1.2954)\n",
      "\n",
      "Epoch: [86][2/16]\tTime 0.188 (0.908)\tETA 0:00:02\tTraining Loss 1.2964 (1.2957)\n",
      "\n",
      "Epoch: [86][3/16]\tTime 0.190 (1.099)\tETA 0:00:02\tTraining Loss 1.2961 (1.2958)\n",
      "\n",
      "Epoch: [86][4/16]\tTime 0.190 (1.289)\tETA 0:00:02\tTraining Loss 1.2936 (1.2954)\n",
      "\n",
      "Epoch: [86][5/16]\tTime 0.185 (1.474)\tETA 0:00:02\tTraining Loss 1.2980 (1.2958)\n",
      "\n",
      "Epoch: [86][6/16]\tTime 0.192 (1.666)\tETA 0:00:01\tTraining Loss 1.2910 (1.2951)\n",
      "\n",
      "Epoch: [86][7/16]\tTime 0.187 (1.852)\tETA 0:00:01\tTraining Loss 1.2904 (1.2945)\n",
      "\n",
      "Epoch: [86][8/16]\tTime 0.195 (2.048)\tETA 0:00:01\tTraining Loss 1.2952 (1.2946)\n",
      "\n",
      "Epoch: [86][9/16]\tTime 0.195 (2.243)\tETA 0:00:01\tTraining Loss 1.2916 (1.2943)\n",
      "\n",
      "Epoch: [86][10/16]\tTime 0.191 (2.434)\tETA 0:00:01\tTraining Loss 1.2899 (1.2939)\n",
      "\n",
      "Epoch: [86][11/16]\tTime 0.196 (2.630)\tETA 0:00:00\tTraining Loss 1.2975 (1.2942)\n",
      "\n",
      "Epoch: [86][12/16]\tTime 0.190 (2.819)\tETA 0:00:00\tTraining Loss 1.2920 (1.2940)\n",
      "\n",
      "Epoch: [86][13/16]\tTime 0.191 (3.010)\tETA 0:00:00\tTraining Loss 1.2986 (1.2944)\n",
      "\n",
      "Epoch: [86][14/16]\tTime 0.194 (3.204)\tETA 0:00:00\tTraining Loss 1.2973 (1.2946)\n",
      "\n",
      "Epoch: [86][15/16]\tTime 0.112 (3.316)\tETA 0:00:00\tTraining Loss 1.2924 (1.2945)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_\n",
      "Validation stats                    IoU        F1      Prec    recall       Acc\n",
      "bg,          0.952800  0.975800  0.975100  0.976600  0.958000\n",
      "real apple   0.239500  0.386400  0.837700  0.251100  0.947600\n",
      "real pepper  0.000000  0.000000  0.000000  0.000000  1.000000\n",
      "real grape   0.809800  0.894900  0.922900  0.868600  0.986800\n",
      "fake apple   0.000000  0.000000  0.000000  0.000000  0.966000\n",
      "fake pepper  0.000000  0.000000  0.000000  0.000000  0.993600\n",
      "fake grape   0.000000  0.000000  0.000000  0.000000  0.991800\n",
      "total        0.286014  0.322443  0.390814  0.299471  0.977686\n",
      "total(-bg)   0.174883  0.213550  0.293433  0.186617  0.980967\n",
      "\n",
      "Epoch: [87][0/16]\tTime 0.405 (0.405)\tETA 0:00:06\tTraining Loss 1.2890 (1.2890)\n",
      "\n",
      "Epoch: [87][1/16]\tTime 0.191 (0.596)\tETA 0:00:02\tTraining Loss 1.2891 (1.2891)\n",
      "\n",
      "Epoch: [87][2/16]\tTime 0.194 (0.790)\tETA 0:00:02\tTraining Loss 1.2931 (1.2904)\n",
      "\n",
      "Epoch: [87][3/16]\tTime 0.191 (0.981)\tETA 0:00:02\tTraining Loss 1.3033 (1.2936)\n",
      "\n",
      "Epoch: [87][4/16]\tTime 0.192 (1.173)\tETA 0:00:02\tTraining Loss 1.2940 (1.2937)\n",
      "\n",
      "Epoch: [87][5/16]\tTime 0.190 (1.363)\tETA 0:00:02\tTraining Loss 1.2915 (1.2933)\n",
      "\n",
      "Epoch: [87][6/16]\tTime 0.190 (1.552)\tETA 0:00:01\tTraining Loss 1.2993 (1.2942)\n",
      "\n",
      "Epoch: [87][7/16]\tTime 0.184 (1.736)\tETA 0:00:01\tTraining Loss 1.2887 (1.2935)\n",
      "\n",
      "Epoch: [87][8/16]\tTime 0.186 (1.922)\tETA 0:00:01\tTraining Loss 1.3008 (1.2943)\n",
      "\n",
      "Epoch: [87][9/16]\tTime 0.198 (2.120)\tETA 0:00:01\tTraining Loss 1.2944 (1.2943)\n",
      "\n",
      "Epoch: [87][10/16]\tTime 0.187 (2.307)\tETA 0:00:01\tTraining Loss 1.2926 (1.2942)\n",
      "\n",
      "Epoch: [87][11/16]\tTime 0.190 (2.497)\tETA 0:00:00\tTraining Loss 1.2990 (1.2946)\n",
      "\n",
      "Epoch: [87][12/16]\tTime 0.190 (2.687)\tETA 0:00:00\tTraining Loss 1.2866 (1.2940)\n",
      "\n",
      "Epoch: [87][13/16]\tTime 0.183 (2.871)\tETA 0:00:00\tTraining Loss 1.2865 (1.2934)\n",
      "\n",
      "Epoch: [87][14/16]\tTime 0.200 (3.071)\tETA 0:00:00\tTraining Loss 1.2907 (1.2932)\n",
      "\n",
      "Epoch: [87][15/16]\tTime 0.111 (3.182)\tETA 0:00:00\tTraining Loss 1.3255 (1.2943)\n",
      "_\n",
      "Validation stats                    IoU        F1      Prec    recall       Acc\n",
      "bg,          0.948600  0.973500  0.977000  0.970200  0.954200\n",
      "real apple   0.109000  0.196600  0.954500  0.109600  0.941100\n",
      "real pepper  0.000000  0.000000  0.000000  0.000000  1.000000\n",
      "real grape   0.538300  0.699800  0.858300  0.590800  0.967200\n",
      "fake apple   0.000000  0.000000  0.000000  0.000000  0.956100\n",
      "fake pepper  0.000000  0.000000  0.000000  0.000000  0.987000\n",
      "fake grape   0.000000  0.000000  0.000000  0.000000  0.972600\n",
      "total        0.227986  0.267129  0.398543  0.238657  0.968314\n",
      "total(-bg)   0.107883  0.149400  0.302133  0.116733  0.970667\n",
      "\n",
      "Epoch: [88][0/16]\tTime 0.427 (0.427)\tETA 0:00:06\tTraining Loss 1.2848 (1.2848)\n",
      "\n",
      "Epoch: [88][1/16]\tTime 0.175 (0.603)\tETA 0:00:02\tTraining Loss 1.2883 (1.2866)\n",
      "\n",
      "Epoch: [88][2/16]\tTime 0.185 (0.788)\tETA 0:00:02\tTraining Loss 1.2905 (1.2879)\n",
      "\n",
      "Epoch: [88][3/16]\tTime 0.201 (0.989)\tETA 0:00:02\tTraining Loss 1.2871 (1.2877)\n",
      "\n",
      "Epoch: [88][4/16]\tTime 0.193 (1.182)\tETA 0:00:02\tTraining Loss 1.2891 (1.2880)\n",
      "\n",
      "Epoch: [88][5/16]\tTime 0.183 (1.365)\tETA 0:00:02\tTraining Loss 1.2961 (1.2893)\n",
      "\n",
      "Epoch: [88][6/16]\tTime 0.193 (1.558)\tETA 0:00:01\tTraining Loss 1.2949 (1.2901)\n",
      "\n",
      "Epoch: [88][7/16]\tTime 0.185 (1.743)\tETA 0:00:01\tTraining Loss 1.2930 (1.2905)\n",
      "\n",
      "Epoch: [88][8/16]\tTime 0.198 (1.941)\tETA 0:00:01\tTraining Loss 1.2875 (1.2901)\n",
      "\n",
      "Epoch: [88][9/16]\tTime 0.187 (2.128)\tETA 0:00:01\tTraining Loss 1.2890 (1.2900)\n",
      "\n",
      "Epoch: [88][10/16]\tTime 0.185 (2.313)\tETA 0:00:01\tTraining Loss 1.3050 (1.2914)\n",
      "\n",
      "Epoch: [88][11/16]\tTime 0.185 (2.498)\tETA 0:00:00\tTraining Loss 1.2909 (1.2914)\n",
      "\n",
      "Epoch: [88][12/16]\tTime 0.187 (2.684)\tETA 0:00:00\tTraining Loss 1.2899 (1.2912)\n",
      "\n",
      "Epoch: [88][13/16]\tTime 0.188 (2.872)\tETA 0:00:00\tTraining Loss 1.2911 (1.2912)\n",
      "\n",
      "Epoch: [88][14/16]\tTime 0.189 (3.061)\tETA 0:00:00\tTraining Loss 1.2962 (1.2916)\n",
      "\n",
      "Epoch: [88][15/16]\tTime 0.114 (3.175)\tETA 0:00:00\tTraining Loss 1.3023 (1.2919)\n",
      "_\n",
      "Validation stats                    IoU        F1      Prec    recall       Acc\n",
      "bg,          0.956700  0.977800  0.982500  0.973300  0.961700\n",
      "real apple   0.164100  0.281900  0.674700  0.178200  0.940300\n",
      "real pepper  0.000000  0.000000  0.000000  0.000000  0.999400\n",
      "real grape   0.603900  0.753000  0.921200  0.636700  0.973000\n",
      "fake apple   0.000000  0.000000  0.000000  0.000000  0.958800\n",
      "fake pepper  0.000000  0.000000  0.000000  0.000000  0.992200\n",
      "fake grape   0.000000  0.000000  0.000000  0.000000  0.973200\n",
      "total        0.246386  0.287529  0.368343  0.255457  0.971229\n",
      "total(-bg)   0.128000  0.172483  0.265983  0.135817  0.972817\n",
      "\n",
      "Epoch: [89][0/16]\tTime 0.497 (0.497)\tETA 0:00:07\tTraining Loss 1.2898 (1.2898)\n",
      "\n",
      "Epoch: [89][1/16]\tTime 0.180 (0.677)\tETA 0:00:02\tTraining Loss 1.2862 (1.2880)\n",
      "\n",
      "Epoch: [89][2/16]\tTime 0.186 (0.862)\tETA 0:00:02\tTraining Loss 1.2876 (1.2879)\n",
      "\n",
      "Epoch: [89][3/16]\tTime 0.196 (1.059)\tETA 0:00:02\tTraining Loss 1.2877 (1.2878)\n",
      "\n",
      "Epoch: [89][4/16]\tTime 0.186 (1.245)\tETA 0:00:02\tTraining Loss 1.2896 (1.2882)\n",
      "\n",
      "Epoch: [89][5/16]\tTime 0.182 (1.427)\tETA 0:00:02\tTraining Loss 1.2944 (1.2892)\n",
      "\n",
      "Epoch: [89][6/16]\tTime 0.187 (1.614)\tETA 0:00:01\tTraining Loss 1.2904 (1.2894)\n",
      "\n",
      "Epoch: [89][7/16]\tTime 0.185 (1.799)\tETA 0:00:01\tTraining Loss 1.2884 (1.2893)\n",
      "\n",
      "Epoch: [89][8/16]\tTime 0.189 (1.988)\tETA 0:00:01\tTraining Loss 1.2970 (1.2901)\n",
      "\n",
      "Epoch: [89][9/16]\tTime 0.186 (2.174)\tETA 0:00:01\tTraining Loss 1.2907 (1.2902)\n",
      "\n",
      "Epoch: [89][10/16]\tTime 0.189 (2.363)\tETA 0:00:01\tTraining Loss 1.3048 (1.2915)\n",
      "\n",
      "Epoch: [89][11/16]\tTime 0.185 (2.548)\tETA 0:00:00\tTraining Loss 1.3019 (1.2924)\n",
      "\n",
      "Epoch: [89][12/16]\tTime 0.204 (2.752)\tETA 0:00:00\tTraining Loss 1.2911 (1.2923)\n",
      "\n",
      "Epoch: [89][13/16]\tTime 0.183 (2.935)\tETA 0:00:00\tTraining Loss 1.3044 (1.2931)\n",
      "\n",
      "Epoch: [89][14/16]\tTime 0.181 (3.117)\tETA 0:00:00\tTraining Loss 1.2897 (1.2929)\n",
      "\n",
      "Epoch: [89][15/16]\tTime 0.118 (3.235)\tETA 0:00:00\tTraining Loss 1.2953 (1.2930)\n",
      "_\n",
      "Validation stats                    IoU        F1      Prec    recall       Acc\n",
      "bg,          0.957200  0.978100  0.982700  0.973700  0.962200\n",
      "real apple   0.251700  0.402200  0.862500  0.262200  0.948800\n",
      "real pepper  0.000000  0.000000  0.000000  0.000000  0.973200\n",
      "real grape   0.392800  0.564000  0.910200  0.408600  0.959100\n",
      "fake apple   0.000000  0.000000  0.000000  0.000000  0.959500\n",
      "fake pepper  0.000000  0.000000  0.000000  0.000000  0.992100\n",
      "fake grape   0.000000  0.000000  0.000000  0.000000  0.985800\n",
      "total        0.228814  0.277757  0.393629  0.234929  0.968671\n",
      "total(-bg)   0.107417  0.161033  0.295450  0.111800  0.969750\n",
      "\n",
      "Epoch: [90][0/16]\tTime 0.466 (0.466)\tETA 0:00:07\tTraining Loss 1.2900 (1.2900)\n",
      "\n",
      "Epoch: [90][1/16]\tTime 0.186 (0.652)\tETA 0:00:02\tTraining Loss 1.2987 (1.2943)\n",
      "\n",
      "Epoch: [90][2/16]\tTime 0.180 (0.832)\tETA 0:00:02\tTraining Loss 1.2918 (1.2935)\n",
      "\n",
      "Epoch: [90][3/16]\tTime 0.180 (1.013)\tETA 0:00:02\tTraining Loss 1.2840 (1.2911)\n",
      "\n",
      "Epoch: [90][4/16]\tTime 0.193 (1.206)\tETA 0:00:02\tTraining Loss 1.3012 (1.2931)\n",
      "\n",
      "Epoch: [90][5/16]\tTime 0.182 (1.388)\tETA 0:00:02\tTraining Loss 1.2902 (1.2926)\n",
      "\n",
      "Epoch: [90][6/16]\tTime 0.191 (1.579)\tETA 0:00:01\tTraining Loss 1.2892 (1.2922)\n",
      "\n",
      "Epoch: [90][7/16]\tTime 0.182 (1.760)\tETA 0:00:01\tTraining Loss 1.2965 (1.2927)\n",
      "\n",
      "Epoch: [90][8/16]\tTime 0.180 (1.941)\tETA 0:00:01\tTraining Loss 1.2919 (1.2926)\n",
      "\n",
      "Epoch: [90][9/16]\tTime 0.184 (2.125)\tETA 0:00:01\tTraining Loss 1.2856 (1.2919)\n",
      "\n",
      "Epoch: [90][10/16]\tTime 0.181 (2.306)\tETA 0:00:01\tTraining Loss 1.2893 (1.2917)\n",
      "\n",
      "Epoch: [90][11/16]\tTime 0.188 (2.494)\tETA 0:00:00\tTraining Loss 1.2869 (1.2913)\n",
      "\n",
      "Epoch: [90][12/16]\tTime 0.188 (2.682)\tETA 0:00:00\tTraining Loss 1.2971 (1.2917)\n",
      "\n",
      "Epoch: [90][13/16]\tTime 0.193 (2.875)\tETA 0:00:00\tTraining Loss 1.2972 (1.2921)\n",
      "\n",
      "Epoch: [90][14/16]\tTime 0.182 (3.057)\tETA 0:00:00\tTraining Loss 1.2871 (1.2918)\n",
      "\n",
      "Epoch: [90][15/16]\tTime 0.118 (3.175)\tETA 0:00:00\tTraining Loss 1.2836 (1.2915)\n",
      "_\n",
      "Validation stats                    IoU        F1      Prec    recall       Acc\n",
      "bg,          0.952200  0.975500  0.975900  0.975200  0.957500\n",
      "real apple   0.307300  0.470100  0.965700  0.310700  0.954000\n",
      "real pepper  0.000000  0.000000  0.000000  0.000000  1.000000\n",
      "real grape   0.788600  0.881700  0.907100  0.857900  0.985100\n",
      "fake apple   0.000000  0.000000  0.000000  0.000000  0.966600\n",
      "fake pepper  0.000000  0.000000  0.000000  0.000000  0.995900\n",
      "fake grape   0.000000  0.000000  0.000000  0.000000  0.988900\n",
      "total        0.292586  0.332471  0.406957  0.306257  0.978286\n",
      "total(-bg)   0.182650  0.225300  0.312133  0.194767  0.981750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: [91][0/16]\tTime 0.490 (0.490)\tETA 0:00:07\tTraining Loss 1.2851 (1.2851)\n",
      "\n",
      "Epoch: [91][1/16]\tTime 0.184 (0.674)\tETA 0:00:02\tTraining Loss 1.2893 (1.2872)\n",
      "\n",
      "Epoch: [91][2/16]\tTime 0.180 (0.854)\tETA 0:00:02\tTraining Loss 1.2906 (1.2883)\n",
      "\n",
      "Epoch: [91][3/16]\tTime 0.188 (1.042)\tETA 0:00:02\tTraining Loss 1.2883 (1.2883)\n",
      "\n",
      "Epoch: [91][4/16]\tTime 0.184 (1.226)\tETA 0:00:02\tTraining Loss 1.2872 (1.2881)\n",
      "\n",
      "Epoch: [91][5/16]\tTime 0.187 (1.413)\tETA 0:00:02\tTraining Loss 1.2803 (1.2868)\n",
      "\n",
      "Epoch: [91][6/16]\tTime 0.183 (1.596)\tETA 0:00:01\tTraining Loss 1.2842 (1.2864)\n",
      "\n",
      "Epoch: [91][7/16]\tTime 0.190 (1.786)\tETA 0:00:01\tTraining Loss 1.2801 (1.2856)\n",
      "\n",
      "Epoch: [91][8/16]\tTime 0.183 (1.968)\tETA 0:00:01\tTraining Loss 1.2836 (1.2854)\n",
      "\n",
      "Epoch: [91][9/16]\tTime 0.193 (2.162)\tETA 0:00:01\tTraining Loss 1.2860 (1.2855)\n",
      "\n",
      "Epoch: [91][10/16]\tTime 0.191 (2.353)\tETA 0:00:01\tTraining Loss 1.2971 (1.2865)\n",
      "\n",
      "Epoch: [91][11/16]\tTime 0.200 (2.553)\tETA 0:00:01\tTraining Loss 1.2823 (1.2862)\n",
      "\n",
      "Epoch: [91][12/16]\tTime 0.188 (2.741)\tETA 0:00:00\tTraining Loss 1.2798 (1.2857)\n",
      "\n",
      "Epoch: [91][13/16]\tTime 0.182 (2.923)\tETA 0:00:00\tTraining Loss 1.2857 (1.2857)\n",
      "\n",
      "Epoch: [91][14/16]\tTime 0.189 (3.112)\tETA 0:00:00\tTraining Loss 1.2828 (1.2855)\n",
      "\n",
      "Epoch: [91][15/16]\tTime 0.115 (3.227)\tETA 0:00:00\tTraining Loss 1.2848 (1.2855)\n",
      "_\n",
      "Validation stats                    IoU        F1      Prec    recall       Acc\n",
      "bg,          0.937300  0.967600  0.977500  0.958000  0.944300\n",
      "real apple   0.041600  0.079900  0.918400  0.041800  0.936800\n",
      "real pepper  0.000000  0.000000  0.000000  0.000000  1.000000\n",
      "real grape   0.627400  0.771000  0.869300  0.692700  0.973400\n",
      "fake apple   0.000000  0.000000  0.000000  0.000000  0.955600\n",
      "fake pepper  0.000000  0.000000  0.000000  0.000000  0.979500\n",
      "fake grape   0.000000  0.000000  0.000000  0.000000  0.971600\n",
      "total        0.229471  0.259786  0.395029  0.241786  0.965886\n",
      "total(-bg)   0.111500  0.141817  0.297950  0.122417  0.969483\n",
      "\n",
      "Epoch: [92][0/16]\tTime 0.450 (0.450)\tETA 0:00:07\tTraining Loss 1.2814 (1.2814)\n",
      "\n",
      "Epoch: [92][1/16]\tTime 0.184 (0.634)\tETA 0:00:02\tTraining Loss 1.2847 (1.2831)\n",
      "\n",
      "Epoch: [92][2/16]\tTime 0.187 (0.821)\tETA 0:00:02\tTraining Loss 1.2781 (1.2814)\n",
      "\n",
      "Epoch: [92][3/16]\tTime 0.186 (1.006)\tETA 0:00:02\tTraining Loss 1.2770 (1.2803)\n",
      "\n",
      "Epoch: [92][4/16]\tTime 0.189 (1.195)\tETA 0:00:02\tTraining Loss 1.2828 (1.2808)\n",
      "\n",
      "Epoch: [92][5/16]\tTime 0.184 (1.378)\tETA 0:00:02\tTraining Loss 1.2881 (1.2820)\n",
      "\n",
      "Epoch: [92][6/16]\tTime 0.191 (1.569)\tETA 0:00:01\tTraining Loss 1.2796 (1.2817)\n",
      "\n",
      "Epoch: [92][7/16]\tTime 0.196 (1.765)\tETA 0:00:01\tTraining Loss 1.2789 (1.2813)\n",
      "\n",
      "Epoch: [92][8/16]\tTime 0.188 (1.954)\tETA 0:00:01\tTraining Loss 1.2847 (1.2817)\n",
      "\n",
      "Epoch: [92][9/16]\tTime 0.180 (2.134)\tETA 0:00:01\tTraining Loss 1.2818 (1.2817)\n",
      "\n",
      "Epoch: [92][10/16]\tTime 0.188 (2.322)\tETA 0:00:01\tTraining Loss 1.2776 (1.2813)\n",
      "\n",
      "Epoch: [92][11/16]\tTime 0.206 (2.528)\tETA 0:00:01\tTraining Loss 1.2855 (1.2817)\n",
      "\n",
      "Epoch: [92][12/16]\tTime 0.201 (2.729)\tETA 0:00:00\tTraining Loss 1.2778 (1.2814)\n",
      "\n",
      "Epoch: [92][13/16]\tTime 0.172 (2.901)\tETA 0:00:00\tTraining Loss 1.2764 (1.2810)\n",
      "\n",
      "Epoch: [92][14/16]\tTime 0.187 (3.089)\tETA 0:00:00\tTraining Loss 1.2836 (1.2812)\n",
      "\n",
      "Epoch: [92][15/16]\tTime 0.121 (3.209)\tETA 0:00:00\tTraining Loss 1.2825 (1.2812)\n",
      "_\n",
      "Validation stats                    IoU        F1      Prec    recall       Acc\n",
      "bg,          0.941600  0.969900  0.977300  0.962700  0.948100\n",
      "real apple   0.171000  0.292000  0.960500  0.172200  0.945100\n",
      "real pepper  0.000000  0.000000  0.000000  0.000000  0.999900\n",
      "real grape   0.623900  0.768300  0.904600  0.667800  0.973900\n",
      "fake apple   0.000000  0.000000  0.000000  0.000000  0.954700\n",
      "fake pepper  0.000000  0.000000  0.000000  0.000000  0.986500\n",
      "fake grape   0.000000  0.000000  0.000000  0.000000  0.975000\n",
      "total        0.248071  0.290029  0.406057  0.257529  0.969029\n",
      "total(-bg)   0.132483  0.176717  0.310850  0.140000  0.972517\n",
      "\n",
      "Epoch: [93][0/16]\tTime 0.393 (0.393)\tETA 0:00:06\tTraining Loss 1.2846 (1.2846)\n",
      "\n",
      "Epoch: [93][1/16]\tTime 0.173 (0.566)\tETA 0:00:02\tTraining Loss 1.2784 (1.2815)\n",
      "\n",
      "Epoch: [93][2/16]\tTime 0.170 (0.736)\tETA 0:00:02\tTraining Loss 1.2811 (1.2814)\n",
      "\n",
      "Epoch: [93][3/16]\tTime 0.193 (0.929)\tETA 0:00:02\tTraining Loss 1.2781 (1.2806)\n",
      "\n",
      "Epoch: [93][4/16]\tTime 0.181 (1.110)\tETA 0:00:02\tTraining Loss 1.2792 (1.2803)\n",
      "\n",
      "Epoch: [93][5/16]\tTime 0.180 (1.290)\tETA 0:00:01\tTraining Loss 1.2767 (1.2797)\n",
      "\n",
      "Epoch: [93][6/16]\tTime 0.190 (1.480)\tETA 0:00:01\tTraining Loss 1.2878 (1.2809)\n",
      "\n",
      "Epoch: [93][7/16]\tTime 0.188 (1.668)\tETA 0:00:01\tTraining Loss 1.2766 (1.2803)\n",
      "\n",
      "Epoch: [93][8/16]\tTime 0.186 (1.854)\tETA 0:00:01\tTraining Loss 1.2773 (1.2800)\n",
      "\n",
      "Epoch: [93][9/16]\tTime 0.191 (2.045)\tETA 0:00:01\tTraining Loss 1.2765 (1.2796)\n",
      "\n",
      "Epoch: [93][10/16]\tTime 0.183 (2.228)\tETA 0:00:01\tTraining Loss 1.2794 (1.2796)\n",
      "\n",
      "Epoch: [93][11/16]\tTime 0.193 (2.420)\tETA 0:00:00\tTraining Loss 1.2777 (1.2795)\n",
      "\n",
      "Epoch: [93][12/16]\tTime 0.178 (2.599)\tETA 0:00:00\tTraining Loss 1.2775 (1.2793)\n",
      "\n",
      "Epoch: [93][13/16]\tTime 0.193 (2.792)\tETA 0:00:00\tTraining Loss 1.2729 (1.2789)\n",
      "\n",
      "Epoch: [93][14/16]\tTime 0.191 (2.983)\tETA 0:00:00\tTraining Loss 1.2798 (1.2789)\n",
      "\n",
      "Epoch: [93][15/16]\tTime 0.113 (3.096)\tETA 0:00:00\tTraining Loss 1.2827 (1.2790)\n",
      "_\n",
      "Validation stats                    IoU        F1      Prec    recall       Acc\n",
      "bg,          0.946000  0.972200  0.976400  0.968100  0.951900\n",
      "real apple   0.079700  0.147600  0.937500  0.080100  0.939200\n",
      "real pepper  0.000000  0.000000  0.000000  0.000000  1.000000\n",
      "real grape   0.602900  0.752200  0.936900  0.628400  0.973200\n",
      "fake apple   0.000000  0.000000  0.000000  0.000000  0.955400\n",
      "fake pepper  0.000000  0.000000  0.000000  0.000000  0.982400\n",
      "fake grape   0.000000  0.000000  0.000000  0.000000  0.973400\n",
      "total        0.232657  0.267429  0.407257  0.239514  0.967929\n",
      "total(-bg)   0.113767  0.149967  0.312400  0.118083  0.970600\n",
      "\n",
      "Epoch: [94][0/16]\tTime 0.470 (0.470)\tETA 0:00:07\tTraining Loss 1.2783 (1.2783)\n",
      "\n",
      "Epoch: [94][1/16]\tTime 0.184 (0.654)\tETA 0:00:02\tTraining Loss 1.2739 (1.2761)\n",
      "\n",
      "Epoch: [94][2/16]\tTime 0.182 (0.837)\tETA 0:00:02\tTraining Loss 1.2767 (1.2763)\n",
      "\n",
      "Epoch: [94][3/16]\tTime 0.194 (1.031)\tETA 0:00:02\tTraining Loss 1.2790 (1.2770)\n",
      "\n",
      "Epoch: [94][4/16]\tTime 0.184 (1.215)\tETA 0:00:02\tTraining Loss 1.2737 (1.2763)\n",
      "\n",
      "Epoch: [94][5/16]\tTime 0.184 (1.399)\tETA 0:00:02\tTraining Loss 1.2757 (1.2762)\n",
      "\n",
      "Epoch: [94][6/16]\tTime 0.197 (1.595)\tETA 0:00:01\tTraining Loss 1.2776 (1.2764)\n",
      "\n",
      "Epoch: [94][7/16]\tTime 0.188 (1.784)\tETA 0:00:01\tTraining Loss 1.2784 (1.2767)\n",
      "\n",
      "Epoch: [94][8/16]\tTime 0.179 (1.963)\tETA 0:00:01\tTraining Loss 1.2779 (1.2768)\n",
      "\n",
      "Epoch: [94][9/16]\tTime 0.184 (2.147)\tETA 0:00:01\tTraining Loss 1.2739 (1.2765)\n",
      "\n",
      "Epoch: [94][10/16]\tTime 0.183 (2.330)\tETA 0:00:01\tTraining Loss 1.2795 (1.2768)\n",
      "\n",
      "Epoch: [94][11/16]\tTime 0.180 (2.510)\tETA 0:00:00\tTraining Loss 1.2749 (1.2766)\n",
      "\n",
      "Epoch: [94][12/16]\tTime 0.178 (2.688)\tETA 0:00:00\tTraining Loss 1.2792 (1.2768)\n",
      "\n",
      "Epoch: [94][13/16]\tTime 0.186 (2.874)\tETA 0:00:00\tTraining Loss 1.2736 (1.2766)\n",
      "\n",
      "Epoch: [94][14/16]\tTime 0.187 (3.061)\tETA 0:00:00\tTraining Loss 1.2726 (1.2763)\n",
      "\n",
      "Epoch: [94][15/16]\tTime 0.115 (3.176)\tETA 0:00:00\tTraining Loss 1.2801 (1.2765)\n",
      "_\n",
      "Validation stats                    IoU        F1      Prec    recall       Acc\n",
      "bg,          0.950100  0.974400  0.975900  0.972900  0.955600\n",
      "real apple   0.072100  0.134500  0.942600  0.072400  0.938800\n",
      "real pepper  0.000000  0.000000  0.000000  0.000000  1.000000\n",
      "real grape   0.564400  0.721500  0.904900  0.600000  0.970000\n",
      "fake apple   0.000000  0.000000  0.000000  0.000000  0.956800\n",
      "fake pepper  0.000000  0.000000  0.000000  0.000000  0.984900\n",
      "fake grape   0.000000  0.000000  0.000000  0.000000  0.973100\n",
      "total        0.226657  0.261486  0.403343  0.235043  0.968457\n",
      "total(-bg)   0.106083  0.142667  0.307917  0.112067  0.970600\n",
      "\n",
      "Epoch: [95][0/16]\tTime 0.467 (0.467)\tETA 0:00:07\tTraining Loss 1.2735 (1.2735)\n",
      "\n",
      "Epoch: [95][1/16]\tTime 0.180 (0.646)\tETA 0:00:02\tTraining Loss 1.2751 (1.2743)\n",
      "\n",
      "Epoch: [95][2/16]\tTime 0.199 (0.846)\tETA 0:00:02\tTraining Loss 1.2736 (1.2741)\n",
      "\n",
      "Epoch: [95][3/16]\tTime 0.182 (1.028)\tETA 0:00:02\tTraining Loss 1.2774 (1.2749)\n",
      "\n",
      "Epoch: [95][4/16]\tTime 0.182 (1.210)\tETA 0:00:02\tTraining Loss 1.2742 (1.2748)\n",
      "\n",
      "Epoch: [95][5/16]\tTime 0.182 (1.392)\tETA 0:00:01\tTraining Loss 1.2754 (1.2749)\n",
      "\n",
      "Epoch: [95][6/16]\tTime 0.184 (1.576)\tETA 0:00:01\tTraining Loss 1.2751 (1.2749)\n",
      "\n",
      "Epoch: [95][7/16]\tTime 0.187 (1.763)\tETA 0:00:01\tTraining Loss 1.2763 (1.2751)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: [95][8/16]\tTime 0.182 (1.945)\tETA 0:00:01\tTraining Loss 1.2730 (1.2748)\n",
      "\n",
      "Epoch: [95][9/16]\tTime 0.184 (2.129)\tETA 0:00:01\tTraining Loss 1.2714 (1.2745)\n",
      "\n",
      "Epoch: [95][10/16]\tTime 0.185 (2.315)\tETA 0:00:01\tTraining Loss 1.2756 (1.2746)\n",
      "\n",
      "Epoch: [95][11/16]\tTime 0.185 (2.500)\tETA 0:00:00\tTraining Loss 1.2715 (1.2743)\n",
      "\n",
      "Epoch: [95][12/16]\tTime 0.187 (2.687)\tETA 0:00:00\tTraining Loss 1.2706 (1.2740)\n",
      "\n",
      "Epoch: [95][13/16]\tTime 0.180 (2.867)\tETA 0:00:00\tTraining Loss 1.2743 (1.2741)\n",
      "\n",
      "Epoch: [95][14/16]\tTime 0.199 (3.066)\tETA 0:00:00\tTraining Loss 1.2712 (1.2739)\n",
      "\n",
      "Epoch: [95][15/16]\tTime 0.123 (3.189)\tETA 0:00:00\tTraining Loss 1.2826 (1.2742)\n",
      "_\n",
      "Validation stats                    IoU        F1     Prec    recall       Acc\n",
      "bg,          0.948000  0.973200  0.97450  0.972100  0.953600\n",
      "real apple   0.042600  0.081600  0.97350  0.042600  0.937000\n",
      "real pepper  0.000000  0.000000  0.00000  0.000000  1.000000\n",
      "real grape   0.335600  0.502500  0.91500  0.346400  0.955600\n",
      "fake apple   0.000000  0.000000  0.00000  0.000000  0.957200\n",
      "fake pepper  0.000000  0.000000  0.00000  0.000000  0.980000\n",
      "fake grape   0.000000  0.000000  0.00000  0.000000  0.957500\n",
      "total        0.189457  0.222471  0.40900  0.194443  0.962986\n",
      "total(-bg)   0.063033  0.097350  0.31475  0.064833  0.964550\n",
      "\n",
      "Epoch: [96][0/16]\tTime 0.487 (0.487)\tETA 0:00:07\tTraining Loss 1.2726 (1.2726)\n",
      "\n",
      "Epoch: [96][1/16]\tTime 0.195 (0.682)\tETA 0:00:02\tTraining Loss 1.2785 (1.2755)\n",
      "\n",
      "Epoch: [96][2/16]\tTime 0.191 (0.873)\tETA 0:00:02\tTraining Loss 1.2759 (1.2757)\n",
      "\n",
      "Epoch: [96][3/16]\tTime 0.185 (1.058)\tETA 0:00:02\tTraining Loss 1.2749 (1.2755)\n",
      "\n",
      "Epoch: [96][4/16]\tTime 0.179 (1.237)\tETA 0:00:02\tTraining Loss 1.2794 (1.2763)\n",
      "\n",
      "Epoch: [96][5/16]\tTime 0.197 (1.434)\tETA 0:00:02\tTraining Loss 1.2690 (1.2751)\n",
      "\n",
      "Epoch: [96][6/16]\tTime 0.193 (1.627)\tETA 0:00:01\tTraining Loss 1.2693 (1.2742)\n",
      "\n",
      "Epoch: [96][7/16]\tTime 0.181 (1.808)\tETA 0:00:01\tTraining Loss 1.2734 (1.2741)\n",
      "\n",
      "Epoch: [96][8/16]\tTime 0.193 (2.001)\tETA 0:00:01\tTraining Loss 1.2738 (1.2741)\n",
      "\n",
      "Epoch: [96][9/16]\tTime 0.191 (2.192)\tETA 0:00:01\tTraining Loss 1.2759 (1.2743)\n",
      "\n",
      "Epoch: [96][10/16]\tTime 0.184 (2.376)\tETA 0:00:01\tTraining Loss 1.2726 (1.2741)\n",
      "\n",
      "Epoch: [96][11/16]\tTime 0.193 (2.569)\tETA 0:00:00\tTraining Loss 1.2707 (1.2738)\n",
      "\n",
      "Epoch: [96][12/16]\tTime 0.191 (2.760)\tETA 0:00:00\tTraining Loss 1.2741 (1.2739)\n",
      "\n",
      "Epoch: [96][13/16]\tTime 0.182 (2.942)\tETA 0:00:00\tTraining Loss 1.2699 (1.2736)\n",
      "\n",
      "Epoch: [96][14/16]\tTime 0.191 (3.133)\tETA 0:00:00\tTraining Loss 1.2685 (1.2732)\n",
      "\n",
      "Epoch: [96][15/16]\tTime 0.113 (3.246)\tETA 0:00:00\tTraining Loss 1.2703 (1.2731)\n",
      "_\n",
      "Validation stats                    IoU        F1      Prec    recall       Acc\n",
      "bg,          0.944500  0.971400  0.975100  0.967800  0.950500\n",
      "real apple   0.152100  0.264000  0.966300  0.152900  0.944000\n",
      "real pepper  0.000000  0.000000  0.000000  0.000000  0.997200\n",
      "real grape   0.796000  0.886400  0.930800  0.846100  0.986000\n",
      "fake apple   0.000000  0.000000  0.000000  0.000000  0.957600\n",
      "fake pepper  0.000000  0.000000  0.000000  0.000000  0.985200\n",
      "fake grape   0.000000  0.000000  0.000000  0.000000  0.992300\n",
      "total        0.270371  0.303114  0.410314  0.280971  0.973257\n",
      "total(-bg)   0.158017  0.191733  0.316183  0.166500  0.977050\n",
      "\n",
      "Epoch: [97][0/16]\tTime 0.428 (0.428)\tETA 0:00:06\tTraining Loss 1.2708 (1.2708)\n",
      "\n",
      "Epoch: [97][1/16]\tTime 0.177 (0.605)\tETA 0:00:02\tTraining Loss 1.2708 (1.2708)\n",
      "\n",
      "Epoch: [97][2/16]\tTime 0.181 (0.785)\tETA 0:00:02\tTraining Loss 1.2711 (1.2709)\n",
      "\n",
      "Epoch: [97][3/16]\tTime 0.185 (0.970)\tETA 0:00:02\tTraining Loss 1.2732 (1.2714)\n",
      "\n",
      "Epoch: [97][4/16]\tTime 0.200 (1.170)\tETA 0:00:02\tTraining Loss 1.2704 (1.2712)\n",
      "\n",
      "Epoch: [97][5/16]\tTime 0.188 (1.358)\tETA 0:00:02\tTraining Loss 1.2725 (1.2714)\n",
      "\n",
      "Epoch: [97][6/16]\tTime 0.195 (1.553)\tETA 0:00:01\tTraining Loss 1.2735 (1.2717)\n",
      "\n",
      "Epoch: [97][7/16]\tTime 0.200 (1.753)\tETA 0:00:01\tTraining Loss 1.2707 (1.2716)\n",
      "\n",
      "Epoch: [97][8/16]\tTime 0.190 (1.943)\tETA 0:00:01\tTraining Loss 1.2696 (1.2714)\n",
      "\n",
      "Epoch: [97][9/16]\tTime 0.180 (2.123)\tETA 0:00:01\tTraining Loss 1.2686 (1.2711)\n",
      "\n",
      "Epoch: [97][10/16]\tTime 0.199 (2.322)\tETA 0:00:01\tTraining Loss 1.2703 (1.2710)\n",
      "\n",
      "Epoch: [97][11/16]\tTime 0.210 (2.532)\tETA 0:00:01\tTraining Loss 1.2660 (1.2706)\n",
      "\n",
      "Epoch: [97][12/16]\tTime 0.210 (2.742)\tETA 0:00:00\tTraining Loss 1.2722 (1.2707)\n",
      "\n",
      "Epoch: [97][13/16]\tTime 0.179 (2.921)\tETA 0:00:00\tTraining Loss 1.2734 (1.2709)\n",
      "\n",
      "Epoch: [97][14/16]\tTime 0.190 (3.112)\tETA 0:00:00\tTraining Loss 1.2689 (1.2708)\n",
      "\n",
      "Epoch: [97][15/16]\tTime 0.118 (3.230)\tETA 0:00:00\tTraining Loss 1.2684 (1.2707)\n",
      "_\n",
      "Validation stats                    IoU        F1      Prec  recall       Acc\n",
      "bg,          0.948100  0.973300  0.976600  0.9701  0.953800\n",
      "real apple   0.361500  0.531000  0.985800  0.3634  0.957800\n",
      "real pepper  0.000000  0.000000  0.000000  0.0000  0.998400\n",
      "real grape   0.760500  0.863900  0.928500  0.8078  0.983500\n",
      "fake apple   0.000000  0.000000  0.000000  0.0000  0.968200\n",
      "fake pepper  0.000000  0.000000  0.000000  0.0000  0.992500\n",
      "fake grape   0.000000  0.000000  0.000000  0.0000  0.985300\n",
      "total        0.295729  0.338314  0.412986  0.3059  0.977071\n",
      "total(-bg)   0.187000  0.232483  0.319050  0.1952  0.980950\n",
      "\n",
      "Epoch: [98][0/16]\tTime 0.490 (0.490)\tETA 0:00:07\tTraining Loss 1.2704 (1.2704)\n",
      "\n",
      "Epoch: [98][1/16]\tTime 0.161 (0.651)\tETA 0:00:02\tTraining Loss 1.2713 (1.2709)\n",
      "\n",
      "Epoch: [98][2/16]\tTime 0.192 (0.843)\tETA 0:00:02\tTraining Loss 1.2680 (1.2699)\n",
      "\n",
      "Epoch: [98][3/16]\tTime 0.191 (1.035)\tETA 0:00:02\tTraining Loss 1.2685 (1.2696)\n",
      "\n",
      "Epoch: [98][4/16]\tTime 0.187 (1.222)\tETA 0:00:02\tTraining Loss 1.2673 (1.2691)\n",
      "\n",
      "Epoch: [98][5/16]\tTime 0.189 (1.411)\tETA 0:00:02\tTraining Loss 1.2690 (1.2691)\n",
      "\n",
      "Epoch: [98][6/16]\tTime 0.187 (1.598)\tETA 0:00:01\tTraining Loss 1.2639 (1.2684)\n",
      "\n",
      "Epoch: [98][7/16]\tTime 0.190 (1.787)\tETA 0:00:01\tTraining Loss 1.2727 (1.2689)\n",
      "\n",
      "Epoch: [98][8/16]\tTime 0.195 (1.982)\tETA 0:00:01\tTraining Loss 1.2714 (1.2692)\n",
      "\n",
      "Epoch: [98][9/16]\tTime 0.184 (2.166)\tETA 0:00:01\tTraining Loss 1.2677 (1.2690)\n",
      "\n",
      "Epoch: [98][10/16]\tTime 0.187 (2.354)\tETA 0:00:01\tTraining Loss 1.2852 (1.2705)\n",
      "\n",
      "Epoch: [98][11/16]\tTime 0.181 (2.535)\tETA 0:00:00\tTraining Loss 1.2683 (1.2703)\n",
      "\n",
      "Epoch: [98][12/16]\tTime 0.182 (2.717)\tETA 0:00:00\tTraining Loss 1.2645 (1.2699)\n",
      "\n",
      "Epoch: [98][13/16]\tTime 0.192 (2.909)\tETA 0:00:00\tTraining Loss 1.2649 (1.2695)\n",
      "\n",
      "Epoch: [98][14/16]\tTime 0.190 (3.099)\tETA 0:00:00\tTraining Loss 1.2702 (1.2696)\n",
      "\n",
      "Epoch: [98][15/16]\tTime 0.111 (3.210)\tETA 0:00:00\tTraining Loss 1.2703 (1.2696)\n",
      "_\n",
      "Validation stats                    IoU      F1      Prec    recall       Acc\n",
      "bg,          0.945700  0.9720  0.977000  0.967200  0.951700\n",
      "real apple   0.331400  0.4978  0.957100  0.336400  0.955400\n",
      "real pepper  0.000000  0.0000  0.000000  0.000000  0.999900\n",
      "real grape   0.743400  0.8528  0.898500  0.811600  0.981900\n",
      "fake apple   0.000000  0.0000  0.000000  0.000000  0.964700\n",
      "fake pepper  0.000000  0.0000  0.000000  0.000000  0.991600\n",
      "fake grape   0.000000  0.0000  0.000000  0.000000  0.986100\n",
      "total        0.288643  0.3318  0.404657  0.302171  0.975900\n",
      "total(-bg)   0.179133  0.2251  0.309267  0.191333  0.979933\n",
      "\n",
      "Epoch: [99][0/16]\tTime 0.477 (0.477)\tETA 0:00:07\tTraining Loss 1.2642 (1.2642)\n",
      "\n",
      "Epoch: [99][1/16]\tTime 0.179 (0.657)\tETA 0:00:02\tTraining Loss 1.2707 (1.2675)\n",
      "\n",
      "Epoch: [99][2/16]\tTime 0.191 (0.848)\tETA 0:00:02\tTraining Loss 1.2636 (1.2662)\n",
      "\n",
      "Epoch: [99][3/16]\tTime 0.196 (1.044)\tETA 0:00:02\tTraining Loss 1.2677 (1.2666)\n",
      "\n",
      "Epoch: [99][4/16]\tTime 0.186 (1.230)\tETA 0:00:02\tTraining Loss 1.2640 (1.2660)\n",
      "\n",
      "Epoch: [99][5/16]\tTime 0.191 (1.421)\tETA 0:00:02\tTraining Loss 1.2736 (1.2673)\n",
      "\n",
      "Epoch: [99][6/16]\tTime 0.191 (1.612)\tETA 0:00:01\tTraining Loss 1.2742 (1.2683)\n",
      "\n",
      "Epoch: [99][7/16]\tTime 0.196 (1.807)\tETA 0:00:01\tTraining Loss 1.2708 (1.2686)\n",
      "\n",
      "Epoch: [99][8/16]\tTime 0.178 (1.985)\tETA 0:00:01\tTraining Loss 1.2639 (1.2681)\n",
      "\n",
      "Epoch: [99][9/16]\tTime 0.200 (2.185)\tETA 0:00:01\tTraining Loss 1.2681 (1.2681)\n",
      "\n",
      "Epoch: [99][10/16]\tTime 0.187 (2.372)\tETA 0:00:01\tTraining Loss 1.2655 (1.2678)\n",
      "\n",
      "Epoch: [99][11/16]\tTime 0.193 (2.566)\tETA 0:00:00\tTraining Loss 1.2653 (1.2676)\n",
      "\n",
      "Epoch: [99][12/16]\tTime 0.181 (2.747)\tETA 0:00:00\tTraining Loss 1.2649 (1.2674)\n",
      "\n",
      "Epoch: [99][13/16]\tTime 0.186 (2.932)\tETA 0:00:00\tTraining Loss 1.2660 (1.2673)\n",
      "\n",
      "Epoch: [99][14/16]\tTime 0.196 (3.129)\tETA 0:00:00\tTraining Loss 1.2657 (1.2672)\n",
      "\n",
      "Epoch: [99][15/16]\tTime 0.113 (3.242)\tETA 0:00:00\tTraining Loss 1.2643 (1.2671)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_\n",
      "Validation stats                    IoU        F1      Prec    recall       Acc\n",
      "bg,          0.947500  0.973000  0.976600  0.969600  0.953300\n",
      "real apple   0.130600  0.231000  0.941900  0.131600  0.942400\n",
      "real pepper  0.000000  0.000000  0.000000  0.000000  1.000000\n",
      "real grape   0.788800  0.881900  0.930900  0.837900  0.985500\n",
      "fake apple   0.000000  0.000000  0.000000  0.000000  0.967600\n",
      "fake pepper  0.000000  0.000000  0.000000  0.000000  0.985200\n",
      "fake grape   0.000000  0.000000  0.000000  0.000000  0.977900\n",
      "total        0.266700  0.297986  0.407057  0.277014  0.973129\n",
      "total(-bg)   0.153233  0.185483  0.312133  0.161583  0.976433\n",
      "\n",
      "Epoch: [100][0/16]\tTime 0.371 (0.371)\tETA 0:00:05\tTraining Loss 1.2716 (1.2716)\n",
      "\n",
      "Epoch: [100][1/16]\tTime 0.191 (0.562)\tETA 0:00:02\tTraining Loss 1.2683 (1.2699)\n",
      "\n",
      "Epoch: [100][2/16]\tTime 0.186 (0.748)\tETA 0:00:02\tTraining Loss 1.2700 (1.2700)\n",
      "\n",
      "Epoch: [100][3/16]\tTime 0.187 (0.935)\tETA 0:00:02\tTraining Loss 1.2655 (1.2689)\n",
      "\n",
      "Epoch: [100][4/16]\tTime 0.188 (1.123)\tETA 0:00:02\tTraining Loss 1.2675 (1.2686)\n",
      "\n",
      "Epoch: [100][5/16]\tTime 0.190 (1.313)\tETA 0:00:02\tTraining Loss 1.2665 (1.2682)\n",
      "\n",
      "Epoch: [100][6/16]\tTime 0.178 (1.491)\tETA 0:00:01\tTraining Loss 1.2680 (1.2682)\n",
      "\n",
      "Epoch: [100][7/16]\tTime 0.195 (1.686)\tETA 0:00:01\tTraining Loss 1.2644 (1.2677)\n",
      "\n",
      "Epoch: [100][8/16]\tTime 0.188 (1.874)\tETA 0:00:01\tTraining Loss 1.2633 (1.2672)\n",
      "\n",
      "Epoch: [100][9/16]\tTime 0.192 (2.066)\tETA 0:00:01\tTraining Loss 1.2668 (1.2672)\n",
      "\n",
      "Epoch: [100][10/16]\tTime 0.198 (2.264)\tETA 0:00:01\tTraining Loss 1.2640 (1.2669)\n",
      "\n",
      "Epoch: [100][11/16]\tTime 0.190 (2.453)\tETA 0:00:00\tTraining Loss 1.2677 (1.2670)\n",
      "\n",
      "Epoch: [100][12/16]\tTime 0.193 (2.646)\tETA 0:00:00\tTraining Loss 1.2649 (1.2668)\n",
      "\n",
      "Epoch: [100][13/16]\tTime 0.186 (2.832)\tETA 0:00:00\tTraining Loss 1.2670 (1.2668)\n",
      "\n",
      "Epoch: [100][14/16]\tTime 0.188 (3.020)\tETA 0:00:00\tTraining Loss 1.2632 (1.2666)\n",
      "\n",
      "Epoch: [100][15/16]\tTime 0.116 (3.136)\tETA 0:00:00\tTraining Loss 1.2661 (1.2666)\n",
      "_\n",
      "Validation stats                    IoU        F1      Prec    recall       Acc\n",
      "bg,          0.948400  0.973500  0.976500  0.970600  0.954100\n",
      "real apple   0.295500  0.456200  0.979000  0.297400  0.953400\n",
      "real pepper  0.000000  0.000000  0.000000  0.000000  0.998500\n",
      "real grape   0.778900  0.875700  0.914200  0.840300  0.984600\n",
      "fake apple   0.000000  0.000000  0.000000  0.000000  0.966700\n",
      "fake pepper  0.000000  0.000000  0.000000  0.000000  0.984500\n",
      "fake grape   0.000000  0.000000  0.000000  0.000000  0.994000\n",
      "total        0.288971  0.329343  0.409957  0.301186  0.976543\n",
      "total(-bg)   0.179067  0.221983  0.315533  0.189617  0.980283\n",
      "\n",
      "Epoch: [101][0/16]\tTime 0.457 (0.457)\tETA 0:00:07\tTraining Loss 1.2629 (1.2629)\n",
      "\n",
      "Epoch: [101][1/16]\tTime 0.176 (0.633)\tETA 0:00:02\tTraining Loss 1.2641 (1.2635)\n",
      "\n",
      "Epoch: [101][2/16]\tTime 0.182 (0.814)\tETA 0:00:02\tTraining Loss 1.2662 (1.2644)\n",
      "\n",
      "Epoch: [101][3/16]\tTime 0.186 (1.001)\tETA 0:00:02\tTraining Loss 1.2612 (1.2636)\n",
      "\n",
      "Epoch: [101][4/16]\tTime 0.191 (1.192)\tETA 0:00:02\tTraining Loss 1.2636 (1.2636)\n",
      "\n",
      "Epoch: [101][5/16]\tTime 0.185 (1.378)\tETA 0:00:02\tTraining Loss 1.2619 (1.2633)\n",
      "\n",
      "Epoch: [101][6/16]\tTime 0.184 (1.562)\tETA 0:00:01\tTraining Loss 1.2604 (1.2629)\n",
      "\n",
      "Epoch: [101][7/16]\tTime 0.200 (1.761)\tETA 0:00:01\tTraining Loss 1.2723 (1.2641)\n",
      "\n",
      "Epoch: [101][8/16]\tTime 0.188 (1.949)\tETA 0:00:01\tTraining Loss 1.2646 (1.2641)\n",
      "\n",
      "Epoch: [101][9/16]\tTime 0.197 (2.147)\tETA 0:00:01\tTraining Loss 1.2613 (1.2638)\n",
      "\n",
      "Epoch: [101][10/16]\tTime 0.290 (2.436)\tETA 0:00:01\tTraining Loss 1.2670 (1.2641)\n",
      "\n",
      "Epoch: [101][11/16]\tTime 0.180 (2.616)\tETA 0:00:00\tTraining Loss 1.2639 (1.2641)\n",
      "\n",
      "Epoch: [101][12/16]\tTime 0.184 (2.801)\tETA 0:00:00\tTraining Loss 1.2739 (1.2649)\n",
      "\n",
      "Epoch: [101][13/16]\tTime 0.190 (2.991)\tETA 0:00:00\tTraining Loss 1.2628 (1.2647)\n",
      "\n",
      "Epoch: [101][14/16]\tTime 0.184 (3.174)\tETA 0:00:00\tTraining Loss 1.2651 (1.2647)\n",
      "\n",
      "Epoch: [101][15/16]\tTime 0.117 (3.291)\tETA 0:00:00\tTraining Loss 1.2700 (1.2649)\n",
      "_\n",
      "Validation stats                    IoU        F1      Prec    recall       Acc\n",
      "bg,          0.946800  0.972600  0.974200  0.971100  0.952500\n",
      "real apple   0.363500  0.533200  0.978900  0.366400  0.957800\n",
      "real pepper  0.000000  0.000000  0.000000  0.000000  0.998900\n",
      "real grape   0.612600  0.759700  0.944000  0.635700  0.974000\n",
      "fake apple   0.000000  0.000000  0.000000  0.000000  0.970500\n",
      "fake pepper  0.000000  0.000000  0.000000  0.000000  0.991500\n",
      "fake grape   0.000000  0.000000  0.000000  0.000000  0.974000\n",
      "total        0.274700  0.323643  0.413871  0.281886  0.974171\n",
      "total(-bg)   0.162683  0.215483  0.320483  0.167017  0.977783\n",
      "\n",
      "Epoch: [102][0/16]\tTime 0.472 (0.472)\tETA 0:00:07\tTraining Loss 1.2637 (1.2637)\n",
      "\n",
      "Epoch: [102][1/16]\tTime 0.186 (0.658)\tETA 0:00:02\tTraining Loss 1.2642 (1.2639)\n",
      "\n",
      "Epoch: [102][2/16]\tTime 0.189 (0.847)\tETA 0:00:02\tTraining Loss 1.2634 (1.2637)\n",
      "\n",
      "Epoch: [102][3/16]\tTime 0.182 (1.029)\tETA 0:00:02\tTraining Loss 1.2654 (1.2642)\n",
      "\n",
      "Epoch: [102][4/16]\tTime 0.182 (1.211)\tETA 0:00:02\tTraining Loss 1.2623 (1.2638)\n",
      "\n",
      "Epoch: [102][5/16]\tTime 0.184 (1.395)\tETA 0:00:02\tTraining Loss 1.2606 (1.2632)\n",
      "\n",
      "Epoch: [102][6/16]\tTime 0.184 (1.579)\tETA 0:00:01\tTraining Loss 1.2609 (1.2629)\n",
      "\n",
      "Epoch: [102][7/16]\tTime 0.193 (1.772)\tETA 0:00:01\tTraining Loss 1.2669 (1.2634)\n",
      "\n",
      "Epoch: [102][8/16]\tTime 0.180 (1.952)\tETA 0:00:01\tTraining Loss 1.2613 (1.2632)\n",
      "\n",
      "Epoch: [102][9/16]\tTime 0.186 (2.138)\tETA 0:00:01\tTraining Loss 1.2674 (1.2636)\n",
      "\n",
      "Epoch: [102][10/16]\tTime 0.186 (2.324)\tETA 0:00:01\tTraining Loss 1.2617 (1.2634)\n",
      "\n",
      "Epoch: [102][11/16]\tTime 0.177 (2.502)\tETA 0:00:00\tTraining Loss 1.2629 (1.2634)\n",
      "\n",
      "Epoch: [102][12/16]\tTime 0.191 (2.693)\tETA 0:00:00\tTraining Loss 1.2641 (1.2634)\n",
      "\n",
      "Epoch: [102][13/16]\tTime 0.184 (2.877)\tETA 0:00:00\tTraining Loss 1.2605 (1.2632)\n",
      "\n",
      "Epoch: [102][14/16]\tTime 0.191 (3.068)\tETA 0:00:00\tTraining Loss 1.2613 (1.2631)\n",
      "\n",
      "Epoch: [102][15/16]\tTime 0.117 (3.185)\tETA 0:00:00\tTraining Loss 1.2563 (1.2629)\n",
      "_\n",
      "Validation stats                    IoU        F1      Prec    recall       Acc\n",
      "bg,          0.950600  0.974600  0.975000  0.974400  0.956000\n",
      "real apple   0.179100  0.303800  0.939800  0.181200  0.945400\n",
      "real pepper  0.000000  0.000000  0.000000  0.000000  0.999900\n",
      "real grape   0.747400  0.855400  0.932400  0.790100  0.982700\n",
      "fake apple   0.000000  0.000000  0.000000  0.000000  0.965500\n",
      "fake pepper  0.000000  0.000000  0.000000  0.000000  0.985200\n",
      "fake grape   0.000000  0.000000  0.000000  0.000000  0.986000\n",
      "total        0.268157  0.304829  0.406743  0.277957  0.974386\n",
      "total(-bg)   0.154417  0.193200  0.312033  0.161883  0.977450\n",
      "\n",
      "Epoch: [103][0/16]\tTime 0.531 (0.531)\tETA 0:00:08\tTraining Loss 1.2594 (1.2594)\n",
      "\n",
      "Epoch: [103][1/16]\tTime 0.196 (0.727)\tETA 0:00:02\tTraining Loss 1.2574 (1.2584)\n",
      "\n",
      "Epoch: [103][2/16]\tTime 0.181 (0.909)\tETA 0:00:02\tTraining Loss 1.2622 (1.2597)\n",
      "\n",
      "Epoch: [103][3/16]\tTime 0.199 (1.107)\tETA 0:00:02\tTraining Loss 1.2689 (1.2620)\n",
      "\n",
      "Epoch: [103][4/16]\tTime 0.191 (1.299)\tETA 0:00:02\tTraining Loss 1.2611 (1.2618)\n",
      "\n",
      "Epoch: [103][5/16]\tTime 0.183 (1.482)\tETA 0:00:02\tTraining Loss 1.2576 (1.2611)\n",
      "\n",
      "Epoch: [103][6/16]\tTime 0.203 (1.685)\tETA 0:00:02\tTraining Loss 1.2633 (1.2614)\n",
      "\n",
      "Epoch: [103][7/16]\tTime 0.209 (1.894)\tETA 0:00:01\tTraining Loss 1.2658 (1.2620)\n",
      "\n",
      "Epoch: [103][8/16]\tTime 0.190 (2.085)\tETA 0:00:01\tTraining Loss 1.2593 (1.2617)\n",
      "\n",
      "Epoch: [103][9/16]\tTime 0.190 (2.275)\tETA 0:00:01\tTraining Loss 1.2612 (1.2616)\n",
      "\n",
      "Epoch: [103][10/16]\tTime 0.181 (2.456)\tETA 0:00:01\tTraining Loss 1.2657 (1.2620)\n",
      "\n",
      "Epoch: [103][11/16]\tTime 0.189 (2.646)\tETA 0:00:00\tTraining Loss 1.2653 (1.2623)\n",
      "\n",
      "Epoch: [103][12/16]\tTime 0.188 (2.834)\tETA 0:00:00\tTraining Loss 1.2565 (1.2618)\n",
      "\n",
      "Epoch: [103][13/16]\tTime 0.188 (3.022)\tETA 0:00:00\tTraining Loss 1.2645 (1.2620)\n",
      "\n",
      "Epoch: [103][14/16]\tTime 0.188 (3.210)\tETA 0:00:00\tTraining Loss 1.2576 (1.2617)\n",
      "\n",
      "Epoch: [103][15/16]\tTime 0.118 (3.328)\tETA 0:00:00\tTraining Loss 1.2670 (1.2619)\n",
      "_\n",
      "Validation stats                    IoU        F1     Prec    recall       Acc\n",
      "bg,          0.953200  0.976000  0.97670  0.975300  0.958300\n",
      "real apple   0.364900  0.534600  0.97300  0.368600  0.957800\n",
      "real pepper  0.000000  0.000000  0.00000  0.000000  0.999900\n",
      "real grape   0.639200  0.779900  0.89090  0.693500  0.974700\n",
      "fake apple   0.000000  0.000000  0.00000  0.000000  0.973400\n",
      "fake pepper  0.000000  0.000000  0.00000  0.000000  0.990600\n",
      "fake grape   0.000000  0.000000  0.00000  0.000000  0.979700\n",
      "total        0.279614  0.327214  0.40580  0.291057  0.976343\n",
      "total(-bg)   0.167350  0.219083  0.31065  0.177017  0.979350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: [104][0/16]\tTime 0.416 (0.416)\tETA 0:00:06\tTraining Loss 1.2599 (1.2599)\n",
      "\n",
      "Epoch: [104][1/16]\tTime 0.187 (0.603)\tETA 0:00:02\tTraining Loss 1.2561 (1.2580)\n",
      "\n",
      "Epoch: [104][2/16]\tTime 0.187 (0.791)\tETA 0:00:02\tTraining Loss 1.2572 (1.2577)\n",
      "\n",
      "Epoch: [104][3/16]\tTime 0.189 (0.980)\tETA 0:00:02\tTraining Loss 1.2583 (1.2579)\n",
      "\n",
      "Epoch: [104][4/16]\tTime 0.199 (1.179)\tETA 0:00:02\tTraining Loss 1.2578 (1.2578)\n",
      "\n",
      "Epoch: [104][5/16]\tTime 0.192 (1.370)\tETA 0:00:02\tTraining Loss 1.2595 (1.2581)\n",
      "\n",
      "Epoch: [104][6/16]\tTime 0.193 (1.563)\tETA 0:00:01\tTraining Loss 1.2582 (1.2581)\n",
      "\n",
      "Epoch: [104][7/16]\tTime 0.206 (1.769)\tETA 0:00:01\tTraining Loss 1.2590 (1.2582)\n",
      "\n",
      "Epoch: [104][8/16]\tTime 0.176 (1.944)\tETA 0:00:01\tTraining Loss 1.2821 (1.2609)\n",
      "\n",
      "Epoch: [104][9/16]\tTime 0.217 (2.162)\tETA 0:00:01\tTraining Loss 1.2665 (1.2615)\n",
      "\n",
      "Epoch: [104][10/16]\tTime 0.185 (2.346)\tETA 0:00:01\tTraining Loss 1.2593 (1.2613)\n",
      "\n",
      "Epoch: [104][11/16]\tTime 0.187 (2.533)\tETA 0:00:00\tTraining Loss 1.2629 (1.2614)\n",
      "\n",
      "Epoch: [104][12/16]\tTime 0.187 (2.720)\tETA 0:00:00\tTraining Loss 1.2585 (1.2612)\n",
      "\n",
      "Epoch: [104][13/16]\tTime 0.192 (2.912)\tETA 0:00:00\tTraining Loss 1.2668 (1.2616)\n",
      "\n",
      "Epoch: [104][14/16]\tTime 0.177 (3.089)\tETA 0:00:00\tTraining Loss 1.2623 (1.2616)\n",
      "\n",
      "Epoch: [104][15/16]\tTime 0.117 (3.206)\tETA 0:00:00\tTraining Loss 1.2577 (1.2615)\n",
      "_\n",
      "Validation stats                    IoU        F1      Prec    recall       Acc\n",
      "bg,          0.944800  0.971600  0.972000  0.971200  0.950700\n",
      "real apple   0.292100  0.452100  0.949500  0.296700  0.952700\n",
      "real pepper  0.000000  0.000000  0.000000  0.000000  0.999900\n",
      "real grape   0.199300  0.332400  0.667600  0.221300  0.942400\n",
      "fake apple   0.000000  0.000000  0.000000  0.000000  0.965700\n",
      "fake pepper  0.000000  0.000000  0.000000  0.000000  0.987500\n",
      "fake grape   0.000000  0.000000  0.000000  0.000000  0.957600\n",
      "total        0.205171  0.250871  0.369871  0.212743  0.965214\n",
      "total(-bg)   0.081900  0.130750  0.269517  0.086333  0.967633\n",
      "\n",
      "Epoch: [105][0/16]\tTime 0.491 (0.491)\tETA 0:00:07\tTraining Loss 1.2620 (1.2620)\n",
      "\n",
      "Epoch: [105][1/16]\tTime 0.184 (0.674)\tETA 0:00:02\tTraining Loss 1.2578 (1.2599)\n",
      "\n",
      "Epoch: [105][2/16]\tTime 0.193 (0.867)\tETA 0:00:02\tTraining Loss 1.2611 (1.2603)\n",
      "\n",
      "Epoch: [105][3/16]\tTime 0.187 (1.053)\tETA 0:00:02\tTraining Loss 1.2579 (1.2597)\n",
      "\n",
      "Epoch: [105][4/16]\tTime 0.181 (1.235)\tETA 0:00:02\tTraining Loss 1.2569 (1.2591)\n",
      "\n",
      "Epoch: [105][5/16]\tTime 0.175 (1.410)\tETA 0:00:01\tTraining Loss 1.2627 (1.2597)\n",
      "\n",
      "Epoch: [105][6/16]\tTime 0.197 (1.607)\tETA 0:00:01\tTraining Loss 1.2638 (1.2603)\n",
      "\n",
      "Epoch: [105][7/16]\tTime 0.187 (1.793)\tETA 0:00:01\tTraining Loss 1.2641 (1.2608)\n",
      "\n",
      "Epoch: [105][8/16]\tTime 0.183 (1.977)\tETA 0:00:01\tTraining Loss 1.2590 (1.2606)\n",
      "\n",
      "Epoch: [105][9/16]\tTime 0.185 (2.162)\tETA 0:00:01\tTraining Loss 1.2573 (1.2603)\n",
      "\n",
      "Epoch: [105][10/16]\tTime 0.189 (2.351)\tETA 0:00:01\tTraining Loss 1.2563 (1.2599)\n",
      "\n",
      "Epoch: [105][11/16]\tTime 0.193 (2.544)\tETA 0:00:00\tTraining Loss 1.2560 (1.2596)\n",
      "\n",
      "Epoch: [105][12/16]\tTime 0.186 (2.730)\tETA 0:00:00\tTraining Loss 1.2597 (1.2596)\n",
      "\n",
      "Epoch: [105][13/16]\tTime 0.187 (2.917)\tETA 0:00:00\tTraining Loss 1.2572 (1.2594)\n",
      "\n",
      "Epoch: [105][14/16]\tTime 0.194 (3.111)\tETA 0:00:00\tTraining Loss 1.2560 (1.2592)\n",
      "\n",
      "Epoch: [105][15/16]\tTime 0.111 (3.222)\tETA 0:00:00\tTraining Loss 1.2557 (1.2591)\n",
      "_\n",
      "Validation stats                    IoU      F1      Prec    recall       Acc\n",
      "bg,          0.948600  0.9736  0.977400  0.969900  0.954300\n",
      "real apple   0.445700  0.6166  0.988200  0.448100  0.963400\n",
      "real pepper  0.000000  0.0000  0.000000  0.000000  0.998400\n",
      "real grape   0.706000  0.8276  0.881400  0.780100  0.979000\n",
      "fake apple   0.000000  0.0000  0.000000  0.000000  0.973500\n",
      "fake pepper  0.000000  0.0000  0.000000  0.000000  0.994400\n",
      "fake grape   0.000000  0.0000  0.000000  0.000000  0.983700\n",
      "total        0.300043  0.3454  0.406714  0.314014  0.978100\n",
      "total(-bg)   0.191950  0.2407  0.311600  0.204700  0.982067\n",
      "\n",
      "Epoch: [106][0/16]\tTime 0.457 (0.457)\tETA 0:00:07\tTraining Loss 1.2588 (1.2588)\n",
      "\n",
      "Epoch: [106][1/16]\tTime 0.186 (0.643)\tETA 0:00:02\tTraining Loss 1.2562 (1.2575)\n",
      "\n",
      "Epoch: [106][2/16]\tTime 0.180 (0.824)\tETA 0:00:02\tTraining Loss 1.2569 (1.2573)\n",
      "\n",
      "Epoch: [106][3/16]\tTime 0.197 (1.021)\tETA 0:00:02\tTraining Loss 1.2673 (1.2598)\n",
      "\n",
      "Epoch: [106][4/16]\tTime 0.180 (1.201)\tETA 0:00:02\tTraining Loss 1.2553 (1.2589)\n",
      "\n",
      "Epoch: [106][5/16]\tTime 0.183 (1.384)\tETA 0:00:02\tTraining Loss 1.2559 (1.2584)\n",
      "\n",
      "Epoch: [106][6/16]\tTime 0.199 (1.583)\tETA 0:00:01\tTraining Loss 1.2573 (1.2582)\n",
      "\n",
      "Epoch: [106][7/16]\tTime 0.188 (1.771)\tETA 0:00:01\tTraining Loss 1.2567 (1.2580)\n",
      "\n",
      "Epoch: [106][8/16]\tTime 0.186 (1.957)\tETA 0:00:01\tTraining Loss 1.2567 (1.2579)\n",
      "\n",
      "Epoch: [106][9/16]\tTime 0.182 (2.139)\tETA 0:00:01\tTraining Loss 1.2563 (1.2577)\n",
      "\n",
      "Epoch: [106][10/16]\tTime 0.178 (2.317)\tETA 0:00:01\tTraining Loss 1.2539 (1.2574)\n",
      "\n",
      "Epoch: [106][11/16]\tTime 0.205 (2.522)\tETA 0:00:01\tTraining Loss 1.2615 (1.2577)\n",
      "\n",
      "Epoch: [106][12/16]\tTime 0.185 (2.707)\tETA 0:00:00\tTraining Loss 1.2592 (1.2578)\n",
      "\n",
      "Epoch: [106][13/16]\tTime 0.186 (2.893)\tETA 0:00:00\tTraining Loss 1.2568 (1.2578)\n",
      "\n",
      "Epoch: [106][14/16]\tTime 0.184 (3.076)\tETA 0:00:00\tTraining Loss 1.2576 (1.2578)\n",
      "\n",
      "Epoch: [106][15/16]\tTime 0.113 (3.190)\tETA 0:00:00\tTraining Loss 1.2604 (1.2578)\n",
      "_\n",
      "Validation stats                    IoU        F1      Prec    recall       Acc\n",
      "bg,          0.944600  0.971500  0.977400  0.965700  0.950800\n",
      "real apple   0.457300  0.627500  0.953400  0.467700  0.963500\n",
      "real pepper  0.000000  0.000000  0.000000  0.000000  0.998800\n",
      "real grape   0.770100  0.870000  0.890800  0.850400  0.983600\n",
      "fake apple   0.000000  0.000000  0.000000  0.000000  0.974200\n",
      "fake pepper  0.000000  0.000000  0.000000  0.000000  0.993100\n",
      "fake grape   0.000000  0.000000  0.000000  0.000000  0.987200\n",
      "total        0.310286  0.352714  0.403086  0.326257  0.978743\n",
      "total(-bg)   0.204567  0.249583  0.307367  0.219683  0.983400\n",
      "\n",
      "Epoch: [107][0/16]\tTime 0.492 (0.492)\tETA 0:00:07\tTraining Loss 1.2546 (1.2546)\n",
      "\n",
      "Epoch: [107][1/16]\tTime 0.186 (0.677)\tETA 0:00:02\tTraining Loss 1.2539 (1.2543)\n",
      "\n",
      "Epoch: [107][2/16]\tTime 0.186 (0.863)\tETA 0:00:02\tTraining Loss 1.2539 (1.2542)\n",
      "\n",
      "Epoch: [107][3/16]\tTime 0.187 (1.050)\tETA 0:00:02\tTraining Loss 1.2580 (1.2551)\n",
      "\n",
      "Epoch: [107][4/16]\tTime 0.172 (1.222)\tETA 0:00:02\tTraining Loss 1.2552 (1.2551)\n",
      "\n",
      "Epoch: [107][5/16]\tTime 0.192 (1.414)\tETA 0:00:02\tTraining Loss 1.2611 (1.2561)\n",
      "\n",
      "Epoch: [107][6/16]\tTime 0.187 (1.601)\tETA 0:00:01\tTraining Loss 1.2542 (1.2559)\n",
      "\n",
      "Epoch: [107][7/16]\tTime 0.194 (1.795)\tETA 0:00:01\tTraining Loss 1.2526 (1.2555)\n",
      "\n",
      "Epoch: [107][8/16]\tTime 0.191 (1.986)\tETA 0:00:01\tTraining Loss 1.2625 (1.2562)\n",
      "\n",
      "Epoch: [107][9/16]\tTime 0.190 (2.176)\tETA 0:00:01\tTraining Loss 1.2554 (1.2562)\n",
      "\n",
      "Epoch: [107][10/16]\tTime 0.171 (2.347)\tETA 0:00:01\tTraining Loss 1.2569 (1.2562)\n",
      "\n",
      "Epoch: [107][11/16]\tTime 0.191 (2.537)\tETA 0:00:00\tTraining Loss 1.2500 (1.2557)\n",
      "\n",
      "Epoch: [107][12/16]\tTime 0.189 (2.726)\tETA 0:00:00\tTraining Loss 1.2599 (1.2560)\n",
      "\n",
      "Epoch: [107][13/16]\tTime 0.187 (2.913)\tETA 0:00:00\tTraining Loss 1.2539 (1.2559)\n",
      "\n",
      "Epoch: [107][14/16]\tTime 0.188 (3.101)\tETA 0:00:00\tTraining Loss 1.2555 (1.2558)\n",
      "\n",
      "Epoch: [107][15/16]\tTime 0.116 (3.217)\tETA 0:00:00\tTraining Loss 1.2567 (1.2559)\n",
      "_\n",
      "Validation stats                    IoU        F1      Prec    recall      Acc\n",
      "bg,          0.951000  0.974800  0.977900  0.971900  0.95650\n",
      "real apple   0.426000  0.597400  0.924000  0.441500  0.96090\n",
      "real pepper  0.000000  0.000000  0.000000  0.000000  0.99990\n",
      "real grape   0.704800  0.826800  0.929800  0.744400  0.97980\n",
      "fake apple   0.000000  0.000000  0.000000  0.000000  0.97590\n",
      "fake pepper  0.000000  0.000000  0.000000  0.000000  0.98960\n",
      "fake grape   0.000000  0.000000  0.000000  0.000000  0.98200\n",
      "total        0.297400  0.342714  0.404529  0.308257  0.97780\n",
      "total(-bg)   0.188467  0.237367  0.308967  0.197650  0.98135\n",
      "\n",
      "Epoch: [108][0/16]\tTime 0.485 (0.485)\tETA 0:00:07\tTraining Loss 1.2513 (1.2513)\n",
      "\n",
      "Epoch: [108][1/16]\tTime 0.181 (0.666)\tETA 0:00:02\tTraining Loss 1.2571 (1.2542)\n",
      "\n",
      "Epoch: [108][2/16]\tTime 0.189 (0.855)\tETA 0:00:02\tTraining Loss 1.2523 (1.2536)\n",
      "\n",
      "Epoch: [108][3/16]\tTime 0.183 (1.037)\tETA 0:00:02\tTraining Loss 1.2520 (1.2532)\n",
      "\n",
      "Epoch: [108][4/16]\tTime 0.183 (1.221)\tETA 0:00:02\tTraining Loss 1.2525 (1.2530)\n",
      "\n",
      "Epoch: [108][5/16]\tTime 0.195 (1.416)\tETA 0:00:02\tTraining Loss 1.2543 (1.2533)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: [108][6/16]\tTime 0.184 (1.600)\tETA 0:00:01\tTraining Loss 1.2535 (1.2533)\n",
      "\n",
      "Epoch: [108][7/16]\tTime 0.182 (1.782)\tETA 0:00:01\tTraining Loss 1.2553 (1.2535)\n",
      "\n",
      "Epoch: [108][8/16]\tTime 0.193 (1.974)\tETA 0:00:01\tTraining Loss 1.2537 (1.2536)\n",
      "\n",
      "Epoch: [108][9/16]\tTime 0.180 (2.155)\tETA 0:00:01\tTraining Loss 1.2533 (1.2535)\n",
      "\n",
      "Epoch: [108][10/16]\tTime 0.207 (2.361)\tETA 0:00:01\tTraining Loss 1.2524 (1.2534)\n",
      "\n",
      "Epoch: [108][11/16]\tTime 0.183 (2.545)\tETA 0:00:00\tTraining Loss 1.2586 (1.2539)\n",
      "\n",
      "Epoch: [108][12/16]\tTime 0.191 (2.735)\tETA 0:00:00\tTraining Loss 1.2513 (1.2537)\n",
      "\n",
      "Epoch: [108][13/16]\tTime 0.191 (2.926)\tETA 0:00:00\tTraining Loss 1.2670 (1.2546)\n",
      "\n",
      "Epoch: [108][14/16]\tTime 0.188 (3.114)\tETA 0:00:00\tTraining Loss 1.2534 (1.2545)\n",
      "\n",
      "Epoch: [108][15/16]\tTime 0.114 (3.228)\tETA 0:00:00\tTraining Loss 1.2595 (1.2547)\n",
      "_\n",
      "Validation stats                    IoU        F1      Prec    recall       Acc\n",
      "bg,          0.950100  0.974400  0.976200  0.972700  0.955600\n",
      "real apple   0.320200  0.485000  0.969400  0.323400  0.954900\n",
      "real pepper  0.000000  0.000000  0.000000  0.000000  0.999800\n",
      "real grape   0.646900  0.785600  0.924400  0.683000  0.975900\n",
      "fake apple   0.000000  0.000000  0.000000  0.000000  0.971700\n",
      "fake pepper  0.000000  0.000000  0.000000  0.000000  0.988200\n",
      "fake grape   0.000000  0.000000  0.000000  0.000000  0.976500\n",
      "total        0.273886  0.320714  0.410000  0.282729  0.974657\n",
      "total(-bg)   0.161183  0.211767  0.315633  0.167733  0.977833\n",
      "\n",
      "Epoch: [109][0/16]\tTime 0.487 (0.487)\tETA 0:00:07\tTraining Loss 1.2561 (1.2561)\n",
      "\n",
      "Epoch: [109][1/16]\tTime 0.195 (0.682)\tETA 0:00:02\tTraining Loss 1.2517 (1.2539)\n",
      "\n",
      "Epoch: [109][2/16]\tTime 0.191 (0.873)\tETA 0:00:02\tTraining Loss 1.2534 (1.2537)\n",
      "\n",
      "Epoch: [109][3/16]\tTime 0.186 (1.059)\tETA 0:00:02\tTraining Loss 1.2516 (1.2532)\n",
      "\n",
      "Epoch: [109][4/16]\tTime 0.187 (1.246)\tETA 0:00:02\tTraining Loss 1.2522 (1.2530)\n",
      "\n",
      "Epoch: [109][5/16]\tTime 0.193 (1.439)\tETA 0:00:02\tTraining Loss 1.2535 (1.2531)\n",
      "\n",
      "Epoch: [109][6/16]\tTime 0.198 (1.637)\tETA 0:00:01\tTraining Loss 1.2529 (1.2531)\n",
      "\n",
      "Epoch: [109][7/16]\tTime 0.189 (1.825)\tETA 0:00:01\tTraining Loss 1.2580 (1.2537)\n",
      "\n",
      "Epoch: [109][8/16]\tTime 0.184 (2.009)\tETA 0:00:01\tTraining Loss 1.2512 (1.2534)\n",
      "\n",
      "Epoch: [109][9/16]\tTime 0.186 (2.195)\tETA 0:00:01\tTraining Loss 1.2569 (1.2537)\n",
      "\n",
      "Epoch: [109][10/16]\tTime 0.191 (2.386)\tETA 0:00:01\tTraining Loss 1.2544 (1.2538)\n",
      "\n",
      "Epoch: [109][11/16]\tTime 0.179 (2.566)\tETA 0:00:00\tTraining Loss 1.2510 (1.2536)\n",
      "\n",
      "Epoch: [109][12/16]\tTime 0.185 (2.750)\tETA 0:00:00\tTraining Loss 1.2514 (1.2534)\n",
      "\n",
      "Epoch: [109][13/16]\tTime 0.188 (2.938)\tETA 0:00:00\tTraining Loss 1.2522 (1.2533)\n",
      "\n",
      "Epoch: [109][14/16]\tTime 0.191 (3.128)\tETA 0:00:00\tTraining Loss 1.2527 (1.2533)\n",
      "\n",
      "Epoch: [109][15/16]\tTime 0.116 (3.244)\tETA 0:00:00\tTraining Loss 1.2649 (1.2536)\n",
      "_\n",
      "Validation stats                    IoU        F1      Prec    recall       Acc\n",
      "bg,          0.948300  0.973400  0.974200  0.972700  0.953900\n",
      "real apple   0.404800  0.576200  0.983700  0.407500  0.960600\n",
      "real pepper  0.000000  0.000000  0.000000  0.000000  0.995400\n",
      "real grape   0.588200  0.740700  0.944000  0.609500  0.972400\n",
      "fake apple   0.000000  0.000000  0.000000  0.000000  0.977700\n",
      "fake pepper  0.000000  0.000000  0.000000  0.000000  0.991300\n",
      "fake grape   0.000000  0.000000  0.000000  0.000000  0.972900\n",
      "total        0.277329  0.327186  0.414557  0.284243  0.974886\n",
      "total(-bg)   0.165500  0.219483  0.321283  0.169500  0.978383\n",
      "\n",
      "Epoch: [110][0/16]\tTime 0.480 (0.480)\tETA 0:00:07\tTraining Loss 1.2505 (1.2505)\n",
      "\n",
      "Epoch: [110][1/16]\tTime 0.182 (0.662)\tETA 0:00:02\tTraining Loss 1.2551 (1.2528)\n",
      "\n",
      "Epoch: [110][2/16]\tTime 0.188 (0.850)\tETA 0:00:02\tTraining Loss 1.2539 (1.2532)\n",
      "\n",
      "Epoch: [110][3/16]\tTime 0.187 (1.037)\tETA 0:00:02\tTraining Loss 1.2512 (1.2527)\n",
      "\n",
      "Epoch: [110][4/16]\tTime 0.191 (1.228)\tETA 0:00:02\tTraining Loss 1.2566 (1.2535)\n",
      "\n",
      "Epoch: [110][5/16]\tTime 0.177 (1.405)\tETA 0:00:01\tTraining Loss 1.2522 (1.2532)\n",
      "\n",
      "Epoch: [110][6/16]\tTime 0.192 (1.597)\tETA 0:00:01\tTraining Loss 1.2548 (1.2535)\n",
      "\n",
      "Epoch: [110][7/16]\tTime 0.194 (1.791)\tETA 0:00:01\tTraining Loss 1.2475 (1.2527)\n",
      "\n",
      "Epoch: [110][8/16]\tTime 0.188 (1.979)\tETA 0:00:01\tTraining Loss 1.2490 (1.2523)\n",
      "\n",
      "Epoch: [110][9/16]\tTime 0.188 (2.167)\tETA 0:00:01\tTraining Loss 1.2500 (1.2521)\n",
      "\n",
      "Epoch: [110][10/16]\tTime 0.181 (2.349)\tETA 0:00:01\tTraining Loss 1.2479 (1.2517)\n",
      "\n",
      "Epoch: [110][11/16]\tTime 0.210 (2.559)\tETA 0:00:01\tTraining Loss 1.2513 (1.2517)\n",
      "\n",
      "Epoch: [110][12/16]\tTime 0.182 (2.741)\tETA 0:00:00\tTraining Loss 1.2497 (1.2515)\n",
      "\n",
      "Epoch: [110][13/16]\tTime 0.192 (2.933)\tETA 0:00:00\tTraining Loss 1.2527 (1.2516)\n",
      "\n",
      "Epoch: [110][14/16]\tTime 0.182 (3.115)\tETA 0:00:00\tTraining Loss 1.2532 (1.2517)\n",
      "\n",
      "Epoch: [110][15/16]\tTime 0.117 (3.232)\tETA 0:00:00\tTraining Loss 1.2499 (1.2517)\n",
      "_\n",
      "Validation stats                  IoU        F1      Prec    recall      Acc\n",
      "bg,          0.9470  0.972700  0.976900  0.968700  0.95290\n",
      "real apple   0.3827  0.553500  0.966400  0.387900  0.95890\n",
      "real pepper  0.0000  0.000000  0.000000  0.000000  0.99850\n",
      "real grape   0.7339  0.846500  0.931300  0.775900  0.98180\n",
      "fake apple   0.0000  0.000000  0.000000  0.000000  0.97220\n",
      "fake pepper  0.0000  0.000000  0.000000  0.000000  0.98460\n",
      "fake grape   0.0000  0.000000  0.000000  0.000000  0.98730\n",
      "total        0.2948  0.338957  0.410657  0.304643  0.97660\n",
      "total(-bg)   0.1861  0.233333  0.316283  0.193967  0.98055\n",
      "\n",
      "Epoch: [111][0/16]\tTime 0.512 (0.512)\tETA 0:00:08\tTraining Loss 1.2506 (1.2506)\n",
      "\n",
      "Epoch: [111][1/16]\tTime 0.183 (0.695)\tETA 0:00:02\tTraining Loss 1.2475 (1.2491)\n",
      "\n",
      "Epoch: [111][2/16]\tTime 0.193 (0.888)\tETA 0:00:02\tTraining Loss 1.2534 (1.2505)\n",
      "\n",
      "Epoch: [111][3/16]\tTime 0.190 (1.078)\tETA 0:00:02\tTraining Loss 1.2505 (1.2505)\n",
      "\n",
      "Epoch: [111][4/16]\tTime 0.195 (1.274)\tETA 0:00:02\tTraining Loss 1.2479 (1.2500)\n",
      "\n",
      "Epoch: [111][5/16]\tTime 0.186 (1.460)\tETA 0:00:02\tTraining Loss 1.2592 (1.2515)\n",
      "\n",
      "Epoch: [111][6/16]\tTime 0.191 (1.651)\tETA 0:00:01\tTraining Loss 1.2486 (1.2511)\n",
      "\n",
      "Epoch: [111][7/16]\tTime 0.187 (1.838)\tETA 0:00:01\tTraining Loss 1.2490 (1.2508)\n",
      "\n",
      "Epoch: [111][8/16]\tTime 0.193 (2.031)\tETA 0:00:01\tTraining Loss 1.2503 (1.2508)\n",
      "\n",
      "Epoch: [111][9/16]\tTime 0.181 (2.212)\tETA 0:00:01\tTraining Loss 1.2514 (1.2508)\n",
      "\n",
      "Epoch: [111][10/16]\tTime 0.199 (2.412)\tETA 0:00:01\tTraining Loss 1.2471 (1.2505)\n",
      "\n",
      "Epoch: [111][11/16]\tTime 0.193 (2.605)\tETA 0:00:00\tTraining Loss 1.2498 (1.2504)\n",
      "\n",
      "Epoch: [111][12/16]\tTime 0.187 (2.792)\tETA 0:00:00\tTraining Loss 1.2511 (1.2505)\n",
      "\n",
      "Epoch: [111][13/16]\tTime 0.186 (2.977)\tETA 0:00:00\tTraining Loss 1.2462 (1.2502)\n",
      "\n",
      "Epoch: [111][14/16]\tTime 0.201 (3.179)\tETA 0:00:00\tTraining Loss 1.2510 (1.2502)\n",
      "\n",
      "Epoch: [111][15/16]\tTime 0.113 (3.291)\tETA 0:00:00\tTraining Loss 1.2496 (1.2502)\n",
      "_\n",
      "Validation stats                    IoU        F1      Prec    recall       Acc\n",
      "bg,          0.946100  0.972300  0.977500  0.967200  0.952100\n",
      "real apple   0.464900  0.634700  0.972200  0.471200  0.964400\n",
      "real pepper  0.000000  0.000000  0.000000  0.000000  0.996800\n",
      "real grape   0.810000  0.895000  0.916900  0.874200  0.986700\n",
      "fake apple   0.000000  0.000000  0.000000  0.000000  0.973600\n",
      "fake pepper  0.000000  0.000000  0.000000  0.000000  0.994300\n",
      "fake grape   0.000000  0.000000  0.000000  0.000000  0.989300\n",
      "total        0.317286  0.357429  0.409514  0.330371  0.979600\n",
      "total(-bg)   0.212483  0.254950  0.314850  0.224233  0.984183\n",
      "\n",
      "Epoch: [112][0/16]\tTime 0.371 (0.371)\tETA 0:00:05\tTraining Loss 1.2529 (1.2529)\n",
      "\n",
      "Epoch: [112][1/16]\tTime 0.186 (0.556)\tETA 0:00:02\tTraining Loss 1.2494 (1.2511)\n",
      "\n",
      "Epoch: [112][2/16]\tTime 0.192 (0.748)\tETA 0:00:02\tTraining Loss 1.2503 (1.2508)\n",
      "\n",
      "Epoch: [112][3/16]\tTime 0.183 (0.931)\tETA 0:00:02\tTraining Loss 1.2456 (1.2495)\n",
      "\n",
      "Epoch: [112][4/16]\tTime 0.196 (1.127)\tETA 0:00:02\tTraining Loss 1.2463 (1.2489)\n",
      "\n",
      "Epoch: [112][5/16]\tTime 0.182 (1.309)\tETA 0:00:02\tTraining Loss 1.2496 (1.2490)\n",
      "\n",
      "Epoch: [112][6/16]\tTime 0.186 (1.495)\tETA 0:00:01\tTraining Loss 1.2465 (1.2486)\n",
      "\n",
      "Epoch: [112][7/16]\tTime 0.190 (1.685)\tETA 0:00:01\tTraining Loss 1.2474 (1.2485)\n",
      "\n",
      "Epoch: [112][8/16]\tTime 0.185 (1.870)\tETA 0:00:01\tTraining Loss 1.2513 (1.2488)\n",
      "\n",
      "Epoch: [112][9/16]\tTime 0.183 (2.053)\tETA 0:00:01\tTraining Loss 1.2486 (1.2488)\n",
      "\n",
      "Epoch: [112][10/16]\tTime 0.190 (2.243)\tETA 0:00:01\tTraining Loss 1.2455 (1.2485)\n",
      "\n",
      "Epoch: [112][11/16]\tTime 0.196 (2.440)\tETA 0:00:00\tTraining Loss 1.2459 (1.2483)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: [112][12/16]\tTime 0.186 (2.626)\tETA 0:00:00\tTraining Loss 1.2494 (1.2484)\n",
      "\n",
      "Epoch: [112][13/16]\tTime 0.190 (2.816)\tETA 0:00:00\tTraining Loss 1.2516 (1.2486)\n",
      "\n",
      "Epoch: [112][14/16]\tTime 0.187 (3.003)\tETA 0:00:00\tTraining Loss 1.2529 (1.2489)\n",
      "\n",
      "Epoch: [112][15/16]\tTime 0.116 (3.119)\tETA 0:00:00\tTraining Loss 1.2569 (1.2491)\n",
      "_\n",
      "Validation stats                    IoU        F1      Prec    recall       Acc\n",
      "bg,          0.947100  0.972800  0.977300  0.968400  0.952900\n",
      "real apple   0.409500  0.581000  0.937000  0.421100  0.960100\n",
      "real pepper  0.000000  0.000000  0.000000  0.000000  0.999700\n",
      "real grape   0.779300  0.875900  0.917200  0.838200  0.984600\n",
      "fake apple   0.000000  0.000000  0.000000  0.000000  0.975800\n",
      "fake pepper  0.000000  0.000000  0.000000  0.000000  0.988400\n",
      "fake grape   0.000000  0.000000  0.000000  0.000000  0.986400\n",
      "total        0.305129  0.347100  0.404500  0.318243  0.978271\n",
      "total(-bg)   0.198133  0.242817  0.309033  0.209883  0.982500\n",
      "\n",
      "Epoch: [113][0/16]\tTime 0.478 (0.478)\tETA 0:00:07\tTraining Loss 1.2480 (1.2480)\n",
      "\n",
      "Epoch: [113][1/16]\tTime 0.185 (0.663)\tETA 0:00:02\tTraining Loss 1.2467 (1.2473)\n",
      "\n",
      "Epoch: [113][2/16]\tTime 0.182 (0.846)\tETA 0:00:02\tTraining Loss 1.2460 (1.2469)\n",
      "\n",
      "Epoch: [113][3/16]\tTime 0.188 (1.034)\tETA 0:00:02\tTraining Loss 1.2482 (1.2472)\n",
      "\n",
      "Epoch: [113][4/16]\tTime 0.194 (1.228)\tETA 0:00:02\tTraining Loss 1.2501 (1.2478)\n",
      "\n",
      "Epoch: [113][5/16]\tTime 0.187 (1.414)\tETA 0:00:02\tTraining Loss 1.2484 (1.2479)\n",
      "\n",
      "Epoch: [113][6/16]\tTime 0.193 (1.607)\tETA 0:00:01\tTraining Loss 1.2482 (1.2479)\n",
      "\n",
      "Epoch: [113][7/16]\tTime 0.197 (1.804)\tETA 0:00:01\tTraining Loss 1.2571 (1.2491)\n",
      "\n",
      "Epoch: [113][8/16]\tTime 0.190 (1.994)\tETA 0:00:01\tTraining Loss 1.2459 (1.2487)\n",
      "\n",
      "Epoch: [113][9/16]\tTime 0.190 (2.184)\tETA 0:00:01\tTraining Loss 1.2540 (1.2493)\n",
      "\n",
      "Epoch: [113][10/16]\tTime 0.194 (2.378)\tETA 0:00:01\tTraining Loss 1.2510 (1.2494)\n",
      "\n",
      "Epoch: [113][11/16]\tTime 0.186 (2.563)\tETA 0:00:00\tTraining Loss 1.2498 (1.2494)\n",
      "\n",
      "Epoch: [113][12/16]\tTime 0.194 (2.757)\tETA 0:00:00\tTraining Loss 1.2451 (1.2491)\n",
      "\n",
      "Epoch: [113][13/16]\tTime 0.192 (2.949)\tETA 0:00:00\tTraining Loss 1.2429 (1.2487)\n",
      "\n",
      "Epoch: [113][14/16]\tTime 0.195 (3.144)\tETA 0:00:00\tTraining Loss 1.2518 (1.2489)\n",
      "\n",
      "Epoch: [113][15/16]\tTime 0.111 (3.256)\tETA 0:00:00\tTraining Loss 1.2501 (1.2489)\n",
      "_\n",
      "Validation stats                    IoU        F1      Prec    recall       Acc\n",
      "bg,          0.945600  0.972000  0.973500  0.970600  0.951500\n",
      "real apple   0.441900  0.612900  0.933700  0.456200  0.962100\n",
      "real pepper  0.000000  0.000000  0.000000  0.000000  1.000000\n",
      "real grape   0.610000  0.757700  0.907700  0.650300  0.973100\n",
      "fake apple   0.000000  0.000000  0.000000  0.000000  0.970900\n",
      "fake pepper  0.000000  0.000000  0.000000  0.000000  0.997500\n",
      "fake grape   0.000000  0.000000  0.000000  0.000000  0.977000\n",
      "total        0.285357  0.334657  0.402129  0.296729  0.976014\n",
      "total(-bg)   0.175317  0.228433  0.306900  0.184417  0.980100\n",
      "\n",
      "Epoch: [114][0/16]\tTime 0.486 (0.486)\tETA 0:00:07\tTraining Loss 1.2477 (1.2477)\n",
      "\n",
      "Epoch: [114][1/16]\tTime 0.194 (0.681)\tETA 0:00:02\tTraining Loss 1.2452 (1.2464)\n",
      "\n",
      "Epoch: [114][2/16]\tTime 0.193 (0.874)\tETA 0:00:02\tTraining Loss 1.2461 (1.2463)\n",
      "\n",
      "Epoch: [114][3/16]\tTime 0.182 (1.056)\tETA 0:00:02\tTraining Loss 1.2470 (1.2465)\n",
      "\n",
      "Epoch: [114][4/16]\tTime 0.192 (1.248)\tETA 0:00:02\tTraining Loss 1.2443 (1.2460)\n",
      "\n",
      "Epoch: [114][5/16]\tTime 0.188 (1.436)\tETA 0:00:02\tTraining Loss 1.2482 (1.2464)\n",
      "\n",
      "Epoch: [114][6/16]\tTime 0.188 (1.623)\tETA 0:00:01\tTraining Loss 1.2443 (1.2461)\n",
      "\n",
      "Epoch: [114][7/16]\tTime 0.183 (1.807)\tETA 0:00:01\tTraining Loss 1.2503 (1.2466)\n",
      "\n",
      "Epoch: [114][8/16]\tTime 0.189 (1.996)\tETA 0:00:01\tTraining Loss 1.2420 (1.2461)\n",
      "\n",
      "Epoch: [114][9/16]\tTime 0.189 (2.184)\tETA 0:00:01\tTraining Loss 1.2437 (1.2459)\n",
      "\n",
      "Epoch: [114][10/16]\tTime 0.188 (2.372)\tETA 0:00:01\tTraining Loss 1.2579 (1.2470)\n",
      "\n",
      "Epoch: [114][11/16]\tTime 0.192 (2.564)\tETA 0:00:00\tTraining Loss 1.2450 (1.2468)\n",
      "\n",
      "Epoch: [114][12/16]\tTime 0.187 (2.751)\tETA 0:00:00\tTraining Loss 1.2512 (1.2471)\n",
      "\n",
      "Epoch: [114][13/16]\tTime 0.187 (2.938)\tETA 0:00:00\tTraining Loss 1.2536 (1.2476)\n",
      "\n",
      "Epoch: [114][14/16]\tTime 0.187 (3.125)\tETA 0:00:00\tTraining Loss 1.2443 (1.2474)\n",
      "\n",
      "Epoch: [114][15/16]\tTime 0.113 (3.238)\tETA 0:00:00\tTraining Loss 1.2454 (1.2473)\n",
      "_\n",
      "Validation stats                    IoU        F1      Prec    recall       Acc\n",
      "bg,          0.946700  0.972600  0.977100  0.968200  0.952600\n",
      "real apple   0.424200  0.595600  0.890500  0.447500  0.960100\n",
      "real pepper  0.000000  0.000000  0.000000  0.000000  1.000000\n",
      "real grape   0.615500  0.761900  0.873200  0.675900  0.972700\n",
      "fake apple   0.000000  0.000000  0.000000  0.000000  0.977000\n",
      "fake pepper  0.000000  0.000000  0.000000  0.000000  0.985500\n",
      "fake grape   0.000000  0.000000  0.000000  0.000000  0.982300\n",
      "total        0.283771  0.332871  0.391543  0.298800  0.975743\n",
      "total(-bg)   0.173283  0.226250  0.293950  0.187233  0.979600\n",
      "\n",
      "Epoch: [115][0/16]\tTime 0.536 (0.536)\tETA 0:00:08\tTraining Loss 1.2437 (1.2437)\n",
      "\n",
      "Epoch: [115][1/16]\tTime 0.204 (0.740)\tETA 0:00:03\tTraining Loss 1.2431 (1.2434)\n",
      "\n",
      "Epoch: [115][2/16]\tTime 0.186 (0.926)\tETA 0:00:02\tTraining Loss 1.2425 (1.2431)\n",
      "\n",
      "Epoch: [115][3/16]\tTime 0.189 (1.115)\tETA 0:00:02\tTraining Loss 1.2431 (1.2431)\n",
      "\n",
      "Epoch: [115][4/16]\tTime 0.191 (1.306)\tETA 0:00:02\tTraining Loss 1.2448 (1.2434)\n",
      "\n",
      "Epoch: [115][5/16]\tTime 0.184 (1.490)\tETA 0:00:02\tTraining Loss 1.2514 (1.2448)\n",
      "\n",
      "Epoch: [115][6/16]\tTime 0.190 (1.680)\tETA 0:00:01\tTraining Loss 1.2471 (1.2451)\n",
      "\n",
      "Epoch: [115][7/16]\tTime 0.192 (1.871)\tETA 0:00:01\tTraining Loss 1.2501 (1.2457)\n",
      "\n",
      "Epoch: [115][8/16]\tTime 0.186 (2.058)\tETA 0:00:01\tTraining Loss 1.2444 (1.2456)\n",
      "\n",
      "Epoch: [115][9/16]\tTime 0.191 (2.248)\tETA 0:00:01\tTraining Loss 1.2499 (1.2460)\n",
      "\n",
      "Epoch: [115][10/16]\tTime 0.208 (2.457)\tETA 0:00:01\tTraining Loss 1.2467 (1.2461)\n",
      "\n",
      "Epoch: [115][11/16]\tTime 0.182 (2.639)\tETA 0:00:00\tTraining Loss 1.2456 (1.2460)\n",
      "\n",
      "Epoch: [115][12/16]\tTime 0.190 (2.829)\tETA 0:00:00\tTraining Loss 1.2442 (1.2459)\n",
      "\n",
      "Epoch: [115][13/16]\tTime 0.183 (3.012)\tETA 0:00:00\tTraining Loss 1.2504 (1.2462)\n",
      "\n",
      "Epoch: [115][14/16]\tTime 0.186 (3.198)\tETA 0:00:00\tTraining Loss 1.2444 (1.2461)\n",
      "\n",
      "Epoch: [115][15/16]\tTime 0.115 (3.313)\tETA 0:00:00\tTraining Loss 1.2734 (1.2470)\n",
      "_\n",
      "Validation stats                    IoU        F1      Prec    recall       Acc\n",
      "bg,          0.942400  0.970300  0.975400  0.965400  0.948700\n",
      "real apple   0.334600  0.501400  0.961200  0.339200  0.955700\n",
      "real pepper  0.000000  0.000000  0.000000  0.000000  0.999700\n",
      "real grape   0.743200  0.852600  0.895200  0.814100  0.981800\n",
      "fake apple   0.000000  0.000000  0.000000  0.000000  0.967700\n",
      "fake pepper  0.000000  0.000000  0.000000  0.000000  0.990500\n",
      "fake grape   0.000000  0.000000  0.000000  0.000000  0.984800\n",
      "total        0.288600  0.332043  0.404543  0.302671  0.975557\n",
      "total(-bg)   0.179633  0.225667  0.309400  0.192217  0.980033\n",
      "\n",
      "Epoch: [116][0/16]\tTime 0.484 (0.484)\tETA 0:00:07\tTraining Loss 1.2478 (1.2478)\n",
      "\n",
      "Epoch: [116][1/16]\tTime 0.186 (0.669)\tETA 0:00:02\tTraining Loss 1.2434 (1.2456)\n",
      "\n",
      "Epoch: [116][2/16]\tTime 0.186 (0.855)\tETA 0:00:02\tTraining Loss 1.2441 (1.2451)\n",
      "\n",
      "Epoch: [116][3/16]\tTime 0.183 (1.038)\tETA 0:00:02\tTraining Loss 1.2502 (1.2464)\n",
      "\n",
      "Epoch: [116][4/16]\tTime 0.193 (1.231)\tETA 0:00:02\tTraining Loss 1.2492 (1.2470)\n",
      "\n",
      "Epoch: [116][5/16]\tTime 0.188 (1.419)\tETA 0:00:02\tTraining Loss 1.2641 (1.2498)\n",
      "\n",
      "Epoch: [116][6/16]\tTime 0.188 (1.607)\tETA 0:00:01\tTraining Loss 1.2460 (1.2493)\n",
      "\n",
      "Epoch: [116][7/16]\tTime 0.183 (1.790)\tETA 0:00:01\tTraining Loss 1.2454 (1.2488)\n",
      "\n",
      "Epoch: [116][8/16]\tTime 0.191 (1.981)\tETA 0:00:01\tTraining Loss 1.2551 (1.2495)\n",
      "\n",
      "Epoch: [116][9/16]\tTime 0.194 (2.175)\tETA 0:00:01\tTraining Loss 1.2537 (1.2499)\n",
      "\n",
      "Epoch: [116][10/16]\tTime 0.183 (2.358)\tETA 0:00:01\tTraining Loss 1.2531 (1.2502)\n",
      "\n",
      "Epoch: [116][11/16]\tTime 0.190 (2.548)\tETA 0:00:00\tTraining Loss 1.2464 (1.2499)\n",
      "\n",
      "Epoch: [116][12/16]\tTime 0.187 (2.735)\tETA 0:00:00\tTraining Loss 1.2750 (1.2518)\n",
      "\n",
      "Epoch: [116][13/16]\tTime 0.185 (2.920)\tETA 0:00:00\tTraining Loss 1.2613 (1.2525)\n",
      "\n",
      "Epoch: [116][14/16]\tTime 0.190 (3.111)\tETA 0:00:00\tTraining Loss 1.2477 (1.2522)\n",
      "\n",
      "Epoch: [116][15/16]\tTime 0.114 (3.225)\tETA 0:00:00\tTraining Loss 1.2766 (1.2530)\n",
      "_\n",
      "Validation stats                    IoU        F1      Prec    recall       Acc\n",
      "bg,          0.948600  0.973600  0.972000  0.975300  0.954100\n",
      "real apple   0.065300  0.122600  0.833300  0.066200  0.937800\n",
      "real pepper  0.000000  0.000000  0.000000  0.000000  1.000000\n",
      "real grape   0.820000  0.901100  0.934900  0.869700  0.987600\n",
      "fake apple   0.000000  0.000000  0.000000  0.000000  0.969700\n",
      "fake pepper  0.000000  0.000000  0.000000  0.000000  0.975300\n",
      "fake grape   0.000000  0.000000  0.000000  0.000000  0.992900\n",
      "total        0.261986  0.285329  0.391457  0.273029  0.973914\n",
      "total(-bg)   0.147550  0.170617  0.294700  0.155983  0.977217\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: [117][0/16]\tTime 0.481 (0.481)\tETA 0:00:07\tTraining Loss 1.2483 (1.2483)\n",
      "\n",
      "Epoch: [117][1/16]\tTime 0.189 (0.669)\tETA 0:00:02\tTraining Loss 1.2591 (1.2537)\n",
      "\n",
      "Epoch: [117][2/16]\tTime 0.187 (0.856)\tETA 0:00:02\tTraining Loss 1.2583 (1.2553)\n",
      "\n",
      "Epoch: [117][3/16]\tTime 0.181 (1.037)\tETA 0:00:02\tTraining Loss 1.2526 (1.2546)\n",
      "\n",
      "Epoch: [117][4/16]\tTime 0.188 (1.225)\tETA 0:00:02\tTraining Loss 1.2554 (1.2548)\n",
      "\n",
      "Epoch: [117][5/16]\tTime 0.192 (1.417)\tETA 0:00:02\tTraining Loss 1.2619 (1.2559)\n",
      "\n",
      "Epoch: [117][6/16]\tTime 0.196 (1.612)\tETA 0:00:01\tTraining Loss 1.2611 (1.2567)\n",
      "\n",
      "Epoch: [117][7/16]\tTime 0.186 (1.798)\tETA 0:00:01\tTraining Loss 1.2480 (1.2556)\n",
      "\n",
      "Epoch: [117][8/16]\tTime 0.186 (1.984)\tETA 0:00:01\tTraining Loss 1.2567 (1.2557)\n",
      "\n",
      "Epoch: [117][9/16]\tTime 0.189 (2.173)\tETA 0:00:01\tTraining Loss 1.2597 (1.2561)\n",
      "\n",
      "Epoch: [117][10/16]\tTime 0.187 (2.360)\tETA 0:00:01\tTraining Loss 1.2614 (1.2566)\n",
      "\n",
      "Epoch: [117][11/16]\tTime 0.177 (2.537)\tETA 0:00:00\tTraining Loss 1.2610 (1.2570)\n",
      "\n",
      "Epoch: [117][12/16]\tTime 0.201 (2.737)\tETA 0:00:00\tTraining Loss 1.2513 (1.2565)\n",
      "\n",
      "Epoch: [117][13/16]\tTime 0.180 (2.917)\tETA 0:00:00\tTraining Loss 1.2518 (1.2562)\n",
      "\n",
      "Epoch: [117][14/16]\tTime 0.189 (3.106)\tETA 0:00:00\tTraining Loss 1.2624 (1.2566)\n",
      "\n",
      "Epoch: [117][15/16]\tTime 0.116 (3.222)\tETA 0:00:00\tTraining Loss 1.2524 (1.2565)\n",
      "_\n",
      "Validation stats                    IoU        F1      Prec    recall       Acc\n",
      "bg,          0.944400  0.971300  0.972800  0.969900  0.950300\n",
      "real apple   0.311900  0.475400  0.927000  0.319700  0.953600\n",
      "real pepper  0.000000  0.000000  0.000000  0.000000  0.999300\n",
      "real grape   0.525600  0.689000  0.930800  0.547000  0.968000\n",
      "fake apple   0.000000  0.000000  0.000000  0.000000  0.966500\n",
      "fake pepper  0.000000  0.000000  0.000000  0.000000  0.982700\n",
      "fake grape   0.000000  0.000000  0.000000  0.000000  0.979200\n",
      "total        0.254557  0.305100  0.404371  0.262371  0.971371\n",
      "total(-bg)   0.139583  0.194067  0.309633  0.144450  0.974883\n",
      "\n",
      "Epoch: [118][0/16]\tTime 0.551 (0.551)\tETA 0:00:08\tTraining Loss 1.2533 (1.2533)\n",
      "\n",
      "Epoch: [118][1/16]\tTime 0.192 (0.744)\tETA 0:00:02\tTraining Loss 1.2507 (1.2520)\n",
      "\n",
      "Epoch: [118][2/16]\tTime 0.198 (0.941)\tETA 0:00:02\tTraining Loss 1.2511 (1.2517)\n",
      "\n",
      "Epoch: [118][3/16]\tTime 0.189 (1.130)\tETA 0:00:02\tTraining Loss 1.2513 (1.2516)\n",
      "\n",
      "Epoch: [118][4/16]\tTime 0.190 (1.321)\tETA 0:00:02\tTraining Loss 1.2576 (1.2528)\n",
      "\n",
      "Epoch: [118][5/16]\tTime 0.186 (1.507)\tETA 0:00:02\tTraining Loss 1.2521 (1.2527)\n",
      "\n",
      "Epoch: [118][6/16]\tTime 0.214 (1.721)\tETA 0:00:02\tTraining Loss 1.2457 (1.2517)\n",
      "\n",
      "Epoch: [118][7/16]\tTime 0.186 (1.907)\tETA 0:00:01\tTraining Loss 1.2537 (1.2519)\n",
      "\n",
      "Epoch: [118][8/16]\tTime 0.194 (2.101)\tETA 0:00:01\tTraining Loss 1.2456 (1.2512)\n",
      "\n",
      "Epoch: [118][9/16]\tTime 0.180 (2.281)\tETA 0:00:01\tTraining Loss 1.2635 (1.2525)\n",
      "\n",
      "Epoch: [118][10/16]\tTime 0.186 (2.467)\tETA 0:00:01\tTraining Loss 1.2463 (1.2519)\n",
      "\n",
      "Epoch: [118][11/16]\tTime 0.188 (2.655)\tETA 0:00:00\tTraining Loss 1.2566 (1.2523)\n",
      "\n",
      "Epoch: [118][12/16]\tTime 0.188 (2.843)\tETA 0:00:00\tTraining Loss 1.2462 (1.2518)\n",
      "\n",
      "Epoch: [118][13/16]\tTime 0.190 (3.033)\tETA 0:00:00\tTraining Loss 1.2474 (1.2515)\n",
      "\n",
      "Epoch: [118][14/16]\tTime 0.187 (3.220)\tETA 0:00:00\tTraining Loss 1.2448 (1.2511)\n",
      "\n",
      "Epoch: [118][15/16]\tTime 0.110 (3.331)\tETA 0:00:00\tTraining Loss 1.2535 (1.2511)\n",
      "_\n",
      "Validation stats                    IoU        F1     Prec    recall       Acc\n",
      "bg,          0.953000  0.975900  0.97790  0.974000  0.958200\n",
      "real apple   0.104100  0.188600  0.84180  0.106200  0.939900\n",
      "real pepper  0.000000  0.000000  0.00000  0.000000  0.998200\n",
      "real grape   0.617000  0.763100  0.94530  0.639800  0.974300\n",
      "fake apple   0.000000  0.000000  0.00000  0.000000  0.963600\n",
      "fake pepper  0.000000  0.000000  0.00000  0.000000  0.978300\n",
      "fake grape   0.000000  0.000000  0.00000  0.000000  0.978100\n",
      "total        0.239157  0.275371  0.39500  0.245714  0.970086\n",
      "total(-bg)   0.120183  0.158617  0.29785  0.124333  0.972067\n",
      "\n",
      "Epoch: [119][0/16]\tTime 0.472 (0.472)\tETA 0:00:07\tTraining Loss 1.2493 (1.2493)\n",
      "\n",
      "Epoch: [119][1/16]\tTime 0.191 (0.664)\tETA 0:00:02\tTraining Loss 1.2471 (1.2482)\n",
      "\n",
      "Epoch: [119][2/16]\tTime 0.180 (0.844)\tETA 0:00:02\tTraining Loss 1.2659 (1.2541)\n",
      "\n",
      "Epoch: [119][3/16]\tTime 0.183 (1.027)\tETA 0:00:02\tTraining Loss 1.2517 (1.2535)\n",
      "\n",
      "Epoch: [119][4/16]\tTime 0.180 (1.207)\tETA 0:00:02\tTraining Loss 1.2532 (1.2534)\n",
      "\n",
      "Epoch: [119][5/16]\tTime 0.190 (1.397)\tETA 0:00:02\tTraining Loss 1.2512 (1.2531)\n",
      "\n",
      "Epoch: [119][6/16]\tTime 0.177 (1.575)\tETA 0:00:01\tTraining Loss 1.2457 (1.2520)\n",
      "\n",
      "Epoch: [119][7/16]\tTime 0.191 (1.766)\tETA 0:00:01\tTraining Loss 1.2469 (1.2514)\n",
      "\n",
      "Epoch: [119][8/16]\tTime 0.184 (1.950)\tETA 0:00:01\tTraining Loss 1.2527 (1.2515)\n",
      "\n",
      "Epoch: [119][9/16]\tTime 0.191 (2.141)\tETA 0:00:01\tTraining Loss 1.2457 (1.2509)\n",
      "\n",
      "Epoch: [119][10/16]\tTime 0.183 (2.324)\tETA 0:00:01\tTraining Loss 1.2451 (1.2504)\n",
      "\n",
      "Epoch: [119][11/16]\tTime 0.185 (2.509)\tETA 0:00:00\tTraining Loss 1.2458 (1.2500)\n",
      "\n",
      "Epoch: [119][12/16]\tTime 0.198 (2.707)\tETA 0:00:00\tTraining Loss 1.2450 (1.2496)\n",
      "\n",
      "Epoch: [119][13/16]\tTime 0.185 (2.892)\tETA 0:00:00\tTraining Loss 1.2467 (1.2494)\n",
      "\n",
      "Epoch: [119][14/16]\tTime 0.189 (3.081)\tETA 0:00:00\tTraining Loss 1.2543 (1.2498)\n",
      "\n",
      "Epoch: [119][15/16]\tTime 0.112 (3.192)\tETA 0:00:00\tTraining Loss 1.2536 (1.2499)\n",
      "_\n",
      "Validation stats                    IoU        F1      Prec    recall       Acc\n",
      "bg,          0.950400  0.974500  0.977600  0.971500  0.955900\n",
      "real apple   0.171300  0.292500  0.950200  0.172900  0.945000\n",
      "real pepper  0.000000  0.000000  0.000000  0.000000  0.999700\n",
      "real grape   0.739100  0.849900  0.938900  0.776500  0.982300\n",
      "fake apple   0.000000  0.000000  0.000000  0.000000  0.962100\n",
      "fake pepper  0.000000  0.000000  0.000000  0.000000  0.989000\n",
      "fake grape   0.000000  0.000000  0.000000  0.000000  0.978800\n",
      "total        0.265829  0.302414  0.409529  0.274414  0.973257\n",
      "total(-bg)   0.151733  0.190400  0.314850  0.158233  0.976150\n",
      "\n",
      "Epoch: [120][0/16]\tTime 0.440 (0.440)\tETA 0:00:07\tTraining Loss 1.2454 (1.2454)\n",
      "\n",
      "Epoch: [120][1/16]\tTime 0.188 (0.628)\tETA 0:00:02\tTraining Loss 1.2483 (1.2469)\n",
      "\n",
      "Epoch: [120][2/16]\tTime 0.201 (0.829)\tETA 0:00:02\tTraining Loss 1.2436 (1.2458)\n",
      "\n",
      "Epoch: [120][3/16]\tTime 0.179 (1.009)\tETA 0:00:02\tTraining Loss 1.2490 (1.2466)\n",
      "\n",
      "Epoch: [120][4/16]\tTime 0.197 (1.205)\tETA 0:00:02\tTraining Loss 1.2469 (1.2466)\n",
      "\n",
      "Epoch: [120][5/16]\tTime 0.199 (1.404)\tETA 0:00:02\tTraining Loss 1.2440 (1.2462)\n",
      "\n",
      "Epoch: [120][6/16]\tTime 0.182 (1.585)\tETA 0:00:01\tTraining Loss 1.2405 (1.2454)\n",
      "\n",
      "Epoch: [120][7/16]\tTime 0.192 (1.778)\tETA 0:00:01\tTraining Loss 1.2430 (1.2451)\n",
      "\n",
      "Epoch: [120][8/16]\tTime 0.181 (1.959)\tETA 0:00:01\tTraining Loss 1.2452 (1.2451)\n",
      "\n",
      "Epoch: [120][9/16]\tTime 0.195 (2.154)\tETA 0:00:01\tTraining Loss 1.2422 (1.2448)\n",
      "\n",
      "Epoch: [120][10/16]\tTime 0.193 (2.347)\tETA 0:00:01\tTraining Loss 1.2509 (1.2454)\n",
      "\n",
      "Epoch: [120][11/16]\tTime 0.190 (2.536)\tETA 0:00:00\tTraining Loss 1.2516 (1.2459)\n",
      "\n",
      "Epoch: [120][12/16]\tTime 0.189 (2.725)\tETA 0:00:00\tTraining Loss 1.2444 (1.2458)\n",
      "\n",
      "Epoch: [120][13/16]\tTime 0.188 (2.914)\tETA 0:00:00\tTraining Loss 1.2437 (1.2456)\n",
      "\n",
      "Epoch: [120][14/16]\tTime 0.195 (3.108)\tETA 0:00:00\tTraining Loss 1.2452 (1.2456)\n",
      "\n",
      "Epoch: [120][15/16]\tTime 0.113 (3.221)\tETA 0:00:00\tTraining Loss 1.2477 (1.2457)\n",
      "_\n",
      "Validation stats                    IoU        F1      Prec    recall       Acc\n",
      "bg,          0.938500  0.968200  0.974500  0.962200  0.945200\n",
      "real apple   0.175600  0.298700  0.899200  0.179100  0.944700\n",
      "real pepper  0.000000  0.000000  0.000000  0.000000  0.996600\n",
      "real grape   0.634900  0.776600  0.927200  0.668200  0.975100\n",
      "fake apple   0.000000  0.000000  0.000000  0.000000  0.967400\n",
      "fake pepper  0.000000  0.000000  0.000000  0.000000  0.967600\n",
      "fake grape   0.000000  0.000000  0.000000  0.000000  0.986600\n",
      "total        0.249857  0.291929  0.400129  0.258500  0.969029\n",
      "total(-bg)   0.135083  0.179217  0.304400  0.141217  0.973000\n",
      "\n",
      "Epoch: [121][0/16]\tTime 0.469 (0.469)\tETA 0:00:07\tTraining Loss 1.2414 (1.2414)\n",
      "\n",
      "Epoch: [121][1/16]\tTime 0.185 (0.653)\tETA 0:00:02\tTraining Loss 1.2426 (1.2420)\n",
      "\n",
      "Epoch: [121][2/16]\tTime 0.192 (0.846)\tETA 0:00:02\tTraining Loss 1.2463 (1.2434)\n",
      "\n",
      "Epoch: [121][3/16]\tTime 0.197 (1.043)\tETA 0:00:02\tTraining Loss 1.2420 (1.2431)\n",
      "\n",
      "Epoch: [121][4/16]\tTime 0.185 (1.228)\tETA 0:00:02\tTraining Loss 1.2433 (1.2431)\n",
      "\n",
      "Epoch: [121][5/16]\tTime 0.189 (1.417)\tETA 0:00:02\tTraining Loss 1.2394 (1.2425)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: [121][6/16]\tTime 0.188 (1.606)\tETA 0:00:01\tTraining Loss 1.2473 (1.2432)\n",
      "\n",
      "Epoch: [121][7/16]\tTime 0.186 (1.792)\tETA 0:00:01\tTraining Loss 1.2492 (1.2439)\n",
      "\n",
      "Epoch: [121][8/16]\tTime 0.191 (1.983)\tETA 0:00:01\tTraining Loss 1.2463 (1.2442)\n",
      "\n",
      "Epoch: [121][9/16]\tTime 0.192 (2.175)\tETA 0:00:01\tTraining Loss 1.2513 (1.2449)\n",
      "\n",
      "Epoch: [121][10/16]\tTime 0.189 (2.364)\tETA 0:00:01\tTraining Loss 1.2418 (1.2446)\n",
      "\n",
      "Epoch: [121][11/16]\tTime 0.188 (2.552)\tETA 0:00:00\tTraining Loss 1.2415 (1.2444)\n",
      "\n",
      "Epoch: [121][12/16]\tTime 0.192 (2.744)\tETA 0:00:00\tTraining Loss 1.2446 (1.2444)\n",
      "\n",
      "Epoch: [121][13/16]\tTime 0.178 (2.922)\tETA 0:00:00\tTraining Loss 1.2495 (1.2447)\n",
      "\n",
      "Epoch: [121][14/16]\tTime 0.190 (3.112)\tETA 0:00:00\tTraining Loss 1.2386 (1.2443)\n",
      "\n",
      "Epoch: [121][15/16]\tTime 0.112 (3.224)\tETA 0:00:00\tTraining Loss 1.2535 (1.2446)\n",
      "_\n",
      "Validation stats                    IoU        F1      Prec    recall       Acc\n",
      "bg,          0.951700  0.975200  0.975300  0.975200  0.956900\n",
      "real apple   0.470100  0.639500  0.951400  0.481700  0.964300\n",
      "real pepper  0.000000  0.000000  0.000000  0.000000  1.000000\n",
      "real grape   0.339200  0.506500  0.898800  0.352700  0.955500\n",
      "fake apple   0.000000  0.000000  0.000000  0.000000  0.977500\n",
      "fake pepper  0.000000  0.000000  0.000000  0.000000  0.995600\n",
      "fake grape   0.000000  0.000000  0.000000  0.000000  0.954900\n",
      "total        0.251571  0.303029  0.403643  0.258514  0.972100\n",
      "total(-bg)   0.134883  0.191000  0.308367  0.139067  0.974633\n",
      "\n",
      "Epoch: [122][0/16]\tTime 0.506 (0.506)\tETA 0:00:08\tTraining Loss 1.2400 (1.2400)\n",
      "\n",
      "Epoch: [122][1/16]\tTime 0.185 (0.690)\tETA 0:00:02\tTraining Loss 1.2448 (1.2424)\n",
      "\n",
      "Epoch: [122][2/16]\tTime 0.187 (0.877)\tETA 0:00:02\tTraining Loss 1.2422 (1.2424)\n",
      "\n",
      "Epoch: [122][3/16]\tTime 0.191 (1.068)\tETA 0:00:02\tTraining Loss 1.2468 (1.2435)\n",
      "\n",
      "Epoch: [122][4/16]\tTime 0.193 (1.262)\tETA 0:00:02\tTraining Loss 1.2441 (1.2436)\n",
      "\n",
      "Epoch: [122][5/16]\tTime 0.189 (1.451)\tETA 0:00:02\tTraining Loss 1.2375 (1.2426)\n",
      "\n",
      "Epoch: [122][6/16]\tTime 0.198 (1.648)\tETA 0:00:01\tTraining Loss 1.2399 (1.2422)\n",
      "\n",
      "Epoch: [122][7/16]\tTime 0.187 (1.835)\tETA 0:00:01\tTraining Loss 1.2393 (1.2418)\n",
      "\n",
      "Epoch: [122][8/16]\tTime 0.203 (2.038)\tETA 0:00:01\tTraining Loss 1.2469 (1.2424)\n",
      "\n",
      "Epoch: [122][9/16]\tTime 0.192 (2.229)\tETA 0:00:01\tTraining Loss 1.2407 (1.2422)\n",
      "\n",
      "Epoch: [122][10/16]\tTime 0.193 (2.422)\tETA 0:00:01\tTraining Loss 1.2415 (1.2422)\n",
      "\n",
      "Epoch: [122][11/16]\tTime 0.174 (2.596)\tETA 0:00:00\tTraining Loss 1.2424 (1.2422)\n",
      "\n",
      "Epoch: [122][12/16]\tTime 0.300 (2.896)\tETA 0:00:01\tTraining Loss 1.2380 (1.2419)\n",
      "\n",
      "Epoch: [122][13/16]\tTime 0.185 (3.081)\tETA 0:00:00\tTraining Loss 1.2391 (1.2417)\n",
      "\n",
      "Epoch: [122][14/16]\tTime 0.190 (3.271)\tETA 0:00:00\tTraining Loss 1.2401 (1.2416)\n",
      "\n",
      "Epoch: [122][15/16]\tTime 0.114 (3.384)\tETA 0:00:00\tTraining Loss 1.2561 (1.2420)\n",
      "_\n",
      "Validation stats                    IoU     F1      Prec    recall       Acc\n",
      "bg,          0.943700  0.971  0.976800  0.965300  0.949900\n",
      "real apple   0.531500  0.694  0.934600  0.552000  0.968000\n",
      "real pepper  0.000000  0.000  0.000000  0.000000  0.994800\n",
      "real grape   0.618200  0.764  0.859700  0.687500  0.972500\n",
      "fake apple   0.000000  0.000  0.000000  0.000000  0.982500\n",
      "fake pepper  0.000000  0.000  0.000000  0.000000  0.991100\n",
      "fake grape   0.000000  0.000  0.000000  0.000000  0.981400\n",
      "total        0.299057  0.347  0.395871  0.314971  0.977171\n",
      "total(-bg)   0.191617  0.243  0.299050  0.206583  0.981717\n",
      "\n",
      "Epoch: [123][0/16]\tTime 0.517 (0.517)\tETA 0:00:08\tTraining Loss 1.2383 (1.2383)\n",
      "\n",
      "Epoch: [123][1/16]\tTime 0.186 (0.703)\tETA 0:00:02\tTraining Loss 1.2383 (1.2383)\n",
      "\n",
      "Epoch: [123][2/16]\tTime 0.196 (0.899)\tETA 0:00:02\tTraining Loss 1.2398 (1.2388)\n",
      "\n",
      "Epoch: [123][3/16]\tTime 0.190 (1.089)\tETA 0:00:02\tTraining Loss 1.2408 (1.2393)\n",
      "\n",
      "Epoch: [123][4/16]\tTime 0.194 (1.283)\tETA 0:00:02\tTraining Loss 1.2432 (1.2401)\n",
      "\n",
      "Epoch: [123][5/16]\tTime 0.190 (1.473)\tETA 0:00:02\tTraining Loss 1.2381 (1.2397)\n",
      "\n",
      "Epoch: [123][6/16]\tTime 0.199 (1.673)\tETA 0:00:01\tTraining Loss 1.2362 (1.2392)\n",
      "\n",
      "Epoch: [123][7/16]\tTime 0.184 (1.857)\tETA 0:00:01\tTraining Loss 1.2392 (1.2392)\n",
      "\n",
      "Epoch: [123][8/16]\tTime 0.203 (2.060)\tETA 0:00:01\tTraining Loss 1.2373 (1.2390)\n",
      "\n",
      "Epoch: [123][9/16]\tTime 0.187 (2.247)\tETA 0:00:01\tTraining Loss 1.2369 (1.2388)\n",
      "\n",
      "Epoch: [123][10/16]\tTime 0.200 (2.447)\tETA 0:00:01\tTraining Loss 1.2341 (1.2384)\n",
      "\n",
      "Epoch: [123][11/16]\tTime 0.195 (2.642)\tETA 0:00:00\tTraining Loss 1.2397 (1.2385)\n",
      "\n",
      "Epoch: [123][12/16]\tTime 0.192 (2.834)\tETA 0:00:00\tTraining Loss 1.2383 (1.2385)\n",
      "\n",
      "Epoch: [123][13/16]\tTime 0.199 (3.033)\tETA 0:00:00\tTraining Loss 1.2486 (1.2392)\n",
      "\n",
      "Epoch: [123][14/16]\tTime 0.192 (3.225)\tETA 0:00:00\tTraining Loss 1.2442 (1.2395)\n",
      "\n",
      "Epoch: [123][15/16]\tTime 0.112 (3.337)\tETA 0:00:00\tTraining Loss 1.2407 (1.2396)\n",
      "_\n",
      "Validation stats                    IoU        F1      Prec    recall       Acc\n",
      "bg,          0.945500  0.972000  0.975900  0.968100  0.951500\n",
      "real apple   0.386600  0.557500  0.950000  0.394600  0.958800\n",
      "real pepper  0.000000  0.000000  0.000000  0.000000  1.000000\n",
      "real grape   0.660800  0.795700  0.916100  0.703400  0.976600\n",
      "fake apple   0.000000  0.000000  0.000000  0.000000  0.977000\n",
      "fake pepper  0.000000  0.000000  0.000000  0.000000  0.984300\n",
      "fake grape   0.000000  0.000000  0.000000  0.000000  0.978300\n",
      "total        0.284700  0.332171  0.406000  0.295157  0.975214\n",
      "total(-bg)   0.174567  0.225533  0.311017  0.183000  0.979167\n",
      "\n",
      "Epoch: [124][0/16]\tTime 0.482 (0.482)\tETA 0:00:07\tTraining Loss 1.2388 (1.2388)\n",
      "\n",
      "Epoch: [124][1/16]\tTime 0.185 (0.667)\tETA 0:00:02\tTraining Loss 1.2369 (1.2378)\n",
      "\n",
      "Epoch: [124][2/16]\tTime 0.185 (0.852)\tETA 0:00:02\tTraining Loss 1.2373 (1.2377)\n",
      "\n",
      "Epoch: [124][3/16]\tTime 0.183 (1.034)\tETA 0:00:02\tTraining Loss 1.2414 (1.2386)\n",
      "\n",
      "Epoch: [124][4/16]\tTime 0.200 (1.234)\tETA 0:00:02\tTraining Loss 1.2428 (1.2394)\n",
      "\n",
      "Epoch: [124][5/16]\tTime 0.180 (1.414)\tETA 0:00:01\tTraining Loss 1.2400 (1.2395)\n",
      "\n",
      "Epoch: [124][6/16]\tTime 0.187 (1.600)\tETA 0:00:01\tTraining Loss 1.2398 (1.2396)\n",
      "\n",
      "Epoch: [124][7/16]\tTime 0.189 (1.790)\tETA 0:00:01\tTraining Loss 1.2356 (1.2391)\n",
      "\n",
      "Epoch: [124][8/16]\tTime 0.194 (1.984)\tETA 0:00:01\tTraining Loss 1.2409 (1.2393)\n",
      "\n",
      "Epoch: [124][9/16]\tTime 0.205 (2.188)\tETA 0:00:01\tTraining Loss 1.2422 (1.2396)\n",
      "\n",
      "Epoch: [124][10/16]\tTime 0.187 (2.376)\tETA 0:00:01\tTraining Loss 1.2356 (1.2392)\n",
      "\n",
      "Epoch: [124][11/16]\tTime 0.187 (2.563)\tETA 0:00:00\tTraining Loss 1.2373 (1.2390)\n",
      "\n",
      "Epoch: [124][12/16]\tTime 0.191 (2.754)\tETA 0:00:00\tTraining Loss 1.2371 (1.2389)\n",
      "\n",
      "Epoch: [124][13/16]\tTime 0.189 (2.943)\tETA 0:00:00\tTraining Loss 1.2376 (1.2388)\n",
      "\n",
      "Epoch: [124][14/16]\tTime 0.188 (3.131)\tETA 0:00:00\tTraining Loss 1.2349 (1.2385)\n",
      "\n",
      "Epoch: [124][15/16]\tTime 0.116 (3.247)\tETA 0:00:00\tTraining Loss 1.2480 (1.2389)\n",
      "_\n",
      "Validation stats                    IoU        F1      Prec    recall       Acc\n",
      "bg,          0.953300  0.976000  0.976100  0.976100  0.958400\n",
      "real apple   0.443600  0.614500  0.926100  0.459800  0.962100\n",
      "real pepper  0.000000  0.000000  0.000000  0.000000  0.999700\n",
      "real grape   0.790900  0.883200  0.920900  0.848600  0.985500\n",
      "fake apple   0.000000  0.000000  0.000000  0.000000  0.974800\n",
      "fake pepper  0.000000  0.000000  0.000000  0.000000  0.996000\n",
      "fake grape   0.000000  0.000000  0.000000  0.000000  0.991300\n",
      "total        0.312543  0.353386  0.403300  0.326357  0.981114\n",
      "total(-bg)   0.205750  0.249617  0.307833  0.218067  0.984900\n",
      "\n",
      "Epoch: [125][0/16]\tTime 0.374 (0.374)\tETA 0:00:05\tTraining Loss 1.2462 (1.2462)\n",
      "\n",
      "Epoch: [125][1/16]\tTime 0.184 (0.557)\tETA 0:00:02\tTraining Loss 1.2337 (1.2400)\n",
      "\n",
      "Epoch: [125][2/16]\tTime 0.188 (0.745)\tETA 0:00:02\tTraining Loss 1.2354 (1.2384)\n",
      "\n",
      "Epoch: [125][3/16]\tTime 0.185 (0.931)\tETA 0:00:02\tTraining Loss 1.2342 (1.2374)\n",
      "\n",
      "Epoch: [125][4/16]\tTime 0.185 (1.116)\tETA 0:00:02\tTraining Loss 1.2368 (1.2373)\n",
      "\n",
      "Epoch: [125][5/16]\tTime 0.192 (1.308)\tETA 0:00:02\tTraining Loss 1.2351 (1.2369)\n",
      "\n",
      "Epoch: [125][6/16]\tTime 0.185 (1.493)\tETA 0:00:01\tTraining Loss 1.2347 (1.2366)\n",
      "\n",
      "Epoch: [125][7/16]\tTime 0.186 (1.678)\tETA 0:00:01\tTraining Loss 1.2381 (1.2368)\n",
      "\n",
      "Epoch: [125][8/16]\tTime 0.185 (1.864)\tETA 0:00:01\tTraining Loss 1.2375 (1.2369)\n",
      "\n",
      "Epoch: [125][9/16]\tTime 0.189 (2.053)\tETA 0:00:01\tTraining Loss 1.2375 (1.2369)\n",
      "\n",
      "Epoch: [125][10/16]\tTime 0.192 (2.245)\tETA 0:00:01\tTraining Loss 1.2376 (1.2370)\n",
      "\n",
      "Epoch: [125][11/16]\tTime 0.193 (2.437)\tETA 0:00:00\tTraining Loss 1.2347 (1.2368)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: [125][12/16]\tTime 0.309 (2.746)\tETA 0:00:01\tTraining Loss 1.2328 (1.2365)\n",
      "\n",
      "Epoch: [125][13/16]\tTime 0.192 (2.939)\tETA 0:00:00\tTraining Loss 1.2374 (1.2365)\n",
      "\n",
      "Epoch: [125][14/16]\tTime 0.188 (3.127)\tETA 0:00:00\tTraining Loss 1.2349 (1.2364)\n",
      "\n",
      "Epoch: [125][15/16]\tTime 0.112 (3.239)\tETA 0:00:00\tTraining Loss 1.2400 (1.2366)\n",
      "_\n",
      "Validation stats                    IoU        F1      Prec    recall       Acc\n",
      "bg,          0.948600  0.973500  0.977100  0.970100  0.954200\n",
      "real apple   0.482900  0.651300  0.954100  0.494400  0.965200\n",
      "real pepper  0.000000  0.000000  0.000000  0.000000  0.999700\n",
      "real grape   0.810100  0.895000  0.906500  0.883900  0.986600\n",
      "fake apple   0.000000  0.000000  0.000000  0.000000  0.977400\n",
      "fake pepper  0.000000  0.000000  0.000000  0.000000  0.993600\n",
      "fake grape   0.000000  0.000000  0.000000  0.000000  0.989700\n",
      "total        0.320229  0.359971  0.405386  0.335486  0.980914\n",
      "total(-bg)   0.215500  0.257717  0.310100  0.229717  0.985367\n",
      "\n",
      "Epoch: [126][0/16]\tTime 0.506 (0.506)\tETA 0:00:08\tTraining Loss 1.2337 (1.2337)\n",
      "\n",
      "Epoch: [126][1/16]\tTime 0.182 (0.688)\tETA 0:00:02\tTraining Loss 1.2391 (1.2364)\n",
      "\n",
      "Epoch: [126][2/16]\tTime 0.191 (0.879)\tETA 0:00:02\tTraining Loss 1.2344 (1.2357)\n",
      "\n",
      "Epoch: [126][3/16]\tTime 0.186 (1.066)\tETA 0:00:02\tTraining Loss 1.2350 (1.2355)\n",
      "\n",
      "Epoch: [126][4/16]\tTime 0.188 (1.253)\tETA 0:00:02\tTraining Loss 1.2358 (1.2356)\n",
      "\n",
      "Epoch: [126][5/16]\tTime 0.187 (1.440)\tETA 0:00:02\tTraining Loss 1.2398 (1.2363)\n",
      "\n",
      "Epoch: [126][6/16]\tTime 0.205 (1.645)\tETA 0:00:02\tTraining Loss 1.2340 (1.2360)\n",
      "\n",
      "Epoch: [126][7/16]\tTime 0.191 (1.836)\tETA 0:00:01\tTraining Loss 1.2340 (1.2357)\n",
      "\n",
      "Epoch: [126][8/16]\tTime 0.191 (2.027)\tETA 0:00:01\tTraining Loss 1.2332 (1.2354)\n",
      "\n",
      "Epoch: [126][9/16]\tTime 0.185 (2.212)\tETA 0:00:01\tTraining Loss 1.2396 (1.2359)\n",
      "\n",
      "Epoch: [126][10/16]\tTime 0.189 (2.401)\tETA 0:00:01\tTraining Loss 1.2339 (1.2357)\n",
      "\n",
      "Epoch: [126][11/16]\tTime 0.184 (2.586)\tETA 0:00:00\tTraining Loss 1.2345 (1.2356)\n",
      "\n",
      "Epoch: [126][12/16]\tTime 0.188 (2.774)\tETA 0:00:00\tTraining Loss 1.2370 (1.2357)\n",
      "\n",
      "Epoch: [126][13/16]\tTime 0.187 (2.961)\tETA 0:00:00\tTraining Loss 1.2333 (1.2355)\n",
      "\n",
      "Epoch: [126][14/16]\tTime 0.188 (3.149)\tETA 0:00:00\tTraining Loss 1.2323 (1.2353)\n",
      "\n",
      "Epoch: [126][15/16]\tTime 0.114 (3.263)\tETA 0:00:00\tTraining Loss 1.2425 (1.2355)\n",
      "_\n",
      "Validation stats                    IoU        F1      Prec    recall       Acc\n",
      "bg,          0.948800  0.973700  0.974700  0.972700  0.954300\n",
      "real apple   0.467300  0.636900  0.951300  0.478800  0.964100\n",
      "real pepper  0.000000  0.000000  0.000000  0.000000  1.000000\n",
      "real grape   0.709300  0.829800  0.926400  0.751600  0.980000\n",
      "fake apple   0.000000  0.000000  0.000000  0.000000  0.979700\n",
      "fake pepper  0.000000  0.000000  0.000000  0.000000  0.992900\n",
      "fake grape   0.000000  0.000000  0.000000  0.000000  0.980800\n",
      "total        0.303629  0.348629  0.407486  0.314729  0.978829\n",
      "total(-bg)   0.196100  0.244450  0.312950  0.205067  0.982917\n",
      "\n",
      "Epoch: [127][0/16]\tTime 0.488 (0.488)\tETA 0:00:07\tTraining Loss 1.2334 (1.2334)\n",
      "\n",
      "Epoch: [127][1/16]\tTime 0.186 (0.673)\tETA 0:00:02\tTraining Loss 1.2327 (1.2330)\n",
      "\n",
      "Epoch: [127][2/16]\tTime 0.188 (0.862)\tETA 0:00:02\tTraining Loss 1.2327 (1.2329)\n",
      "\n",
      "Epoch: [127][3/16]\tTime 0.190 (1.052)\tETA 0:00:02\tTraining Loss 1.2330 (1.2329)\n",
      "\n",
      "Epoch: [127][4/16]\tTime 0.187 (1.239)\tETA 0:00:02\tTraining Loss 1.2390 (1.2341)\n",
      "\n",
      "Epoch: [127][5/16]\tTime 0.179 (1.418)\tETA 0:00:01\tTraining Loss 1.2360 (1.2345)\n",
      "\n",
      "Epoch: [127][6/16]\tTime 0.192 (1.609)\tETA 0:00:01\tTraining Loss 1.2320 (1.2341)\n",
      "\n",
      "Epoch: [127][7/16]\tTime 0.191 (1.800)\tETA 0:00:01\tTraining Loss 1.2333 (1.2340)\n",
      "\n",
      "Epoch: [127][8/16]\tTime 0.184 (1.985)\tETA 0:00:01\tTraining Loss 1.2392 (1.2346)\n",
      "\n",
      "Epoch: [127][9/16]\tTime 0.193 (2.178)\tETA 0:00:01\tTraining Loss 1.2369 (1.2348)\n",
      "\n",
      "Epoch: [127][10/16]\tTime 0.196 (2.374)\tETA 0:00:01\tTraining Loss 1.2318 (1.2345)\n",
      "\n",
      "Epoch: [127][11/16]\tTime 0.182 (2.555)\tETA 0:00:00\tTraining Loss 1.2321 (1.2343)\n",
      "\n",
      "Epoch: [127][12/16]\tTime 0.205 (2.760)\tETA 0:00:00\tTraining Loss 1.2328 (1.2342)\n",
      "\n",
      "Epoch: [127][13/16]\tTime 0.189 (2.949)\tETA 0:00:00\tTraining Loss 1.2335 (1.2342)\n",
      "\n",
      "Epoch: [127][14/16]\tTime 0.188 (3.137)\tETA 0:00:00\tTraining Loss 1.2312 (1.2340)\n",
      "\n",
      "Epoch: [127][15/16]\tTime 0.114 (3.251)\tETA 0:00:00\tTraining Loss 1.2364 (1.2340)\n",
      "_\n",
      "Validation stats                    IoU        F1      Prec    recall       Acc\n",
      "bg,          0.948800  0.973700  0.977000  0.970400  0.954500\n",
      "real apple   0.503600  0.669800  0.925900  0.524700  0.966000\n",
      "real pepper  0.000000  0.000000  0.000000  0.000000  0.999100\n",
      "real grape   0.731300  0.844800  0.905400  0.791800  0.981200\n",
      "fake apple   0.000000  0.000000  0.000000  0.000000  0.980300\n",
      "fake pepper  0.000000  0.000000  0.000000  0.000000  0.995100\n",
      "fake grape   0.000000  0.000000  0.000000  0.000000  0.982900\n",
      "total        0.311957  0.355471  0.401186  0.326700  0.979871\n",
      "total(-bg)   0.205817  0.252433  0.305217  0.219417  0.984100\n",
      "\n",
      "Epoch: [128][0/16]\tTime 0.478 (0.478)\tETA 0:00:07\tTraining Loss 1.2310 (1.2310)\n",
      "\n",
      "Epoch: [128][1/16]\tTime 0.184 (0.662)\tETA 0:00:02\tTraining Loss 1.2353 (1.2331)\n",
      "\n",
      "Epoch: [128][2/16]\tTime 0.187 (0.849)\tETA 0:00:02\tTraining Loss 1.2318 (1.2327)\n",
      "\n",
      "Epoch: [128][3/16]\tTime 0.183 (1.032)\tETA 0:00:02\tTraining Loss 1.2342 (1.2330)\n",
      "\n",
      "Epoch: [128][4/16]\tTime 0.198 (1.231)\tETA 0:00:02\tTraining Loss 1.2331 (1.2331)\n",
      "\n",
      "Epoch: [128][5/16]\tTime 0.182 (1.413)\tETA 0:00:02\tTraining Loss 1.2315 (1.2328)\n",
      "\n",
      "Epoch: [128][6/16]\tTime 0.202 (1.615)\tETA 0:00:02\tTraining Loss 1.2319 (1.2327)\n",
      "\n",
      "Epoch: [128][7/16]\tTime 0.184 (1.799)\tETA 0:00:01\tTraining Loss 1.2311 (1.2325)\n",
      "\n",
      "Epoch: [128][8/16]\tTime 0.191 (1.990)\tETA 0:00:01\tTraining Loss 1.2367 (1.2329)\n",
      "\n",
      "Epoch: [128][9/16]\tTime 0.187 (2.177)\tETA 0:00:01\tTraining Loss 1.2314 (1.2328)\n",
      "\n",
      "Epoch: [128][10/16]\tTime 0.187 (2.364)\tETA 0:00:01\tTraining Loss 1.2291 (1.2324)\n",
      "\n",
      "Epoch: [128][11/16]\tTime 0.186 (2.549)\tETA 0:00:00\tTraining Loss 1.2360 (1.2327)\n",
      "\n",
      "Epoch: [128][12/16]\tTime 0.189 (2.738)\tETA 0:00:00\tTraining Loss 1.2316 (1.2327)\n",
      "\n",
      "Epoch: [128][13/16]\tTime 0.187 (2.924)\tETA 0:00:00\tTraining Loss 1.2334 (1.2327)\n",
      "\n",
      "Epoch: [128][14/16]\tTime 0.190 (3.114)\tETA 0:00:00\tTraining Loss 1.2298 (1.2325)\n",
      "\n",
      "Epoch: [128][15/16]\tTime 0.113 (3.228)\tETA 0:00:00\tTraining Loss 1.2382 (1.2327)\n",
      "_\n",
      "Validation stats                   IoU        F1      Prec    recall       Acc\n",
      "bg,          0.95120  0.975000  0.978900  0.971100  0.956700\n",
      "real apple   0.43840  0.609600  0.942200  0.450500  0.962100\n",
      "real pepper  0.00000  0.000000  0.000000  0.000000  0.998100\n",
      "real grape   0.71390  0.833000  0.930000  0.754400  0.980400\n",
      "fake apple   0.00000  0.000000  0.000000  0.000000  0.974600\n",
      "fake pepper  0.00000  0.000000  0.000000  0.000000  0.995300\n",
      "fake grape   0.00000  0.000000  0.000000  0.000000  0.978600\n",
      "total        0.30050  0.345371  0.407300  0.310857  0.977971\n",
      "total(-bg)   0.19205  0.240433  0.312033  0.200817  0.981517\n",
      "\n",
      "Epoch: [129][0/16]\tTime 0.429 (0.429)\tETA 0:00:06\tTraining Loss 1.2359 (1.2359)\n",
      "\n",
      "Epoch: [129][1/16]\tTime 0.183 (0.612)\tETA 0:00:02\tTraining Loss 1.2290 (1.2325)\n",
      "\n",
      "Epoch: [129][2/16]\tTime 0.184 (0.796)\tETA 0:00:02\tTraining Loss 1.2393 (1.2347)\n",
      "\n",
      "Epoch: [129][3/16]\tTime 0.190 (0.985)\tETA 0:00:02\tTraining Loss 1.2323 (1.2341)\n",
      "\n",
      "Epoch: [129][4/16]\tTime 0.186 (1.171)\tETA 0:00:02\tTraining Loss 1.2295 (1.2332)\n",
      "\n",
      "Epoch: [129][5/16]\tTime 0.187 (1.358)\tETA 0:00:02\tTraining Loss 1.2308 (1.2328)\n",
      "\n",
      "Epoch: [129][6/16]\tTime 0.184 (1.543)\tETA 0:00:01\tTraining Loss 1.2325 (1.2328)\n",
      "\n",
      "Epoch: [129][7/16]\tTime 0.187 (1.729)\tETA 0:00:01\tTraining Loss 1.2301 (1.2324)\n",
      "\n",
      "Epoch: [129][8/16]\tTime 0.189 (1.918)\tETA 0:00:01\tTraining Loss 1.2287 (1.2320)\n",
      "\n",
      "Epoch: [129][9/16]\tTime 0.185 (2.103)\tETA 0:00:01\tTraining Loss 1.2279 (1.2316)\n",
      "\n",
      "Epoch: [129][10/16]\tTime 0.188 (2.291)\tETA 0:00:01\tTraining Loss 1.2281 (1.2313)\n",
      "\n",
      "Epoch: [129][11/16]\tTime 0.196 (2.488)\tETA 0:00:00\tTraining Loss 1.2296 (1.2311)\n",
      "\n",
      "Epoch: [129][12/16]\tTime 0.183 (2.670)\tETA 0:00:00\tTraining Loss 1.2397 (1.2318)\n",
      "\n",
      "Epoch: [129][13/16]\tTime 0.187 (2.857)\tETA 0:00:00\tTraining Loss 1.2354 (1.2321)\n",
      "\n",
      "Epoch: [129][14/16]\tTime 0.190 (3.047)\tETA 0:00:00\tTraining Loss 1.2333 (1.2321)\n",
      "\n",
      "Epoch: [129][15/16]\tTime 0.109 (3.156)\tETA 0:00:00\tTraining Loss 1.2305 (1.2321)\n",
      "_\n",
      "Validation stats                    IoU        F1      Prec    recall       Acc\n",
      "bg,          0.951500  0.975100  0.977400  0.972900  0.956900\n",
      "real apple   0.495100  0.662300  0.869000  0.535100  0.964100\n",
      "real pepper  0.000000  0.000000  0.000000  0.000000  0.999700\n",
      "real grape   0.635200  0.776800  0.926000  0.669100  0.975100\n",
      "fake apple   0.000000  0.000000  0.000000  0.000000  0.984700\n",
      "fake pepper  0.000000  0.000000  0.000000  0.000000  0.993200\n",
      "fake grape   0.000000  0.000000  0.000000  0.000000  0.975100\n",
      "total        0.297400  0.344886  0.396057  0.311014  0.978400\n",
      "total(-bg)   0.188383  0.239850  0.299167  0.200700  0.981983\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: [130][0/16]\tTime 0.470 (0.470)\tETA 0:00:07\tTraining Loss 1.2318 (1.2318)\n",
      "\n",
      "Epoch: [130][1/16]\tTime 0.183 (0.653)\tETA 0:00:02\tTraining Loss 1.2275 (1.2297)\n",
      "\n",
      "Epoch: [130][2/16]\tTime 0.186 (0.839)\tETA 0:00:02\tTraining Loss 1.2407 (1.2333)\n",
      "\n",
      "Epoch: [130][3/16]\tTime 0.187 (1.026)\tETA 0:00:02\tTraining Loss 1.2288 (1.2322)\n",
      "\n",
      "Epoch: [130][4/16]\tTime 0.191 (1.217)\tETA 0:00:02\tTraining Loss 1.2288 (1.2315)\n",
      "\n",
      "Epoch: [130][5/16]\tTime 0.182 (1.399)\tETA 0:00:02\tTraining Loss 1.2303 (1.2313)\n",
      "\n",
      "Epoch: [130][6/16]\tTime 0.195 (1.595)\tETA 0:00:01\tTraining Loss 1.2333 (1.2316)\n",
      "\n",
      "Epoch: [130][7/16]\tTime 0.189 (1.784)\tETA 0:00:01\tTraining Loss 1.2324 (1.2317)\n",
      "\n",
      "Epoch: [130][8/16]\tTime 0.183 (1.966)\tETA 0:00:01\tTraining Loss 1.2287 (1.2314)\n",
      "\n",
      "Epoch: [130][9/16]\tTime 0.208 (2.175)\tETA 0:00:01\tTraining Loss 1.2356 (1.2318)\n",
      "\n",
      "Epoch: [130][10/16]\tTime 0.188 (2.363)\tETA 0:00:01\tTraining Loss 1.2281 (1.2315)\n",
      "\n",
      "Epoch: [130][11/16]\tTime 0.190 (2.553)\tETA 0:00:00\tTraining Loss 1.2330 (1.2316)\n",
      "\n",
      "Epoch: [130][12/16]\tTime 0.187 (2.740)\tETA 0:00:00\tTraining Loss 1.2307 (1.2315)\n",
      "\n",
      "Epoch: [130][13/16]\tTime 0.184 (2.924)\tETA 0:00:00\tTraining Loss 1.2333 (1.2317)\n",
      "\n",
      "Epoch: [130][14/16]\tTime 0.199 (3.123)\tETA 0:00:00\tTraining Loss 1.2309 (1.2316)\n",
      "\n",
      "Epoch: [130][15/16]\tTime 0.113 (3.236)\tETA 0:00:00\tTraining Loss 1.2315 (1.2316)\n",
      "_\n",
      "Validation stats                    IoU        F1      Prec    recall       Acc\n",
      "bg,          0.953400  0.976100  0.977600  0.974700  0.958600\n",
      "real apple   0.494400  0.661700  0.921600  0.516100  0.965300\n",
      "real pepper  0.000000  0.000000  0.000000  0.000000  1.000000\n",
      "real grape   0.704200  0.826400  0.915000  0.753500  0.979500\n",
      "fake apple   0.000000  0.000000  0.000000  0.000000  0.981400\n",
      "fake pepper  0.000000  0.000000  0.000000  0.000000  0.995800\n",
      "fake grape   0.000000  0.000000  0.000000  0.000000  0.979900\n",
      "total        0.307429  0.352029  0.402029  0.320614  0.980071\n",
      "total(-bg)   0.199767  0.248017  0.306100  0.211600  0.983650\n",
      "\n",
      "Epoch: [131][0/16]\tTime 0.377 (0.377)\tETA 0:00:06\tTraining Loss 1.2318 (1.2318)\n",
      "\n",
      "Epoch: [131][1/16]\tTime 0.184 (0.562)\tETA 0:00:02\tTraining Loss 1.2286 (1.2302)\n",
      "\n",
      "Epoch: [131][2/16]\tTime 0.189 (0.751)\tETA 0:00:02\tTraining Loss 1.2286 (1.2297)\n",
      "\n",
      "Epoch: [131][3/16]\tTime 0.181 (0.931)\tETA 0:00:02\tTraining Loss 1.2278 (1.2292)\n",
      "\n",
      "Epoch: [131][4/16]\tTime 0.182 (1.113)\tETA 0:00:02\tTraining Loss 1.2340 (1.2302)\n",
      "\n",
      "Epoch: [131][5/16]\tTime 0.182 (1.295)\tETA 0:00:02\tTraining Loss 1.2294 (1.2300)\n",
      "\n",
      "Epoch: [131][6/16]\tTime 0.187 (1.483)\tETA 0:00:01\tTraining Loss 1.2304 (1.2301)\n",
      "\n",
      "Epoch: [131][7/16]\tTime 0.187 (1.670)\tETA 0:00:01\tTraining Loss 1.2276 (1.2298)\n",
      "\n",
      "Epoch: [131][8/16]\tTime 0.190 (1.859)\tETA 0:00:01\tTraining Loss 1.2280 (1.2296)\n",
      "\n",
      "Epoch: [131][9/16]\tTime 0.187 (2.046)\tETA 0:00:01\tTraining Loss 1.2348 (1.2301)\n",
      "\n",
      "Epoch: [131][10/16]\tTime 0.192 (2.238)\tETA 0:00:01\tTraining Loss 1.2348 (1.2305)\n",
      "\n",
      "Epoch: [131][11/16]\tTime 0.185 (2.423)\tETA 0:00:00\tTraining Loss 1.2250 (1.2301)\n",
      "\n",
      "Epoch: [131][12/16]\tTime 0.198 (2.622)\tETA 0:00:00\tTraining Loss 1.2299 (1.2301)\n",
      "\n",
      "Epoch: [131][13/16]\tTime 0.183 (2.805)\tETA 0:00:00\tTraining Loss 1.2287 (1.2300)\n",
      "\n",
      "Epoch: [131][14/16]\tTime 0.188 (2.993)\tETA 0:00:00\tTraining Loss 1.2297 (1.2299)\n",
      "\n",
      "Epoch: [131][15/16]\tTime 0.114 (3.106)\tETA 0:00:00\tTraining Loss 1.2276 (1.2299)\n",
      "_\n",
      "Validation stats                    IoU        F1      Prec    recall       Acc\n",
      "bg,          0.951400  0.975000  0.978000  0.972100  0.956800\n",
      "real apple   0.491200  0.658800  0.905600  0.517800  0.964800\n",
      "real pepper  0.000000  0.000000  0.000000  0.000000  1.000000\n",
      "real grape   0.719800  0.837000  0.919600  0.768100  0.980600\n",
      "fake apple   0.000000  0.000000  0.000000  0.000000  0.982800\n",
      "fake pepper  0.000000  0.000000  0.000000  0.000000  0.994800\n",
      "fake grape   0.000000  0.000000  0.000000  0.000000  0.978300\n",
      "total        0.308914  0.352971  0.400457  0.322571  0.979729\n",
      "total(-bg)   0.201833  0.249300  0.304200  0.214317  0.983550\n",
      "\n",
      "Epoch: [132][0/16]\tTime 0.458 (0.458)\tETA 0:00:07\tTraining Loss 1.2316 (1.2316)\n",
      "\n",
      "Epoch: [132][1/16]\tTime 0.187 (0.645)\tETA 0:00:02\tTraining Loss 1.2267 (1.2291)\n",
      "\n",
      "Epoch: [132][2/16]\tTime 0.183 (0.828)\tETA 0:00:02\tTraining Loss 1.2276 (1.2286)\n",
      "\n",
      "Epoch: [132][3/16]\tTime 0.189 (1.017)\tETA 0:00:02\tTraining Loss 1.2282 (1.2285)\n",
      "\n",
      "Epoch: [132][4/16]\tTime 0.188 (1.206)\tETA 0:00:02\tTraining Loss 1.2261 (1.2280)\n",
      "\n",
      "Epoch: [132][5/16]\tTime 0.189 (1.395)\tETA 0:00:02\tTraining Loss 1.2276 (1.2280)\n",
      "\n",
      "Epoch: [132][6/16]\tTime 0.191 (1.585)\tETA 0:00:01\tTraining Loss 1.2276 (1.2279)\n",
      "\n",
      "Epoch: [132][7/16]\tTime 0.185 (1.770)\tETA 0:00:01\tTraining Loss 1.2293 (1.2281)\n",
      "\n",
      "Epoch: [132][8/16]\tTime 0.197 (1.967)\tETA 0:00:01\tTraining Loss 1.2293 (1.2282)\n",
      "\n",
      "Epoch: [132][9/16]\tTime 0.184 (2.151)\tETA 0:00:01\tTraining Loss 1.2341 (1.2288)\n",
      "\n",
      "Epoch: [132][10/16]\tTime 0.198 (2.349)\tETA 0:00:01\tTraining Loss 1.2282 (1.2287)\n",
      "\n",
      "Epoch: [132][11/16]\tTime 0.181 (2.530)\tETA 0:00:00\tTraining Loss 1.2297 (1.2288)\n",
      "\n",
      "Epoch: [132][12/16]\tTime 0.181 (2.711)\tETA 0:00:00\tTraining Loss 1.2281 (1.2288)\n",
      "\n",
      "Epoch: [132][13/16]\tTime 0.183 (2.894)\tETA 0:00:00\tTraining Loss 1.2255 (1.2285)\n",
      "\n",
      "Epoch: [132][14/16]\tTime 0.186 (3.080)\tETA 0:00:00\tTraining Loss 1.2301 (1.2286)\n",
      "\n",
      "Epoch: [132][15/16]\tTime 0.114 (3.194)\tETA 0:00:00\tTraining Loss 1.2285 (1.2286)\n",
      "_\n",
      "Validation stats                    IoU        F1      Prec  recall       Acc\n",
      "bg,          0.954100  0.976500  0.976400  0.9767  0.959200\n",
      "real apple   0.487700  0.655600  0.948800  0.5009  0.965400\n",
      "real pepper  0.000000  0.000000  0.000000  0.0000  0.999800\n",
      "real grape   0.711500  0.831400  0.929800  0.7519  0.980300\n",
      "fake apple   0.000000  0.000000  0.000000  0.0000  0.979800\n",
      "fake pepper  0.000000  0.000000  0.000000  0.0000  0.994700\n",
      "fake grape   0.000000  0.000000  0.000000  0.0000  0.982600\n",
      "total        0.307614  0.351929  0.407857  0.3185  0.980257\n",
      "total(-bg)   0.199867  0.247833  0.313100  0.2088  0.983767\n",
      "\n",
      "Epoch: [133][0/16]\tTime 0.387 (0.387)\tETA 0:00:06\tTraining Loss 1.2371 (1.2371)\n",
      "\n",
      "Epoch: [133][1/16]\tTime 0.199 (0.586)\tETA 0:00:02\tTraining Loss 1.2247 (1.2309)\n",
      "\n",
      "Epoch: [133][2/16]\tTime 0.180 (0.767)\tETA 0:00:02\tTraining Loss 1.2324 (1.2314)\n",
      "\n",
      "Epoch: [133][3/16]\tTime 0.183 (0.950)\tETA 0:00:02\tTraining Loss 1.2292 (1.2309)\n",
      "\n",
      "Epoch: [133][4/16]\tTime 0.188 (1.137)\tETA 0:00:02\tTraining Loss 1.2259 (1.2299)\n",
      "\n",
      "Epoch: [133][5/16]\tTime 0.188 (1.325)\tETA 0:00:02\tTraining Loss 1.2255 (1.2292)\n",
      "\n",
      "Epoch: [133][6/16]\tTime 0.186 (1.511)\tETA 0:00:01\tTraining Loss 1.2309 (1.2294)\n",
      "\n",
      "Epoch: [133][7/16]\tTime 0.185 (1.696)\tETA 0:00:01\tTraining Loss 1.2240 (1.2287)\n",
      "\n",
      "Epoch: [133][8/16]\tTime 0.190 (1.886)\tETA 0:00:01\tTraining Loss 1.2312 (1.2290)\n",
      "\n",
      "Epoch: [133][9/16]\tTime 0.187 (2.073)\tETA 0:00:01\tTraining Loss 1.2276 (1.2289)\n",
      "\n",
      "Epoch: [133][10/16]\tTime 0.180 (2.253)\tETA 0:00:01\tTraining Loss 1.2258 (1.2286)\n",
      "\n",
      "Epoch: [133][11/16]\tTime 0.177 (2.430)\tETA 0:00:00\tTraining Loss 1.2257 (1.2283)\n",
      "\n",
      "Epoch: [133][12/16]\tTime 0.191 (2.621)\tETA 0:00:00\tTraining Loss 1.2260 (1.2282)\n",
      "\n",
      "Epoch: [133][13/16]\tTime 0.178 (2.799)\tETA 0:00:00\tTraining Loss 1.2257 (1.2280)\n",
      "\n",
      "Epoch: [133][14/16]\tTime 0.188 (2.987)\tETA 0:00:00\tTraining Loss 1.2288 (1.2280)\n",
      "\n",
      "Epoch: [133][15/16]\tTime 0.114 (3.101)\tETA 0:00:00\tTraining Loss 1.2358 (1.2283)\n",
      "_\n",
      "Validation stats                    IoU        F1      Prec    recall       Acc\n",
      "bg,          0.950200  0.974400  0.977200  0.971800  0.955800\n",
      "real apple   0.472300  0.641500  0.870000  0.508100  0.962700\n",
      "real pepper  0.000000  0.000000  0.000000  0.000000  1.000000\n",
      "real grape   0.701500  0.824600  0.928300  0.741700  0.979600\n",
      "fake apple   0.000000  0.000000  0.000000  0.000000  0.983700\n",
      "fake pepper  0.000000  0.000000  0.000000  0.000000  0.991200\n",
      "fake grape   0.000000  0.000000  0.000000  0.000000  0.979900\n",
      "total        0.303429  0.348643  0.396500  0.317371  0.978986\n",
      "total(-bg)   0.195633  0.244350  0.299717  0.208300  0.982850\n",
      "\n",
      "Epoch: [134][0/16]\tTime 0.376 (0.376)\tETA 0:00:06\tTraining Loss 1.2300 (1.2300)\n",
      "\n",
      "Epoch: [134][1/16]\tTime 0.188 (0.563)\tETA 0:00:02\tTraining Loss 1.2268 (1.2284)\n",
      "\n",
      "Epoch: [134][2/16]\tTime 0.183 (0.746)\tETA 0:00:02\tTraining Loss 1.2320 (1.2296)\n",
      "\n",
      "Epoch: [134][3/16]\tTime 0.184 (0.929)\tETA 0:00:02\tTraining Loss 1.2259 (1.2287)\n",
      "\n",
      "Epoch: [134][4/16]\tTime 0.186 (1.115)\tETA 0:00:02\tTraining Loss 1.2249 (1.2279)\n",
      "\n",
      "Epoch: [134][5/16]\tTime 0.178 (1.293)\tETA 0:00:01\tTraining Loss 1.2234 (1.2272)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: [134][6/16]\tTime 0.195 (1.488)\tETA 0:00:01\tTraining Loss 1.2244 (1.2268)\n",
      "\n",
      "Epoch: [134][7/16]\tTime 0.180 (1.668)\tETA 0:00:01\tTraining Loss 1.2254 (1.2266)\n",
      "\n",
      "Epoch: [134][8/16]\tTime 0.196 (1.864)\tETA 0:00:01\tTraining Loss 1.2229 (1.2262)\n",
      "\n",
      "Epoch: [134][9/16]\tTime 0.183 (2.047)\tETA 0:00:01\tTraining Loss 1.2286 (1.2264)\n",
      "\n",
      "Epoch: [134][10/16]\tTime 0.184 (2.231)\tETA 0:00:01\tTraining Loss 1.2252 (1.2263)\n",
      "\n",
      "Epoch: [134][11/16]\tTime 0.206 (2.437)\tETA 0:00:01\tTraining Loss 1.2283 (1.2265)\n",
      "\n",
      "Epoch: [134][12/16]\tTime 0.195 (2.632)\tETA 0:00:00\tTraining Loss 1.2246 (1.2264)\n",
      "\n",
      "Epoch: [134][13/16]\tTime 0.176 (2.808)\tETA 0:00:00\tTraining Loss 1.2277 (1.2265)\n",
      "\n",
      "Epoch: [134][14/16]\tTime 0.184 (2.991)\tETA 0:00:00\tTraining Loss 1.2239 (1.2263)\n",
      "\n",
      "Epoch: [134][15/16]\tTime 0.118 (3.109)\tETA 0:00:00\tTraining Loss 1.2357 (1.2266)\n",
      "_\n",
      "Validation stats                    IoU        F1      Prec    recall       Acc\n",
      "bg,          0.949000  0.973800  0.976300  0.971400  0.954600\n",
      "real apple   0.512000  0.677200  0.929700  0.532600  0.966600\n",
      "real pepper  0.000000  0.000000  0.000000  0.000000  0.999800\n",
      "real grape   0.776800  0.874300  0.919600  0.833400  0.984500\n",
      "fake apple   0.000000  0.000000  0.000000  0.000000  0.979000\n",
      "fake pepper  0.000000  0.000000  0.000000  0.000000  0.995000\n",
      "fake grape   0.000000  0.000000  0.000000  0.000000  0.987700\n",
      "total        0.319686  0.360757  0.403657  0.333914  0.981029\n",
      "total(-bg)   0.214800  0.258583  0.308217  0.227667  0.985433\n",
      "\n",
      "Epoch: [135][0/16]\tTime 0.377 (0.377)\tETA 0:00:06\tTraining Loss 1.2260 (1.2260)\n",
      "\n",
      "Epoch: [135][1/16]\tTime 0.181 (0.558)\tETA 0:00:02\tTraining Loss 1.2240 (1.2250)\n",
      "\n",
      "Epoch: [135][2/16]\tTime 0.182 (0.740)\tETA 0:00:02\tTraining Loss 1.2287 (1.2262)\n",
      "\n",
      "Epoch: [135][3/16]\tTime 0.196 (0.936)\tETA 0:00:02\tTraining Loss 1.2276 (1.2266)\n",
      "\n",
      "Epoch: [135][4/16]\tTime 0.182 (1.118)\tETA 0:00:02\tTraining Loss 1.2250 (1.2263)\n",
      "\n",
      "Epoch: [135][5/16]\tTime 0.187 (1.305)\tETA 0:00:02\tTraining Loss 1.2289 (1.2267)\n",
      "\n",
      "Epoch: [135][6/16]\tTime 0.189 (1.494)\tETA 0:00:01\tTraining Loss 1.2242 (1.2263)\n",
      "\n",
      "Epoch: [135][7/16]\tTime 0.189 (1.683)\tETA 0:00:01\tTraining Loss 1.2261 (1.2263)\n",
      "\n",
      "Epoch: [135][8/16]\tTime 0.187 (1.870)\tETA 0:00:01\tTraining Loss 1.2260 (1.2263)\n",
      "\n",
      "Epoch: [135][9/16]\tTime 0.190 (2.060)\tETA 0:00:01\tTraining Loss 1.2260 (1.2263)\n",
      "\n",
      "Epoch: [135][10/16]\tTime 0.185 (2.245)\tETA 0:00:01\tTraining Loss 1.2248 (1.2261)\n",
      "\n",
      "Epoch: [135][11/16]\tTime 0.181 (2.426)\tETA 0:00:00\tTraining Loss 1.2242 (1.2260)\n",
      "\n",
      "Epoch: [135][12/16]\tTime 0.195 (2.621)\tETA 0:00:00\tTraining Loss 1.2232 (1.2257)\n",
      "\n",
      "Epoch: [135][13/16]\tTime 0.183 (2.804)\tETA 0:00:00\tTraining Loss 1.2263 (1.2258)\n",
      "\n",
      "Epoch: [135][14/16]\tTime 0.189 (2.993)\tETA 0:00:00\tTraining Loss 1.2269 (1.2259)\n",
      "\n",
      "Epoch: [135][15/16]\tTime 0.117 (3.110)\tETA 0:00:00\tTraining Loss 1.2277 (1.2259)\n",
      "_\n",
      "Validation stats                    IoU        F1      Prec    recall       Acc\n",
      "bg,          0.951600  0.975200  0.976000  0.974400  0.956900\n",
      "real apple   0.590900  0.742800  0.927100  0.619700  0.971800\n",
      "real pepper  0.000000  0.000000  0.000000  0.000000  1.000000\n",
      "real grape   0.666400  0.799800  0.930200  0.701500  0.977300\n",
      "fake apple   0.000000  0.000000  0.000000  0.000000  0.986000\n",
      "fake pepper  0.000000  0.000000  0.000000  0.000000  0.994700\n",
      "fake grape   0.000000  0.000000  0.000000  0.000000  0.980200\n",
      "total        0.315557  0.359686  0.404757  0.327943  0.980986\n",
      "total(-bg)   0.209550  0.257100  0.309550  0.220200  0.985000\n",
      "\n",
      "Epoch: [136][0/16]\tTime 0.480 (0.480)\tETA 0:00:07\tTraining Loss 1.2338 (1.2338)\n",
      "\n",
      "Epoch: [136][1/16]\tTime 0.181 (0.661)\tETA 0:00:02\tTraining Loss 1.2253 (1.2296)\n",
      "\n",
      "Epoch: [136][2/16]\tTime 0.183 (0.845)\tETA 0:00:02\tTraining Loss 1.2218 (1.2270)\n",
      "\n",
      "Epoch: [136][3/16]\tTime 0.192 (1.037)\tETA 0:00:02\tTraining Loss 1.2219 (1.2257)\n",
      "\n",
      "Epoch: [136][4/16]\tTime 0.190 (1.226)\tETA 0:00:02\tTraining Loss 1.2241 (1.2254)\n",
      "\n",
      "Epoch: [136][5/16]\tTime 0.184 (1.410)\tETA 0:00:02\tTraining Loss 1.2275 (1.2257)\n",
      "\n",
      "Epoch: [136][6/16]\tTime 0.198 (1.608)\tETA 0:00:01\tTraining Loss 1.2405 (1.2279)\n",
      "\n",
      "Epoch: [136][7/16]\tTime 0.186 (1.794)\tETA 0:00:01\tTraining Loss 1.2260 (1.2276)\n",
      "\n",
      "Epoch: [136][8/16]\tTime 0.183 (1.977)\tETA 0:00:01\tTraining Loss 1.2237 (1.2272)\n",
      "\n",
      "Epoch: [136][9/16]\tTime 0.183 (2.160)\tETA 0:00:01\tTraining Loss 1.2231 (1.2268)\n",
      "\n",
      "Epoch: [136][10/16]\tTime 0.193 (2.353)\tETA 0:00:01\tTraining Loss 1.2248 (1.2266)\n",
      "\n",
      "Epoch: [136][11/16]\tTime 0.185 (2.538)\tETA 0:00:00\tTraining Loss 1.2207 (1.2261)\n",
      "\n",
      "Epoch: [136][12/16]\tTime 0.186 (2.724)\tETA 0:00:00\tTraining Loss 1.2321 (1.2266)\n",
      "\n",
      "Epoch: [136][13/16]\tTime 0.181 (2.905)\tETA 0:00:00\tTraining Loss 1.2232 (1.2263)\n",
      "\n",
      "Epoch: [136][14/16]\tTime 0.193 (3.098)\tETA 0:00:00\tTraining Loss 1.2236 (1.2261)\n",
      "\n",
      "Epoch: [136][15/16]\tTime 0.115 (3.213)\tETA 0:00:00\tTraining Loss 1.2226 (1.2260)\n",
      "_\n",
      "Validation stats                    IoU        F1      Prec    recall       Acc\n",
      "bg,          0.947200  0.972800  0.976900  0.968900  0.953000\n",
      "real apple   0.584000  0.737300  0.935100  0.608700  0.971500\n",
      "real pepper  0.000000  0.000000  0.000000  0.000000  0.998700\n",
      "real grape   0.727300  0.842000  0.903800  0.788300  0.980900\n",
      "fake apple   0.000000  0.000000  0.000000  0.000000  0.987200\n",
      "fake pepper  0.000000  0.000000  0.000000  0.000000  0.992800\n",
      "fake grape   0.000000  0.000000  0.000000  0.000000  0.982900\n",
      "total        0.322643  0.364586  0.402257  0.337986  0.981000\n",
      "total(-bg)   0.218550  0.263217  0.306483  0.232833  0.985667\n",
      "\n",
      "Epoch: [137][0/16]\tTime 0.496 (0.496)\tETA 0:00:07\tTraining Loss 1.2226 (1.2226)\n",
      "\n",
      "Epoch: [137][1/16]\tTime 0.185 (0.681)\tETA 0:00:02\tTraining Loss 1.2249 (1.2238)\n",
      "\n",
      "Epoch: [137][2/16]\tTime 0.187 (0.867)\tETA 0:00:02\tTraining Loss 1.2229 (1.2235)\n",
      "\n",
      "Epoch: [137][3/16]\tTime 0.185 (1.052)\tETA 0:00:02\tTraining Loss 1.2244 (1.2237)\n",
      "\n",
      "Epoch: [137][4/16]\tTime 0.190 (1.242)\tETA 0:00:02\tTraining Loss 1.2299 (1.2249)\n",
      "\n",
      "Epoch: [137][5/16]\tTime 0.190 (1.432)\tETA 0:00:02\tTraining Loss 1.2222 (1.2245)\n",
      "\n",
      "Epoch: [137][6/16]\tTime 0.181 (1.613)\tETA 0:00:01\tTraining Loss 1.2272 (1.2249)\n",
      "\n",
      "Epoch: [137][7/16]\tTime 0.186 (1.799)\tETA 0:00:01\tTraining Loss 1.2266 (1.2251)\n",
      "\n",
      "Epoch: [137][8/16]\tTime 0.192 (1.991)\tETA 0:00:01\tTraining Loss 1.2227 (1.2248)\n",
      "\n",
      "Epoch: [137][9/16]\tTime 0.196 (2.188)\tETA 0:00:01\tTraining Loss 1.2207 (1.2244)\n",
      "\n",
      "Epoch: [137][10/16]\tTime 0.188 (2.376)\tETA 0:00:01\tTraining Loss 1.2239 (1.2244)\n",
      "\n",
      "Epoch: [137][11/16]\tTime 0.195 (2.571)\tETA 0:00:00\tTraining Loss 1.2275 (1.2246)\n",
      "\n",
      "Epoch: [137][12/16]\tTime 0.188 (2.759)\tETA 0:00:00\tTraining Loss 1.2292 (1.2250)\n",
      "\n",
      "Epoch: [137][13/16]\tTime 0.190 (2.948)\tETA 0:00:00\tTraining Loss 1.2263 (1.2251)\n",
      "\n",
      "Epoch: [137][14/16]\tTime 0.190 (3.139)\tETA 0:00:00\tTraining Loss 1.2205 (1.2248)\n",
      "\n",
      "Epoch: [137][15/16]\tTime 0.113 (3.252)\tETA 0:00:00\tTraining Loss 1.2232 (1.2247)\n",
      "_\n",
      "Validation stats                    IoU        F1     Prec    recall       Acc\n",
      "bg,          0.955600  0.977200  0.97670  0.977800  0.960500\n",
      "real apple   0.529600  0.692400  0.90760  0.559800  0.967300\n",
      "real pepper  0.000000  0.000000  0.00000  0.000000  0.999900\n",
      "real grape   0.791500  0.883600  0.88910  0.878300  0.985000\n",
      "fake apple   0.000000  0.000000  0.00000  0.000000  0.987600\n",
      "fake pepper  0.000000  0.000000  0.00000  0.000000  0.995200\n",
      "fake grape   0.000000  0.000000  0.00000  0.000000  0.992300\n",
      "total        0.325243  0.364743  0.39620  0.345129  0.983971\n",
      "total(-bg)   0.220183  0.262667  0.29945  0.239683  0.987883\n",
      "\n",
      "Epoch: [138][0/16]\tTime 0.382 (0.382)\tETA 0:00:06\tTraining Loss 1.2200 (1.2200)\n",
      "\n",
      "Epoch: [138][1/16]\tTime 0.187 (0.569)\tETA 0:00:02\tTraining Loss 1.2275 (1.2237)\n",
      "\n",
      "Epoch: [138][2/16]\tTime 0.191 (0.760)\tETA 0:00:02\tTraining Loss 1.2228 (1.2234)\n",
      "\n",
      "Epoch: [138][3/16]\tTime 0.181 (0.942)\tETA 0:00:02\tTraining Loss 1.2225 (1.2232)\n",
      "\n",
      "Epoch: [138][4/16]\tTime 0.186 (1.127)\tETA 0:00:02\tTraining Loss 1.2242 (1.2234)\n",
      "\n",
      "Epoch: [138][5/16]\tTime 0.186 (1.313)\tETA 0:00:02\tTraining Loss 1.2394 (1.2261)\n",
      "\n",
      "Epoch: [138][6/16]\tTime 0.187 (1.500)\tETA 0:00:01\tTraining Loss 1.2229 (1.2256)\n",
      "\n",
      "Epoch: [138][7/16]\tTime 0.179 (1.679)\tETA 0:00:01\tTraining Loss 1.2277 (1.2259)\n",
      "\n",
      "Epoch: [138][8/16]\tTime 0.178 (1.857)\tETA 0:00:01\tTraining Loss 1.2224 (1.2255)\n",
      "\n",
      "Epoch: [138][9/16]\tTime 0.193 (2.051)\tETA 0:00:01\tTraining Loss 1.2205 (1.2250)\n",
      "\n",
      "Epoch: [138][10/16]\tTime 0.187 (2.238)\tETA 0:00:01\tTraining Loss 1.2236 (1.2249)\n",
      "\n",
      "Epoch: [138][11/16]\tTime 0.185 (2.423)\tETA 0:00:00\tTraining Loss 1.2269 (1.2250)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: [138][12/16]\tTime 0.189 (2.613)\tETA 0:00:00\tTraining Loss 1.2257 (1.2251)\n",
      "\n",
      "Epoch: [138][13/16]\tTime 0.186 (2.798)\tETA 0:00:00\tTraining Loss 1.2223 (1.2249)\n",
      "\n",
      "Epoch: [138][14/16]\tTime 0.189 (2.987)\tETA 0:00:00\tTraining Loss 1.2206 (1.2246)\n",
      "\n",
      "Epoch: [138][15/16]\tTime 0.113 (3.100)\tETA 0:00:00\tTraining Loss 1.2226 (1.2245)\n",
      "_\n",
      "Validation stats                    IoU        F1      Prec    recall     Acc\n",
      "bg,          0.949700  0.974200  0.977500  0.970900  0.9553\n",
      "real apple   0.550100  0.709700  0.916400  0.579200  0.9689\n",
      "real pepper  0.000000  0.000000  0.000000  0.000000  1.0000\n",
      "real grape   0.593700  0.745000  0.904400  0.633400  0.9719\n",
      "fake apple   0.000000  0.000000  0.000000  0.000000  0.9848\n",
      "fake pepper  0.000000  0.000000  0.000000  0.000000  0.9907\n",
      "fake grape   0.000000  0.000000  0.000000  0.000000  0.9751\n",
      "total        0.299071  0.346986  0.399757  0.311929  0.9781\n",
      "total(-bg)   0.190633  0.242450  0.303467  0.202100  0.9819\n",
      "\n",
      "Epoch: [139][0/16]\tTime 0.476 (0.476)\tETA 0:00:07\tTraining Loss 1.2205 (1.2205)\n",
      "\n",
      "Epoch: [139][1/16]\tTime 0.182 (0.658)\tETA 0:00:02\tTraining Loss 1.2269 (1.2237)\n",
      "\n",
      "Epoch: [139][2/16]\tTime 0.192 (0.850)\tETA 0:00:02\tTraining Loss 1.2222 (1.2232)\n",
      "\n",
      "Epoch: [139][3/16]\tTime 0.190 (1.041)\tETA 0:00:02\tTraining Loss 1.2282 (1.2245)\n",
      "\n",
      "Epoch: [139][4/16]\tTime 0.186 (1.227)\tETA 0:00:02\tTraining Loss 1.2258 (1.2247)\n",
      "\n",
      "Epoch: [139][5/16]\tTime 0.188 (1.414)\tETA 0:00:02\tTraining Loss 1.2200 (1.2239)\n",
      "\n",
      "Epoch: [139][6/16]\tTime 0.187 (1.602)\tETA 0:00:01\tTraining Loss 1.2229 (1.2238)\n",
      "\n",
      "Epoch: [139][7/16]\tTime 0.184 (1.786)\tETA 0:00:01\tTraining Loss 1.2234 (1.2237)\n",
      "\n",
      "Epoch: [139][8/16]\tTime 0.195 (1.981)\tETA 0:00:01\tTraining Loss 1.2222 (1.2236)\n",
      "\n",
      "Epoch: [139][9/16]\tTime 0.199 (2.180)\tETA 0:00:01\tTraining Loss 1.2222 (1.2234)\n",
      "\n",
      "Epoch: [139][10/16]\tTime 0.186 (2.366)\tETA 0:00:01\tTraining Loss 1.2209 (1.2232)\n",
      "\n",
      "Epoch: [139][11/16]\tTime 0.206 (2.572)\tETA 0:00:01\tTraining Loss 1.2254 (1.2234)\n",
      "\n",
      "Epoch: [139][12/16]\tTime 0.182 (2.754)\tETA 0:00:00\tTraining Loss 1.2203 (1.2231)\n",
      "\n",
      "Epoch: [139][13/16]\tTime 0.188 (2.942)\tETA 0:00:00\tTraining Loss 1.2199 (1.2229)\n",
      "\n",
      "Epoch: [139][14/16]\tTime 0.176 (3.118)\tETA 0:00:00\tTraining Loss 1.2204 (1.2227)\n",
      "\n",
      "Epoch: [139][15/16]\tTime 0.114 (3.233)\tETA 0:00:00\tTraining Loss 1.2231 (1.2228)\n",
      "_\n",
      "Validation stats                    IoU        F1      Prec    recall       Acc\n",
      "bg,          0.952500  0.975600  0.977100  0.974300  0.957800\n",
      "real apple   0.481700  0.650100  0.884400  0.514000  0.963600\n",
      "real pepper  0.000000  0.000000  0.000000  0.000000  0.999500\n",
      "real grape   0.728400  0.842800  0.921600  0.776600  0.981300\n",
      "fake apple   0.000000  0.000000  0.000000  0.000000  0.986400\n",
      "fake pepper  0.000000  0.000000  0.000000  0.000000  0.991000\n",
      "fake grape   0.000000  0.000000  0.000000  0.000000  0.983000\n",
      "total        0.308943  0.352643  0.397586  0.323557  0.980371\n",
      "total(-bg)   0.201683  0.248817  0.301000  0.215100  0.984133\n",
      "\n",
      "Epoch: [140][0/16]\tTime 0.489 (0.489)\tETA 0:00:07\tTraining Loss 1.2216 (1.2216)\n",
      "\n",
      "Epoch: [140][1/16]\tTime 0.182 (0.671)\tETA 0:00:02\tTraining Loss 1.2243 (1.2230)\n",
      "\n",
      "Epoch: [140][2/16]\tTime 0.174 (0.846)\tETA 0:00:02\tTraining Loss 1.2247 (1.2235)\n",
      "\n",
      "Epoch: [140][3/16]\tTime 0.200 (1.045)\tETA 0:00:02\tTraining Loss 1.2238 (1.2236)\n",
      "\n",
      "Epoch: [140][4/16]\tTime 0.192 (1.238)\tETA 0:00:02\tTraining Loss 1.2210 (1.2231)\n",
      "\n",
      "Epoch: [140][5/16]\tTime 0.187 (1.424)\tETA 0:00:02\tTraining Loss 1.2241 (1.2233)\n",
      "\n",
      "Epoch: [140][6/16]\tTime 0.185 (1.609)\tETA 0:00:01\tTraining Loss 1.2227 (1.2232)\n",
      "\n",
      "Epoch: [140][7/16]\tTime 0.185 (1.794)\tETA 0:00:01\tTraining Loss 1.2206 (1.2229)\n",
      "\n",
      "Epoch: [140][8/16]\tTime 0.182 (1.976)\tETA 0:00:01\tTraining Loss 1.2188 (1.2224)\n",
      "\n",
      "Epoch: [140][9/16]\tTime 0.183 (2.160)\tETA 0:00:01\tTraining Loss 1.2215 (1.2223)\n",
      "\n",
      "Epoch: [140][10/16]\tTime 0.183 (2.343)\tETA 0:00:01\tTraining Loss 1.2224 (1.2223)\n",
      "\n",
      "Epoch: [140][11/16]\tTime 0.184 (2.527)\tETA 0:00:00\tTraining Loss 1.2237 (1.2224)\n",
      "\n",
      "Epoch: [140][12/16]\tTime 0.189 (2.716)\tETA 0:00:00\tTraining Loss 1.2180 (1.2221)\n",
      "\n",
      "Epoch: [140][13/16]\tTime 0.187 (2.903)\tETA 0:00:00\tTraining Loss 1.2198 (1.2219)\n",
      "\n",
      "Epoch: [140][14/16]\tTime 0.186 (3.090)\tETA 0:00:00\tTraining Loss 1.2290 (1.2224)\n",
      "\n",
      "Epoch: [140][15/16]\tTime 0.114 (3.203)\tETA 0:00:00\tTraining Loss 1.2226 (1.2224)\n",
      "_\n",
      "Validation stats                    IoU        F1      Prec    recall       Acc\n",
      "bg,          0.949600  0.974100  0.978800  0.969600  0.955200\n",
      "real apple   0.495800  0.662900  0.903400  0.523600  0.965000\n",
      "real pepper  0.000000  0.000000  0.000000  0.000000  0.999800\n",
      "real grape   0.701300  0.824400  0.895100  0.764100  0.978900\n",
      "fake apple   0.000000  0.000000  0.000000  0.000000  0.984200\n",
      "fake pepper  0.000000  0.000000  0.000000  0.000000  0.990400\n",
      "fake grape   0.000000  0.000000  0.000000  0.000000  0.980300\n",
      "total        0.306671  0.351629  0.396757  0.322471  0.979114\n",
      "total(-bg)   0.199517  0.247883  0.299750  0.214617  0.983100\n",
      "\n",
      "Epoch: [141][0/16]\tTime 0.376 (0.376)\tETA 0:00:06\tTraining Loss 1.2228 (1.2228)\n",
      "\n",
      "Epoch: [141][1/16]\tTime 0.190 (0.566)\tETA 0:00:02\tTraining Loss 1.2222 (1.2225)\n",
      "\n",
      "Epoch: [141][2/16]\tTime 0.185 (0.751)\tETA 0:00:02\tTraining Loss 1.2184 (1.2211)\n",
      "\n",
      "Epoch: [141][3/16]\tTime 0.186 (0.937)\tETA 0:00:02\tTraining Loss 1.2195 (1.2207)\n",
      "\n",
      "Epoch: [141][4/16]\tTime 0.179 (1.116)\tETA 0:00:02\tTraining Loss 1.2217 (1.2209)\n",
      "\n",
      "Epoch: [141][5/16]\tTime 0.191 (1.307)\tETA 0:00:02\tTraining Loss 1.2215 (1.2210)\n",
      "\n",
      "Epoch: [141][6/16]\tTime 0.188 (1.495)\tETA 0:00:01\tTraining Loss 1.2244 (1.2215)\n",
      "\n",
      "Epoch: [141][7/16]\tTime 0.200 (1.695)\tETA 0:00:01\tTraining Loss 1.2306 (1.2226)\n",
      "\n",
      "Epoch: [141][8/16]\tTime 0.184 (1.880)\tETA 0:00:01\tTraining Loss 1.2198 (1.2223)\n",
      "\n",
      "Epoch: [141][9/16]\tTime 0.187 (2.067)\tETA 0:00:01\tTraining Loss 1.2234 (1.2224)\n",
      "\n",
      "Epoch: [141][10/16]\tTime 0.187 (2.254)\tETA 0:00:01\tTraining Loss 1.2175 (1.2220)\n",
      "\n",
      "Epoch: [141][11/16]\tTime 0.181 (2.434)\tETA 0:00:00\tTraining Loss 1.2208 (1.2219)\n",
      "\n",
      "Epoch: [141][12/16]\tTime 0.189 (2.623)\tETA 0:00:00\tTraining Loss 1.2199 (1.2217)\n",
      "\n",
      "Epoch: [141][13/16]\tTime 0.182 (2.805)\tETA 0:00:00\tTraining Loss 1.2223 (1.2218)\n",
      "\n",
      "Epoch: [141][14/16]\tTime 0.189 (2.995)\tETA 0:00:00\tTraining Loss 1.2179 (1.2215)\n",
      "\n",
      "Epoch: [141][15/16]\tTime 0.114 (3.109)\tETA 0:00:00\tTraining Loss 1.2223 (1.2215)\n",
      "_\n",
      "Validation stats                    IoU        F1      Prec    recall       Acc\n",
      "bg,          0.955000  0.976900  0.976700  0.977200  0.959900\n",
      "real apple   0.490600  0.658200  0.915400  0.513900  0.964900\n",
      "real pepper  0.000000  0.000000  0.000000  0.000000  1.000000\n",
      "real grape   0.714300  0.833300  0.898500  0.777000  0.979900\n",
      "fake apple   0.000000  0.000000  0.000000  0.000000  0.983800\n",
      "fake pepper  0.000000  0.000000  0.000000  0.000000  0.993600\n",
      "fake grape   0.000000  0.000000  0.000000  0.000000  0.985500\n",
      "total        0.308557  0.352629  0.398657  0.324014  0.981086\n",
      "total(-bg)   0.200817  0.248583  0.302317  0.215150  0.984617\n",
      "\n",
      "Epoch: [142][0/16]\tTime 0.503 (0.503)\tETA 0:00:08\tTraining Loss 1.2209 (1.2209)\n",
      "\n",
      "Epoch: [142][1/16]\tTime 0.183 (0.685)\tETA 0:00:02\tTraining Loss 1.2223 (1.2216)\n",
      "\n",
      "Epoch: [142][2/16]\tTime 0.189 (0.874)\tETA 0:00:02\tTraining Loss 1.2200 (1.2211)\n",
      "\n",
      "Epoch: [142][3/16]\tTime 0.185 (1.059)\tETA 0:00:02\tTraining Loss 1.2229 (1.2215)\n",
      "\n",
      "Epoch: [142][4/16]\tTime 0.187 (1.246)\tETA 0:00:02\tTraining Loss 1.2190 (1.2210)\n",
      "\n",
      "Epoch: [142][5/16]\tTime 0.186 (1.432)\tETA 0:00:02\tTraining Loss 1.2165 (1.2203)\n",
      "\n",
      "Epoch: [142][6/16]\tTime 0.191 (1.624)\tETA 0:00:01\tTraining Loss 1.2229 (1.2206)\n",
      "\n",
      "Epoch: [142][7/16]\tTime 0.290 (1.913)\tETA 0:00:02\tTraining Loss 1.2187 (1.2204)\n",
      "\n",
      "Epoch: [142][8/16]\tTime 0.288 (2.201)\tETA 0:00:02\tTraining Loss 1.2175 (1.2201)\n",
      "\n",
      "Epoch: [142][9/16]\tTime 0.185 (2.387)\tETA 0:00:01\tTraining Loss 1.2201 (1.2201)\n",
      "\n",
      "Epoch: [142][10/16]\tTime 0.193 (2.579)\tETA 0:00:01\tTraining Loss 1.2191 (1.2200)\n",
      "\n",
      "Epoch: [142][11/16]\tTime 0.184 (2.764)\tETA 0:00:00\tTraining Loss 1.2177 (1.2198)\n",
      "\n",
      "Epoch: [142][12/16]\tTime 0.196 (2.960)\tETA 0:00:00\tTraining Loss 1.2273 (1.2204)\n",
      "\n",
      "Epoch: [142][13/16]\tTime 0.180 (3.139)\tETA 0:00:00\tTraining Loss 1.2172 (1.2202)\n",
      "\n",
      "Epoch: [142][14/16]\tTime 0.191 (3.331)\tETA 0:00:00\tTraining Loss 1.2188 (1.2201)\n",
      "\n",
      "Epoch: [142][15/16]\tTime 0.111 (3.442)\tETA 0:00:00\tTraining Loss 1.2235 (1.2202)\n",
      "_\n",
      "Validation stats                    IoU        F1      Prec    recall       Acc\n",
      "bg,          0.953000  0.975900  0.977500  0.974400  0.958200\n",
      "real apple   0.492300  0.659800  0.865600  0.533100  0.963900\n",
      "real pepper  0.000000  0.000000  0.000000  0.000000  1.000000\n",
      "real grape   0.751300  0.858000  0.899500  0.820200  0.982400\n",
      "fake apple   0.000000  0.000000  0.000000  0.000000  0.985100\n",
      "fake pepper  0.000000  0.000000  0.000000  0.000000  0.993700\n",
      "fake grape   0.000000  0.000000  0.000000  0.000000  0.987400\n",
      "total        0.313800  0.356243  0.391800  0.332529  0.981529\n",
      "total(-bg)   0.207267  0.252967  0.294183  0.225550  0.985417\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: [143][0/16]\tTime 0.473 (0.473)\tETA 0:00:07\tTraining Loss 1.2207 (1.2207)\n",
      "\n",
      "Epoch: [143][1/16]\tTime 0.180 (0.653)\tETA 0:00:02\tTraining Loss 1.2177 (1.2192)\n",
      "\n",
      "Epoch: [143][2/16]\tTime 0.194 (0.847)\tETA 0:00:02\tTraining Loss 1.2199 (1.2194)\n",
      "\n",
      "Epoch: [143][3/16]\tTime 0.209 (1.056)\tETA 0:00:02\tTraining Loss 1.2186 (1.2192)\n",
      "\n",
      "Epoch: [143][4/16]\tTime 0.166 (1.222)\tETA 0:00:01\tTraining Loss 1.2197 (1.2193)\n",
      "\n",
      "Epoch: [143][5/16]\tTime 0.184 (1.407)\tETA 0:00:02\tTraining Loss 1.2189 (1.2192)\n",
      "\n",
      "Epoch: [143][6/16]\tTime 0.181 (1.587)\tETA 0:00:01\tTraining Loss 1.2175 (1.2190)\n",
      "\n",
      "Epoch: [143][7/16]\tTime 0.193 (1.780)\tETA 0:00:01\tTraining Loss 1.2206 (1.2192)\n",
      "\n",
      "Epoch: [143][8/16]\tTime 0.190 (1.970)\tETA 0:00:01\tTraining Loss 1.2265 (1.2200)\n",
      "\n",
      "Epoch: [143][9/16]\tTime 0.188 (2.158)\tETA 0:00:01\tTraining Loss 1.2182 (1.2198)\n",
      "\n",
      "Epoch: [143][10/16]\tTime 0.188 (2.346)\tETA 0:00:01\tTraining Loss 1.2221 (1.2200)\n",
      "\n",
      "Epoch: [143][11/16]\tTime 0.182 (2.528)\tETA 0:00:00\tTraining Loss 1.2169 (1.2198)\n",
      "\n",
      "Epoch: [143][12/16]\tTime 0.188 (2.715)\tETA 0:00:00\tTraining Loss 1.2210 (1.2199)\n",
      "\n",
      "Epoch: [143][13/16]\tTime 0.188 (2.903)\tETA 0:00:00\tTraining Loss 1.2167 (1.2196)\n",
      "\n",
      "Epoch: [143][14/16]\tTime 0.178 (3.081)\tETA 0:00:00\tTraining Loss 1.2196 (1.2196)\n",
      "\n",
      "Epoch: [143][15/16]\tTime 0.117 (3.197)\tETA 0:00:00\tTraining Loss 1.2283 (1.2199)\n",
      "_\n",
      "Validation stats                    IoU        F1      Prec    recall       Acc\n",
      "bg,          0.950000  0.974300  0.976400  0.972300  0.955500\n",
      "real apple   0.487600  0.655500  0.882500  0.521500  0.964000\n",
      "real pepper  0.000000  0.000000  0.000000  0.000000  1.000000\n",
      "real grape   0.777400  0.874700  0.925300  0.829400  0.984600\n",
      "fake apple   0.000000  0.000000  0.000000  0.000000  0.984100\n",
      "fake pepper  0.000000  0.000000  0.000000  0.000000  0.990200\n",
      "fake grape   0.000000  0.000000  0.000000  0.000000  0.988400\n",
      "total        0.316429  0.357786  0.397743  0.331886  0.980971\n",
      "total(-bg)   0.210833  0.255033  0.301300  0.225150  0.985217\n",
      "\n",
      "Epoch: [144][0/16]\tTime 0.476 (0.476)\tETA 0:00:07\tTraining Loss 1.2230 (1.2230)\n",
      "\n",
      "Epoch: [144][1/16]\tTime 0.184 (0.660)\tETA 0:00:02\tTraining Loss 1.2210 (1.2220)\n",
      "\n",
      "Epoch: [144][2/16]\tTime 0.191 (0.851)\tETA 0:00:02\tTraining Loss 1.2170 (1.2203)\n",
      "\n",
      "Epoch: [144][3/16]\tTime 0.177 (1.028)\tETA 0:00:02\tTraining Loss 1.2168 (1.2195)\n",
      "\n",
      "Epoch: [144][4/16]\tTime 0.190 (1.218)\tETA 0:00:02\tTraining Loss 1.2215 (1.2199)\n",
      "\n",
      "Epoch: [144][5/16]\tTime 0.195 (1.414)\tETA 0:00:02\tTraining Loss 1.2179 (1.2195)\n",
      "\n",
      "Epoch: [144][6/16]\tTime 0.188 (1.601)\tETA 0:00:01\tTraining Loss 1.2208 (1.2197)\n",
      "\n",
      "Epoch: [144][7/16]\tTime 0.191 (1.792)\tETA 0:00:01\tTraining Loss 1.2180 (1.2195)\n",
      "\n",
      "Epoch: [144][8/16]\tTime 0.184 (1.976)\tETA 0:00:01\tTraining Loss 1.2177 (1.2193)\n",
      "\n",
      "Epoch: [144][9/16]\tTime 0.185 (2.161)\tETA 0:00:01\tTraining Loss 1.2181 (1.2192)\n",
      "\n",
      "Epoch: [144][10/16]\tTime 0.193 (2.354)\tETA 0:00:01\tTraining Loss 1.2175 (1.2190)\n",
      "\n",
      "Epoch: [144][11/16]\tTime 0.191 (2.545)\tETA 0:00:00\tTraining Loss 1.2157 (1.2187)\n",
      "\n",
      "Epoch: [144][12/16]\tTime 0.190 (2.735)\tETA 0:00:00\tTraining Loss 1.2237 (1.2191)\n",
      "\n",
      "Epoch: [144][13/16]\tTime 0.183 (2.918)\tETA 0:00:00\tTraining Loss 1.2181 (1.2191)\n",
      "\n",
      "Epoch: [144][14/16]\tTime 0.184 (3.103)\tETA 0:00:00\tTraining Loss 1.2155 (1.2188)\n",
      "\n",
      "Epoch: [144][15/16]\tTime 0.115 (3.218)\tETA 0:00:00\tTraining Loss 1.2196 (1.2188)\n",
      "_\n",
      "Validation stats                    IoU        F1      Prec  recall       Acc\n",
      "bg,          0.952100  0.975400  0.978300  0.9727  0.957500\n",
      "real apple   0.481500  0.649900  0.888500  0.5124  0.963700\n",
      "real pepper  0.000000  0.000000  0.000000  0.0000  0.999700\n",
      "real grape   0.720200  0.837300  0.893600  0.7878  0.980200\n",
      "fake apple   0.000000  0.000000  0.000000  0.0000  0.982100\n",
      "fake pepper  0.000000  0.000000  0.000000  0.0000  0.992200\n",
      "fake grape   0.000000  0.000000  0.000000  0.0000  0.985500\n",
      "total        0.307686  0.351800  0.394343  0.3247  0.980129\n",
      "total(-bg)   0.200283  0.247867  0.297017  0.2167  0.983900\n",
      "\n",
      "Epoch: [145][0/16]\tTime 0.343 (0.343)\tETA 0:00:05\tTraining Loss 1.2182 (1.2182)\n",
      "\n",
      "Epoch: [145][1/16]\tTime 0.194 (0.537)\tETA 0:00:02\tTraining Loss 1.2169 (1.2175)\n",
      "\n",
      "Epoch: [145][2/16]\tTime 0.184 (0.722)\tETA 0:00:02\tTraining Loss 1.2162 (1.2171)\n",
      "\n",
      "Epoch: [145][3/16]\tTime 0.188 (0.910)\tETA 0:00:02\tTraining Loss 1.2205 (1.2179)\n",
      "\n",
      "Epoch: [145][4/16]\tTime 0.180 (1.090)\tETA 0:00:02\tTraining Loss 1.2163 (1.2176)\n",
      "\n",
      "Epoch: [145][5/16]\tTime 0.192 (1.282)\tETA 0:00:02\tTraining Loss 1.2166 (1.2175)\n",
      "\n",
      "Epoch: [145][6/16]\tTime 0.181 (1.464)\tETA 0:00:01\tTraining Loss 1.2158 (1.2172)\n",
      "\n",
      "Epoch: [145][7/16]\tTime 0.206 (1.670)\tETA 0:00:01\tTraining Loss 1.2181 (1.2173)\n",
      "\n",
      "Epoch: [145][8/16]\tTime 0.186 (1.856)\tETA 0:00:01\tTraining Loss 1.2217 (1.2178)\n",
      "\n",
      "Epoch: [145][9/16]\tTime 0.178 (2.034)\tETA 0:00:01\tTraining Loss 1.2157 (1.2176)\n",
      "\n",
      "Epoch: [145][10/16]\tTime 0.193 (2.227)\tETA 0:00:01\tTraining Loss 1.2174 (1.2176)\n",
      "\n",
      "Epoch: [145][11/16]\tTime 0.192 (2.419)\tETA 0:00:00\tTraining Loss 1.2180 (1.2176)\n",
      "\n",
      "Epoch: [145][12/16]\tTime 0.180 (2.599)\tETA 0:00:00\tTraining Loss 1.2160 (1.2175)\n",
      "\n",
      "Epoch: [145][13/16]\tTime 0.187 (2.785)\tETA 0:00:00\tTraining Loss 1.2168 (1.2175)\n",
      "\n",
      "Epoch: [145][14/16]\tTime 0.187 (2.973)\tETA 0:00:00\tTraining Loss 1.2204 (1.2176)\n",
      "\n",
      "Epoch: [145][15/16]\tTime 0.115 (3.088)\tETA 0:00:00\tTraining Loss 1.2783 (1.2196)\n",
      "_\n",
      "Validation stats                    IoU        F1      Prec    recall       Acc\n",
      "bg,          0.950000  0.974300  0.977600  0.971100  0.955600\n",
      "real apple   0.166600  0.285500  0.871400  0.170800  0.943800\n",
      "real pepper  0.000000  0.000000  0.000000  0.000000  0.998800\n",
      "real grape   0.805600  0.892300  0.890500  0.894200  0.986000\n",
      "fake apple   0.000000  0.000000  0.000000  0.000000  0.967500\n",
      "fake pepper  0.000000  0.000000  0.000000  0.000000  0.983100\n",
      "fake grape   0.000000  0.000000  0.000000  0.000000  0.992300\n",
      "total        0.274600  0.307443  0.391357  0.290871  0.975300\n",
      "total(-bg)   0.162033  0.196300  0.293650  0.177500  0.978583\n",
      "\n",
      "Epoch: [146][0/16]\tTime 0.404 (0.404)\tETA 0:00:06\tTraining Loss 1.2176 (1.2176)\n",
      "\n",
      "Epoch: [146][1/16]\tTime 0.182 (0.586)\tETA 0:00:02\tTraining Loss 1.2186 (1.2181)\n",
      "\n",
      "Epoch: [146][2/16]\tTime 0.186 (0.772)\tETA 0:00:02\tTraining Loss 1.2227 (1.2196)\n",
      "\n",
      "Epoch: [146][3/16]\tTime 0.190 (0.962)\tETA 0:00:02\tTraining Loss 1.2226 (1.2204)\n",
      "\n",
      "Epoch: [146][4/16]\tTime 0.188 (1.150)\tETA 0:00:02\tTraining Loss 1.2178 (1.2199)\n",
      "\n",
      "Epoch: [146][5/16]\tTime 0.178 (1.328)\tETA 0:00:01\tTraining Loss 1.2258 (1.2208)\n",
      "\n",
      "Epoch: [146][6/16]\tTime 0.191 (1.519)\tETA 0:00:01\tTraining Loss 1.2276 (1.2218)\n",
      "\n",
      "Epoch: [146][7/16]\tTime 0.185 (1.704)\tETA 0:00:01\tTraining Loss 1.2202 (1.2216)\n",
      "\n",
      "Epoch: [146][8/16]\tTime 0.187 (1.891)\tETA 0:00:01\tTraining Loss 1.2223 (1.2217)\n",
      "\n",
      "Epoch: [146][9/16]\tTime 0.186 (2.077)\tETA 0:00:01\tTraining Loss 1.2187 (1.2214)\n",
      "\n",
      "Epoch: [146][10/16]\tTime 0.198 (2.275)\tETA 0:00:01\tTraining Loss 1.2179 (1.2211)\n",
      "\n",
      "Epoch: [146][11/16]\tTime 0.184 (2.459)\tETA 0:00:00\tTraining Loss 1.2257 (1.2215)\n",
      "\n",
      "Epoch: [146][12/16]\tTime 0.189 (2.648)\tETA 0:00:00\tTraining Loss 1.2209 (1.2214)\n",
      "\n",
      "Epoch: [146][13/16]\tTime 0.178 (2.827)\tETA 0:00:00\tTraining Loss 1.2231 (1.2215)\n",
      "\n",
      "Epoch: [146][14/16]\tTime 0.199 (3.025)\tETA 0:00:00\tTraining Loss 1.2206 (1.2215)\n",
      "\n",
      "Epoch: [146][15/16]\tTime 0.118 (3.143)\tETA 0:00:00\tTraining Loss 1.2246 (1.2216)\n",
      "_\n",
      "Validation stats                    IoU        F1      Prec    recall       Acc\n",
      "bg,          0.955200  0.977000  0.975500  0.978700  0.960100\n",
      "real apple   0.437000  0.608200  0.882500  0.464000  0.960700\n",
      "real pepper  0.000000  0.000000  0.000000  0.000000  0.995100\n",
      "real grape   0.469900  0.639300  0.887200  0.499700  0.963500\n",
      "fake apple   0.000000  0.000000  0.000000  0.000000  0.986000\n",
      "fake pepper  0.000000  0.000000  0.000000  0.000000  0.999400\n",
      "fake grape   0.000000  0.000000  0.000000  0.000000  0.962900\n",
      "total        0.266014  0.317786  0.392171  0.277486  0.975386\n",
      "total(-bg)   0.151150  0.207917  0.294950  0.160617  0.977933\n",
      "\n",
      "Epoch: [147][0/16]\tTime 0.507 (0.507)\tETA 0:00:08\tTraining Loss 1.2234 (1.2234)\n",
      "\n",
      "Epoch: [147][1/16]\tTime 0.151 (0.658)\tETA 0:00:02\tTraining Loss 1.2189 (1.2212)\n",
      "\n",
      "Epoch: [147][2/16]\tTime 0.189 (0.847)\tETA 0:00:02\tTraining Loss 1.2211 (1.2211)\n",
      "\n",
      "Epoch: [147][3/16]\tTime 0.192 (1.038)\tETA 0:00:02\tTraining Loss 1.2342 (1.2244)\n",
      "\n",
      "Epoch: [147][4/16]\tTime 0.187 (1.225)\tETA 0:00:02\tTraining Loss 1.2172 (1.2230)\n",
      "\n",
      "Epoch: [147][5/16]\tTime 0.185 (1.410)\tETA 0:00:02\tTraining Loss 1.2198 (1.2224)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: [147][6/16]\tTime 0.203 (1.613)\tETA 0:00:02\tTraining Loss 1.2192 (1.2220)\n",
      "\n",
      "Epoch: [147][7/16]\tTime 0.189 (1.802)\tETA 0:00:01\tTraining Loss 1.2221 (1.2220)\n",
      "\n",
      "Epoch: [147][8/16]\tTime 0.193 (1.995)\tETA 0:00:01\tTraining Loss 1.2222 (1.2220)\n",
      "\n",
      "Epoch: [147][9/16]\tTime 0.174 (2.169)\tETA 0:00:01\tTraining Loss 1.2196 (1.2218)\n",
      "\n",
      "Epoch: [147][10/16]\tTime 0.193 (2.362)\tETA 0:00:01\tTraining Loss 1.2250 (1.2221)\n",
      "\n",
      "Epoch: [147][11/16]\tTime 0.180 (2.542)\tETA 0:00:00\tTraining Loss 1.2199 (1.2219)\n",
      "\n",
      "Epoch: [147][12/16]\tTime 0.188 (2.731)\tETA 0:00:00\tTraining Loss 1.2198 (1.2217)\n",
      "\n",
      "Epoch: [147][13/16]\tTime 0.183 (2.913)\tETA 0:00:00\tTraining Loss 1.2212 (1.2217)\n",
      "\n",
      "Epoch: [147][14/16]\tTime 0.187 (3.101)\tETA 0:00:00\tTraining Loss 1.2225 (1.2217)\n",
      "\n",
      "Epoch: [147][15/16]\tTime 0.112 (3.213)\tETA 0:00:00\tTraining Loss 1.2264 (1.2219)\n",
      "_\n",
      "Validation stats                    IoU        F1      Prec    recall       Acc\n",
      "bg,          0.957700  0.978400  0.975300  0.981500  0.962300\n",
      "real apple   0.464000  0.633800  0.916900  0.484300  0.963200\n",
      "real pepper  0.000000  0.000000  0.000000  0.000000  1.000000\n",
      "real grape   0.641400  0.781500  0.876400  0.705200  0.974500\n",
      "fake apple   0.000000  0.000000  0.000000  0.000000  0.983500\n",
      "fake pepper  0.000000  0.000000  0.000000  0.000000  0.998500\n",
      "fake grape   0.000000  0.000000  0.000000  0.000000  0.979900\n",
      "total        0.294729  0.341957  0.395514  0.310143  0.980271\n",
      "total(-bg)   0.184233  0.235883  0.298883  0.198250  0.983267\n",
      "\n",
      "Epoch: [148][0/16]\tTime 0.434 (0.434)\tETA 0:00:06\tTraining Loss 1.2177 (1.2177)\n",
      "\n",
      "Epoch: [148][1/16]\tTime 0.179 (0.613)\tETA 0:00:02\tTraining Loss 1.2230 (1.2204)\n",
      "\n",
      "Epoch: [148][2/16]\tTime 0.182 (0.795)\tETA 0:00:02\tTraining Loss 1.2270 (1.2226)\n",
      "\n",
      "Epoch: [148][3/16]\tTime 0.183 (0.978)\tETA 0:00:02\tTraining Loss 1.2316 (1.2248)\n",
      "\n",
      "Epoch: [148][4/16]\tTime 0.188 (1.166)\tETA 0:00:02\tTraining Loss 1.2188 (1.2236)\n",
      "\n",
      "Epoch: [148][5/16]\tTime 0.180 (1.346)\tETA 0:00:01\tTraining Loss 1.2175 (1.2226)\n",
      "\n",
      "Epoch: [148][6/16]\tTime 0.187 (1.533)\tETA 0:00:01\tTraining Loss 1.2200 (1.2223)\n",
      "\n",
      "Epoch: [148][7/16]\tTime 0.193 (1.726)\tETA 0:00:01\tTraining Loss 1.2185 (1.2218)\n",
      "\n",
      "Epoch: [148][8/16]\tTime 0.189 (1.915)\tETA 0:00:01\tTraining Loss 1.2219 (1.2218)\n",
      "\n",
      "Epoch: [148][9/16]\tTime 0.182 (2.097)\tETA 0:00:01\tTraining Loss 1.2203 (1.2216)\n",
      "\n",
      "Epoch: [148][10/16]\tTime 0.188 (2.285)\tETA 0:00:01\tTraining Loss 1.2238 (1.2218)\n",
      "\n",
      "Epoch: [148][11/16]\tTime 0.181 (2.466)\tETA 0:00:00\tTraining Loss 1.2161 (1.2214)\n",
      "\n",
      "Epoch: [148][12/16]\tTime 0.184 (2.650)\tETA 0:00:00\tTraining Loss 1.2167 (1.2210)\n",
      "\n",
      "Epoch: [148][13/16]\tTime 0.185 (2.836)\tETA 0:00:00\tTraining Loss 1.2374 (1.2222)\n",
      "\n",
      "Epoch: [148][14/16]\tTime 0.181 (3.017)\tETA 0:00:00\tTraining Loss 1.2213 (1.2221)\n",
      "\n",
      "Epoch: [148][15/16]\tTime 0.116 (3.133)\tETA 0:00:00\tTraining Loss 1.2310 (1.2224)\n",
      "_\n",
      "Validation stats                    IoU        F1      Prec    recall       Acc\n",
      "bg,          0.946300  0.972400  0.973700  0.971100  0.952100\n",
      "real apple   0.603200  0.752400  0.826900  0.690400  0.970200\n",
      "real pepper  0.000000  0.000000  0.000000  0.000000  0.995800\n",
      "real grape   0.441300  0.612300  0.883400  0.468600  0.961600\n",
      "fake apple   0.000000  0.000000  0.000000  0.000000  0.983400\n",
      "fake pepper  0.000000  0.000000  0.000000  0.000000  0.999200\n",
      "fake grape   0.000000  0.000000  0.000000  0.000000  0.978000\n",
      "total        0.284400  0.333871  0.383429  0.304300  0.977186\n",
      "total(-bg)   0.174083  0.227450  0.285050  0.193167  0.981367\n",
      "\n",
      "Epoch: [149][0/16]\tTime 0.480 (0.480)\tETA 0:00:07\tTraining Loss 1.2179 (1.2179)\n",
      "\n",
      "Epoch: [149][1/16]\tTime 0.168 (0.648)\tETA 0:00:02\tTraining Loss 1.2210 (1.2194)\n",
      "\n",
      "Epoch: [149][2/16]\tTime 0.188 (0.836)\tETA 0:00:02\tTraining Loss 1.2177 (1.2189)\n",
      "\n",
      "Epoch: [149][3/16]\tTime 0.194 (1.029)\tETA 0:00:02\tTraining Loss 1.2239 (1.2201)\n",
      "\n",
      "Epoch: [149][4/16]\tTime 0.187 (1.217)\tETA 0:00:02\tTraining Loss 1.2185 (1.2198)\n",
      "\n",
      "Epoch: [149][5/16]\tTime 0.187 (1.403)\tETA 0:00:02\tTraining Loss 1.2197 (1.2198)\n",
      "\n",
      "Epoch: [149][6/16]\tTime 0.204 (1.607)\tETA 0:00:02\tTraining Loss 1.2258 (1.2206)\n",
      "\n",
      "Epoch: [149][7/16]\tTime 0.186 (1.793)\tETA 0:00:01\tTraining Loss 1.2182 (1.2203)\n",
      "\n",
      "Epoch: [149][8/16]\tTime 0.190 (1.984)\tETA 0:00:01\tTraining Loss 1.2207 (1.2204)\n",
      "\n",
      "Epoch: [149][9/16]\tTime 0.186 (2.170)\tETA 0:00:01\tTraining Loss 1.2215 (1.2205)\n",
      "\n",
      "Epoch: [149][10/16]\tTime 0.183 (2.352)\tETA 0:00:01\tTraining Loss 1.2175 (1.2202)\n",
      "\n",
      "Epoch: [149][11/16]\tTime 0.197 (2.549)\tETA 0:00:00\tTraining Loss 1.2193 (1.2201)\n",
      "\n",
      "Epoch: [149][12/16]\tTime 0.188 (2.737)\tETA 0:00:00\tTraining Loss 1.2219 (1.2203)\n",
      "\n",
      "Epoch: [149][13/16]\tTime 0.182 (2.920)\tETA 0:00:00\tTraining Loss 1.2273 (1.2208)\n",
      "\n",
      "Epoch: [149][14/16]\tTime 0.189 (3.108)\tETA 0:00:00\tTraining Loss 1.2183 (1.2206)\n",
      "\n",
      "Epoch: [149][15/16]\tTime 0.111 (3.219)\tETA 0:00:00\tTraining Loss 1.2179 (1.2205)\n",
      "_\n",
      "Validation stats                    IoU        F1    Prec  recall       Acc\n",
      "bg,          0.953000  0.975900  0.9728  0.9791  0.958000\n",
      "real apple   0.302300  0.464300  0.9428  0.3080  0.953300\n",
      "real pepper  0.000000  0.000000  0.0000  0.0000  1.000000\n",
      "real grape   0.068300  0.127900  0.9040  0.0688  0.939200\n",
      "fake apple   0.000000  0.000000  0.0000  0.0000  0.944900\n",
      "fake pepper  0.000000  0.000000  0.0000  0.0000  0.994900\n",
      "fake grape   0.000000  0.000000  0.0000  0.0000  0.961800\n",
      "total        0.189086  0.224014  0.4028  0.1937  0.964586\n",
      "total(-bg)   0.061767  0.098700  0.3078  0.0628  0.965683\n",
      "\n",
      "Epoch: [150][0/16]\tTime 0.503 (0.503)\tETA 0:00:08\tTraining Loss 1.2255 (1.2255)\n",
      "\n",
      "Epoch: [150][1/16]\tTime 0.192 (0.695)\tETA 0:00:02\tTraining Loss 1.2162 (1.2208)\n",
      "\n",
      "Epoch: [150][2/16]\tTime 0.184 (0.879)\tETA 0:00:02\tTraining Loss 1.2242 (1.2219)\n",
      "\n",
      "Epoch: [150][3/16]\tTime 0.192 (1.071)\tETA 0:00:02\tTraining Loss 1.2217 (1.2219)\n",
      "\n",
      "Epoch: [150][4/16]\tTime 0.192 (1.264)\tETA 0:00:02\tTraining Loss 1.2211 (1.2217)\n",
      "\n",
      "Epoch: [150][5/16]\tTime 0.184 (1.448)\tETA 0:00:02\tTraining Loss 1.2179 (1.2211)\n",
      "\n",
      "Epoch: [150][6/16]\tTime 0.196 (1.644)\tETA 0:00:01\tTraining Loss 1.2301 (1.2224)\n",
      "\n",
      "Epoch: [150][7/16]\tTime 0.197 (1.841)\tETA 0:00:01\tTraining Loss 1.2219 (1.2223)\n",
      "\n",
      "Epoch: [150][8/16]\tTime 0.191 (2.032)\tETA 0:00:01\tTraining Loss 1.2166 (1.2217)\n",
      "\n",
      "Epoch: [150][9/16]\tTime 0.192 (2.225)\tETA 0:00:01\tTraining Loss 1.2235 (1.2219)\n",
      "\n",
      "Epoch: [150][10/16]\tTime 0.195 (2.419)\tETA 0:00:01\tTraining Loss 1.2363 (1.2232)\n",
      "\n",
      "Epoch: [150][11/16]\tTime 0.200 (2.620)\tETA 0:00:01\tTraining Loss 1.2404 (1.2246)\n",
      "\n",
      "Epoch: [150][12/16]\tTime 0.183 (2.803)\tETA 0:00:00\tTraining Loss 1.2146 (1.2238)\n",
      "\n",
      "Epoch: [150][13/16]\tTime 0.198 (3.001)\tETA 0:00:00\tTraining Loss 1.2215 (1.2237)\n",
      "\n",
      "Epoch: [150][14/16]\tTime 0.192 (3.193)\tETA 0:00:00\tTraining Loss 1.2316 (1.2242)\n",
      "\n",
      "Epoch: [150][15/16]\tTime 0.118 (3.311)\tETA 0:00:00\tTraining Loss 1.2229 (1.2242)\n",
      "_\n",
      "Validation stats                    IoU        F1      Prec    recall       Acc\n",
      "bg,          0.941200  0.969700  0.976800  0.962800  0.947700\n",
      "real apple   0.483400  0.651700  0.864500  0.523000  0.963300\n",
      "real pepper  0.000000  0.000000  0.000000  0.000000  0.996200\n",
      "real grape   0.701200  0.824300  0.851800  0.798600  0.978000\n",
      "fake apple   0.000000  0.000000  0.000000  0.000000  0.975700\n",
      "fake pepper  0.000000  0.000000  0.000000  0.000000  0.994900\n",
      "fake grape   0.000000  0.000000  0.000000  0.000000  0.990700\n",
      "total        0.303686  0.349386  0.384729  0.326343  0.978071\n",
      "total(-bg)   0.197433  0.246000  0.286050  0.220267  0.983133\n",
      "\n",
      "Epoch: [151][0/16]\tTime 0.476 (0.476)\tETA 0:00:07\tTraining Loss 1.2248 (1.2248)\n",
      "\n",
      "Epoch: [151][1/16]\tTime 0.193 (0.669)\tETA 0:00:02\tTraining Loss 1.2267 (1.2257)\n",
      "\n",
      "Epoch: [151][2/16]\tTime 0.188 (0.857)\tETA 0:00:02\tTraining Loss 1.2316 (1.2277)\n",
      "\n",
      "Epoch: [151][3/16]\tTime 0.185 (1.042)\tETA 0:00:02\tTraining Loss 1.2253 (1.2271)\n",
      "\n",
      "Epoch: [151][4/16]\tTime 0.184 (1.226)\tETA 0:00:02\tTraining Loss 1.2171 (1.2251)\n",
      "\n",
      "Epoch: [151][5/16]\tTime 0.186 (1.412)\tETA 0:00:02\tTraining Loss 1.2172 (1.2238)\n",
      "\n",
      "Epoch: [151][6/16]\tTime 0.185 (1.597)\tETA 0:00:01\tTraining Loss 1.2234 (1.2237)\n",
      "\n",
      "Epoch: [151][7/16]\tTime 0.185 (1.782)\tETA 0:00:01\tTraining Loss 1.2257 (1.2240)\n",
      "\n",
      "Epoch: [151][8/16]\tTime 0.185 (1.967)\tETA 0:00:01\tTraining Loss 1.2222 (1.2238)\n",
      "\n",
      "Epoch: [151][9/16]\tTime 0.186 (2.152)\tETA 0:00:01\tTraining Loss 1.2211 (1.2235)\n",
      "\n",
      "Epoch: [151][10/16]\tTime 0.189 (2.342)\tETA 0:00:01\tTraining Loss 1.2255 (1.2237)\n",
      "\n",
      "Epoch: [151][11/16]\tTime 0.191 (2.532)\tETA 0:00:00\tTraining Loss 1.2181 (1.2232)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: [151][12/16]\tTime 0.200 (2.733)\tETA 0:00:00\tTraining Loss 1.2244 (1.2233)\n",
      "\n",
      "Epoch: [151][13/16]\tTime 0.292 (3.025)\tETA 0:00:00\tTraining Loss 1.2241 (1.2234)\n",
      "\n",
      "Epoch: [151][14/16]\tTime 0.222 (3.247)\tETA 0:00:00\tTraining Loss 1.2132 (1.2227)\n",
      "\n",
      "Epoch: [151][15/16]\tTime 0.123 (3.369)\tETA 0:00:00\tTraining Loss 1.2217 (1.2227)\n",
      "_\n",
      "Validation stats                    IoU        F1      Prec    recall       Acc\n",
      "bg,          0.951400  0.975000  0.975400  0.974800  0.956700\n",
      "real apple   0.453700  0.624200  0.754400  0.532400  0.957900\n",
      "real pepper  0.000000  0.000000  0.000000  0.000000  0.996200\n",
      "real grape   0.668500  0.801300  0.887700  0.730300  0.976600\n",
      "fake apple   0.000000  0.000000  0.000000  0.000000  0.976300\n",
      "fake pepper  0.000000  0.000000  0.000000  0.000000  0.999800\n",
      "fake grape   0.000000  0.000000  0.000000  0.000000  0.996400\n",
      "total        0.296229  0.342929  0.373929  0.319643  0.979986\n",
      "total(-bg)   0.187033  0.237583  0.273683  0.210450  0.983867\n",
      "\n",
      "Epoch: [152][0/16]\tTime 0.438 (0.438)\tETA 0:00:07\tTraining Loss 1.2209 (1.2209)\n",
      "\n",
      "Epoch: [152][1/16]\tTime 0.184 (0.623)\tETA 0:00:02\tTraining Loss 1.2188 (1.2198)\n",
      "\n",
      "Epoch: [152][2/16]\tTime 0.190 (0.812)\tETA 0:00:02\tTraining Loss 1.2153 (1.2183)\n",
      "\n",
      "Epoch: [152][3/16]\tTime 0.189 (1.002)\tETA 0:00:02\tTraining Loss 1.2165 (1.2179)\n",
      "\n",
      "Epoch: [152][4/16]\tTime 0.180 (1.182)\tETA 0:00:02\tTraining Loss 1.2169 (1.2177)\n",
      "\n",
      "Epoch: [152][5/16]\tTime 0.188 (1.369)\tETA 0:00:02\tTraining Loss 1.2138 (1.2170)\n",
      "\n",
      "Epoch: [152][6/16]\tTime 0.190 (1.559)\tETA 0:00:01\tTraining Loss 1.2208 (1.2176)\n",
      "\n",
      "Epoch: [152][7/16]\tTime 0.183 (1.742)\tETA 0:00:01\tTraining Loss 1.2152 (1.2173)\n",
      "\n",
      "Epoch: [152][8/16]\tTime 0.182 (1.924)\tETA 0:00:01\tTraining Loss 1.2119 (1.2167)\n",
      "\n",
      "Epoch: [152][9/16]\tTime 0.190 (2.114)\tETA 0:00:01\tTraining Loss 1.2162 (1.2166)\n",
      "\n",
      "Epoch: [152][10/16]\tTime 0.185 (2.299)\tETA 0:00:01\tTraining Loss 1.2260 (1.2175)\n",
      "\n",
      "Epoch: [152][11/16]\tTime 0.184 (2.483)\tETA 0:00:00\tTraining Loss 1.2130 (1.2171)\n",
      "\n",
      "Epoch: [152][12/16]\tTime 0.193 (2.675)\tETA 0:00:00\tTraining Loss 1.2240 (1.2176)\n",
      "\n",
      "Epoch: [152][13/16]\tTime 0.181 (2.857)\tETA 0:00:00\tTraining Loss 1.2154 (1.2175)\n",
      "\n",
      "Epoch: [152][14/16]\tTime 0.190 (3.046)\tETA 0:00:00\tTraining Loss 1.2145 (1.2173)\n",
      "\n",
      "Epoch: [152][15/16]\tTime 0.111 (3.158)\tETA 0:00:00\tTraining Loss 1.2249 (1.2175)\n",
      "_\n",
      "Validation stats                    IoU        F1      Prec    recall       Acc\n",
      "bg,          0.945800  0.972100  0.976200  0.968100  0.951800\n",
      "real apple   0.253800  0.404800  0.685700  0.287200  0.944500\n",
      "real pepper  0.000000  0.000000  0.000000  0.000000  0.999800\n",
      "real grape   0.539900  0.701100  0.921700  0.565800  0.968800\n",
      "fake apple   0.000000  0.000000  0.000000  0.000000  0.967500\n",
      "fake pepper  0.000000  0.000000  0.000000  0.000000  0.994900\n",
      "fake grape   0.000000  0.000000  0.000000  0.000000  0.967400\n",
      "total        0.248500  0.296857  0.369086  0.260157  0.970671\n",
      "total(-bg)   0.132283  0.184317  0.267900  0.142167  0.973817\n",
      "\n",
      "Epoch: [153][0/16]\tTime 0.459 (0.459)\tETA 0:00:07\tTraining Loss 1.2140 (1.2140)\n",
      "\n",
      "Epoch: [153][1/16]\tTime 0.181 (0.640)\tETA 0:00:02\tTraining Loss 1.2164 (1.2152)\n",
      "\n",
      "Epoch: [153][2/16]\tTime 0.188 (0.827)\tETA 0:00:02\tTraining Loss 1.2171 (1.2158)\n",
      "\n",
      "Epoch: [153][3/16]\tTime 0.187 (1.014)\tETA 0:00:02\tTraining Loss 1.2136 (1.2152)\n",
      "\n",
      "Epoch: [153][4/16]\tTime 0.184 (1.198)\tETA 0:00:02\tTraining Loss 1.2195 (1.2161)\n",
      "\n",
      "Epoch: [153][5/16]\tTime 0.188 (1.386)\tETA 0:00:02\tTraining Loss 1.2269 (1.2179)\n",
      "\n",
      "Epoch: [153][6/16]\tTime 0.185 (1.570)\tETA 0:00:01\tTraining Loss 1.2122 (1.2171)\n",
      "\n",
      "Epoch: [153][7/16]\tTime 0.188 (1.758)\tETA 0:00:01\tTraining Loss 1.2142 (1.2167)\n",
      "\n",
      "Epoch: [153][8/16]\tTime 0.175 (1.934)\tETA 0:00:01\tTraining Loss 1.2155 (1.2166)\n",
      "\n",
      "Epoch: [153][9/16]\tTime 0.187 (2.121)\tETA 0:00:01\tTraining Loss 1.2160 (1.2165)\n",
      "\n",
      "Epoch: [153][10/16]\tTime 0.182 (2.303)\tETA 0:00:01\tTraining Loss 1.2133 (1.2162)\n",
      "\n",
      "Epoch: [153][11/16]\tTime 0.184 (2.488)\tETA 0:00:00\tTraining Loss 1.2135 (1.2160)\n",
      "\n",
      "Epoch: [153][12/16]\tTime 0.194 (2.681)\tETA 0:00:00\tTraining Loss 1.2148 (1.2159)\n",
      "\n",
      "Epoch: [153][13/16]\tTime 0.185 (2.866)\tETA 0:00:00\tTraining Loss 1.2148 (1.2158)\n",
      "\n",
      "Epoch: [153][14/16]\tTime 0.184 (3.050)\tETA 0:00:00\tTraining Loss 1.2157 (1.2158)\n",
      "\n",
      "Epoch: [153][15/16]\tTime 0.115 (3.165)\tETA 0:00:00\tTraining Loss 1.2143 (1.2158)\n",
      "_\n",
      "Validation stats                    IoU        F1      Prec  recall       Acc\n",
      "bg,          0.946200  0.972300  0.976900  0.9679  0.952200\n",
      "real apple   0.471200  0.640600  0.797000  0.5355  0.960500\n",
      "real pepper  0.000000  0.000000  0.000000  0.0000  1.000000\n",
      "real grape   0.711800  0.831600  0.899000  0.7737  0.979700\n",
      "fake apple   0.000000  0.000000  0.000000  0.0000  0.984700\n",
      "fake pepper  0.000000  0.000000  0.000000  0.0000  0.992600\n",
      "fake grape   0.000000  0.000000  0.000000  0.0000  0.984200\n",
      "total        0.304171  0.349214  0.381843  0.3253  0.979129\n",
      "total(-bg)   0.197167  0.245367  0.282667  0.2182  0.983617\n",
      "\n",
      "Epoch: [154][0/16]\tTime 0.473 (0.473)\tETA 0:00:07\tTraining Loss 1.2139 (1.2139)\n",
      "\n",
      "Epoch: [154][1/16]\tTime 0.189 (0.662)\tETA 0:00:02\tTraining Loss 1.2121 (1.2130)\n",
      "\n",
      "Epoch: [154][2/16]\tTime 0.192 (0.854)\tETA 0:00:02\tTraining Loss 1.2121 (1.2127)\n",
      "\n",
      "Epoch: [154][3/16]\tTime 0.182 (1.035)\tETA 0:00:02\tTraining Loss 1.2122 (1.2126)\n",
      "\n",
      "Epoch: [154][4/16]\tTime 0.190 (1.225)\tETA 0:00:02\tTraining Loss 1.2140 (1.2128)\n",
      "\n",
      "Epoch: [154][5/16]\tTime 0.181 (1.407)\tETA 0:00:01\tTraining Loss 1.2160 (1.2134)\n",
      "\n",
      "Epoch: [154][6/16]\tTime 0.185 (1.591)\tETA 0:00:01\tTraining Loss 1.2167 (1.2139)\n",
      "\n",
      "Epoch: [154][7/16]\tTime 0.190 (1.782)\tETA 0:00:01\tTraining Loss 1.2158 (1.2141)\n",
      "\n",
      "Epoch: [154][8/16]\tTime 0.185 (1.967)\tETA 0:00:01\tTraining Loss 1.2173 (1.2145)\n",
      "\n",
      "Epoch: [154][9/16]\tTime 0.182 (2.148)\tETA 0:00:01\tTraining Loss 1.2167 (1.2147)\n",
      "\n",
      "Epoch: [154][10/16]\tTime 0.190 (2.338)\tETA 0:00:01\tTraining Loss 1.2156 (1.2148)\n",
      "\n",
      "Epoch: [154][11/16]\tTime 0.181 (2.519)\tETA 0:00:00\tTraining Loss 1.2120 (1.2145)\n",
      "\n",
      "Epoch: [154][12/16]\tTime 0.188 (2.708)\tETA 0:00:00\tTraining Loss 1.2114 (1.2143)\n",
      "\n",
      "Epoch: [154][13/16]\tTime 0.181 (2.888)\tETA 0:00:00\tTraining Loss 1.2155 (1.2144)\n",
      "\n",
      "Epoch: [154][14/16]\tTime 0.187 (3.075)\tETA 0:00:00\tTraining Loss 1.2142 (1.2144)\n",
      "\n",
      "Epoch: [154][15/16]\tTime 0.113 (3.188)\tETA 0:00:00\tTraining Loss 1.2128 (1.2143)\n",
      "_\n",
      "Validation stats                    IoU        F1      Prec    recall       Acc\n",
      "bg,          0.951000  0.974800  0.976700  0.973100  0.956400\n",
      "real apple   0.263800  0.417400  0.759700  0.287800  0.947200\n",
      "real pepper  0.000000  0.000000  0.000000  0.000000  1.000000\n",
      "real grape   0.665500  0.799100  0.909500  0.712700  0.976800\n",
      "fake apple   0.000000  0.000000  0.000000  0.000000  0.969500\n",
      "fake pepper  0.000000  0.000000  0.000000  0.000000  0.990400\n",
      "fake grape   0.000000  0.000000  0.000000  0.000000  0.982200\n",
      "total        0.268614  0.313043  0.377986  0.281943  0.974643\n",
      "total(-bg)   0.154883  0.202750  0.278200  0.166750  0.977683\n",
      "\n",
      "Epoch: [155][0/16]\tTime 0.473 (0.473)\tETA 0:00:07\tTraining Loss 1.2154 (1.2154)\n",
      "\n",
      "Epoch: [155][1/16]\tTime 0.186 (0.659)\tETA 0:00:02\tTraining Loss 1.2135 (1.2145)\n",
      "\n",
      "Epoch: [155][2/16]\tTime 0.195 (0.855)\tETA 0:00:02\tTraining Loss 1.2132 (1.2140)\n",
      "\n",
      "Epoch: [155][3/16]\tTime 0.180 (1.035)\tETA 0:00:02\tTraining Loss 1.2104 (1.2131)\n",
      "\n",
      "Epoch: [155][4/16]\tTime 0.189 (1.224)\tETA 0:00:02\tTraining Loss 1.2141 (1.2133)\n",
      "\n",
      "Epoch: [155][5/16]\tTime 0.185 (1.409)\tETA 0:00:02\tTraining Loss 1.2145 (1.2135)\n",
      "\n",
      "Epoch: [155][6/16]\tTime 0.191 (1.600)\tETA 0:00:01\tTraining Loss 1.2112 (1.2132)\n",
      "\n",
      "Epoch: [155][7/16]\tTime 0.186 (1.786)\tETA 0:00:01\tTraining Loss 1.2121 (1.2131)\n",
      "\n",
      "Epoch: [155][8/16]\tTime 0.182 (1.968)\tETA 0:00:01\tTraining Loss 1.2129 (1.2130)\n",
      "\n",
      "Epoch: [155][9/16]\tTime 0.194 (2.162)\tETA 0:00:01\tTraining Loss 1.2273 (1.2145)\n",
      "\n",
      "Epoch: [155][10/16]\tTime 0.194 (2.356)\tETA 0:00:01\tTraining Loss 1.2104 (1.2141)\n",
      "\n",
      "Epoch: [155][11/16]\tTime 0.199 (2.555)\tETA 0:00:00\tTraining Loss 1.2105 (1.2138)\n",
      "\n",
      "Epoch: [155][12/16]\tTime 0.185 (2.740)\tETA 0:00:00\tTraining Loss 1.2141 (1.2138)\n",
      "\n",
      "Epoch: [155][13/16]\tTime 0.196 (2.936)\tETA 0:00:00\tTraining Loss 1.2121 (1.2137)\n",
      "\n",
      "Epoch: [155][14/16]\tTime 0.180 (3.116)\tETA 0:00:00\tTraining Loss 1.2114 (1.2135)\n",
      "\n",
      "Epoch: [155][15/16]\tTime 0.117 (3.232)\tETA 0:00:00\tTraining Loss 1.2188 (1.2137)\n",
      "_\n",
      "Validation stats                    IoU        F1      Prec    recall       Acc\n",
      "bg,          0.949200  0.973900  0.976600  0.971300  0.954800\n",
      "real apple   0.392100  0.563300  0.899200  0.410100  0.958200\n",
      "real pepper  0.000000  0.000000  0.000000  0.000000  1.000000\n",
      "real grape   0.743700  0.852900  0.863600  0.842600  0.981200\n",
      "fake apple   0.000000  0.000000  0.000000  0.000000  0.979500\n",
      "fake pepper  0.000000  0.000000  0.000000  0.000000  0.989600\n",
      "fake grape   0.000000  0.000000  0.000000  0.000000  0.988800\n",
      "total        0.297857  0.341443  0.391343  0.317714  0.978871\n",
      "total(-bg)   0.189300  0.236033  0.293800  0.208783  0.982883\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: [156][0/16]\tTime 0.424 (0.424)\tETA 0:00:06\tTraining Loss 1.2101 (1.2101)\n",
      "\n",
      "Epoch: [156][1/16]\tTime 0.194 (0.618)\tETA 0:00:02\tTraining Loss 1.2175 (1.2138)\n",
      "\n",
      "Epoch: [156][2/16]\tTime 0.182 (0.800)\tETA 0:00:02\tTraining Loss 1.2113 (1.2130)\n",
      "\n",
      "Epoch: [156][3/16]\tTime 0.184 (0.984)\tETA 0:00:02\tTraining Loss 1.2095 (1.2121)\n",
      "\n",
      "Epoch: [156][4/16]\tTime 0.184 (1.168)\tETA 0:00:02\tTraining Loss 1.2147 (1.2126)\n",
      "\n",
      "Epoch: [156][5/16]\tTime 0.196 (1.364)\tETA 0:00:02\tTraining Loss 1.2144 (1.2129)\n",
      "\n",
      "Epoch: [156][6/16]\tTime 0.188 (1.553)\tETA 0:00:01\tTraining Loss 1.2110 (1.2126)\n",
      "\n",
      "Epoch: [156][7/16]\tTime 0.180 (1.733)\tETA 0:00:01\tTraining Loss 1.2141 (1.2128)\n",
      "\n",
      "Epoch: [156][8/16]\tTime 0.186 (1.919)\tETA 0:00:01\tTraining Loss 1.2115 (1.2127)\n",
      "\n",
      "Epoch: [156][9/16]\tTime 0.187 (2.106)\tETA 0:00:01\tTraining Loss 1.2098 (1.2124)\n",
      "\n",
      "Epoch: [156][10/16]\tTime 0.182 (2.288)\tETA 0:00:01\tTraining Loss 1.2089 (1.2121)\n",
      "\n",
      "Epoch: [156][11/16]\tTime 0.185 (2.473)\tETA 0:00:00\tTraining Loss 1.2112 (1.2120)\n",
      "\n",
      "Epoch: [156][12/16]\tTime 0.183 (2.656)\tETA 0:00:00\tTraining Loss 1.2119 (1.2120)\n",
      "\n",
      "Epoch: [156][13/16]\tTime 0.188 (2.844)\tETA 0:00:00\tTraining Loss 1.2099 (1.2119)\n",
      "\n",
      "Epoch: [156][14/16]\tTime 0.180 (3.025)\tETA 0:00:00\tTraining Loss 1.2115 (1.2118)\n",
      "\n",
      "Epoch: [156][15/16]\tTime 0.119 (3.143)\tETA 0:00:00\tTraining Loss 1.2150 (1.2119)\n",
      "_\n",
      "Validation stats                    IoU        F1      Prec    recall       Acc\n",
      "bg,          0.953300  0.976000  0.976500  0.975600  0.958400\n",
      "real apple   0.378200  0.548800  0.836800  0.408300  0.955900\n",
      "real pepper  0.000000  0.000000  0.000000  0.000000  0.999800\n",
      "real grape   0.712000  0.831800  0.905500  0.769200  0.979900\n",
      "fake apple   0.000000  0.000000  0.000000  0.000000  0.978800\n",
      "fake pepper  0.000000  0.000000  0.000000  0.000000  0.994200\n",
      "fake grape   0.000000  0.000000  0.000000  0.000000  0.983000\n",
      "total        0.291929  0.336657  0.388400  0.307586  0.978571\n",
      "total(-bg)   0.181700  0.230100  0.290383  0.196250  0.981933\n",
      "\n",
      "Epoch: [157][0/16]\tTime 0.369 (0.369)\tETA 0:00:05\tTraining Loss 1.2104 (1.2104)\n",
      "\n",
      "Epoch: [157][1/16]\tTime 0.175 (0.545)\tETA 0:00:02\tTraining Loss 1.2110 (1.2107)\n",
      "\n",
      "Epoch: [157][2/16]\tTime 0.193 (0.737)\tETA 0:00:02\tTraining Loss 1.2146 (1.2120)\n",
      "\n",
      "Epoch: [157][3/16]\tTime 0.179 (0.917)\tETA 0:00:02\tTraining Loss 1.2103 (1.2116)\n",
      "\n",
      "Epoch: [157][4/16]\tTime 0.187 (1.104)\tETA 0:00:02\tTraining Loss 1.2113 (1.2116)\n",
      "\n",
      "Epoch: [157][5/16]\tTime 0.187 (1.290)\tETA 0:00:02\tTraining Loss 1.2112 (1.2115)\n",
      "\n",
      "Epoch: [157][6/16]\tTime 0.188 (1.479)\tETA 0:00:01\tTraining Loss 1.2093 (1.2112)\n",
      "\n",
      "Epoch: [157][7/16]\tTime 0.180 (1.659)\tETA 0:00:01\tTraining Loss 1.2091 (1.2109)\n",
      "\n",
      "Epoch: [157][8/16]\tTime 0.184 (1.843)\tETA 0:00:01\tTraining Loss 1.2084 (1.2106)\n",
      "\n",
      "Epoch: [157][9/16]\tTime 0.182 (2.024)\tETA 0:00:01\tTraining Loss 1.2111 (1.2107)\n",
      "\n",
      "Epoch: [157][10/16]\tTime 0.192 (2.216)\tETA 0:00:01\tTraining Loss 1.2143 (1.2110)\n",
      "\n",
      "Epoch: [157][11/16]\tTime 0.182 (2.398)\tETA 0:00:00\tTraining Loss 1.2136 (1.2112)\n",
      "\n",
      "Epoch: [157][12/16]\tTime 0.182 (2.580)\tETA 0:00:00\tTraining Loss 1.2111 (1.2112)\n",
      "\n",
      "Epoch: [157][13/16]\tTime 0.185 (2.765)\tETA 0:00:00\tTraining Loss 1.2128 (1.2113)\n",
      "\n",
      "Epoch: [157][14/16]\tTime 0.178 (2.943)\tETA 0:00:00\tTraining Loss 1.2135 (1.2115)\n",
      "\n",
      "Epoch: [157][15/16]\tTime 0.115 (3.058)\tETA 0:00:00\tTraining Loss 1.2095 (1.2114)\n",
      "_\n",
      "Validation stats                    IoU        F1      Prec    recall       Acc\n",
      "bg,          0.952700  0.975700  0.977500  0.974100  0.957900\n",
      "real apple   0.520600  0.684700  0.885300  0.558300  0.966200\n",
      "real pepper  0.000000  0.000000  0.000000  0.000000  1.000000\n",
      "real grape   0.762300  0.865100  0.889700  0.841900  0.983000\n",
      "fake apple   0.000000  0.000000  0.000000  0.000000  0.982100\n",
      "fake pepper  0.000000  0.000000  0.000000  0.000000  0.995400\n",
      "fake grape   0.000000  0.000000  0.000000  0.000000  0.991600\n",
      "total        0.319371  0.360786  0.393214  0.339186  0.982314\n",
      "total(-bg)   0.213817  0.258300  0.295833  0.233367  0.986383\n",
      "\n",
      "Epoch: [158][0/16]\tTime 0.352 (0.352)\tETA 0:00:05\tTraining Loss 1.2107 (1.2107)\n",
      "\n",
      "Epoch: [158][1/16]\tTime 0.180 (0.531)\tETA 0:00:02\tTraining Loss 1.2101 (1.2104)\n",
      "\n",
      "Epoch: [158][2/16]\tTime 0.192 (0.724)\tETA 0:00:02\tTraining Loss 1.2116 (1.2108)\n",
      "\n",
      "Epoch: [158][3/16]\tTime 0.178 (0.902)\tETA 0:00:02\tTraining Loss 1.2085 (1.2102)\n",
      "\n",
      "Epoch: [158][4/16]\tTime 0.183 (1.085)\tETA 0:00:02\tTraining Loss 1.2072 (1.2096)\n",
      "\n",
      "Epoch: [158][5/16]\tTime 0.178 (1.263)\tETA 0:00:01\tTraining Loss 1.2116 (1.2099)\n",
      "\n",
      "Epoch: [158][6/16]\tTime 0.180 (1.444)\tETA 0:00:01\tTraining Loss 1.2137 (1.2105)\n",
      "\n",
      "Epoch: [158][7/16]\tTime 0.193 (1.637)\tETA 0:00:01\tTraining Loss 1.2112 (1.2106)\n",
      "\n",
      "Epoch: [158][8/16]\tTime 0.179 (1.816)\tETA 0:00:01\tTraining Loss 1.2075 (1.2102)\n",
      "\n",
      "Epoch: [158][9/16]\tTime 0.183 (1.999)\tETA 0:00:01\tTraining Loss 1.2092 (1.2101)\n",
      "\n",
      "Epoch: [158][10/16]\tTime 0.186 (2.184)\tETA 0:00:01\tTraining Loss 1.2129 (1.2104)\n",
      "\n",
      "Epoch: [158][11/16]\tTime 0.190 (2.374)\tETA 0:00:00\tTraining Loss 1.2063 (1.2100)\n",
      "\n",
      "Epoch: [158][12/16]\tTime 0.188 (2.562)\tETA 0:00:00\tTraining Loss 1.2119 (1.2102)\n",
      "\n",
      "Epoch: [158][13/16]\tTime 0.194 (2.756)\tETA 0:00:00\tTraining Loss 1.2110 (1.2102)\n",
      "\n",
      "Epoch: [158][14/16]\tTime 0.173 (2.930)\tETA 0:00:00\tTraining Loss 1.2103 (1.2102)\n",
      "\n",
      "Epoch: [158][15/16]\tTime 0.114 (3.044)\tETA 0:00:00\tTraining Loss 1.2133 (1.2103)\n",
      "_\n",
      "Validation stats                   IoU        F1      Prec    recall       Acc\n",
      "bg,          0.95290  0.975800  0.976400  0.975400  0.958100\n",
      "real apple   0.48400  0.652200  0.889000  0.515100  0.963900\n",
      "real pepper  0.00000  0.000000  0.000000  0.000000  1.000000\n",
      "real grape   0.74150  0.851500  0.898700  0.809100  0.981700\n",
      "fake apple   0.00000  0.000000  0.000000  0.000000  0.985100\n",
      "fake pepper  0.00000  0.000000  0.000000  0.000000  0.993100\n",
      "fake grape   0.00000  0.000000  0.000000  0.000000  0.986900\n",
      "total        0.31120  0.354214  0.394871  0.328514  0.981257\n",
      "total(-bg)   0.20425  0.250617  0.297950  0.220700  0.985117\n",
      "\n",
      "Epoch: [159][0/16]\tTime 0.344 (0.344)\tETA 0:00:05\tTraining Loss 1.2086 (1.2086)\n",
      "\n",
      "Epoch: [159][1/16]\tTime 0.178 (0.522)\tETA 0:00:02\tTraining Loss 1.2094 (1.2090)\n",
      "\n",
      "Epoch: [159][2/16]\tTime 0.185 (0.707)\tETA 0:00:02\tTraining Loss 1.2090 (1.2090)\n",
      "\n",
      "Epoch: [159][3/16]\tTime 0.184 (0.891)\tETA 0:00:02\tTraining Loss 1.2106 (1.2094)\n",
      "\n",
      "Epoch: [159][4/16]\tTime 0.184 (1.075)\tETA 0:00:02\tTraining Loss 1.2075 (1.2090)\n",
      "\n",
      "Epoch: [159][5/16]\tTime 0.191 (1.266)\tETA 0:00:02\tTraining Loss 1.2079 (1.2088)\n",
      "\n",
      "Epoch: [159][6/16]\tTime 0.192 (1.458)\tETA 0:00:01\tTraining Loss 1.2169 (1.2100)\n",
      "\n",
      "Epoch: [159][7/16]\tTime 0.182 (1.640)\tETA 0:00:01\tTraining Loss 1.2104 (1.2100)\n",
      "\n",
      "Epoch: [159][8/16]\tTime 0.181 (1.821)\tETA 0:00:01\tTraining Loss 1.2099 (1.2100)\n",
      "\n",
      "Epoch: [159][9/16]\tTime 0.179 (1.999)\tETA 0:00:01\tTraining Loss 1.2087 (1.2099)\n",
      "\n",
      "Epoch: [159][10/16]\tTime 0.184 (2.184)\tETA 0:00:01\tTraining Loss 1.2169 (1.2105)\n",
      "\n",
      "Epoch: [159][11/16]\tTime 0.175 (2.359)\tETA 0:00:00\tTraining Loss 1.2055 (1.2101)\n",
      "\n",
      "Epoch: [159][12/16]\tTime 0.191 (2.550)\tETA 0:00:00\tTraining Loss 1.2109 (1.2102)\n",
      "\n",
      "Epoch: [159][13/16]\tTime 0.181 (2.731)\tETA 0:00:00\tTraining Loss 1.2094 (1.2101)\n",
      "\n",
      "Epoch: [159][14/16]\tTime 0.190 (2.921)\tETA 0:00:00\tTraining Loss 1.2063 (1.2098)\n",
      "\n",
      "Epoch: [159][15/16]\tTime 0.116 (3.037)\tETA 0:00:00\tTraining Loss 1.2174 (1.2101)\n",
      "_\n",
      "Validation stats                    IoU        F1      Prec    recall       Acc\n",
      "bg,          0.948700  0.973600  0.978600  0.968800  0.954500\n",
      "real apple   0.398400  0.569700  0.797900  0.443100  0.956000\n",
      "real pepper  0.000000  0.000000  0.000000  0.000000  0.999900\n",
      "real grape   0.761400  0.864500  0.877700  0.851800  0.982700\n",
      "fake apple   0.000000  0.000000  0.000000  0.000000  0.978600\n",
      "fake pepper  0.000000  0.000000  0.000000  0.000000  0.993500\n",
      "fake grape   0.000000  0.000000  0.000000  0.000000  0.988200\n",
      "total        0.301214  0.343971  0.379171  0.323386  0.979057\n",
      "total(-bg)   0.193300  0.239033  0.279267  0.215817  0.983150\n",
      "\n",
      "Epoch: [160][0/16]\tTime 0.467 (0.467)\tETA 0:00:07\tTraining Loss 1.2120 (1.2120)\n",
      "\n",
      "Epoch: [160][1/16]\tTime 0.190 (0.657)\tETA 0:00:02\tTraining Loss 1.2073 (1.2096)\n",
      "\n",
      "Epoch: [160][2/16]\tTime 0.185 (0.842)\tETA 0:00:02\tTraining Loss 1.2121 (1.2105)\n",
      "\n",
      "Epoch: [160][3/16]\tTime 0.185 (1.027)\tETA 0:00:02\tTraining Loss 1.2087 (1.2100)\n",
      "\n",
      "Epoch: [160][4/16]\tTime 0.185 (1.212)\tETA 0:00:02\tTraining Loss 1.2072 (1.2094)\n",
      "\n",
      "Epoch: [160][5/16]\tTime 0.186 (1.398)\tETA 0:00:02\tTraining Loss 1.2078 (1.2092)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: [160][6/16]\tTime 0.194 (1.592)\tETA 0:00:01\tTraining Loss 1.2104 (1.2093)\n",
      "\n",
      "Epoch: [160][7/16]\tTime 0.188 (1.780)\tETA 0:00:01\tTraining Loss 1.2133 (1.2098)\n",
      "\n",
      "Epoch: [160][8/16]\tTime 0.196 (1.976)\tETA 0:00:01\tTraining Loss 1.2071 (1.2095)\n",
      "\n",
      "Epoch: [160][9/16]\tTime 0.187 (2.164)\tETA 0:00:01\tTraining Loss 1.2130 (1.2099)\n",
      "\n",
      "Epoch: [160][10/16]\tTime 0.185 (2.349)\tETA 0:00:01\tTraining Loss 1.2054 (1.2095)\n",
      "\n",
      "Epoch: [160][11/16]\tTime 0.188 (2.537)\tETA 0:00:00\tTraining Loss 1.2124 (1.2097)\n",
      "\n",
      "Epoch: [160][12/16]\tTime 0.196 (2.733)\tETA 0:00:00\tTraining Loss 1.2070 (1.2095)\n",
      "\n",
      "Epoch: [160][13/16]\tTime 0.184 (2.917)\tETA 0:00:00\tTraining Loss 1.2099 (1.2095)\n",
      "\n",
      "Epoch: [160][14/16]\tTime 0.197 (3.114)\tETA 0:00:00\tTraining Loss 1.2054 (1.2093)\n",
      "\n",
      "Epoch: [160][15/16]\tTime 0.114 (3.228)\tETA 0:00:00\tTraining Loss 1.2056 (1.2091)\n",
      "_\n",
      "Validation stats                    IoU      F1      Prec    recall       Acc\n",
      "bg,          0.954700  0.9768  0.977400  0.976200  0.959700\n",
      "real apple   0.594800  0.7459  0.907100  0.633400  0.971600\n",
      "real pepper  0.000000  0.0000  0.000000  0.000000  0.999800\n",
      "real grape   0.781100  0.8771  0.889200  0.865300  0.984300\n",
      "fake apple   0.000000  0.0000  0.000000  0.000000  0.990900\n",
      "fake pepper  0.000000  0.0000  0.000000  0.000000  0.996900\n",
      "fake grape   0.000000  0.0000  0.000000  0.000000  0.989900\n",
      "total        0.332943  0.3714  0.396243  0.353557  0.984729\n",
      "total(-bg)   0.229317  0.2705  0.299383  0.249783  0.988900\n",
      "\n",
      "Epoch: [161][0/16]\tTime 0.501 (0.501)\tETA 0:00:08\tTraining Loss 1.2081 (1.2081)\n",
      "\n",
      "Epoch: [161][1/16]\tTime 0.189 (0.690)\tETA 0:00:02\tTraining Loss 1.2065 (1.2073)\n",
      "\n",
      "Epoch: [161][2/16]\tTime 0.195 (0.885)\tETA 0:00:02\tTraining Loss 1.2065 (1.2070)\n",
      "\n",
      "Epoch: [161][3/16]\tTime 0.184 (1.070)\tETA 0:00:02\tTraining Loss 1.2051 (1.2065)\n",
      "\n",
      "Epoch: [161][4/16]\tTime 0.186 (1.256)\tETA 0:00:02\tTraining Loss 1.2077 (1.2068)\n",
      "\n",
      "Epoch: [161][5/16]\tTime 0.192 (1.448)\tETA 0:00:02\tTraining Loss 1.2084 (1.2070)\n",
      "\n",
      "Epoch: [161][6/16]\tTime 0.187 (1.635)\tETA 0:00:01\tTraining Loss 1.2083 (1.2072)\n",
      "\n",
      "Epoch: [161][7/16]\tTime 0.192 (1.827)\tETA 0:00:01\tTraining Loss 1.2085 (1.2074)\n",
      "\n",
      "Epoch: [161][8/16]\tTime 0.190 (2.017)\tETA 0:00:01\tTraining Loss 1.2110 (1.2078)\n",
      "\n",
      "Epoch: [161][9/16]\tTime 0.188 (2.205)\tETA 0:00:01\tTraining Loss 1.2067 (1.2077)\n",
      "\n",
      "Epoch: [161][10/16]\tTime 0.182 (2.387)\tETA 0:00:01\tTraining Loss 1.2057 (1.2075)\n",
      "\n",
      "Epoch: [161][11/16]\tTime 0.187 (2.575)\tETA 0:00:00\tTraining Loss 1.2055 (1.2073)\n",
      "\n",
      "Epoch: [161][12/16]\tTime 0.193 (2.768)\tETA 0:00:00\tTraining Loss 1.2064 (1.2073)\n",
      "\n",
      "Epoch: [161][13/16]\tTime 0.187 (2.955)\tETA 0:00:00\tTraining Loss 1.2148 (1.2078)\n",
      "\n",
      "Epoch: [161][14/16]\tTime 0.185 (3.140)\tETA 0:00:00\tTraining Loss 1.2080 (1.2078)\n",
      "\n",
      "Epoch: [161][15/16]\tTime 0.113 (3.253)\tETA 0:00:00\tTraining Loss 1.2248 (1.2084)\n",
      "_\n",
      "Validation stats                    IoU        F1      Prec    recall      Acc\n",
      "bg,          0.953200  0.976000  0.976200  0.975800  0.95830\n",
      "real apple   0.376000  0.546500  0.786700  0.418700  0.95430\n",
      "real pepper  0.000000  0.000000  0.000000  0.000000  1.00000\n",
      "real grape   0.778900  0.875700  0.908900  0.844900  0.98450\n",
      "fake apple   0.000000  0.000000  0.000000  0.000000  0.97770\n",
      "fake pepper  0.000000  0.000000  0.000000  0.000000  0.99740\n",
      "fake grape   0.000000  0.000000  0.000000  0.000000  0.98920\n",
      "total        0.301157  0.342600  0.381686  0.319914  0.98020\n",
      "total(-bg)   0.192483  0.237033  0.282600  0.210600  0.98385\n",
      "\n",
      "Epoch: [162][0/16]\tTime 0.435 (0.435)\tETA 0:00:06\tTraining Loss 1.2061 (1.2061)\n",
      "\n",
      "Epoch: [162][1/16]\tTime 0.185 (0.620)\tETA 0:00:02\tTraining Loss 1.2117 (1.2089)\n",
      "\n",
      "Epoch: [162][2/16]\tTime 0.188 (0.808)\tETA 0:00:02\tTraining Loss 1.2130 (1.2103)\n",
      "\n",
      "Epoch: [162][3/16]\tTime 0.193 (1.001)\tETA 0:00:02\tTraining Loss 1.2055 (1.2091)\n",
      "\n",
      "Epoch: [162][4/16]\tTime 0.174 (1.175)\tETA 0:00:02\tTraining Loss 1.2102 (1.2093)\n",
      "\n",
      "Epoch: [162][5/16]\tTime 0.183 (1.358)\tETA 0:00:02\tTraining Loss 1.2054 (1.2086)\n",
      "\n",
      "Epoch: [162][6/16]\tTime 0.185 (1.543)\tETA 0:00:01\tTraining Loss 1.2079 (1.2085)\n",
      "\n",
      "Epoch: [162][7/16]\tTime 0.188 (1.731)\tETA 0:00:01\tTraining Loss 1.2067 (1.2083)\n",
      "\n",
      "Epoch: [162][8/16]\tTime 0.188 (1.918)\tETA 0:00:01\tTraining Loss 1.2132 (1.2089)\n",
      "\n",
      "Epoch: [162][9/16]\tTime 0.184 (2.102)\tETA 0:00:01\tTraining Loss 1.2048 (1.2085)\n",
      "\n",
      "Epoch: [162][10/16]\tTime 0.200 (2.302)\tETA 0:00:01\tTraining Loss 1.2052 (1.2082)\n",
      "\n",
      "Epoch: [162][11/16]\tTime 0.187 (2.489)\tETA 0:00:00\tTraining Loss 1.2062 (1.2080)\n",
      "\n",
      "Epoch: [162][12/16]\tTime 0.187 (2.676)\tETA 0:00:00\tTraining Loss 1.2150 (1.2085)\n",
      "\n",
      "Epoch: [162][13/16]\tTime 0.185 (2.862)\tETA 0:00:00\tTraining Loss 1.2071 (1.2084)\n",
      "\n",
      "Epoch: [162][14/16]\tTime 0.188 (3.050)\tETA 0:00:00\tTraining Loss 1.2095 (1.2085)\n",
      "\n",
      "Epoch: [162][15/16]\tTime 0.114 (3.163)\tETA 0:00:00\tTraining Loss 1.2063 (1.2084)\n",
      "_\n",
      "Validation stats                    IoU        F1      Prec    recall       Acc\n",
      "bg,          0.945800  0.972100  0.977700  0.966700  0.951800\n",
      "real apple   0.381700  0.552500  0.830100  0.414100  0.955900\n",
      "real pepper  0.000000  0.000000  0.000000  0.000000  1.000000\n",
      "real grape   0.762400  0.865200  0.909800  0.824800  0.983400\n",
      "fake apple   0.000000  0.000000  0.000000  0.000000  0.977500\n",
      "fake pepper  0.000000  0.000000  0.000000  0.000000  0.987100\n",
      "fake grape   0.000000  0.000000  0.000000  0.000000  0.986600\n",
      "total        0.298557  0.341400  0.388229  0.315086  0.977471\n",
      "total(-bg)   0.190683  0.236283  0.289983  0.206483  0.981750\n",
      "\n",
      "Epoch: [163][0/16]\tTime 0.471 (0.471)\tETA 0:00:07\tTraining Loss 1.2095 (1.2095)\n",
      "\n",
      "Epoch: [163][1/16]\tTime 0.174 (0.645)\tETA 0:00:02\tTraining Loss 1.2063 (1.2079)\n",
      "\n",
      "Epoch: [163][2/16]\tTime 0.190 (0.835)\tETA 0:00:02\tTraining Loss 1.2062 (1.2073)\n",
      "\n",
      "Epoch: [163][3/16]\tTime 0.177 (1.012)\tETA 0:00:02\tTraining Loss 1.2106 (1.2081)\n",
      "\n",
      "Epoch: [163][4/16]\tTime 0.192 (1.204)\tETA 0:00:02\tTraining Loss 1.2071 (1.2079)\n",
      "\n",
      "Epoch: [163][5/16]\tTime 0.176 (1.380)\tETA 0:00:01\tTraining Loss 1.2057 (1.2076)\n",
      "\n",
      "Epoch: [163][6/16]\tTime 0.199 (1.578)\tETA 0:00:01\tTraining Loss 1.2059 (1.2073)\n",
      "\n",
      "Epoch: [163][7/16]\tTime 0.187 (1.765)\tETA 0:00:01\tTraining Loss 1.2084 (1.2075)\n",
      "\n",
      "Epoch: [163][8/16]\tTime 0.187 (1.953)\tETA 0:00:01\tTraining Loss 1.2067 (1.2074)\n",
      "\n",
      "Epoch: [163][9/16]\tTime 0.184 (2.137)\tETA 0:00:01\tTraining Loss 1.2075 (1.2074)\n",
      "\n",
      "Epoch: [163][10/16]\tTime 0.193 (2.330)\tETA 0:00:01\tTraining Loss 1.2053 (1.2072)\n",
      "\n",
      "Epoch: [163][11/16]\tTime 0.182 (2.513)\tETA 0:00:00\tTraining Loss 1.2076 (1.2072)\n",
      "\n",
      "Epoch: [163][12/16]\tTime 0.193 (2.706)\tETA 0:00:00\tTraining Loss 1.2073 (1.2072)\n",
      "\n",
      "Epoch: [163][13/16]\tTime 0.189 (2.895)\tETA 0:00:00\tTraining Loss 1.2073 (1.2072)\n",
      "\n",
      "Epoch: [163][14/16]\tTime 0.190 (3.085)\tETA 0:00:00\tTraining Loss 1.2056 (1.2071)\n",
      "\n",
      "Epoch: [163][15/16]\tTime 0.115 (3.200)\tETA 0:00:00\tTraining Loss 1.2213 (1.2076)\n",
      "_\n",
      "Validation stats                    IoU        F1      Prec    recall       Acc\n",
      "bg,          0.958400  0.978700  0.976500  0.981000  0.963000\n",
      "real apple   0.489000  0.656800  0.840000  0.539200  0.963000\n",
      "real pepper  0.000000  0.000000  0.000000  0.000000  0.999900\n",
      "real grape   0.651300  0.788800  0.900100  0.702000  0.975700\n",
      "fake apple   0.000000  0.000000  0.000000  0.000000  0.987000\n",
      "fake pepper  0.000000  0.000000  0.000000  0.000000  1.000000\n",
      "fake grape   0.000000  0.000000  0.000000  0.000000  0.979400\n",
      "total        0.299814  0.346329  0.388086  0.317457  0.981143\n",
      "total(-bg)   0.190050  0.240933  0.290017  0.206867  0.984167\n",
      "\n",
      "Epoch: [164][0/16]\tTime 0.494 (0.494)\tETA 0:00:07\tTraining Loss 1.2077 (1.2077)\n",
      "\n",
      "Epoch: [164][1/16]\tTime 0.159 (0.653)\tETA 0:00:02\tTraining Loss 1.2070 (1.2073)\n",
      "\n",
      "Epoch: [164][2/16]\tTime 0.181 (0.833)\tETA 0:00:02\tTraining Loss 1.2065 (1.2070)\n",
      "\n",
      "Epoch: [164][3/16]\tTime 0.176 (1.010)\tETA 0:00:02\tTraining Loss 1.2106 (1.2079)\n",
      "\n",
      "Epoch: [164][4/16]\tTime 0.195 (1.204)\tETA 0:00:02\tTraining Loss 1.2061 (1.2076)\n",
      "\n",
      "Epoch: [164][5/16]\tTime 0.183 (1.387)\tETA 0:00:02\tTraining Loss 1.2084 (1.2077)\n",
      "\n",
      "Epoch: [164][6/16]\tTime 0.192 (1.579)\tETA 0:00:01\tTraining Loss 1.2105 (1.2081)\n",
      "\n",
      "Epoch: [164][7/16]\tTime 0.186 (1.765)\tETA 0:00:01\tTraining Loss 1.2110 (1.2085)\n",
      "\n",
      "Epoch: [164][8/16]\tTime 0.197 (1.963)\tETA 0:00:01\tTraining Loss 1.2108 (1.2087)\n",
      "\n",
      "Epoch: [164][9/16]\tTime 0.186 (2.148)\tETA 0:00:01\tTraining Loss 1.2067 (1.2085)\n",
      "\n",
      "Epoch: [164][10/16]\tTime 0.184 (2.332)\tETA 0:00:01\tTraining Loss 1.2046 (1.2082)\n",
      "\n",
      "Epoch: [164][11/16]\tTime 0.190 (2.522)\tETA 0:00:00\tTraining Loss 1.2055 (1.2079)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: [164][12/16]\tTime 0.200 (2.722)\tETA 0:00:00\tTraining Loss 1.2117 (1.2082)\n",
      "\n",
      "Epoch: [164][13/16]\tTime 0.189 (2.911)\tETA 0:00:00\tTraining Loss 1.2044 (1.2080)\n",
      "\n",
      "Epoch: [164][14/16]\tTime 0.183 (3.094)\tETA 0:00:00\tTraining Loss 1.2077 (1.2079)\n",
      "\n",
      "Epoch: [164][15/16]\tTime 0.119 (3.214)\tETA 0:00:00\tTraining Loss 1.2119 (1.2081)\n",
      "_\n",
      "Validation stats                    IoU        F1      Prec    recall       Acc\n",
      "bg,          0.953100  0.975900  0.976500  0.975400  0.958300\n",
      "real apple   0.349700  0.518100  0.819100  0.378900  0.953700\n",
      "real pepper  0.000000  0.000000  0.000000  0.000000  1.000000\n",
      "real grape   0.730900  0.844500  0.875000  0.816200  0.980500\n",
      "fake apple   0.000000  0.000000  0.000000  0.000000  0.975400\n",
      "fake pepper  0.000000  0.000000  0.000000  0.000000  0.996600\n",
      "fake grape   0.000000  0.000000  0.000000  0.000000  0.987300\n",
      "total        0.290529  0.334071  0.381514  0.310071  0.978829\n",
      "total(-bg)   0.180100  0.227100  0.282350  0.199183  0.982250\n",
      "\n",
      "Epoch: [165][0/16]\tTime 0.487 (0.487)\tETA 0:00:07\tTraining Loss 1.2089 (1.2089)\n",
      "\n",
      "Epoch: [165][1/16]\tTime 0.196 (0.684)\tETA 0:00:02\tTraining Loss 1.2051 (1.2070)\n",
      "\n",
      "Epoch: [165][2/16]\tTime 0.186 (0.869)\tETA 0:00:02\tTraining Loss 1.2065 (1.2068)\n",
      "\n",
      "Epoch: [165][3/16]\tTime 0.185 (1.054)\tETA 0:00:02\tTraining Loss 1.2065 (1.2067)\n",
      "\n",
      "Epoch: [165][4/16]\tTime 0.189 (1.243)\tETA 0:00:02\tTraining Loss 1.2057 (1.2065)\n",
      "\n",
      "Epoch: [165][5/16]\tTime 0.186 (1.429)\tETA 0:00:02\tTraining Loss 1.2069 (1.2066)\n",
      "\n",
      "Epoch: [165][6/16]\tTime 0.197 (1.626)\tETA 0:00:01\tTraining Loss 1.2054 (1.2064)\n",
      "\n",
      "Epoch: [165][7/16]\tTime 0.183 (1.809)\tETA 0:00:01\tTraining Loss 1.2058 (1.2063)\n",
      "\n",
      "Epoch: [165][8/16]\tTime 0.186 (1.995)\tETA 0:00:01\tTraining Loss 1.2043 (1.2061)\n",
      "\n",
      "Epoch: [165][9/16]\tTime 0.304 (2.299)\tETA 0:00:02\tTraining Loss 1.2034 (1.2058)\n",
      "\n",
      "Epoch: [165][10/16]\tTime 0.216 (2.515)\tETA 0:00:01\tTraining Loss 1.2096 (1.2062)\n",
      "\n",
      "Epoch: [165][11/16]\tTime 0.189 (2.703)\tETA 0:00:00\tTraining Loss 1.2078 (1.2063)\n",
      "\n",
      "Epoch: [165][12/16]\tTime 0.190 (2.893)\tETA 0:00:00\tTraining Loss 1.2067 (1.2064)\n",
      "\n",
      "Epoch: [165][13/16]\tTime 0.191 (3.084)\tETA 0:00:00\tTraining Loss 1.2072 (1.2064)\n",
      "\n",
      "Epoch: [165][14/16]\tTime 0.189 (3.273)\tETA 0:00:00\tTraining Loss 1.2096 (1.2066)\n",
      "\n",
      "Epoch: [165][15/16]\tTime 0.112 (3.386)\tETA 0:00:00\tTraining Loss 1.2037 (1.2065)\n",
      "_\n",
      "Validation stats                    IoU        F1      Prec    recall       Acc\n",
      "bg,          0.954300  0.976600  0.978500  0.974800  0.959400\n",
      "real apple   0.335400  0.502300  0.840400  0.358300  0.953400\n",
      "real pepper  0.000000  0.000000  0.000000  0.000000  0.999800\n",
      "real grape   0.670900  0.803000  0.876200  0.741100  0.976500\n",
      "fake apple   0.000000  0.000000  0.000000  0.000000  0.973800\n",
      "fake pepper  0.000000  0.000000  0.000000  0.000000  0.993700\n",
      "fake grape   0.000000  0.000000  0.000000  0.000000  0.981800\n",
      "total        0.280086  0.325986  0.385014  0.296314  0.976914\n",
      "total(-bg)   0.167717  0.217550  0.286100  0.183233  0.979833\n",
      "\n",
      "Epoch: [166][0/16]\tTime 0.541 (0.541)\tETA 0:00:08\tTraining Loss 1.2071 (1.2071)\n",
      "\n",
      "Epoch: [166][1/16]\tTime 0.210 (0.752)\tETA 0:00:03\tTraining Loss 1.2084 (1.2077)\n",
      "\n",
      "Epoch: [166][2/16]\tTime 0.172 (0.924)\tETA 0:00:02\tTraining Loss 1.2061 (1.2072)\n",
      "\n",
      "Epoch: [166][3/16]\tTime 0.199 (1.123)\tETA 0:00:02\tTraining Loss 1.2067 (1.2071)\n",
      "\n",
      "Epoch: [166][4/16]\tTime 0.184 (1.307)\tETA 0:00:02\tTraining Loss 1.2051 (1.2067)\n",
      "\n",
      "Epoch: [166][5/16]\tTime 0.189 (1.495)\tETA 0:00:02\tTraining Loss 1.2056 (1.2065)\n",
      "\n",
      "Epoch: [166][6/16]\tTime 0.196 (1.691)\tETA 0:00:01\tTraining Loss 1.2111 (1.2072)\n",
      "\n",
      "Epoch: [166][7/16]\tTime 0.194 (1.885)\tETA 0:00:01\tTraining Loss 1.2080 (1.2073)\n",
      "\n",
      "Epoch: [166][8/16]\tTime 0.191 (2.076)\tETA 0:00:01\tTraining Loss 1.2046 (1.2070)\n",
      "\n",
      "Epoch: [166][9/16]\tTime 0.190 (2.266)\tETA 0:00:01\tTraining Loss 1.2043 (1.2067)\n",
      "\n",
      "Epoch: [166][10/16]\tTime 0.202 (2.468)\tETA 0:00:01\tTraining Loss 1.2033 (1.2064)\n",
      "\n",
      "Epoch: [166][11/16]\tTime 0.194 (2.662)\tETA 0:00:00\tTraining Loss 1.2085 (1.2066)\n",
      "\n",
      "Epoch: [166][12/16]\tTime 0.206 (2.868)\tETA 0:00:00\tTraining Loss 1.2039 (1.2064)\n",
      "\n",
      "Epoch: [166][13/16]\tTime 0.196 (3.064)\tETA 0:00:00\tTraining Loss 1.2050 (1.2063)\n",
      "\n",
      "Epoch: [166][14/16]\tTime 0.193 (3.257)\tETA 0:00:00\tTraining Loss 1.2091 (1.2065)\n",
      "\n",
      "Epoch: [166][15/16]\tTime 0.114 (3.371)\tETA 0:00:00\tTraining Loss 1.2096 (1.2066)\n",
      "_\n",
      "Validation stats                    IoU        F1      Prec    recall       Acc\n",
      "bg,          0.954700  0.976800  0.976500  0.977200  0.959700\n",
      "real apple   0.426600  0.598000  0.890700  0.450200  0.960200\n",
      "real pepper  0.000000  0.000000  0.000000  0.000000  0.999600\n",
      "real grape   0.809200  0.894500  0.908600  0.880900  0.986500\n",
      "fake apple   0.000000  0.000000  0.000000  0.000000  0.978600\n",
      "fake pepper  0.000000  0.000000  0.000000  0.000000  0.996600\n",
      "fake grape   0.000000  0.000000  0.000000  0.000000  0.991400\n",
      "total        0.312929  0.352757  0.396543  0.329757  0.981800\n",
      "total(-bg)   0.205967  0.248750  0.299883  0.221850  0.985483\n",
      "\n",
      "Epoch: [167][0/16]\tTime 0.422 (0.422)\tETA 0:00:06\tTraining Loss 1.2037 (1.2037)\n",
      "\n",
      "Epoch: [167][1/16]\tTime 0.185 (0.607)\tETA 0:00:02\tTraining Loss 1.2079 (1.2058)\n",
      "\n",
      "Epoch: [167][2/16]\tTime 0.181 (0.788)\tETA 0:00:02\tTraining Loss 1.2048 (1.2055)\n",
      "\n",
      "Epoch: [167][3/16]\tTime 0.185 (0.973)\tETA 0:00:02\tTraining Loss 1.2082 (1.2061)\n",
      "\n",
      "Epoch: [167][4/16]\tTime 0.193 (1.166)\tETA 0:00:02\tTraining Loss 1.2084 (1.2066)\n",
      "\n",
      "Epoch: [167][5/16]\tTime 0.194 (1.360)\tETA 0:00:02\tTraining Loss 1.2076 (1.2068)\n",
      "\n",
      "Epoch: [167][6/16]\tTime 0.192 (1.553)\tETA 0:00:01\tTraining Loss 1.2109 (1.2074)\n",
      "\n",
      "Epoch: [167][7/16]\tTime 0.194 (1.747)\tETA 0:00:01\tTraining Loss 1.2073 (1.2073)\n",
      "\n",
      "Epoch: [167][8/16]\tTime 0.187 (1.934)\tETA 0:00:01\tTraining Loss 1.2049 (1.2071)\n",
      "\n",
      "Epoch: [167][9/16]\tTime 0.190 (2.124)\tETA 0:00:01\tTraining Loss 1.2046 (1.2068)\n",
      "\n",
      "Epoch: [167][10/16]\tTime 0.192 (2.316)\tETA 0:00:01\tTraining Loss 1.2055 (1.2067)\n",
      "\n",
      "Epoch: [167][11/16]\tTime 0.184 (2.500)\tETA 0:00:00\tTraining Loss 1.2059 (1.2066)\n",
      "\n",
      "Epoch: [167][12/16]\tTime 0.197 (2.697)\tETA 0:00:00\tTraining Loss 1.2038 (1.2064)\n",
      "\n",
      "Epoch: [167][13/16]\tTime 0.192 (2.889)\tETA 0:00:00\tTraining Loss 1.2080 (1.2065)\n",
      "\n",
      "Epoch: [167][14/16]\tTime 0.190 (3.079)\tETA 0:00:00\tTraining Loss 1.2091 (1.2067)\n",
      "\n",
      "Epoch: [167][15/16]\tTime 0.115 (3.194)\tETA 0:00:00\tTraining Loss 1.2060 (1.2067)\n",
      "_\n",
      "Validation stats                    IoU        F1      Prec    recall       Acc\n",
      "bg,          0.951700  0.975200  0.978400  0.972200  0.957100\n",
      "real apple   0.451600  0.622100  0.909000  0.473000  0.962200\n",
      "real pepper  0.000000  0.000000  0.000000  0.000000  0.999000\n",
      "real grape   0.846300  0.916700  0.905400  0.928400  0.989100\n",
      "fake apple   0.000000  0.000000  0.000000  0.000000  0.978600\n",
      "fake pepper  0.000000  0.000000  0.000000  0.000000  0.997000\n",
      "fake grape   0.000000  0.000000  0.000000  0.000000  0.990100\n",
      "total        0.321371  0.359143  0.398971  0.339086  0.981871\n",
      "total(-bg)   0.216317  0.256467  0.302400  0.233567  0.986000\n",
      "\n",
      "Epoch: [168][0/16]\tTime 0.427 (0.427)\tETA 0:00:06\tTraining Loss 1.2068 (1.2068)\n",
      "\n",
      "Epoch: [168][1/16]\tTime 0.188 (0.615)\tETA 0:00:02\tTraining Loss 1.2030 (1.2049)\n",
      "\n",
      "Epoch: [168][2/16]\tTime 0.198 (0.814)\tETA 0:00:02\tTraining Loss 1.2089 (1.2063)\n",
      "\n",
      "Epoch: [168][3/16]\tTime 0.209 (1.022)\tETA 0:00:02\tTraining Loss 1.2101 (1.2072)\n",
      "\n",
      "Epoch: [168][4/16]\tTime 0.170 (1.192)\tETA 0:00:02\tTraining Loss 1.2028 (1.2063)\n",
      "\n",
      "Epoch: [168][5/16]\tTime 0.185 (1.378)\tETA 0:00:02\tTraining Loss 1.2063 (1.2063)\n",
      "\n",
      "Epoch: [168][6/16]\tTime 0.192 (1.570)\tETA 0:00:01\tTraining Loss 1.2120 (1.2071)\n",
      "\n",
      "Epoch: [168][7/16]\tTime 0.193 (1.763)\tETA 0:00:01\tTraining Loss 1.2100 (1.2075)\n",
      "\n",
      "Epoch: [168][8/16]\tTime 0.192 (1.956)\tETA 0:00:01\tTraining Loss 1.2035 (1.2070)\n",
      "\n",
      "Epoch: [168][9/16]\tTime 0.194 (2.150)\tETA 0:00:01\tTraining Loss 1.2040 (1.2067)\n",
      "\n",
      "Epoch: [168][10/16]\tTime 0.215 (2.365)\tETA 0:00:01\tTraining Loss 1.2049 (1.2066)\n",
      "\n",
      "Epoch: [168][11/16]\tTime 0.186 (2.551)\tETA 0:00:00\tTraining Loss 1.2097 (1.2068)\n",
      "\n",
      "Epoch: [168][12/16]\tTime 0.198 (2.750)\tETA 0:00:00\tTraining Loss 1.2204 (1.2079)\n",
      "\n",
      "Epoch: [168][13/16]\tTime 0.184 (2.933)\tETA 0:00:00\tTraining Loss 1.2051 (1.2077)\n",
      "\n",
      "Epoch: [168][14/16]\tTime 0.192 (3.126)\tETA 0:00:00\tTraining Loss 1.2086 (1.2078)\n",
      "\n",
      "Epoch: [168][15/16]\tTime 0.116 (3.242)\tETA 0:00:00\tTraining Loss 1.2089 (1.2078)\n",
      "_\n",
      "Validation stats                    IoU        F1      Prec    recall       Acc\n",
      "bg,          0.945800  0.972100  0.977400  0.966900  0.951800\n",
      "real apple   0.529000  0.691900  0.907700  0.559100  0.967300\n",
      "real pepper  0.000000  0.000000  0.000000  0.000000  0.999200\n",
      "real grape   0.776600  0.874200  0.853000  0.896500  0.983300\n",
      "fake apple   0.000000  0.000000  0.000000  0.000000  0.990500\n",
      "fake pepper  0.000000  0.000000  0.000000  0.000000  0.986400\n",
      "fake grape   0.000000  0.000000  0.000000  0.000000  0.992700\n",
      "total        0.321629  0.362600  0.391157  0.346071  0.981600\n",
      "total(-bg)   0.217600  0.261017  0.293450  0.242600  0.986567\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: [169][0/16]\tTime 0.399 (0.399)\tETA 0:00:06\tTraining Loss 1.2057 (1.2057)\n",
      "\n",
      "Epoch: [169][1/16]\tTime 0.189 (0.588)\tETA 0:00:02\tTraining Loss 1.2045 (1.2051)\n",
      "\n",
      "Epoch: [169][2/16]\tTime 0.190 (0.777)\tETA 0:00:02\tTraining Loss 1.2073 (1.2059)\n",
      "\n",
      "Epoch: [169][3/16]\tTime 0.186 (0.963)\tETA 0:00:02\tTraining Loss 1.2116 (1.2073)\n",
      "\n",
      "Epoch: [169][4/16]\tTime 0.190 (1.153)\tETA 0:00:02\tTraining Loss 1.2054 (1.2069)\n",
      "\n",
      "Epoch: [169][5/16]\tTime 0.192 (1.345)\tETA 0:00:02\tTraining Loss 1.2063 (1.2068)\n",
      "\n",
      "Epoch: [169][6/16]\tTime 0.196 (1.541)\tETA 0:00:01\tTraining Loss 1.2091 (1.2071)\n",
      "\n",
      "Epoch: [169][7/16]\tTime 0.198 (1.739)\tETA 0:00:01\tTraining Loss 1.2091 (1.2074)\n",
      "\n",
      "Epoch: [169][8/16]\tTime 0.192 (1.931)\tETA 0:00:01\tTraining Loss 1.2041 (1.2070)\n",
      "\n",
      "Epoch: [169][9/16]\tTime 0.195 (2.126)\tETA 0:00:01\tTraining Loss 1.2062 (1.2069)\n",
      "\n",
      "Epoch: [169][10/16]\tTime 0.193 (2.319)\tETA 0:00:01\tTraining Loss 1.2044 (1.2067)\n",
      "\n",
      "Epoch: [169][11/16]\tTime 0.190 (2.509)\tETA 0:00:00\tTraining Loss 1.2053 (1.2066)\n",
      "\n",
      "Epoch: [169][12/16]\tTime 0.216 (2.724)\tETA 0:00:00\tTraining Loss 1.2036 (1.2064)\n",
      "\n",
      "Epoch: [169][13/16]\tTime 0.189 (2.914)\tETA 0:00:00\tTraining Loss 1.2096 (1.2066)\n",
      "\n",
      "Epoch: [169][14/16]\tTime 0.199 (3.113)\tETA 0:00:00\tTraining Loss 1.2092 (1.2068)\n",
      "\n",
      "Epoch: [169][15/16]\tTime 0.114 (3.227)\tETA 0:00:00\tTraining Loss 1.2073 (1.2068)\n",
      "_\n",
      "Validation stats                    IoU        F1      Prec    recall       Acc\n",
      "bg,          0.954900  0.976900  0.975300  0.978600  0.959800\n",
      "real apple   0.579400  0.733600  0.914100  0.612700  0.970800\n",
      "real pepper  0.000000  0.000000  0.000000  0.000000  0.999100\n",
      "real grape   0.467200  0.636800  0.844900  0.511000  0.962300\n",
      "fake apple   0.000000  0.000000  0.000000  0.000000  0.991300\n",
      "fake pepper  0.000000  0.000000  0.000000  0.000000  0.997400\n",
      "fake grape   0.000000  0.000000  0.000000  0.000000  0.967900\n",
      "total        0.285929  0.335329  0.390614  0.300329  0.978371\n",
      "total(-bg)   0.174433  0.228400  0.293167  0.187283  0.981467\n",
      "\n",
      "Epoch: [170][0/16]\tTime 0.476 (0.476)\tETA 0:00:07\tTraining Loss 1.2019 (1.2019)\n",
      "\n",
      "Epoch: [170][1/16]\tTime 0.191 (0.668)\tETA 0:00:02\tTraining Loss 1.2080 (1.2050)\n",
      "\n",
      "Epoch: [170][2/16]\tTime 0.183 (0.851)\tETA 0:00:02\tTraining Loss 1.2046 (1.2048)\n",
      "\n",
      "Epoch: [170][3/16]\tTime 0.192 (1.043)\tETA 0:00:02\tTraining Loss 1.2085 (1.2058)\n",
      "\n",
      "Epoch: [170][4/16]\tTime 0.192 (1.235)\tETA 0:00:02\tTraining Loss 1.2091 (1.2064)\n",
      "\n",
      "Epoch: [170][5/16]\tTime 0.183 (1.418)\tETA 0:00:02\tTraining Loss 1.2065 (1.2064)\n",
      "\n",
      "Epoch: [170][6/16]\tTime 0.189 (1.607)\tETA 0:00:01\tTraining Loss 1.2043 (1.2061)\n",
      "\n",
      "Epoch: [170][7/16]\tTime 0.191 (1.798)\tETA 0:00:01\tTraining Loss 1.2028 (1.2057)\n",
      "\n",
      "Epoch: [170][8/16]\tTime 0.196 (1.994)\tETA 0:00:01\tTraining Loss 1.2048 (1.2056)\n",
      "\n",
      "Epoch: [170][9/16]\tTime 0.182 (2.177)\tETA 0:00:01\tTraining Loss 1.2082 (1.2059)\n",
      "\n",
      "Epoch: [170][10/16]\tTime 0.184 (2.361)\tETA 0:00:01\tTraining Loss 1.2079 (1.2061)\n",
      "\n",
      "Epoch: [170][11/16]\tTime 0.199 (2.560)\tETA 0:00:00\tTraining Loss 1.2072 (1.2062)\n",
      "\n",
      "Epoch: [170][12/16]\tTime 0.195 (2.755)\tETA 0:00:00\tTraining Loss 1.2022 (1.2059)\n",
      "\n",
      "Epoch: [170][13/16]\tTime 0.193 (2.947)\tETA 0:00:00\tTraining Loss 1.2079 (1.2060)\n",
      "\n",
      "Epoch: [170][14/16]\tTime 0.196 (3.144)\tETA 0:00:00\tTraining Loss 1.2092 (1.2062)\n",
      "\n",
      "Epoch: [170][15/16]\tTime 0.117 (3.261)\tETA 0:00:00\tTraining Loss 1.2086 (1.2063)\n",
      "_\n",
      "Validation stats                    IoU        F1      Prec    recall       Acc\n",
      "bg,          0.949800  0.974200  0.977700  0.970800  0.955400\n",
      "real apple   0.596300  0.747100  0.931400  0.623800  0.972300\n",
      "real pepper  0.000000  0.000000  0.000000  0.000000  1.000000\n",
      "real grape   0.409300  0.580900  0.805900  0.454100  0.957600\n",
      "fake apple   0.000000  0.000000  0.000000  0.000000  0.994000\n",
      "fake pepper  0.000000  0.000000  0.000000  0.000000  0.987300\n",
      "fake grape   0.000000  0.000000  0.000000  0.000000  0.962600\n",
      "total        0.279343  0.328886  0.387857  0.292671  0.975600\n",
      "total(-bg)   0.167600  0.221333  0.289550  0.179650  0.978967\n",
      "\n",
      "Epoch: [171][0/16]\tTime 0.492 (0.492)\tETA 0:00:07\tTraining Loss 1.2063 (1.2063)\n",
      "\n",
      "Epoch: [171][1/16]\tTime 0.183 (0.675)\tETA 0:00:02\tTraining Loss 1.2042 (1.2053)\n",
      "\n",
      "Epoch: [171][2/16]\tTime 0.184 (0.859)\tETA 0:00:02\tTraining Loss 1.2058 (1.2054)\n",
      "\n",
      "Epoch: [171][3/16]\tTime 0.204 (1.063)\tETA 0:00:02\tTraining Loss 1.2050 (1.2053)\n",
      "\n",
      "Epoch: [171][4/16]\tTime 0.179 (1.241)\tETA 0:00:02\tTraining Loss 1.2039 (1.2050)\n",
      "\n",
      "Epoch: [171][5/16]\tTime 0.185 (1.427)\tETA 0:00:02\tTraining Loss 1.2038 (1.2048)\n",
      "\n",
      "Epoch: [171][6/16]\tTime 0.184 (1.610)\tETA 0:00:01\tTraining Loss 1.2026 (1.2045)\n",
      "\n",
      "Epoch: [171][7/16]\tTime 0.189 (1.800)\tETA 0:00:01\tTraining Loss 1.2103 (1.2052)\n",
      "\n",
      "Epoch: [171][8/16]\tTime 0.198 (1.998)\tETA 0:00:01\tTraining Loss 1.2037 (1.2051)\n",
      "\n",
      "Epoch: [171][9/16]\tTime 0.194 (2.191)\tETA 0:00:01\tTraining Loss 1.2048 (1.2050)\n",
      "\n",
      "Epoch: [171][10/16]\tTime 0.184 (2.376)\tETA 0:00:01\tTraining Loss 1.2031 (1.2049)\n",
      "\n",
      "Epoch: [171][11/16]\tTime 0.191 (2.567)\tETA 0:00:00\tTraining Loss 1.2059 (1.2050)\n",
      "\n",
      "Epoch: [171][12/16]\tTime 0.184 (2.751)\tETA 0:00:00\tTraining Loss 1.2078 (1.2052)\n",
      "\n",
      "Epoch: [171][13/16]\tTime 0.182 (2.933)\tETA 0:00:00\tTraining Loss 1.2054 (1.2052)\n",
      "\n",
      "Epoch: [171][14/16]\tTime 0.203 (3.136)\tETA 0:00:00\tTraining Loss 1.2021 (1.2050)\n",
      "\n",
      "Epoch: [171][15/16]\tTime 0.115 (3.251)\tETA 0:00:00\tTraining Loss 1.2153 (1.2053)\n",
      "_\n",
      "Validation stats                    IoU        F1      Prec  recall       Acc\n",
      "bg,          0.951100  0.974900  0.975100  0.9748  0.956500\n",
      "real apple   0.527200  0.690400  0.823900  0.5941  0.965000\n",
      "real pepper  0.000000  0.000000  0.000000  0.0000  1.000000\n",
      "real grape   0.460500  0.630500  0.852600  0.5003  0.962000\n",
      "fake apple   0.000000  0.000000  0.000000  0.0000  0.992100\n",
      "fake pepper  0.000000  0.000000  0.000000  0.0000  0.994600\n",
      "fake grape   0.000000  0.000000  0.000000  0.0000  0.967900\n",
      "total        0.276971  0.327971  0.378800  0.2956  0.976871\n",
      "total(-bg)   0.164617  0.220150  0.279417  0.1824  0.980267\n",
      "\n",
      "Epoch: [172][0/16]\tTime 0.535 (0.535)\tETA 0:00:08\tTraining Loss 1.2015 (1.2015)\n",
      "\n",
      "Epoch: [172][1/16]\tTime 0.186 (0.721)\tETA 0:00:02\tTraining Loss 1.2017 (1.2016)\n",
      "\n",
      "Epoch: [172][2/16]\tTime 0.195 (0.916)\tETA 0:00:02\tTraining Loss 1.2053 (1.2028)\n",
      "\n",
      "Epoch: [172][3/16]\tTime 0.199 (1.115)\tETA 0:00:02\tTraining Loss 1.2074 (1.2040)\n",
      "\n",
      "Epoch: [172][4/16]\tTime 0.188 (1.303)\tETA 0:00:02\tTraining Loss 1.2060 (1.2044)\n",
      "\n",
      "Epoch: [172][5/16]\tTime 0.191 (1.494)\tETA 0:00:02\tTraining Loss 1.2189 (1.2068)\n",
      "\n",
      "Epoch: [172][6/16]\tTime 0.198 (1.692)\tETA 0:00:01\tTraining Loss 1.2044 (1.2065)\n",
      "\n",
      "Epoch: [172][7/16]\tTime 0.189 (1.880)\tETA 0:00:01\tTraining Loss 1.2094 (1.2068)\n",
      "\n",
      "Epoch: [172][8/16]\tTime 0.198 (2.078)\tETA 0:00:01\tTraining Loss 1.2025 (1.2064)\n",
      "\n",
      "Epoch: [172][9/16]\tTime 0.187 (2.266)\tETA 0:00:01\tTraining Loss 1.2030 (1.2060)\n",
      "\n",
      "Epoch: [172][10/16]\tTime 0.190 (2.455)\tETA 0:00:01\tTraining Loss 1.2041 (1.2058)\n",
      "\n",
      "Epoch: [172][11/16]\tTime 0.186 (2.641)\tETA 0:00:00\tTraining Loss 1.2067 (1.2059)\n",
      "\n",
      "Epoch: [172][12/16]\tTime 0.211 (2.852)\tETA 0:00:00\tTraining Loss 1.2105 (1.2063)\n",
      "\n",
      "Epoch: [172][13/16]\tTime 0.188 (3.040)\tETA 0:00:00\tTraining Loss 1.2040 (1.2061)\n",
      "\n",
      "Epoch: [172][14/16]\tTime 0.197 (3.237)\tETA 0:00:00\tTraining Loss 1.2022 (1.2058)\n",
      "\n",
      "Epoch: [172][15/16]\tTime 0.110 (3.347)\tETA 0:00:00\tTraining Loss 1.2001 (1.2057)\n",
      "_\n",
      "Validation stats                   IoU        F1      Prec    recall       Acc\n",
      "bg,          0.94830  0.973400  0.975500  0.971400  0.953900\n",
      "real apple   0.36520  0.535000  0.760900  0.412600  0.952900\n",
      "real pepper  0.00000  0.000000  0.000000  0.000000  0.999700\n",
      "real grape   0.82850  0.906200  0.899900  0.912700  0.987800\n",
      "fake apple   0.00000  0.000000  0.000000  0.000000  0.981700\n",
      "fake pepper  0.00000  0.000000  0.000000  0.000000  0.992000\n",
      "fake grape   0.00000  0.000000  0.000000  0.000000  0.993800\n",
      "total        0.30600  0.344943  0.376614  0.328100  0.980257\n",
      "total(-bg)   0.19895  0.240200  0.276800  0.220883  0.984650\n",
      "\n",
      "Epoch: [173][0/16]\tTime 0.392 (0.392)\tETA 0:00:06\tTraining Loss 1.2065 (1.2065)\n",
      "\n",
      "Epoch: [173][1/16]\tTime 0.182 (0.575)\tETA 0:00:02\tTraining Loss 1.2053 (1.2059)\n",
      "\n",
      "Epoch: [173][2/16]\tTime 0.193 (0.768)\tETA 0:00:02\tTraining Loss 1.2055 (1.2058)\n",
      "\n",
      "Epoch: [173][3/16]\tTime 0.190 (0.958)\tETA 0:00:02\tTraining Loss 1.2039 (1.2053)\n",
      "\n",
      "Epoch: [173][4/16]\tTime 0.195 (1.153)\tETA 0:00:02\tTraining Loss 1.2024 (1.2047)\n",
      "\n",
      "Epoch: [173][5/16]\tTime 0.200 (1.353)\tETA 0:00:02\tTraining Loss 1.2020 (1.2043)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: [173][6/16]\tTime 0.192 (1.545)\tETA 0:00:01\tTraining Loss 1.2025 (1.2040)\n",
      "\n",
      "Epoch: [173][7/16]\tTime 0.191 (1.736)\tETA 0:00:01\tTraining Loss 1.2057 (1.2042)\n",
      "\n",
      "Epoch: [173][8/16]\tTime 0.190 (1.926)\tETA 0:00:01\tTraining Loss 1.2077 (1.2046)\n",
      "\n",
      "Epoch: [173][9/16]\tTime 0.187 (2.113)\tETA 0:00:01\tTraining Loss 1.2023 (1.2044)\n",
      "\n",
      "Epoch: [173][10/16]\tTime 0.190 (2.304)\tETA 0:00:01\tTraining Loss 1.2024 (1.2042)\n",
      "\n",
      "Epoch: [173][11/16]\tTime 0.178 (2.482)\tETA 0:00:00\tTraining Loss 1.2037 (1.2042)\n",
      "\n",
      "Epoch: [173][12/16]\tTime 0.196 (2.678)\tETA 0:00:00\tTraining Loss 1.2042 (1.2042)\n",
      "\n",
      "Epoch: [173][13/16]\tTime 0.195 (2.873)\tETA 0:00:00\tTraining Loss 1.2087 (1.2045)\n",
      "\n",
      "Epoch: [173][14/16]\tTime 0.184 (3.056)\tETA 0:00:00\tTraining Loss 1.2028 (1.2044)\n",
      "\n",
      "Epoch: [173][15/16]\tTime 0.115 (3.171)\tETA 0:00:00\tTraining Loss 1.2053 (1.2044)\n",
      "_\n",
      "Validation stats                    IoU        F1      Prec    recall       Acc\n",
      "bg,          0.954400  0.976600  0.977500  0.975900  0.959500\n",
      "real apple   0.359900  0.529300  0.803400  0.394700  0.953900\n",
      "real pepper  0.000000  0.000000  0.000000  0.000000  1.000000\n",
      "real grape   0.425700  0.597200  0.899300  0.447000  0.961000\n",
      "fake apple   0.000000  0.000000  0.000000  0.000000  0.977000\n",
      "fake pepper  0.000000  0.000000  0.000000  0.000000  0.996600\n",
      "fake grape   0.000000  0.000000  0.000000  0.000000  0.958900\n",
      "total        0.248571  0.300443  0.382886  0.259657  0.972414\n",
      "total(-bg)   0.130933  0.187750  0.283783  0.140283  0.974567\n",
      "\n",
      "Epoch: [174][0/16]\tTime 0.412 (0.412)\tETA 0:00:06\tTraining Loss 1.2014 (1.2014)\n",
      "\n",
      "Epoch: [174][1/16]\tTime 0.177 (0.589)\tETA 0:00:02\tTraining Loss 1.2020 (1.2017)\n",
      "\n",
      "Epoch: [174][2/16]\tTime 0.186 (0.775)\tETA 0:00:02\tTraining Loss 1.2018 (1.2017)\n",
      "\n",
      "Epoch: [174][3/16]\tTime 0.190 (0.965)\tETA 0:00:02\tTraining Loss 1.2027 (1.2019)\n",
      "\n",
      "Epoch: [174][4/16]\tTime 0.190 (1.155)\tETA 0:00:02\tTraining Loss 1.2045 (1.2025)\n",
      "\n",
      "Epoch: [174][5/16]\tTime 0.189 (1.344)\tETA 0:00:02\tTraining Loss 1.2089 (1.2035)\n",
      "\n",
      "Epoch: [174][6/16]\tTime 0.212 (1.557)\tETA 0:00:02\tTraining Loss 1.2020 (1.2033)\n",
      "\n",
      "Epoch: [174][7/16]\tTime 0.191 (1.747)\tETA 0:00:01\tTraining Loss 1.2029 (1.2033)\n",
      "\n",
      "Epoch: [174][8/16]\tTime 0.185 (1.933)\tETA 0:00:01\tTraining Loss 1.2025 (1.2032)\n",
      "\n",
      "Epoch: [174][9/16]\tTime 0.182 (2.115)\tETA 0:00:01\tTraining Loss 1.2012 (1.2030)\n",
      "\n",
      "Epoch: [174][10/16]\tTime 0.189 (2.304)\tETA 0:00:01\tTraining Loss 1.2000 (1.2027)\n",
      "\n",
      "Epoch: [174][11/16]\tTime 0.188 (2.492)\tETA 0:00:00\tTraining Loss 1.2021 (1.2027)\n",
      "\n",
      "Epoch: [174][12/16]\tTime 0.191 (2.682)\tETA 0:00:00\tTraining Loss 1.2040 (1.2028)\n",
      "\n",
      "Epoch: [174][13/16]\tTime 0.183 (2.865)\tETA 0:00:00\tTraining Loss 1.2041 (1.2029)\n",
      "\n",
      "Epoch: [174][14/16]\tTime 0.198 (3.063)\tETA 0:00:00\tTraining Loss 1.2146 (1.2036)\n",
      "\n",
      "Epoch: [174][15/16]\tTime 0.116 (3.179)\tETA 0:00:00\tTraining Loss 1.2080 (1.2038)\n",
      "_\n",
      "Validation stats                    IoU        F1      Prec    recall       Acc\n",
      "bg,          0.949900  0.974300  0.978200  0.970500  0.955500\n",
      "real apple   0.534800  0.696800  0.848400  0.591200  0.966200\n",
      "real pepper  0.000000  0.000000  0.000000  0.000000  1.000000\n",
      "real grape   0.695600  0.820400  0.920700  0.740000  0.979000\n",
      "fake apple   0.000000  0.000000  0.000000  0.000000  0.988800\n",
      "fake pepper  0.000000  0.000000  0.000000  0.000000  0.992500\n",
      "fake grape   0.000000  0.000000  0.000000  0.000000  0.979200\n",
      "total        0.311471  0.355929  0.392471  0.328814  0.980171\n",
      "total(-bg)   0.205067  0.252867  0.294850  0.221867  0.984283\n",
      "\n",
      "Epoch: [175][0/16]\tTime 0.409 (0.409)\tETA 0:00:06\tTraining Loss 1.2010 (1.2010)\n",
      "\n",
      "Epoch: [175][1/16]\tTime 0.190 (0.599)\tETA 0:00:02\tTraining Loss 1.2006 (1.2008)\n",
      "\n",
      "Epoch: [175][2/16]\tTime 0.193 (0.793)\tETA 0:00:02\tTraining Loss 1.1999 (1.2005)\n",
      "\n",
      "Epoch: [175][3/16]\tTime 0.181 (0.974)\tETA 0:00:02\tTraining Loss 1.2009 (1.2006)\n",
      "\n",
      "Epoch: [175][4/16]\tTime 0.189 (1.163)\tETA 0:00:02\tTraining Loss 1.1997 (1.2004)\n",
      "\n",
      "Epoch: [175][5/16]\tTime 0.185 (1.348)\tETA 0:00:02\tTraining Loss 1.2185 (1.2034)\n",
      "\n",
      "Epoch: [175][6/16]\tTime 0.187 (1.535)\tETA 0:00:01\tTraining Loss 1.2023 (1.2033)\n",
      "\n",
      "Epoch: [175][7/16]\tTime 0.188 (1.723)\tETA 0:00:01\tTraining Loss 1.2091 (1.2040)\n",
      "\n",
      "Epoch: [175][8/16]\tTime 0.190 (1.912)\tETA 0:00:01\tTraining Loss 1.2017 (1.2037)\n",
      "\n",
      "Epoch: [175][9/16]\tTime 0.192 (2.104)\tETA 0:00:01\tTraining Loss 1.2030 (1.2037)\n",
      "\n",
      "Epoch: [175][10/16]\tTime 0.204 (2.308)\tETA 0:00:01\tTraining Loss 1.2054 (1.2038)\n",
      "\n",
      "Epoch: [175][11/16]\tTime 0.193 (2.501)\tETA 0:00:00\tTraining Loss 1.2059 (1.2040)\n",
      "\n",
      "Epoch: [175][12/16]\tTime 0.193 (2.694)\tETA 0:00:00\tTraining Loss 1.2014 (1.2038)\n",
      "\n",
      "Epoch: [175][13/16]\tTime 0.193 (2.887)\tETA 0:00:00\tTraining Loss 1.2005 (1.2036)\n",
      "\n",
      "Epoch: [175][14/16]\tTime 0.185 (3.072)\tETA 0:00:00\tTraining Loss 1.2026 (1.2035)\n",
      "\n",
      "Epoch: [175][15/16]\tTime 0.113 (3.185)\tETA 0:00:00\tTraining Loss 1.2010 (1.2034)\n",
      "_\n",
      "Validation stats                    IoU        F1      Prec    recall       Acc\n",
      "bg,          0.952400  0.975600  0.977000  0.974200  0.957600\n",
      "real apple   0.407400  0.578900  0.811300  0.450100  0.957000\n",
      "real pepper  0.000000  0.000000  0.000000  0.000000  0.999300\n",
      "real grape   0.811900  0.896100  0.915200  0.877900  0.986800\n",
      "fake apple   0.000000  0.000000  0.000000  0.000000  0.980500\n",
      "fake pepper  0.000000  0.000000  0.000000  0.000000  0.993100\n",
      "fake grape   0.000000  0.000000  0.000000  0.000000  0.992800\n",
      "total        0.310243  0.350086  0.386214  0.328886  0.981014\n",
      "total(-bg)   0.203217  0.245833  0.287750  0.221333  0.984917\n",
      "\n",
      "Epoch: [176][0/16]\tTime 0.427 (0.427)\tETA 0:00:06\tTraining Loss 1.2033 (1.2033)\n",
      "\n",
      "Epoch: [176][1/16]\tTime 0.183 (0.610)\tETA 0:00:02\tTraining Loss 1.2043 (1.2038)\n",
      "\n",
      "Epoch: [176][2/16]\tTime 0.193 (0.803)\tETA 0:00:02\tTraining Loss 1.1990 (1.2022)\n",
      "\n",
      "Epoch: [176][3/16]\tTime 0.186 (0.989)\tETA 0:00:02\tTraining Loss 1.2070 (1.2034)\n",
      "\n",
      "Epoch: [176][4/16]\tTime 0.195 (1.183)\tETA 0:00:02\tTraining Loss 1.1996 (1.2026)\n",
      "\n",
      "Epoch: [176][5/16]\tTime 0.186 (1.369)\tETA 0:00:02\tTraining Loss 1.2022 (1.2026)\n",
      "\n",
      "Epoch: [176][6/16]\tTime 0.191 (1.561)\tETA 0:00:01\tTraining Loss 1.2051 (1.2029)\n",
      "\n",
      "Epoch: [176][7/16]\tTime 0.191 (1.751)\tETA 0:00:01\tTraining Loss 1.2019 (1.2028)\n",
      "\n",
      "Epoch: [176][8/16]\tTime 0.187 (1.939)\tETA 0:00:01\tTraining Loss 1.1994 (1.2024)\n",
      "\n",
      "Epoch: [176][9/16]\tTime 0.195 (2.133)\tETA 0:00:01\tTraining Loss 1.2009 (1.2023)\n",
      "\n",
      "Epoch: [176][10/16]\tTime 0.191 (2.324)\tETA 0:00:01\tTraining Loss 1.1991 (1.2020)\n",
      "\n",
      "Epoch: [176][11/16]\tTime 0.189 (2.513)\tETA 0:00:00\tTraining Loss 1.1994 (1.2018)\n",
      "\n",
      "Epoch: [176][12/16]\tTime 0.203 (2.716)\tETA 0:00:00\tTraining Loss 1.2014 (1.2017)\n",
      "\n",
      "Epoch: [176][13/16]\tTime 0.197 (2.913)\tETA 0:00:00\tTraining Loss 1.2051 (1.2020)\n",
      "\n",
      "Epoch: [176][14/16]\tTime 0.192 (3.105)\tETA 0:00:00\tTraining Loss 1.2034 (1.2021)\n",
      "\n",
      "Epoch: [176][15/16]\tTime 0.118 (3.223)\tETA 0:00:00\tTraining Loss 1.2142 (1.2025)\n",
      "_\n",
      "Validation stats                    IoU        F1      Prec    recall       Acc\n",
      "bg,          0.950400  0.974500  0.976500  0.972700  0.955900\n",
      "real apple   0.429200  0.600600  0.859700  0.461600  0.959700\n",
      "real pepper  0.000000  0.000000  0.000000  0.000000  0.999800\n",
      "real grape   0.800000  0.888800  0.896600  0.881300  0.985700\n",
      "fake apple   0.000000  0.000000  0.000000  0.000000  0.980100\n",
      "fake pepper  0.000000  0.000000  0.000000  0.000000  0.990800\n",
      "fake grape   0.000000  0.000000  0.000000  0.000000  0.994400\n",
      "total        0.311371  0.351986  0.390400  0.330800  0.980914\n",
      "total(-bg)   0.204867  0.248233  0.292717  0.223817  0.985083\n",
      "\n",
      "Epoch: [177][0/16]\tTime 0.398 (0.398)\tETA 0:00:06\tTraining Loss 1.2000 (1.2000)\n",
      "\n",
      "Epoch: [177][1/16]\tTime 0.201 (0.599)\tETA 0:00:03\tTraining Loss 1.2013 (1.2006)\n",
      "\n",
      "Epoch: [177][2/16]\tTime 0.176 (0.775)\tETA 0:00:02\tTraining Loss 1.2070 (1.2028)\n",
      "\n",
      "Epoch: [177][3/16]\tTime 0.186 (0.962)\tETA 0:00:02\tTraining Loss 1.2031 (1.2029)\n",
      "\n",
      "Epoch: [177][4/16]\tTime 0.189 (1.150)\tETA 0:00:02\tTraining Loss 1.2037 (1.2030)\n",
      "\n",
      "Epoch: [177][5/16]\tTime 0.194 (1.344)\tETA 0:00:02\tTraining Loss 1.2041 (1.2032)\n",
      "\n",
      "Epoch: [177][6/16]\tTime 0.186 (1.530)\tETA 0:00:01\tTraining Loss 1.2046 (1.2034)\n",
      "\n",
      "Epoch: [177][7/16]\tTime 0.217 (1.747)\tETA 0:00:01\tTraining Loss 1.2047 (1.2036)\n",
      "\n",
      "Epoch: [177][8/16]\tTime 0.193 (1.940)\tETA 0:00:01\tTraining Loss 1.2052 (1.2037)\n",
      "\n",
      "Epoch: [177][9/16]\tTime 0.192 (2.132)\tETA 0:00:01\tTraining Loss 1.2029 (1.2037)\n",
      "\n",
      "Epoch: [177][10/16]\tTime 0.183 (2.315)\tETA 0:00:01\tTraining Loss 1.1993 (1.2033)\n",
      "\n",
      "Epoch: [177][11/16]\tTime 0.190 (2.505)\tETA 0:00:00\tTraining Loss 1.2022 (1.2032)\n",
      "\n",
      "Epoch: [177][12/16]\tTime 0.187 (2.693)\tETA 0:00:00\tTraining Loss 1.2005 (1.2030)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: [177][13/16]\tTime 0.183 (2.876)\tETA 0:00:00\tTraining Loss 1.2012 (1.2028)\n",
      "\n",
      "Epoch: [177][14/16]\tTime 0.184 (3.060)\tETA 0:00:00\tTraining Loss 1.2000 (1.2027)\n",
      "\n",
      "Epoch: [177][15/16]\tTime 0.116 (3.176)\tETA 0:00:00\tTraining Loss 1.2032 (1.2027)\n",
      "_\n",
      "Validation stats                    IoU        F1      Prec    recall       Acc\n",
      "bg,          0.953100  0.976000  0.975300  0.976700  0.958200\n",
      "real apple   0.320500  0.485400  0.809000  0.346800  0.951700\n",
      "real pepper  0.000000  0.000000  0.000000  0.000000  1.000000\n",
      "real grape   0.771300  0.870800  0.896900  0.846400  0.983700\n",
      "fake apple   0.000000  0.000000  0.000000  0.000000  0.975200\n",
      "fake pepper  0.000000  0.000000  0.000000  0.000000  0.995700\n",
      "fake grape   0.000000  0.000000  0.000000  0.000000  0.989200\n",
      "total        0.292129  0.333171  0.383029  0.309986  0.979100\n",
      "total(-bg)   0.181967  0.226033  0.284317  0.198867  0.982583\n",
      "\n",
      "Epoch: [178][0/16]\tTime 0.419 (0.419)\tETA 0:00:06\tTraining Loss 1.1994 (1.1994)\n",
      "\n",
      "Epoch: [178][1/16]\tTime 0.185 (0.604)\tETA 0:00:02\tTraining Loss 1.2044 (1.2019)\n",
      "\n",
      "Epoch: [178][2/16]\tTime 0.193 (0.797)\tETA 0:00:02\tTraining Loss 1.1990 (1.2009)\n",
      "\n",
      "Epoch: [178][3/16]\tTime 0.194 (0.991)\tETA 0:00:02\tTraining Loss 1.2004 (1.2008)\n",
      "\n",
      "Epoch: [178][4/16]\tTime 0.195 (1.186)\tETA 0:00:02\tTraining Loss 1.1996 (1.2006)\n",
      "\n",
      "Epoch: [178][5/16]\tTime 0.187 (1.373)\tETA 0:00:02\tTraining Loss 1.2062 (1.2015)\n",
      "\n",
      "Epoch: [178][6/16]\tTime 0.196 (1.569)\tETA 0:00:01\tTraining Loss 1.2051 (1.2020)\n",
      "\n",
      "Epoch: [178][7/16]\tTime 0.184 (1.753)\tETA 0:00:01\tTraining Loss 1.2027 (1.2021)\n",
      "\n",
      "Epoch: [178][8/16]\tTime 0.196 (1.949)\tETA 0:00:01\tTraining Loss 1.2006 (1.2019)\n",
      "\n",
      "Epoch: [178][9/16]\tTime 0.191 (2.140)\tETA 0:00:01\tTraining Loss 1.2000 (1.2017)\n",
      "\n",
      "Epoch: [178][10/16]\tTime 0.202 (2.343)\tETA 0:00:01\tTraining Loss 1.2014 (1.2017)\n",
      "\n",
      "Epoch: [178][11/16]\tTime 0.188 (2.531)\tETA 0:00:00\tTraining Loss 1.2003 (1.2016)\n",
      "\n",
      "Epoch: [178][12/16]\tTime 0.198 (2.728)\tETA 0:00:00\tTraining Loss 1.2009 (1.2015)\n",
      "\n",
      "Epoch: [178][13/16]\tTime 0.196 (2.925)\tETA 0:00:00\tTraining Loss 1.2008 (1.2015)\n",
      "\n",
      "Epoch: [178][14/16]\tTime 0.196 (3.121)\tETA 0:00:00\tTraining Loss 1.2010 (1.2015)\n",
      "\n",
      "Epoch: [178][15/16]\tTime 0.119 (3.240)\tETA 0:00:00\tTraining Loss 1.1991 (1.2014)\n",
      "_\n",
      "Validation stats                    IoU        F1      Prec    recall       Acc\n",
      "bg,          0.955700  0.977300  0.977100  0.977600  0.960600\n",
      "real apple   0.596000  0.746800  0.906400  0.635100  0.971700\n",
      "real pepper  0.000000  0.000000  0.000000  0.000000  0.999600\n",
      "real grape   0.652800  0.789900  0.869700  0.723600  0.975100\n",
      "fake apple   0.000000  0.000000  0.000000  0.000000  0.993900\n",
      "fake pepper  0.000000  0.000000  0.000000  0.000000  0.997300\n",
      "fake grape   0.000000  0.000000  0.000000  0.000000  0.979000\n",
      "total        0.314929  0.359143  0.393314  0.333757  0.982457\n",
      "total(-bg)   0.208133  0.256117  0.296017  0.226450  0.986100\n",
      "\n",
      "Epoch: [179][0/16]\tTime 0.395 (0.395)\tETA 0:00:06\tTraining Loss 1.2030 (1.2030)\n",
      "\n",
      "Epoch: [179][1/16]\tTime 0.193 (0.588)\tETA 0:00:02\tTraining Loss 1.1997 (1.2013)\n",
      "\n",
      "Epoch: [179][2/16]\tTime 0.193 (0.781)\tETA 0:00:02\tTraining Loss 1.1976 (1.2001)\n",
      "\n",
      "Epoch: [179][3/16]\tTime 0.186 (0.967)\tETA 0:00:02\tTraining Loss 1.2028 (1.2008)\n",
      "\n",
      "Epoch: [179][4/16]\tTime 0.199 (1.166)\tETA 0:00:02\tTraining Loss 1.1988 (1.2004)\n",
      "\n",
      "Epoch: [179][5/16]\tTime 0.186 (1.352)\tETA 0:00:02\tTraining Loss 1.2017 (1.2006)\n",
      "\n",
      "Epoch: [179][6/16]\tTime 0.305 (1.657)\tETA 0:00:03\tTraining Loss 1.1986 (1.2003)\n",
      "\n",
      "Epoch: [179][7/16]\tTime 0.197 (1.854)\tETA 0:00:01\tTraining Loss 1.1983 (1.2001)\n",
      "\n",
      "Epoch: [179][8/16]\tTime 0.187 (2.040)\tETA 0:00:01\tTraining Loss 1.2024 (1.2003)\n",
      "\n",
      "Epoch: [179][9/16]\tTime 0.198 (2.238)\tETA 0:00:01\tTraining Loss 1.2019 (1.2005)\n",
      "\n",
      "Epoch: [179][10/16]\tTime 0.188 (2.426)\tETA 0:00:01\tTraining Loss 1.2000 (1.2004)\n",
      "\n",
      "Epoch: [179][11/16]\tTime 0.196 (2.622)\tETA 0:00:00\tTraining Loss 1.2004 (1.2004)\n",
      "\n",
      "Epoch: [179][12/16]\tTime 0.195 (2.817)\tETA 0:00:00\tTraining Loss 1.1996 (1.2004)\n",
      "\n",
      "Epoch: [179][13/16]\tTime 0.185 (3.002)\tETA 0:00:00\tTraining Loss 1.2076 (1.2009)\n",
      "\n",
      "Epoch: [179][14/16]\tTime 0.193 (3.195)\tETA 0:00:00\tTraining Loss 1.1985 (1.2007)\n",
      "\n",
      "Epoch: [179][15/16]\tTime 0.111 (3.306)\tETA 0:00:00\tTraining Loss 1.1992 (1.2007)\n",
      "_\n",
      "Validation stats                    IoU        F1      Prec    recall       Acc\n",
      "bg,          0.950300  0.974500  0.976700  0.972300  0.955800\n",
      "real apple   0.444200  0.615100  0.875600  0.474100  0.961000\n",
      "real pepper  0.000000  0.000000  0.000000  0.000000  1.000000\n",
      "real grape   0.765500  0.867100  0.894800  0.841200  0.983300\n",
      "fake apple   0.000000  0.000000  0.000000  0.000000  0.981500\n",
      "fake pepper  0.000000  0.000000  0.000000  0.000000  0.992500\n",
      "fake grape   0.000000  0.000000  0.000000  0.000000  0.988100\n",
      "total        0.308571  0.350957  0.392443  0.326800  0.980314\n",
      "total(-bg)   0.201617  0.247033  0.295067  0.219217  0.984400\n",
      "\n",
      "Epoch: [180][0/16]\tTime 0.448 (0.448)\tETA 0:00:07\tTraining Loss 1.1989 (1.1989)\n",
      "\n",
      "Epoch: [180][1/16]\tTime 0.185 (0.633)\tETA 0:00:02\tTraining Loss 1.1997 (1.1993)\n",
      "\n",
      "Epoch: [180][2/16]\tTime 0.185 (0.818)\tETA 0:00:02\tTraining Loss 1.1980 (1.1989)\n",
      "\n",
      "Epoch: [180][3/16]\tTime 0.210 (1.028)\tETA 0:00:02\tTraining Loss 1.2006 (1.1993)\n",
      "\n",
      "Epoch: [180][4/16]\tTime 0.167 (1.195)\tETA 0:00:02\tTraining Loss 1.1989 (1.1992)\n",
      "\n",
      "Epoch: [180][5/16]\tTime 0.185 (1.380)\tETA 0:00:02\tTraining Loss 1.1998 (1.1993)\n",
      "\n",
      "Epoch: [180][6/16]\tTime 0.177 (1.557)\tETA 0:00:01\tTraining Loss 1.2008 (1.1995)\n",
      "\n",
      "Epoch: [180][7/16]\tTime 0.197 (1.754)\tETA 0:00:01\tTraining Loss 1.1990 (1.1995)\n",
      "\n",
      "Epoch: [180][8/16]\tTime 0.187 (1.941)\tETA 0:00:01\tTraining Loss 1.1986 (1.1994)\n",
      "\n",
      "Epoch: [180][9/16]\tTime 0.187 (2.128)\tETA 0:00:01\tTraining Loss 1.2025 (1.1997)\n",
      "\n",
      "Epoch: [180][10/16]\tTime 0.183 (2.311)\tETA 0:00:01\tTraining Loss 1.2003 (1.1997)\n",
      "\n",
      "Epoch: [180][11/16]\tTime 0.197 (2.508)\tETA 0:00:00\tTraining Loss 1.1997 (1.1997)\n",
      "\n",
      "Epoch: [180][12/16]\tTime 0.180 (2.688)\tETA 0:00:00\tTraining Loss 1.2015 (1.1999)\n",
      "\n",
      "Epoch: [180][13/16]\tTime 0.186 (2.874)\tETA 0:00:00\tTraining Loss 1.2004 (1.1999)\n",
      "\n",
      "Epoch: [180][14/16]\tTime 0.184 (3.058)\tETA 0:00:00\tTraining Loss 1.1974 (1.1997)\n",
      "\n",
      "Epoch: [180][15/16]\tTime 0.117 (3.175)\tETA 0:00:00\tTraining Loss 1.2017 (1.1998)\n",
      "_\n",
      "Validation stats                    IoU        F1      Prec    recall      Acc\n",
      "bg,          0.949900  0.974200  0.977700  0.970900  0.95540\n",
      "real apple   0.618100  0.764000  0.896900  0.665400  0.97300\n",
      "real pepper  0.000000  0.000000  0.000000  0.000000  1.00000\n",
      "real grape   0.725500  0.840900  0.892300  0.795200  0.98050\n",
      "fake apple   0.000000  0.000000  0.000000  0.000000  0.99050\n",
      "fake pepper  0.000000  0.000000  0.000000  0.000000  0.99370\n",
      "fake grape   0.000000  0.000000  0.000000  0.000000  0.98580\n",
      "total        0.327643  0.368443  0.395271  0.347357  0.98270\n",
      "total(-bg)   0.223933  0.267483  0.298200  0.243433  0.98725\n",
      "\n",
      "Epoch: [181][0/16]\tTime 0.497 (0.497)\tETA 0:00:07\tTraining Loss 1.1980 (1.1980)\n",
      "\n",
      "Epoch: [181][1/16]\tTime 0.186 (0.683)\tETA 0:00:02\tTraining Loss 1.1973 (1.1976)\n",
      "\n",
      "Epoch: [181][2/16]\tTime 0.191 (0.875)\tETA 0:00:02\tTraining Loss 1.1976 (1.1976)\n",
      "\n",
      "Epoch: [181][3/16]\tTime 0.182 (1.057)\tETA 0:00:02\tTraining Loss 1.2033 (1.1991)\n",
      "\n",
      "Epoch: [181][4/16]\tTime 0.193 (1.250)\tETA 0:00:02\tTraining Loss 1.1984 (1.1989)\n",
      "\n",
      "Epoch: [181][5/16]\tTime 0.184 (1.433)\tETA 0:00:02\tTraining Loss 1.1983 (1.1988)\n",
      "\n",
      "Epoch: [181][6/16]\tTime 0.191 (1.625)\tETA 0:00:01\tTraining Loss 1.1968 (1.1985)\n",
      "\n",
      "Epoch: [181][7/16]\tTime 0.189 (1.814)\tETA 0:00:01\tTraining Loss 1.1968 (1.1983)\n",
      "\n",
      "Epoch: [181][8/16]\tTime 0.193 (2.006)\tETA 0:00:01\tTraining Loss 1.1989 (1.1984)\n",
      "\n",
      "Epoch: [181][9/16]\tTime 0.181 (2.188)\tETA 0:00:01\tTraining Loss 1.1965 (1.1982)\n",
      "\n",
      "Epoch: [181][10/16]\tTime 0.194 (2.382)\tETA 0:00:01\tTraining Loss 1.2019 (1.1985)\n",
      "\n",
      "Epoch: [181][11/16]\tTime 0.183 (2.565)\tETA 0:00:00\tTraining Loss 1.2015 (1.1988)\n",
      "\n",
      "Epoch: [181][12/16]\tTime 0.191 (2.756)\tETA 0:00:00\tTraining Loss 1.1988 (1.1988)\n",
      "\n",
      "Epoch: [181][13/16]\tTime 0.185 (2.941)\tETA 0:00:00\tTraining Loss 1.2015 (1.1990)\n",
      "\n",
      "Epoch: [181][14/16]\tTime 0.188 (3.129)\tETA 0:00:00\tTraining Loss 1.1984 (1.1989)\n",
      "\n",
      "Epoch: [181][15/16]\tTime 0.114 (3.243)\tETA 0:00:00\tTraining Loss 1.1968 (1.1989)\n",
      "_\n",
      "Validation stats                    IoU        F1      Prec    recall       Acc\n",
      "bg,          0.949200  0.973900  0.977800  0.970100  0.954900\n",
      "real apple   0.449000  0.619700  0.891700  0.474900  0.961700\n",
      "real pepper  0.000000  0.000000  0.000000  0.000000  1.000000\n",
      "real grape   0.743500  0.852900  0.876600  0.830400  0.981500\n",
      "fake apple   0.000000  0.000000  0.000000  0.000000  0.989600\n",
      "fake pepper  0.000000  0.000000  0.000000  0.000000  0.984300\n",
      "fake grape   0.000000  0.000000  0.000000  0.000000  0.985100\n",
      "total        0.305957  0.349500  0.392300  0.325057  0.979586\n",
      "total(-bg)   0.198750  0.245433  0.294717  0.217550  0.983700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: [182][0/16]\tTime 0.477 (0.477)\tETA 0:00:07\tTraining Loss 1.1959 (1.1959)\n",
      "\n",
      "Epoch: [182][1/16]\tTime 0.183 (0.660)\tETA 0:00:02\tTraining Loss 1.1976 (1.1967)\n",
      "\n",
      "Epoch: [182][2/16]\tTime 0.191 (0.851)\tETA 0:00:02\tTraining Loss 1.2004 (1.1979)\n",
      "\n",
      "Epoch: [182][3/16]\tTime 0.184 (1.035)\tETA 0:00:02\tTraining Loss 1.1998 (1.1984)\n",
      "\n",
      "Epoch: [182][4/16]\tTime 0.193 (1.228)\tETA 0:00:02\tTraining Loss 1.1994 (1.1986)\n",
      "\n",
      "Epoch: [182][5/16]\tTime 0.185 (1.413)\tETA 0:00:02\tTraining Loss 1.1982 (1.1985)\n",
      "\n",
      "Epoch: [182][6/16]\tTime 0.192 (1.605)\tETA 0:00:01\tTraining Loss 1.2010 (1.1989)\n",
      "\n",
      "Epoch: [182][7/16]\tTime 0.191 (1.796)\tETA 0:00:01\tTraining Loss 1.2031 (1.1994)\n",
      "\n",
      "Epoch: [182][8/16]\tTime 0.192 (1.988)\tETA 0:00:01\tTraining Loss 1.1974 (1.1992)\n",
      "\n",
      "Epoch: [182][9/16]\tTime 0.191 (2.179)\tETA 0:00:01\tTraining Loss 1.1997 (1.1992)\n",
      "\n",
      "Epoch: [182][10/16]\tTime 0.194 (2.373)\tETA 0:00:01\tTraining Loss 1.1996 (1.1993)\n",
      "\n",
      "Epoch: [182][11/16]\tTime 0.183 (2.556)\tETA 0:00:00\tTraining Loss 1.1957 (1.1990)\n",
      "\n",
      "Epoch: [182][12/16]\tTime 0.189 (2.746)\tETA 0:00:00\tTraining Loss 1.1967 (1.1988)\n",
      "\n",
      "Epoch: [182][13/16]\tTime 0.192 (2.937)\tETA 0:00:00\tTraining Loss 1.1980 (1.1987)\n",
      "\n",
      "Epoch: [182][14/16]\tTime 0.187 (3.125)\tETA 0:00:00\tTraining Loss 1.1987 (1.1987)\n",
      "\n",
      "Epoch: [182][15/16]\tTime 0.114 (3.239)\tETA 0:00:00\tTraining Loss 1.1989 (1.1987)\n",
      "_\n",
      "Validation stats                    IoU        F1      Prec    recall       Acc\n",
      "bg,          0.954000  0.976400  0.975100  0.977800  0.959000\n",
      "real apple   0.423600  0.595100  0.862700  0.454300  0.959400\n",
      "real pepper  0.000000  0.000000  0.000000  0.000000  1.000000\n",
      "real grape   0.661800  0.796400  0.891900  0.719500  0.976200\n",
      "fake apple   0.000000  0.000000  0.000000  0.000000  0.982000\n",
      "fake pepper  0.000000  0.000000  0.000000  0.000000  0.993500\n",
      "fake grape   0.000000  0.000000  0.000000  0.000000  0.983300\n",
      "total        0.291343  0.338271  0.389957  0.307371  0.979057\n",
      "total(-bg)   0.180900  0.231917  0.292433  0.195633  0.982400\n",
      "\n",
      "Epoch: [183][0/16]\tTime 0.396 (0.396)\tETA 0:00:06\tTraining Loss 1.1952 (1.1952)\n",
      "\n",
      "Epoch: [183][1/16]\tTime 0.194 (0.591)\tETA 0:00:02\tTraining Loss 1.1980 (1.1966)\n",
      "\n",
      "Epoch: [183][2/16]\tTime 0.192 (0.783)\tETA 0:00:02\tTraining Loss 1.1959 (1.1964)\n",
      "\n",
      "Epoch: [183][3/16]\tTime 0.190 (0.973)\tETA 0:00:02\tTraining Loss 1.1993 (1.1971)\n",
      "\n",
      "Epoch: [183][4/16]\tTime 0.198 (1.171)\tETA 0:00:02\tTraining Loss 1.1990 (1.1975)\n",
      "\n",
      "Epoch: [183][5/16]\tTime 0.190 (1.361)\tETA 0:00:02\tTraining Loss 1.2025 (1.1983)\n",
      "\n",
      "Epoch: [183][6/16]\tTime 0.205 (1.566)\tETA 0:00:02\tTraining Loss 1.1982 (1.1983)\n",
      "\n",
      "Epoch: [183][7/16]\tTime 0.183 (1.749)\tETA 0:00:01\tTraining Loss 1.1970 (1.1981)\n",
      "\n",
      "Epoch: [183][8/16]\tTime 0.187 (1.936)\tETA 0:00:01\tTraining Loss 1.1991 (1.1982)\n",
      "\n",
      "Epoch: [183][9/16]\tTime 0.194 (2.130)\tETA 0:00:01\tTraining Loss 1.1967 (1.1981)\n",
      "\n",
      "Epoch: [183][10/16]\tTime 0.191 (2.321)\tETA 0:00:01\tTraining Loss 1.1961 (1.1979)\n",
      "\n",
      "Epoch: [183][11/16]\tTime 0.215 (2.536)\tETA 0:00:01\tTraining Loss 1.2001 (1.1981)\n",
      "\n",
      "Epoch: [183][12/16]\tTime 0.204 (2.740)\tETA 0:00:00\tTraining Loss 1.1975 (1.1980)\n",
      "\n",
      "Epoch: [183][13/16]\tTime 0.185 (2.926)\tETA 0:00:00\tTraining Loss 1.2025 (1.1984)\n",
      "\n",
      "Epoch: [183][14/16]\tTime 0.187 (3.113)\tETA 0:00:00\tTraining Loss 1.1955 (1.1982)\n",
      "\n",
      "Epoch: [183][15/16]\tTime 0.112 (3.225)\tETA 0:00:00\tTraining Loss 1.2000 (1.1982)\n",
      "_\n",
      "Validation stats                    IoU       F1      Prec    recall       Acc\n",
      "bg,          0.955600  0.97730  0.977800  0.976800  0.960600\n",
      "real apple   0.640800  0.78100  0.897000  0.691700  0.974500\n",
      "real pepper  0.000000  0.00000  0.000000  0.000000  1.000000\n",
      "real grape   0.773700  0.87230  0.895300  0.850600  0.983900\n",
      "fake apple   0.000000  0.00000  0.000000  0.000000  0.993500\n",
      "fake pepper  0.000000  0.00000  0.000000  0.000000  0.998700\n",
      "fake grape   0.000000  0.00000  0.000000  0.000000  0.988600\n",
      "total        0.338586  0.37580  0.395729  0.359871  0.985686\n",
      "total(-bg)   0.235750  0.27555  0.298717  0.257050  0.989867\n",
      "\n",
      "Epoch: [184][0/16]\tTime 0.498 (0.498)\tETA 0:00:07\tTraining Loss 1.1982 (1.1982)\n",
      "\n",
      "Epoch: [184][1/16]\tTime 0.181 (0.678)\tETA 0:00:02\tTraining Loss 1.1994 (1.1988)\n",
      "\n",
      "Epoch: [184][2/16]\tTime 0.190 (0.869)\tETA 0:00:02\tTraining Loss 1.1953 (1.1976)\n",
      "\n",
      "Epoch: [184][3/16]\tTime 0.181 (1.049)\tETA 0:00:02\tTraining Loss 1.1963 (1.1973)\n",
      "\n",
      "Epoch: [184][4/16]\tTime 0.184 (1.233)\tETA 0:00:02\tTraining Loss 1.1977 (1.1974)\n",
      "\n",
      "Epoch: [184][5/16]\tTime 0.184 (1.417)\tETA 0:00:02\tTraining Loss 1.1981 (1.1975)\n",
      "\n",
      "Epoch: [184][6/16]\tTime 0.192 (1.609)\tETA 0:00:01\tTraining Loss 1.1980 (1.1976)\n",
      "\n",
      "Epoch: [184][7/16]\tTime 0.192 (1.801)\tETA 0:00:01\tTraining Loss 1.1948 (1.1972)\n",
      "\n",
      "Epoch: [184][8/16]\tTime 0.184 (1.985)\tETA 0:00:01\tTraining Loss 1.1966 (1.1971)\n",
      "\n",
      "Epoch: [184][9/16]\tTime 0.188 (2.173)\tETA 0:00:01\tTraining Loss 1.1979 (1.1972)\n",
      "\n",
      "Epoch: [184][10/16]\tTime 0.176 (2.349)\tETA 0:00:01\tTraining Loss 1.1975 (1.1972)\n",
      "\n",
      "Epoch: [184][11/16]\tTime 0.191 (2.540)\tETA 0:00:00\tTraining Loss 1.1955 (1.1971)\n",
      "\n",
      "Epoch: [184][12/16]\tTime 0.185 (2.725)\tETA 0:00:00\tTraining Loss 1.1971 (1.1971)\n",
      "\n",
      "Epoch: [184][13/16]\tTime 0.191 (2.916)\tETA 0:00:00\tTraining Loss 1.1996 (1.1973)\n",
      "\n",
      "Epoch: [184][14/16]\tTime 0.188 (3.105)\tETA 0:00:00\tTraining Loss 1.2004 (1.1975)\n",
      "\n",
      "Epoch: [184][15/16]\tTime 0.114 (3.219)\tETA 0:00:00\tTraining Loss 1.2024 (1.1976)\n",
      "_\n",
      "Validation stats                    IoU        F1      Prec    recall       Acc\n",
      "bg,          0.953000  0.975900  0.977400  0.974400  0.958200\n",
      "real apple   0.611600  0.758900  0.906500  0.652800  0.972800\n",
      "real pepper  0.000000  0.000000  0.000000  0.000000  1.000000\n",
      "real grape   0.786000  0.880100  0.896200  0.864700  0.984800\n",
      "fake apple   0.000000  0.000000  0.000000  0.000000  0.991600\n",
      "fake pepper  0.000000  0.000000  0.000000  0.000000  0.997400\n",
      "fake grape   0.000000  0.000000  0.000000  0.000000  0.987700\n",
      "total        0.335800  0.373557  0.397157  0.355986  0.984643\n",
      "total(-bg)   0.232933  0.273167  0.300450  0.252917  0.989050\n",
      "\n",
      "Epoch: [185][0/16]\tTime 0.488 (0.488)\tETA 0:00:07\tTraining Loss 1.1962 (1.1962)\n",
      "\n",
      "Epoch: [185][1/16]\tTime 0.182 (0.669)\tETA 0:00:02\tTraining Loss 1.1983 (1.1973)\n",
      "\n",
      "Epoch: [185][2/16]\tTime 0.185 (0.854)\tETA 0:00:02\tTraining Loss 1.1983 (1.1976)\n",
      "\n",
      "Epoch: [185][3/16]\tTime 0.181 (1.035)\tETA 0:00:02\tTraining Loss 1.1964 (1.1973)\n",
      "\n",
      "Epoch: [185][4/16]\tTime 0.187 (1.222)\tETA 0:00:02\tTraining Loss 1.1981 (1.1975)\n",
      "\n",
      "Epoch: [185][5/16]\tTime 0.186 (1.408)\tETA 0:00:02\tTraining Loss 1.1968 (1.1973)\n",
      "\n",
      "Epoch: [185][6/16]\tTime 0.186 (1.594)\tETA 0:00:01\tTraining Loss 1.1990 (1.1976)\n",
      "\n",
      "Epoch: [185][7/16]\tTime 0.191 (1.785)\tETA 0:00:01\tTraining Loss 1.1981 (1.1976)\n",
      "\n",
      "Epoch: [185][8/16]\tTime 0.183 (1.969)\tETA 0:00:01\tTraining Loss 1.1973 (1.1976)\n",
      "\n",
      "Epoch: [185][9/16]\tTime 0.179 (2.148)\tETA 0:00:01\tTraining Loss 1.2009 (1.1979)\n",
      "\n",
      "Epoch: [185][10/16]\tTime 0.182 (2.330)\tETA 0:00:01\tTraining Loss 1.1951 (1.1977)\n",
      "\n",
      "Epoch: [185][11/16]\tTime 0.187 (2.517)\tETA 0:00:00\tTraining Loss 1.1976 (1.1977)\n",
      "\n",
      "Epoch: [185][12/16]\tTime 0.197 (2.714)\tETA 0:00:00\tTraining Loss 1.1982 (1.1977)\n",
      "\n",
      "Epoch: [185][13/16]\tTime 0.188 (2.902)\tETA 0:00:00\tTraining Loss 1.1959 (1.1976)\n",
      "\n",
      "Epoch: [185][14/16]\tTime 0.186 (3.087)\tETA 0:00:00\tTraining Loss 1.1962 (1.1975)\n",
      "\n",
      "Epoch: [185][15/16]\tTime 0.113 (3.200)\tETA 0:00:00\tTraining Loss 1.2017 (1.1976)\n",
      "_\n",
      "Validation stats                    IoU        F1      Prec    recall       Acc\n",
      "bg,          0.955600  0.977300  0.976400  0.978200  0.960500\n",
      "real apple   0.488400  0.656300  0.891200  0.519400  0.964200\n",
      "real pepper  0.000000  0.000000  0.000000  0.000000  1.000000\n",
      "real grape   0.706400  0.827900  0.900100  0.766500  0.979400\n",
      "fake apple   0.000000  0.000000  0.000000  0.000000  0.984700\n",
      "fake pepper  0.000000  0.000000  0.000000  0.000000  0.997000\n",
      "fake grape   0.000000  0.000000  0.000000  0.000000  0.982900\n",
      "total        0.307200  0.351643  0.395386  0.323443  0.981243\n",
      "total(-bg)   0.199133  0.247367  0.298550  0.214317  0.984700\n",
      "\n",
      "Epoch: [186][0/16]\tTime 0.484 (0.484)\tETA 0:00:07\tTraining Loss 1.1976 (1.1976)\n",
      "\n",
      "Epoch: [186][1/16]\tTime 0.191 (0.675)\tETA 0:00:02\tTraining Loss 1.1977 (1.1977)\n",
      "\n",
      "Epoch: [186][2/16]\tTime 0.186 (0.861)\tETA 0:00:02\tTraining Loss 1.1954 (1.1969)\n",
      "\n",
      "Epoch: [186][3/16]\tTime 0.192 (1.053)\tETA 0:00:02\tTraining Loss 1.2003 (1.1978)\n",
      "\n",
      "Epoch: [186][4/16]\tTime 0.188 (1.241)\tETA 0:00:02\tTraining Loss 1.1949 (1.1972)\n",
      "\n",
      "Epoch: [186][5/16]\tTime 0.183 (1.424)\tETA 0:00:02\tTraining Loss 1.1936 (1.1966)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: [186][6/16]\tTime 0.188 (1.612)\tETA 0:00:01\tTraining Loss 1.1964 (1.1966)\n",
      "\n",
      "Epoch: [186][7/16]\tTime 0.185 (1.798)\tETA 0:00:01\tTraining Loss 1.1966 (1.1966)\n",
      "\n",
      "Epoch: [186][8/16]\tTime 0.176 (1.974)\tETA 0:00:01\tTraining Loss 1.1989 (1.1968)\n",
      "\n",
      "Epoch: [186][9/16]\tTime 0.186 (2.159)\tETA 0:00:01\tTraining Loss 1.1961 (1.1968)\n",
      "\n",
      "Epoch: [186][10/16]\tTime 0.185 (2.345)\tETA 0:00:01\tTraining Loss 1.1971 (1.1968)\n",
      "\n",
      "Epoch: [186][11/16]\tTime 0.184 (2.529)\tETA 0:00:00\tTraining Loss 1.1948 (1.1966)\n",
      "\n",
      "Epoch: [186][12/16]\tTime 0.185 (2.714)\tETA 0:00:00\tTraining Loss 1.1984 (1.1968)\n",
      "\n",
      "Epoch: [186][13/16]\tTime 0.179 (2.893)\tETA 0:00:00\tTraining Loss 1.1947 (1.1966)\n",
      "\n",
      "Epoch: [186][14/16]\tTime 0.186 (3.079)\tETA 0:00:00\tTraining Loss 1.1963 (1.1966)\n",
      "\n",
      "Epoch: [186][15/16]\tTime 0.112 (3.191)\tETA 0:00:00\tTraining Loss 1.1990 (1.1967)\n",
      "_\n",
      "Validation stats                    IoU        F1      Prec    recall       Acc\n",
      "bg,          0.953600  0.976200  0.977500  0.975100  0.958800\n",
      "real apple   0.432700  0.604000  0.867800  0.463200  0.960100\n",
      "real pepper  0.000000  0.000000  0.000000  0.000000  1.000000\n",
      "real grape   0.754600  0.860100  0.888400  0.833600  0.982400\n",
      "fake apple   0.000000  0.000000  0.000000  0.000000  0.980200\n",
      "fake pepper  0.000000  0.000000  0.000000  0.000000  0.995300\n",
      "fake grape   0.000000  0.000000  0.000000  0.000000  0.987900\n",
      "total        0.305843  0.348614  0.390529  0.324557  0.980671\n",
      "total(-bg)   0.197883  0.244017  0.292700  0.216133  0.984317\n",
      "\n",
      "Epoch: [187][0/16]\tTime 0.515 (0.515)\tETA 0:00:08\tTraining Loss 1.1959 (1.1959)\n",
      "\n",
      "Epoch: [187][1/16]\tTime 0.185 (0.700)\tETA 0:00:02\tTraining Loss 1.1935 (1.1947)\n",
      "\n",
      "Epoch: [187][2/16]\tTime 0.183 (0.883)\tETA 0:00:02\tTraining Loss 1.2005 (1.1967)\n",
      "\n",
      "Epoch: [187][3/16]\tTime 0.193 (1.076)\tETA 0:00:02\tTraining Loss 1.1972 (1.1968)\n",
      "\n",
      "Epoch: [187][4/16]\tTime 0.188 (1.264)\tETA 0:00:02\tTraining Loss 1.1971 (1.1969)\n",
      "\n",
      "Epoch: [187][5/16]\tTime 0.191 (1.454)\tETA 0:00:02\tTraining Loss 1.1969 (1.1969)\n",
      "\n",
      "Epoch: [187][6/16]\tTime 0.191 (1.645)\tETA 0:00:01\tTraining Loss 1.1964 (1.1968)\n",
      "\n",
      "Epoch: [187][7/16]\tTime 0.191 (1.836)\tETA 0:00:01\tTraining Loss 1.1955 (1.1966)\n",
      "\n",
      "Epoch: [187][8/16]\tTime 0.191 (2.028)\tETA 0:00:01\tTraining Loss 1.1946 (1.1964)\n",
      "\n",
      "Epoch: [187][9/16]\tTime 0.199 (2.227)\tETA 0:00:01\tTraining Loss 1.1940 (1.1962)\n",
      "\n",
      "Epoch: [187][10/16]\tTime 0.200 (2.426)\tETA 0:00:01\tTraining Loss 1.1946 (1.1960)\n",
      "\n",
      "Epoch: [187][11/16]\tTime 0.186 (2.612)\tETA 0:00:00\tTraining Loss 1.1975 (1.1961)\n",
      "\n",
      "Epoch: [187][12/16]\tTime 0.189 (2.801)\tETA 0:00:00\tTraining Loss 1.1944 (1.1960)\n",
      "\n",
      "Epoch: [187][13/16]\tTime 0.187 (2.989)\tETA 0:00:00\tTraining Loss 1.1961 (1.1960)\n",
      "\n",
      "Epoch: [187][14/16]\tTime 0.188 (3.177)\tETA 0:00:00\tTraining Loss 1.1987 (1.1962)\n",
      "\n",
      "Epoch: [187][15/16]\tTime 0.117 (3.294)\tETA 0:00:00\tTraining Loss 1.1982 (1.1963)\n",
      "_\n",
      "Validation stats                    IoU        F1      Prec    recall       Acc\n",
      "bg,          0.953300  0.976000  0.976500  0.975600  0.958400\n",
      "real apple   0.457100  0.627400  0.876000  0.488700  0.961900\n",
      "real pepper  0.000000  0.000000  0.000000  0.000000  0.999800\n",
      "real grape   0.770400  0.870300  0.896500  0.845600  0.983700\n",
      "fake apple   0.000000  0.000000  0.000000  0.000000  0.983200\n",
      "fake pepper  0.000000  0.000000  0.000000  0.000000  0.994900\n",
      "fake grape   0.000000  0.000000  0.000000  0.000000  0.988500\n",
      "total        0.311543  0.353386  0.392714  0.329986  0.981486\n",
      "total(-bg)   0.204583  0.249617  0.295417  0.222383  0.985333\n",
      "\n",
      "Epoch: [188][0/16]\tTime 0.471 (0.471)\tETA 0:00:07\tTraining Loss 1.1970 (1.1970)\n",
      "\n",
      "Epoch: [188][1/16]\tTime 0.197 (0.668)\tETA 0:00:02\tTraining Loss 1.1951 (1.1961)\n",
      "\n",
      "Epoch: [188][2/16]\tTime 0.292 (0.960)\tETA 0:00:04\tTraining Loss 1.2000 (1.1974)\n",
      "\n",
      "Epoch: [188][3/16]\tTime 0.182 (1.142)\tETA 0:00:02\tTraining Loss 1.1996 (1.1979)\n",
      "\n",
      "Epoch: [188][4/16]\tTime 0.189 (1.332)\tETA 0:00:02\tTraining Loss 1.1993 (1.1982)\n",
      "\n",
      "Epoch: [188][5/16]\tTime 0.185 (1.517)\tETA 0:00:02\tTraining Loss 1.1959 (1.1978)\n",
      "\n",
      "Epoch: [188][6/16]\tTime 0.184 (1.700)\tETA 0:00:01\tTraining Loss 1.1942 (1.1973)\n",
      "\n",
      "Epoch: [188][7/16]\tTime 0.188 (1.889)\tETA 0:00:01\tTraining Loss 1.1951 (1.1970)\n",
      "\n",
      "Epoch: [188][8/16]\tTime 0.187 (2.076)\tETA 0:00:01\tTraining Loss 1.1947 (1.1968)\n",
      "\n",
      "Epoch: [188][9/16]\tTime 0.186 (2.262)\tETA 0:00:01\tTraining Loss 1.1945 (1.1965)\n",
      "\n",
      "Epoch: [188][10/16]\tTime 0.192 (2.454)\tETA 0:00:01\tTraining Loss 1.1942 (1.1963)\n",
      "\n",
      "Epoch: [188][11/16]\tTime 0.187 (2.640)\tETA 0:00:00\tTraining Loss 1.1949 (1.1962)\n",
      "\n",
      "Epoch: [188][12/16]\tTime 0.194 (2.834)\tETA 0:00:00\tTraining Loss 1.1999 (1.1965)\n",
      "\n",
      "Epoch: [188][13/16]\tTime 0.175 (3.009)\tETA 0:00:00\tTraining Loss 1.1944 (1.1963)\n",
      "\n",
      "Epoch: [188][14/16]\tTime 0.196 (3.205)\tETA 0:00:00\tTraining Loss 1.1939 (1.1962)\n",
      "\n",
      "Epoch: [188][15/16]\tTime 0.111 (3.316)\tETA 0:00:00\tTraining Loss 1.1981 (1.1962)\n",
      "_\n",
      "Validation stats                    IoU        F1      Prec    recall       Acc\n",
      "bg,          0.953400  0.976100  0.977400  0.974900  0.958600\n",
      "real apple   0.588100  0.740600  0.898100  0.630100  0.971000\n",
      "real pepper  0.000000  0.000000  0.000000  0.000000  1.000000\n",
      "real grape   0.740500  0.850800  0.875900  0.827300  0.981200\n",
      "fake apple   0.000000  0.000000  0.000000  0.000000  0.992000\n",
      "fake pepper  0.000000  0.000000  0.000000  0.000000  0.997700\n",
      "fake grape   0.000000  0.000000  0.000000  0.000000  0.985000\n",
      "total        0.326000  0.366786  0.393057  0.347471  0.983643\n",
      "total(-bg)   0.221433  0.265233  0.295667  0.242900  0.987817\n",
      "\n",
      "Epoch: [189][0/16]\tTime 0.386 (0.386)\tETA 0:00:06\tTraining Loss 1.1931 (1.1931)\n",
      "\n",
      "Epoch: [189][1/16]\tTime 0.181 (0.567)\tETA 0:00:02\tTraining Loss 1.1971 (1.1951)\n",
      "\n",
      "Epoch: [189][2/16]\tTime 0.190 (0.757)\tETA 0:00:02\tTraining Loss 1.1955 (1.1952)\n",
      "\n",
      "Epoch: [189][3/16]\tTime 0.179 (0.936)\tETA 0:00:02\tTraining Loss 1.1951 (1.1952)\n",
      "\n",
      "Epoch: [189][4/16]\tTime 0.193 (1.128)\tETA 0:00:02\tTraining Loss 1.1961 (1.1954)\n",
      "\n",
      "Epoch: [189][5/16]\tTime 0.187 (1.316)\tETA 0:00:02\tTraining Loss 1.1960 (1.1955)\n",
      "\n",
      "Epoch: [189][6/16]\tTime 0.182 (1.498)\tETA 0:00:01\tTraining Loss 1.1950 (1.1954)\n",
      "\n",
      "Epoch: [189][7/16]\tTime 0.187 (1.684)\tETA 0:00:01\tTraining Loss 1.1974 (1.1957)\n",
      "\n",
      "Epoch: [189][8/16]\tTime 0.185 (1.869)\tETA 0:00:01\tTraining Loss 1.1957 (1.1957)\n",
      "\n",
      "Epoch: [189][9/16]\tTime 0.180 (2.049)\tETA 0:00:01\tTraining Loss 1.1955 (1.1956)\n",
      "\n",
      "Epoch: [189][10/16]\tTime 0.184 (2.233)\tETA 0:00:01\tTraining Loss 1.1949 (1.1956)\n",
      "\n",
      "Epoch: [189][11/16]\tTime 0.184 (2.417)\tETA 0:00:00\tTraining Loss 1.1943 (1.1955)\n",
      "\n",
      "Epoch: [189][12/16]\tTime 0.191 (2.608)\tETA 0:00:00\tTraining Loss 1.1944 (1.1954)\n",
      "\n",
      "Epoch: [189][13/16]\tTime 0.181 (2.789)\tETA 0:00:00\tTraining Loss 1.1943 (1.1953)\n",
      "\n",
      "Epoch: [189][14/16]\tTime 0.171 (2.960)\tETA 0:00:00\tTraining Loss 1.2017 (1.1957)\n",
      "\n",
      "Epoch: [189][15/16]\tTime 0.113 (3.073)\tETA 0:00:00\tTraining Loss 1.1957 (1.1957)\n",
      "_\n",
      "Validation stats                    IoU        F1      Prec    recall       Acc\n",
      "bg,          0.955200  0.977000  0.977400  0.976700  0.960100\n",
      "real apple   0.613500  0.760400  0.927200  0.644500  0.973300\n",
      "real pepper  0.000000  0.000000  0.000000  0.000000  1.000000\n",
      "real grape   0.789500  0.882300  0.891400  0.873500  0.984900\n",
      "fake apple   0.000000  0.000000  0.000000  0.000000  0.991800\n",
      "fake pepper  0.000000  0.000000  0.000000  0.000000  0.997000\n",
      "fake grape   0.000000  0.000000  0.000000  0.000000  0.989300\n",
      "total        0.336886  0.374243  0.399429  0.356386  0.985200\n",
      "total(-bg)   0.233833  0.273783  0.303100  0.253000  0.989383\n",
      "\n",
      "Epoch: [190][0/16]\tTime 0.407 (0.407)\tETA 0:00:06\tTraining Loss 1.1946 (1.1946)\n",
      "\n",
      "Epoch: [190][1/16]\tTime 0.186 (0.593)\tETA 0:00:02\tTraining Loss 1.1932 (1.1939)\n",
      "\n",
      "Epoch: [190][2/16]\tTime 0.192 (0.785)\tETA 0:00:02\tTraining Loss 1.1950 (1.1943)\n",
      "\n",
      "Epoch: [190][3/16]\tTime 0.185 (0.970)\tETA 0:00:02\tTraining Loss 1.1996 (1.1956)\n",
      "\n",
      "Epoch: [190][4/16]\tTime 0.186 (1.156)\tETA 0:00:02\tTraining Loss 1.1944 (1.1954)\n",
      "\n",
      "Epoch: [190][5/16]\tTime 0.193 (1.348)\tETA 0:00:02\tTraining Loss 1.1953 (1.1954)\n",
      "\n",
      "Epoch: [190][6/16]\tTime 0.196 (1.545)\tETA 0:00:01\tTraining Loss 1.1942 (1.1952)\n",
      "\n",
      "Epoch: [190][7/16]\tTime 0.186 (1.731)\tETA 0:00:01\tTraining Loss 1.1986 (1.1956)\n",
      "\n",
      "Epoch: [190][8/16]\tTime 0.187 (1.918)\tETA 0:00:01\tTraining Loss 1.1929 (1.1953)\n",
      "\n",
      "Epoch: [190][9/16]\tTime 0.189 (2.107)\tETA 0:00:01\tTraining Loss 1.1942 (1.1952)\n",
      "\n",
      "Epoch: [190][10/16]\tTime 0.185 (2.292)\tETA 0:00:01\tTraining Loss 1.1931 (1.1950)\n",
      "\n",
      "Epoch: [190][11/16]\tTime 0.185 (2.477)\tETA 0:00:00\tTraining Loss 1.1957 (1.1951)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: [190][12/16]\tTime 0.186 (2.663)\tETA 0:00:00\tTraining Loss 1.1940 (1.1950)\n",
      "\n",
      "Epoch: [190][13/16]\tTime 0.186 (2.849)\tETA 0:00:00\tTraining Loss 1.1953 (1.1950)\n",
      "\n",
      "Epoch: [190][14/16]\tTime 0.189 (3.038)\tETA 0:00:00\tTraining Loss 1.1941 (1.1950)\n",
      "\n",
      "Epoch: [190][15/16]\tTime 0.114 (3.152)\tETA 0:00:00\tTraining Loss 1.1946 (1.1949)\n",
      "_\n",
      "Validation stats                    IoU        F1      Prec    recall      Acc\n",
      "bg,          0.955200  0.977000  0.977000  0.977100  0.96010\n",
      "real apple   0.521200  0.685200  0.890300  0.557000  0.96640\n",
      "real pepper  0.000000  0.000000  0.000000  0.000000  1.00000\n",
      "real grape   0.741400  0.851400  0.889800  0.816300  0.98160\n",
      "fake apple   0.000000  0.000000  0.000000  0.000000  0.98760\n",
      "fake pepper  0.000000  0.000000  0.000000  0.000000  0.99770\n",
      "fake grape   0.000000  0.000000  0.000000  0.000000  0.98480\n",
      "total        0.316829  0.359086  0.393871  0.335771  0.98260\n",
      "total(-bg)   0.210433  0.256100  0.296683  0.228883  0.98635\n",
      "\n",
      "Epoch: [191][0/16]\tTime 0.379 (0.379)\tETA 0:00:06\tTraining Loss 1.1929 (1.1929)\n",
      "\n",
      "Epoch: [191][1/16]\tTime 0.195 (0.574)\tETA 0:00:02\tTraining Loss 1.1985 (1.1957)\n",
      "\n",
      "Epoch: [191][2/16]\tTime 0.185 (0.759)\tETA 0:00:02\tTraining Loss 1.1956 (1.1957)\n",
      "\n",
      "Epoch: [191][3/16]\tTime 0.183 (0.943)\tETA 0:00:02\tTraining Loss 1.1969 (1.1960)\n",
      "\n",
      "Epoch: [191][4/16]\tTime 0.188 (1.131)\tETA 0:00:02\tTraining Loss 1.1934 (1.1955)\n",
      "\n",
      "Epoch: [191][5/16]\tTime 0.192 (1.323)\tETA 0:00:02\tTraining Loss 1.1945 (1.1953)\n",
      "\n",
      "Epoch: [191][6/16]\tTime 0.186 (1.509)\tETA 0:00:01\tTraining Loss 1.1927 (1.1949)\n",
      "\n",
      "Epoch: [191][7/16]\tTime 0.184 (1.693)\tETA 0:00:01\tTraining Loss 1.1940 (1.1948)\n",
      "\n",
      "Epoch: [191][8/16]\tTime 0.192 (1.885)\tETA 0:00:01\tTraining Loss 1.1929 (1.1946)\n",
      "\n",
      "Epoch: [191][9/16]\tTime 0.187 (2.072)\tETA 0:00:01\tTraining Loss 1.1929 (1.1944)\n",
      "\n",
      "Epoch: [191][10/16]\tTime 0.191 (2.263)\tETA 0:00:01\tTraining Loss 1.1982 (1.1948)\n",
      "\n",
      "Epoch: [191][11/16]\tTime 0.183 (2.446)\tETA 0:00:00\tTraining Loss 1.1930 (1.1946)\n",
      "\n",
      "Epoch: [191][12/16]\tTime 0.187 (2.633)\tETA 0:00:00\tTraining Loss 1.1966 (1.1948)\n",
      "\n",
      "Epoch: [191][13/16]\tTime 0.187 (2.820)\tETA 0:00:00\tTraining Loss 1.1947 (1.1948)\n",
      "\n",
      "Epoch: [191][14/16]\tTime 0.189 (3.009)\tETA 0:00:00\tTraining Loss 1.1950 (1.1948)\n",
      "\n",
      "Epoch: [191][15/16]\tTime 0.113 (3.122)\tETA 0:00:00\tTraining Loss 1.1986 (1.1949)\n",
      "_\n",
      "Validation stats                    IoU        F1      Prec    recall       Acc\n",
      "bg,          0.952300  0.975500  0.977600  0.973600  0.957600\n",
      "real apple   0.430800  0.602100  0.873000  0.459600  0.960100\n",
      "real pepper  0.000000  0.000000  0.000000  0.000000  1.000000\n",
      "real grape   0.748000  0.855800  0.880200  0.832800  0.981800\n",
      "fake apple   0.000000  0.000000  0.000000  0.000000  0.980200\n",
      "fake pepper  0.000000  0.000000  0.000000  0.000000  0.994500\n",
      "fake grape   0.000000  0.000000  0.000000  0.000000  0.987200\n",
      "total        0.304443  0.347629  0.390114  0.323714  0.980200\n",
      "total(-bg)   0.196467  0.242983  0.292200  0.215400  0.983967\n",
      "\n",
      "Epoch: [192][0/16]\tTime 0.475 (0.475)\tETA 0:00:07\tTraining Loss 1.1959 (1.1959)\n",
      "\n",
      "Epoch: [192][1/16]\tTime 0.180 (0.655)\tETA 0:00:02\tTraining Loss 1.1930 (1.1945)\n",
      "\n",
      "Epoch: [192][2/16]\tTime 0.186 (0.840)\tETA 0:00:02\tTraining Loss 1.1924 (1.1938)\n",
      "\n",
      "Epoch: [192][3/16]\tTime 0.180 (1.020)\tETA 0:00:02\tTraining Loss 1.1956 (1.1942)\n",
      "\n",
      "Epoch: [192][4/16]\tTime 0.185 (1.205)\tETA 0:00:02\tTraining Loss 1.1919 (1.1938)\n",
      "\n",
      "Epoch: [192][5/16]\tTime 0.183 (1.389)\tETA 0:00:02\tTraining Loss 1.1918 (1.1934)\n",
      "\n",
      "Epoch: [192][6/16]\tTime 0.182 (1.571)\tETA 0:00:01\tTraining Loss 1.1942 (1.1936)\n",
      "\n",
      "Epoch: [192][7/16]\tTime 0.197 (1.767)\tETA 0:00:01\tTraining Loss 1.1960 (1.1939)\n",
      "\n",
      "Epoch: [192][8/16]\tTime 0.187 (1.954)\tETA 0:00:01\tTraining Loss 1.1953 (1.1940)\n",
      "\n",
      "Epoch: [192][9/16]\tTime 0.191 (2.145)\tETA 0:00:01\tTraining Loss 1.1924 (1.1939)\n",
      "\n",
      "Epoch: [192][10/16]\tTime 0.179 (2.324)\tETA 0:00:01\tTraining Loss 1.1936 (1.1938)\n",
      "\n",
      "Epoch: [192][11/16]\tTime 0.181 (2.504)\tETA 0:00:00\tTraining Loss 1.1946 (1.1939)\n",
      "\n",
      "Epoch: [192][12/16]\tTime 0.191 (2.695)\tETA 0:00:00\tTraining Loss 1.1959 (1.1941)\n",
      "\n",
      "Epoch: [192][13/16]\tTime 0.185 (2.880)\tETA 0:00:00\tTraining Loss 1.1933 (1.1940)\n",
      "\n",
      "Epoch: [192][14/16]\tTime 0.186 (3.066)\tETA 0:00:00\tTraining Loss 1.1949 (1.1941)\n",
      "\n",
      "Epoch: [192][15/16]\tTime 0.118 (3.184)\tETA 0:00:00\tTraining Loss 1.1943 (1.1941)\n",
      "_\n",
      "Validation stats                    IoU        F1      Prec    recall       Acc\n",
      "bg,          0.952600  0.975700  0.977500  0.973900  0.957800\n",
      "real apple   0.487400  0.655300  0.857700  0.530300  0.963300\n",
      "real pepper  0.000000  0.000000  0.000000  0.000000  1.000000\n",
      "real grape   0.751800  0.858300  0.886300  0.832100  0.982200\n",
      "fake apple   0.000000  0.000000  0.000000  0.000000  0.986000\n",
      "fake pepper  0.000000  0.000000  0.000000  0.000000  0.996000\n",
      "fake grape   0.000000  0.000000  0.000000  0.000000  0.985800\n",
      "total        0.313114  0.355614  0.388786  0.333757  0.981586\n",
      "total(-bg)   0.206533  0.252267  0.290667  0.227067  0.985550\n",
      "\n",
      "Epoch: [193][0/16]\tTime 0.517 (0.517)\tETA 0:00:08\tTraining Loss 1.1960 (1.1960)\n",
      "\n",
      "Epoch: [193][1/16]\tTime 0.198 (0.715)\tETA 0:00:02\tTraining Loss 1.1965 (1.1963)\n",
      "\n",
      "Epoch: [193][2/16]\tTime 0.179 (0.894)\tETA 0:00:02\tTraining Loss 1.1954 (1.1960)\n",
      "\n",
      "Epoch: [193][3/16]\tTime 0.198 (1.092)\tETA 0:00:02\tTraining Loss 1.1937 (1.1954)\n",
      "\n",
      "Epoch: [193][4/16]\tTime 0.193 (1.284)\tETA 0:00:02\tTraining Loss 1.1919 (1.1947)\n",
      "\n",
      "Epoch: [193][5/16]\tTime 0.191 (1.475)\tETA 0:00:02\tTraining Loss 1.1944 (1.1946)\n",
      "\n",
      "Epoch: [193][6/16]\tTime 0.196 (1.671)\tETA 0:00:01\tTraining Loss 1.1940 (1.1946)\n",
      "\n",
      "Epoch: [193][7/16]\tTime 0.208 (1.878)\tETA 0:00:01\tTraining Loss 1.1953 (1.1946)\n",
      "\n",
      "Epoch: [193][8/16]\tTime 0.184 (2.063)\tETA 0:00:01\tTraining Loss 1.1949 (1.1947)\n",
      "\n",
      "Epoch: [193][9/16]\tTime 0.186 (2.249)\tETA 0:00:01\tTraining Loss 1.1918 (1.1944)\n",
      "\n",
      "Epoch: [193][10/16]\tTime 0.188 (2.437)\tETA 0:00:01\tTraining Loss 1.1943 (1.1944)\n",
      "\n",
      "Epoch: [193][11/16]\tTime 0.192 (2.629)\tETA 0:00:00\tTraining Loss 1.1955 (1.1945)\n",
      "\n",
      "Epoch: [193][12/16]\tTime 0.192 (2.820)\tETA 0:00:00\tTraining Loss 1.1926 (1.1943)\n",
      "\n",
      "Epoch: [193][13/16]\tTime 0.187 (3.008)\tETA 0:00:00\tTraining Loss 1.1952 (1.1944)\n",
      "\n",
      "Epoch: [193][14/16]\tTime 0.191 (3.199)\tETA 0:00:00\tTraining Loss 1.1917 (1.1942)\n",
      "\n",
      "Epoch: [193][15/16]\tTime 0.112 (3.311)\tETA 0:00:00\tTraining Loss 1.1920 (1.1941)\n",
      "_\n",
      "Validation stats                    IoU        F1      Prec    recall     Acc\n",
      "bg,          0.955400  0.977100  0.977100  0.977200  0.9603\n",
      "real apple   0.492900  0.660300  0.871500  0.531600  0.9641\n",
      "real pepper  0.000000  0.000000  0.000000  0.000000  1.0000\n",
      "real grape   0.754000  0.859700  0.886400  0.834700  0.9824\n",
      "fake apple   0.000000  0.000000  0.000000  0.000000  0.9861\n",
      "fake pepper  0.000000  0.000000  0.000000  0.000000  0.9983\n",
      "fake grape   0.000000  0.000000  0.000000  0.000000  0.9863\n",
      "total        0.314614  0.356729  0.390714  0.334786  0.9825\n",
      "total(-bg)   0.207817  0.253333  0.292983  0.227717  0.9862\n",
      "\n",
      "Epoch: [194][0/16]\tTime 0.415 (0.415)\tETA 0:00:06\tTraining Loss 1.1922 (1.1922)\n",
      "\n",
      "Epoch: [194][1/16]\tTime 0.187 (0.602)\tETA 0:00:02\tTraining Loss 1.1926 (1.1924)\n",
      "\n",
      "Epoch: [194][2/16]\tTime 0.190 (0.793)\tETA 0:00:02\tTraining Loss 1.1929 (1.1926)\n",
      "\n",
      "Epoch: [194][3/16]\tTime 0.187 (0.979)\tETA 0:00:02\tTraining Loss 1.1935 (1.1928)\n",
      "\n",
      "Epoch: [194][4/16]\tTime 0.196 (1.175)\tETA 0:00:02\tTraining Loss 1.1928 (1.1928)\n",
      "\n",
      "Epoch: [194][5/16]\tTime 0.191 (1.366)\tETA 0:00:02\tTraining Loss 1.1923 (1.1927)\n",
      "\n",
      "Epoch: [194][6/16]\tTime 0.195 (1.562)\tETA 0:00:01\tTraining Loss 1.1922 (1.1926)\n",
      "\n",
      "Epoch: [194][7/16]\tTime 0.186 (1.748)\tETA 0:00:01\tTraining Loss 1.1921 (1.1926)\n",
      "\n",
      "Epoch: [194][8/16]\tTime 0.189 (1.936)\tETA 0:00:01\tTraining Loss 1.1958 (1.1929)\n",
      "\n",
      "Epoch: [194][9/16]\tTime 0.195 (2.131)\tETA 0:00:01\tTraining Loss 1.1918 (1.1928)\n",
      "\n",
      "Epoch: [194][10/16]\tTime 0.200 (2.331)\tETA 0:00:01\tTraining Loss 1.1956 (1.1931)\n",
      "\n",
      "Epoch: [194][11/16]\tTime 0.196 (2.527)\tETA 0:00:00\tTraining Loss 1.1935 (1.1931)\n",
      "\n",
      "Epoch: [194][12/16]\tTime 0.193 (2.720)\tETA 0:00:00\tTraining Loss 1.1987 (1.1935)\n",
      "\n",
      "Epoch: [194][13/16]\tTime 0.186 (2.905)\tETA 0:00:00\tTraining Loss 1.1917 (1.1934)\n",
      "\n",
      "Epoch: [194][14/16]\tTime 0.197 (3.102)\tETA 0:00:00\tTraining Loss 1.1951 (1.1935)\n",
      "\n",
      "Epoch: [194][15/16]\tTime 0.117 (3.219)\tETA 0:00:00\tTraining Loss 1.1947 (1.1936)\n",
      "_\n",
      "Validation stats                    IoU        F1      Prec    recall       Acc\n",
      "bg,          0.955300  0.977100  0.977000  0.977300  0.960200\n",
      "real apple   0.486100  0.654100  0.888600  0.517600  0.964000\n",
      "real pepper  0.000000  0.000000  0.000000  0.000000  1.000000\n",
      "real grape   0.756000  0.861000  0.887200  0.836300  0.982500\n",
      "fake apple   0.000000  0.000000  0.000000  0.000000  0.985300\n",
      "fake pepper  0.000000  0.000000  0.000000  0.000000  0.996800\n",
      "fake grape   0.000000  0.000000  0.000000  0.000000  0.987000\n",
      "total        0.313914  0.356029  0.393257  0.333029  0.982257\n",
      "total(-bg)   0.207017  0.252517  0.295967  0.225650  0.985933\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: [195][0/16]\tTime 0.397 (0.397)\tETA 0:00:06\tTraining Loss 1.1924 (1.1924)\n",
      "\n",
      "Epoch: [195][1/16]\tTime 0.191 (0.588)\tETA 0:00:02\tTraining Loss 1.1959 (1.1941)\n",
      "\n",
      "Epoch: [195][2/16]\tTime 0.186 (0.775)\tETA 0:00:02\tTraining Loss 1.1920 (1.1934)\n",
      "\n",
      "Epoch: [195][3/16]\tTime 0.190 (0.965)\tETA 0:00:02\tTraining Loss 1.1953 (1.1939)\n",
      "\n",
      "Epoch: [195][4/16]\tTime 0.182 (1.147)\tETA 0:00:02\tTraining Loss 1.1954 (1.1942)\n",
      "\n",
      "Epoch: [195][5/16]\tTime 0.191 (1.338)\tETA 0:00:02\tTraining Loss 1.1918 (1.1938)\n",
      "\n",
      "Epoch: [195][6/16]\tTime 0.217 (1.555)\tETA 0:00:02\tTraining Loss 1.2039 (1.1952)\n",
      "\n",
      "Epoch: [195][7/16]\tTime 0.192 (1.747)\tETA 0:00:01\tTraining Loss 1.1914 (1.1947)\n",
      "\n",
      "Epoch: [195][8/16]\tTime 0.193 (1.940)\tETA 0:00:01\tTraining Loss 1.1959 (1.1949)\n",
      "\n",
      "Epoch: [195][9/16]\tTime 0.186 (2.126)\tETA 0:00:01\tTraining Loss 1.1959 (1.1950)\n",
      "\n",
      "Epoch: [195][10/16]\tTime 0.189 (2.315)\tETA 0:00:01\tTraining Loss 1.1915 (1.1947)\n",
      "\n",
      "Epoch: [195][11/16]\tTime 0.187 (2.503)\tETA 0:00:00\tTraining Loss 1.1929 (1.1945)\n",
      "\n",
      "Epoch: [195][12/16]\tTime 0.183 (2.685)\tETA 0:00:00\tTraining Loss 1.1911 (1.1942)\n",
      "\n",
      "Epoch: [195][13/16]\tTime 0.184 (2.869)\tETA 0:00:00\tTraining Loss 1.1966 (1.1944)\n",
      "\n",
      "Epoch: [195][14/16]\tTime 0.196 (3.065)\tETA 0:00:00\tTraining Loss 1.1932 (1.1943)\n",
      "\n",
      "Epoch: [195][15/16]\tTime 0.111 (3.176)\tETA 0:00:00\tTraining Loss 1.1988 (1.1945)\n",
      "_\n",
      "Validation stats                    IoU        F1      Prec    recall      Acc\n",
      "bg,          0.955000  0.976900  0.977300  0.976600  0.95990\n",
      "real apple   0.370600  0.540800  0.851200  0.396300  0.95580\n",
      "real pepper  0.000000  0.000000  0.000000  0.000000  1.00000\n",
      "real grape   0.703900  0.826200  0.875700  0.782000  0.97870\n",
      "fake apple   0.000000  0.000000  0.000000  0.000000  0.97640\n",
      "fake pepper  0.000000  0.000000  0.000000  0.000000  0.99660\n",
      "fake grape   0.000000  0.000000  0.000000  0.000000  0.98420\n",
      "total        0.289929  0.334843  0.386314  0.307843  0.97880\n",
      "total(-bg)   0.179083  0.227833  0.287817  0.196383  0.98195\n",
      "\n",
      "Epoch: [196][0/16]\tTime 0.478 (0.478)\tETA 0:00:07\tTraining Loss 1.1922 (1.1922)\n",
      "\n",
      "Epoch: [196][1/16]\tTime 0.187 (0.666)\tETA 0:00:02\tTraining Loss 1.1922 (1.1922)\n",
      "\n",
      "Epoch: [196][2/16]\tTime 0.190 (0.856)\tETA 0:00:02\tTraining Loss 1.1930 (1.1925)\n",
      "\n",
      "Epoch: [196][3/16]\tTime 0.186 (1.042)\tETA 0:00:02\tTraining Loss 1.1913 (1.1922)\n",
      "\n",
      "Epoch: [196][4/16]\tTime 0.186 (1.228)\tETA 0:00:02\tTraining Loss 1.1968 (1.1931)\n",
      "\n",
      "Epoch: [196][5/16]\tTime 0.186 (1.415)\tETA 0:00:02\tTraining Loss 1.1920 (1.1929)\n",
      "\n",
      "Epoch: [196][6/16]\tTime 0.189 (1.604)\tETA 0:00:01\tTraining Loss 1.1911 (1.1927)\n",
      "\n",
      "Epoch: [196][7/16]\tTime 0.191 (1.795)\tETA 0:00:01\tTraining Loss 1.1962 (1.1931)\n",
      "\n",
      "Epoch: [196][8/16]\tTime 0.189 (1.983)\tETA 0:00:01\tTraining Loss 1.1928 (1.1931)\n",
      "\n",
      "Epoch: [196][9/16]\tTime 0.182 (2.165)\tETA 0:00:01\tTraining Loss 1.1958 (1.1933)\n",
      "\n",
      "Epoch: [196][10/16]\tTime 0.193 (2.358)\tETA 0:00:01\tTraining Loss 1.1940 (1.1934)\n",
      "\n",
      "Epoch: [196][11/16]\tTime 0.185 (2.543)\tETA 0:00:00\tTraining Loss 1.1918 (1.1933)\n",
      "\n",
      "Epoch: [196][12/16]\tTime 0.187 (2.730)\tETA 0:00:00\tTraining Loss 1.1924 (1.1932)\n",
      "\n",
      "Epoch: [196][13/16]\tTime 0.184 (2.914)\tETA 0:00:00\tTraining Loss 1.1937 (1.1932)\n",
      "\n",
      "Epoch: [196][14/16]\tTime 0.188 (3.102)\tETA 0:00:00\tTraining Loss 1.1913 (1.1931)\n",
      "\n",
      "Epoch: [196][15/16]\tTime 0.113 (3.216)\tETA 0:00:00\tTraining Loss 1.1942 (1.1931)\n",
      "_\n",
      "Validation stats                    IoU        F1      Prec    recall       Acc\n",
      "bg,          0.957100  0.978000  0.977700  0.978500  0.961900\n",
      "real apple   0.627800  0.771300  0.921900  0.663100  0.974200\n",
      "real pepper  0.000000  0.000000  0.000000  0.000000  1.000000\n",
      "real grape   0.782700  0.878000  0.902500  0.855000  0.984600\n",
      "fake apple   0.000000  0.000000  0.000000  0.000000  0.991400\n",
      "fake pepper  0.000000  0.000000  0.000000  0.000000  0.997600\n",
      "fake grape   0.000000  0.000000  0.000000  0.000000  0.989900\n",
      "total        0.338229  0.375329  0.400300  0.356657  0.985657\n",
      "total(-bg)   0.235083  0.274883  0.304067  0.253017  0.989617\n",
      "\n",
      "Epoch: [197][0/16]\tTime 0.476 (0.476)\tETA 0:00:07\tTraining Loss 1.1912 (1.1912)\n",
      "\n",
      "Epoch: [197][1/16]\tTime 0.191 (0.666)\tETA 0:00:02\tTraining Loss 1.1939 (1.1925)\n",
      "\n",
      "Epoch: [197][2/16]\tTime 0.190 (0.856)\tETA 0:00:02\tTraining Loss 1.1953 (1.1935)\n",
      "\n",
      "Epoch: [197][3/16]\tTime 0.194 (1.050)\tETA 0:00:02\tTraining Loss 1.1944 (1.1937)\n",
      "\n",
      "Epoch: [197][4/16]\tTime 0.182 (1.232)\tETA 0:00:02\tTraining Loss 1.1914 (1.1932)\n",
      "\n",
      "Epoch: [197][5/16]\tTime 0.184 (1.416)\tETA 0:00:02\tTraining Loss 1.1924 (1.1931)\n",
      "\n",
      "Epoch: [197][6/16]\tTime 0.194 (1.610)\tETA 0:00:01\tTraining Loss 1.1923 (1.1930)\n",
      "\n",
      "Epoch: [197][7/16]\tTime 0.189 (1.799)\tETA 0:00:01\tTraining Loss 1.1919 (1.1929)\n",
      "\n",
      "Epoch: [197][8/16]\tTime 0.189 (1.987)\tETA 0:00:01\tTraining Loss 1.1912 (1.1927)\n",
      "\n",
      "Epoch: [197][9/16]\tTime 0.187 (2.174)\tETA 0:00:01\tTraining Loss 1.1909 (1.1925)\n",
      "\n",
      "Epoch: [197][10/16]\tTime 0.182 (2.356)\tETA 0:00:01\tTraining Loss 1.1961 (1.1928)\n",
      "\n",
      "Epoch: [197][11/16]\tTime 0.187 (2.542)\tETA 0:00:00\tTraining Loss 1.1912 (1.1927)\n",
      "\n",
      "Epoch: [197][12/16]\tTime 0.185 (2.728)\tETA 0:00:00\tTraining Loss 1.1942 (1.1928)\n",
      "\n",
      "Epoch: [197][13/16]\tTime 0.187 (2.915)\tETA 0:00:00\tTraining Loss 1.1928 (1.1928)\n",
      "\n",
      "Epoch: [197][14/16]\tTime 0.184 (3.099)\tETA 0:00:00\tTraining Loss 1.1910 (1.1927)\n",
      "\n",
      "Epoch: [197][15/16]\tTime 0.115 (3.214)\tETA 0:00:00\tTraining Loss 1.1954 (1.1928)\n",
      "_\n",
      "Validation stats                    IoU        F1      Prec    recall       Acc\n",
      "bg,          0.955700  0.977300  0.977200  0.977500  0.960600\n",
      "real apple   0.493600  0.660900  0.878800  0.529600  0.964300\n",
      "real pepper  0.000000  0.000000  0.000000  0.000000  1.000000\n",
      "real grape   0.724300  0.840000  0.889700  0.795700  0.980400\n",
      "fake apple   0.000000  0.000000  0.000000  0.000000  0.986300\n",
      "fake pepper  0.000000  0.000000  0.000000  0.000000  0.997200\n",
      "fake grape   0.000000  0.000000  0.000000  0.000000  0.983800\n",
      "total        0.310514  0.354029  0.392243  0.328971  0.981800\n",
      "total(-bg)   0.202983  0.250150  0.294750  0.220883  0.985333\n",
      "\n",
      "Epoch: [198][0/16]\tTime 0.459 (0.459)\tETA 0:00:07\tTraining Loss 1.1919 (1.1919)\n",
      "\n",
      "Epoch: [198][1/16]\tTime 0.178 (0.637)\tETA 0:00:02\tTraining Loss 1.1926 (1.1922)\n",
      "\n",
      "Epoch: [198][2/16]\tTime 0.179 (0.816)\tETA 0:00:02\tTraining Loss 1.1906 (1.1917)\n",
      "\n",
      "Epoch: [198][3/16]\tTime 0.191 (1.007)\tETA 0:00:02\tTraining Loss 1.1916 (1.1917)\n",
      "\n",
      "Epoch: [198][4/16]\tTime 0.188 (1.194)\tETA 0:00:02\tTraining Loss 1.1901 (1.1913)\n",
      "\n",
      "Epoch: [198][5/16]\tTime 0.192 (1.386)\tETA 0:00:02\tTraining Loss 1.1943 (1.1918)\n",
      "\n",
      "Epoch: [198][6/16]\tTime 0.187 (1.574)\tETA 0:00:01\tTraining Loss 1.1922 (1.1919)\n",
      "\n",
      "Epoch: [198][7/16]\tTime 0.181 (1.754)\tETA 0:00:01\tTraining Loss 1.1897 (1.1916)\n",
      "\n",
      "Epoch: [198][8/16]\tTime 0.183 (1.937)\tETA 0:00:01\tTraining Loss 1.1947 (1.1920)\n",
      "\n",
      "Epoch: [198][9/16]\tTime 0.185 (2.122)\tETA 0:00:01\tTraining Loss 1.1922 (1.1920)\n",
      "\n",
      "Epoch: [198][10/16]\tTime 0.195 (2.316)\tETA 0:00:01\tTraining Loss 1.1943 (1.1922)\n",
      "\n",
      "Epoch: [198][11/16]\tTime 0.186 (2.503)\tETA 0:00:00\tTraining Loss 1.1915 (1.1921)\n",
      "\n",
      "Epoch: [198][12/16]\tTime 0.183 (2.685)\tETA 0:00:00\tTraining Loss 1.1937 (1.1923)\n",
      "\n",
      "Epoch: [198][13/16]\tTime 0.187 (2.872)\tETA 0:00:00\tTraining Loss 1.1956 (1.1925)\n",
      "\n",
      "Epoch: [198][14/16]\tTime 0.187 (3.058)\tETA 0:00:00\tTraining Loss 1.1910 (1.1924)\n",
      "\n",
      "Epoch: [198][15/16]\tTime 0.113 (3.171)\tETA 0:00:00\tTraining Loss 1.1958 (1.1925)\n",
      "_\n",
      "Validation stats                    IoU        F1    Prec    recall       Acc\n",
      "bg,          0.957300  0.978100  0.9782  0.978200  0.962100\n",
      "real apple   0.496700  0.663700  0.8724  0.535600  0.964300\n",
      "real pepper  0.000000  0.000000  0.0000  0.000000  1.000000\n",
      "real grape   0.743500  0.852900  0.8892  0.819500  0.981700\n",
      "fake apple   0.000000  0.000000  0.0000  0.000000  0.985700\n",
      "fake pepper  0.000000  0.000000  0.0000  0.000000  0.998200\n",
      "fake grape   0.000000  0.000000  0.0000  0.000000  0.985700\n",
      "total        0.313929  0.356386  0.3914  0.333329  0.982529\n",
      "total(-bg)   0.206700  0.252767  0.2936  0.225850  0.985933\n",
      "\n",
      "Epoch: [199][0/16]\tTime 0.424 (0.424)\tETA 0:00:06\tTraining Loss 1.1902 (1.1902)\n",
      "\n",
      "Epoch: [199][1/16]\tTime 0.185 (0.609)\tETA 0:00:02\tTraining Loss 1.1948 (1.1925)\n",
      "\n",
      "Epoch: [199][2/16]\tTime 0.183 (0.792)\tETA 0:00:02\tTraining Loss 1.1908 (1.1920)\n",
      "\n",
      "Epoch: [199][3/16]\tTime 0.186 (0.978)\tETA 0:00:02\tTraining Loss 1.1916 (1.1919)\n",
      "\n",
      "Epoch: [199][4/16]\tTime 0.190 (1.167)\tETA 0:00:02\tTraining Loss 1.1935 (1.1922)\n",
      "\n",
      "Epoch: [199][5/16]\tTime 0.184 (1.351)\tETA 0:00:02\tTraining Loss 1.1922 (1.1922)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: [199][6/16]\tTime 0.185 (1.536)\tETA 0:00:01\tTraining Loss 1.1903 (1.1919)\n",
      "\n",
      "Epoch: [199][7/16]\tTime 0.189 (1.724)\tETA 0:00:01\tTraining Loss 1.1907 (1.1918)\n",
      "\n",
      "Epoch: [199][8/16]\tTime 0.185 (1.909)\tETA 0:00:01\tTraining Loss 1.1922 (1.1918)\n",
      "\n",
      "Epoch: [199][9/16]\tTime 0.179 (2.088)\tETA 0:00:01\tTraining Loss 1.1919 (1.1918)\n",
      "\n",
      "Epoch: [199][10/16]\tTime 0.192 (2.280)\tETA 0:00:01\tTraining Loss 1.1916 (1.1918)\n",
      "\n",
      "Epoch: [199][11/16]\tTime 0.184 (2.464)\tETA 0:00:00\tTraining Loss 1.1907 (1.1917)\n",
      "\n",
      "Epoch: [199][12/16]\tTime 0.178 (2.642)\tETA 0:00:00\tTraining Loss 1.1918 (1.1917)\n",
      "\n",
      "Epoch: [199][13/16]\tTime 0.188 (2.829)\tETA 0:00:00\tTraining Loss 1.1905 (1.1917)\n",
      "\n",
      "Epoch: [199][14/16]\tTime 0.191 (3.020)\tETA 0:00:00\tTraining Loss 1.1907 (1.1916)\n",
      "\n",
      "Epoch: [199][15/16]\tTime 0.116 (3.137)\tETA 0:00:00\tTraining Loss 1.2022 (1.1919)\n",
      "_\n",
      "Validation stats                    IoU        F1      Prec    recall       Acc\n",
      "bg,          0.957200  0.978100  0.977200  0.979100  0.961900\n",
      "real apple   0.497200  0.664200  0.884400  0.531800  0.964700\n",
      "real pepper  0.000000  0.000000  0.000000  0.000000  1.000000\n",
      "real grape   0.662000  0.796600  0.876400  0.730200  0.975900\n",
      "fake apple   0.000000  0.000000  0.000000  0.000000  0.986400\n",
      "fake pepper  0.000000  0.000000  0.000000  0.000000  0.998500\n",
      "fake grape   0.000000  0.000000  0.000000  0.000000  0.979900\n",
      "total        0.302343  0.348414  0.391143  0.320157  0.981043\n",
      "total(-bg)   0.193200  0.243467  0.293467  0.210333  0.984233\n",
      "\n",
      "Epoch: [200][0/16]\tTime 0.490 (0.490)\tETA 0:00:07\tTraining Loss 1.1916 (1.1916)\n",
      "\n",
      "Epoch: [200][1/16]\tTime 0.188 (0.678)\tETA 0:00:02\tTraining Loss 1.1909 (1.1913)\n",
      "\n",
      "Epoch: [200][2/16]\tTime 0.175 (0.853)\tETA 0:00:02\tTraining Loss 1.1933 (1.1919)\n",
      "\n",
      "Epoch: [200][3/16]\tTime 0.186 (1.039)\tETA 0:00:02\tTraining Loss 1.1931 (1.1922)\n",
      "\n",
      "Epoch: [200][4/16]\tTime 0.187 (1.226)\tETA 0:00:02\tTraining Loss 1.1937 (1.1925)\n",
      "\n",
      "Epoch: [200][5/16]\tTime 0.182 (1.408)\tETA 0:00:02\tTraining Loss 1.1920 (1.1924)\n",
      "\n",
      "Epoch: [200][6/16]\tTime 0.187 (1.595)\tETA 0:00:01\tTraining Loss 1.1925 (1.1924)\n",
      "\n",
      "Epoch: [200][7/16]\tTime 0.193 (1.788)\tETA 0:00:01\tTraining Loss 1.1926 (1.1925)\n",
      "\n",
      "Epoch: [200][8/16]\tTime 0.183 (1.970)\tETA 0:00:01\tTraining Loss 1.1907 (1.1923)\n",
      "\n",
      "Epoch: [200][9/16]\tTime 0.188 (2.158)\tETA 0:00:01\tTraining Loss 1.1911 (1.1921)\n",
      "\n",
      "Epoch: [200][10/16]\tTime 0.190 (2.349)\tETA 0:00:01\tTraining Loss 1.1909 (1.1920)\n",
      "\n",
      "Epoch: [200][11/16]\tTime 0.188 (2.537)\tETA 0:00:00\tTraining Loss 1.1938 (1.1922)\n",
      "\n",
      "Epoch: [200][12/16]\tTime 0.189 (2.726)\tETA 0:00:00\tTraining Loss 1.1968 (1.1925)\n",
      "\n",
      "Epoch: [200][13/16]\tTime 0.186 (2.913)\tETA 0:00:00\tTraining Loss 1.1905 (1.1924)\n",
      "\n",
      "Epoch: [200][14/16]\tTime 0.190 (3.103)\tETA 0:00:00\tTraining Loss 1.1920 (1.1924)\n",
      "\n",
      "Epoch: [200][15/16]\tTime 0.114 (3.217)\tETA 0:00:00\tTraining Loss 1.1921 (1.1924)\n",
      "_\n",
      "Validation stats                  IoU        F1      Prec    recall       Acc\n",
      "bg,          0.9542  0.976500  0.977600  0.975600  0.959300\n",
      "real apple   0.4999  0.666500  0.888600  0.533300  0.964900\n",
      "real pepper  0.0000  0.000000  0.000000  0.000000  1.000000\n",
      "real grape   0.7061  0.827700  0.871800  0.787900  0.978800\n",
      "fake apple   0.0000  0.000000  0.000000  0.000000  0.985600\n",
      "fake pepper  0.0000  0.000000  0.000000  0.000000  0.997100\n",
      "fake grape   0.0000  0.000000  0.000000  0.000000  0.983000\n",
      "total        0.3086  0.352957  0.391143  0.328114  0.981243\n",
      "total(-bg)   0.2010  0.249033  0.293400  0.220200  0.984900\n",
      "\n",
      "Epoch: [201][0/16]\tTime 0.478 (0.478)\tETA 0:00:07\tTraining Loss 1.1895 (1.1895)\n",
      "\n",
      "Epoch: [201][1/16]\tTime 0.182 (0.660)\tETA 0:00:02\tTraining Loss 1.1906 (1.1901)\n",
      "\n",
      "Epoch: [201][2/16]\tTime 0.187 (0.847)\tETA 0:00:02\tTraining Loss 1.1975 (1.1925)\n",
      "\n",
      "Epoch: [201][3/16]\tTime 0.183 (1.030)\tETA 0:00:02\tTraining Loss 1.1929 (1.1926)\n",
      "\n",
      "Epoch: [201][4/16]\tTime 0.192 (1.222)\tETA 0:00:02\tTraining Loss 1.1940 (1.1929)\n",
      "\n",
      "Epoch: [201][5/16]\tTime 0.183 (1.405)\tETA 0:00:02\tTraining Loss 1.1931 (1.1929)\n",
      "\n",
      "Epoch: [201][6/16]\tTime 0.190 (1.595)\tETA 0:00:01\tTraining Loss 1.1924 (1.1928)\n",
      "\n",
      "Epoch: [201][7/16]\tTime 0.187 (1.783)\tETA 0:00:01\tTraining Loss 1.1897 (1.1925)\n",
      "\n",
      "Epoch: [201][8/16]\tTime 0.191 (1.974)\tETA 0:00:01\tTraining Loss 1.1934 (1.1926)\n",
      "\n",
      "Epoch: [201][9/16]\tTime 0.184 (2.158)\tETA 0:00:01\tTraining Loss 1.1912 (1.1924)\n",
      "\n",
      "Epoch: [201][10/16]\tTime 0.191 (2.349)\tETA 0:00:01\tTraining Loss 1.1911 (1.1923)\n",
      "\n",
      "Epoch: [201][11/16]\tTime 0.189 (2.538)\tETA 0:00:00\tTraining Loss 1.1933 (1.1924)\n",
      "\n",
      "Epoch: [201][12/16]\tTime 0.189 (2.727)\tETA 0:00:00\tTraining Loss 1.1891 (1.1921)\n",
      "\n",
      "Epoch: [201][13/16]\tTime 0.183 (2.910)\tETA 0:00:00\tTraining Loss 1.1909 (1.1921)\n",
      "\n",
      "Epoch: [201][14/16]\tTime 0.199 (3.109)\tETA 0:00:00\tTraining Loss 1.1922 (1.1921)\n",
      "\n",
      "Epoch: [201][15/16]\tTime 0.112 (3.221)\tETA 0:00:00\tTraining Loss 1.1918 (1.1921)\n",
      "_\n",
      "Validation stats                    IoU      F1      Prec    recall       Acc\n",
      "bg,          0.955500  0.9772  0.977200  0.977400  0.960400\n",
      "real apple   0.526100  0.6894  0.882800  0.565600  0.966500\n",
      "real pepper  0.000000  0.0000  0.000000  0.000000  0.999900\n",
      "real grape   0.822200  0.9024  0.911900  0.893100  0.987500\n",
      "fake apple   0.000000  0.0000  0.000000  0.000000  0.986000\n",
      "fake pepper  0.000000  0.0000  0.000000  0.000000  0.997700\n",
      "fake grape   0.000000  0.0000  0.000000  0.000000  0.991600\n",
      "total        0.329114  0.3670  0.395986  0.348014  0.984229\n",
      "total(-bg)   0.224717  0.2653  0.299117  0.243117  0.988200\n",
      "\n",
      "Epoch: [202][0/16]\tTime 0.480 (0.480)\tETA 0:00:07\tTraining Loss 1.1899 (1.1899)\n",
      "\n",
      "Epoch: [202][1/16]\tTime 0.184 (0.664)\tETA 0:00:02\tTraining Loss 1.1926 (1.1912)\n",
      "\n",
      "Epoch: [202][2/16]\tTime 0.188 (0.853)\tETA 0:00:02\tTraining Loss 1.1939 (1.1921)\n",
      "\n",
      "Epoch: [202][3/16]\tTime 0.188 (1.040)\tETA 0:00:02\tTraining Loss 1.1912 (1.1919)\n",
      "\n",
      "Epoch: [202][4/16]\tTime 0.189 (1.229)\tETA 0:00:02\tTraining Loss 1.1901 (1.1915)\n",
      "\n",
      "Epoch: [202][5/16]\tTime 0.183 (1.412)\tETA 0:00:02\tTraining Loss 1.1908 (1.1914)\n",
      "\n",
      "Epoch: [202][6/16]\tTime 0.190 (1.603)\tETA 0:00:01\tTraining Loss 1.1940 (1.1918)\n",
      "\n",
      "Epoch: [202][7/16]\tTime 0.195 (1.798)\tETA 0:00:01\tTraining Loss 1.1908 (1.1917)\n",
      "\n",
      "Epoch: [202][8/16]\tTime 0.185 (1.982)\tETA 0:00:01\tTraining Loss 1.1949 (1.1920)\n",
      "\n",
      "Epoch: [202][9/16]\tTime 0.183 (2.165)\tETA 0:00:01\tTraining Loss 1.1905 (1.1919)\n",
      "\n",
      "Epoch: [202][10/16]\tTime 0.183 (2.348)\tETA 0:00:01\tTraining Loss 1.1901 (1.1917)\n",
      "\n",
      "Epoch: [202][11/16]\tTime 0.185 (2.532)\tETA 0:00:00\tTraining Loss 1.1893 (1.1915)\n",
      "\n",
      "Epoch: [202][12/16]\tTime 0.182 (2.715)\tETA 0:00:00\tTraining Loss 1.1914 (1.1915)\n",
      "\n",
      "Epoch: [202][13/16]\tTime 0.185 (2.899)\tETA 0:00:00\tTraining Loss 1.1911 (1.1915)\n",
      "\n",
      "Epoch: [202][14/16]\tTime 0.188 (3.087)\tETA 0:00:00\tTraining Loss 1.1900 (1.1914)\n",
      "\n",
      "Epoch: [202][15/16]\tTime 0.113 (3.201)\tETA 0:00:00\tTraining Loss 1.1980 (1.1916)\n",
      "_\n",
      "Validation stats                    IoU        F1      Prec    recall       Acc\n",
      "bg,          0.957300  0.978200  0.976800  0.979600  0.962000\n",
      "real apple   0.585600  0.738600  0.874900  0.639100  0.970300\n",
      "real pepper  0.000000  0.000000  0.000000  0.000000  1.000000\n",
      "real grape   0.775700  0.873600  0.900200  0.848600  0.984100\n",
      "fake apple   0.000000  0.000000  0.000000  0.000000  0.996600\n",
      "fake pepper  0.000000  0.000000  0.000000  0.000000  0.999500\n",
      "fake grape   0.000000  0.000000  0.000000  0.000000  0.984900\n",
      "total        0.331229  0.370057  0.393129  0.352471  0.985343\n",
      "total(-bg)   0.226883  0.268700  0.295850  0.247950  0.989233\n",
      "\n",
      "Epoch: [203][0/16]\tTime 0.476 (0.476)\tETA 0:00:07\tTraining Loss 1.1914 (1.1914)\n",
      "\n",
      "Epoch: [203][1/16]\tTime 0.190 (0.667)\tETA 0:00:02\tTraining Loss 1.1935 (1.1925)\n",
      "\n",
      "Epoch: [203][2/16]\tTime 0.187 (0.854)\tETA 0:00:02\tTraining Loss 1.1915 (1.1921)\n",
      "\n",
      "Epoch: [203][3/16]\tTime 0.184 (1.038)\tETA 0:00:02\tTraining Loss 1.1923 (1.1922)\n",
      "\n",
      "Epoch: [203][4/16]\tTime 0.184 (1.222)\tETA 0:00:02\tTraining Loss 1.1912 (1.1920)\n",
      "\n",
      "Epoch: [203][5/16]\tTime 0.185 (1.406)\tETA 0:00:02\tTraining Loss 1.1976 (1.1929)\n",
      "\n",
      "Epoch: [203][6/16]\tTime 0.183 (1.590)\tETA 0:00:01\tTraining Loss 1.1910 (1.1926)\n",
      "\n",
      "Epoch: [203][7/16]\tTime 0.192 (1.782)\tETA 0:00:01\tTraining Loss 1.1916 (1.1925)\n",
      "\n",
      "Epoch: [203][8/16]\tTime 0.179 (1.961)\tETA 0:00:01\tTraining Loss 1.1918 (1.1924)\n",
      "\n",
      "Epoch: [203][9/16]\tTime 0.189 (2.150)\tETA 0:00:01\tTraining Loss 1.1892 (1.1921)\n",
      "\n",
      "Epoch: [203][10/16]\tTime 0.190 (2.340)\tETA 0:00:01\tTraining Loss 1.1905 (1.1920)\n",
      "\n",
      "Epoch: [203][11/16]\tTime 0.191 (2.531)\tETA 0:00:00\tTraining Loss 1.1906 (1.1919)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: [203][12/16]\tTime 0.186 (2.717)\tETA 0:00:00\tTraining Loss 1.1923 (1.1919)\n",
      "\n",
      "Epoch: [203][13/16]\tTime 0.193 (2.910)\tETA 0:00:00\tTraining Loss 1.1886 (1.1917)\n",
      "\n",
      "Epoch: [203][14/16]\tTime 0.185 (3.095)\tETA 0:00:00\tTraining Loss 1.1910 (1.1916)\n",
      "\n",
      "Epoch: [203][15/16]\tTime 0.114 (3.209)\tETA 0:00:00\tTraining Loss 1.1924 (1.1916)\n",
      "_\n",
      "Validation stats                    IoU        F1     Prec    recall       Acc\n",
      "bg,          0.958200  0.978600  0.97750  0.979900  0.962800\n",
      "real apple   0.495000  0.662200  0.88090  0.530500  0.964400\n",
      "real pepper  0.000000  0.000000  0.00000  0.000000  1.000000\n",
      "real grape   0.748900  0.856400  0.89960  0.817200  0.982300\n",
      "fake apple   0.000000  0.000000  0.00000  0.000000  0.986000\n",
      "fake pepper  0.000000  0.000000  0.00000  0.000000  0.997100\n",
      "fake grape   0.000000  0.000000  0.00000  0.000000  0.987000\n",
      "total        0.314586  0.356743  0.39400  0.332514  0.982800\n",
      "total(-bg)   0.207317  0.253100  0.29675  0.224617  0.986133\n",
      "\n",
      "Epoch: [204][0/16]\tTime 0.427 (0.427)\tETA 0:00:06\tTraining Loss 1.1914 (1.1914)\n",
      "\n",
      "Epoch: [204][1/16]\tTime 0.181 (0.608)\tETA 0:00:02\tTraining Loss 1.1954 (1.1934)\n",
      "\n",
      "Epoch: [204][2/16]\tTime 0.197 (0.805)\tETA 0:00:02\tTraining Loss 1.1901 (1.1923)\n",
      "\n",
      "Epoch: [204][3/16]\tTime 0.186 (0.991)\tETA 0:00:02\tTraining Loss 1.1900 (1.1917)\n",
      "\n",
      "Epoch: [204][4/16]\tTime 0.185 (1.176)\tETA 0:00:02\tTraining Loss 1.1896 (1.1913)\n",
      "\n",
      "Epoch: [204][5/16]\tTime 0.189 (1.364)\tETA 0:00:02\tTraining Loss 1.1895 (1.1910)\n",
      "\n",
      "Epoch: [204][6/16]\tTime 0.186 (1.550)\tETA 0:00:01\tTraining Loss 1.1907 (1.1910)\n",
      "\n",
      "Epoch: [204][7/16]\tTime 0.187 (1.737)\tETA 0:00:01\tTraining Loss 1.1893 (1.1908)\n",
      "\n",
      "Epoch: [204][8/16]\tTime 0.185 (1.922)\tETA 0:00:01\tTraining Loss 1.1903 (1.1907)\n",
      "\n",
      "Epoch: [204][9/16]\tTime 0.186 (2.108)\tETA 0:00:01\tTraining Loss 1.1898 (1.1906)\n",
      "\n",
      "Epoch: [204][10/16]\tTime 0.184 (2.293)\tETA 0:00:01\tTraining Loss 1.1903 (1.1906)\n",
      "\n",
      "Epoch: [204][11/16]\tTime 0.191 (2.483)\tETA 0:00:00\tTraining Loss 1.1924 (1.1907)\n",
      "\n",
      "Epoch: [204][12/16]\tTime 0.187 (2.671)\tETA 0:00:00\tTraining Loss 1.1901 (1.1907)\n",
      "\n",
      "Epoch: [204][13/16]\tTime 0.183 (2.854)\tETA 0:00:00\tTraining Loss 1.2007 (1.1914)\n",
      "\n",
      "Epoch: [204][14/16]\tTime 0.188 (3.042)\tETA 0:00:00\tTraining Loss 1.1897 (1.1913)\n",
      "\n",
      "Epoch: [204][15/16]\tTime 0.115 (3.157)\tETA 0:00:00\tTraining Loss 1.1876 (1.1912)\n",
      "_\n",
      "Validation stats                    IoU        F1      Prec    recall       Acc\n",
      "bg,          0.952200  0.975400  0.977800  0.973200  0.957500\n",
      "real apple   0.440400  0.611500  0.823900  0.486200  0.959400\n",
      "real pepper  0.000000  0.000000  0.000000  0.000000  1.000000\n",
      "real grape   0.699500  0.823100  0.867600  0.783100  0.978200\n",
      "fake apple   0.000000  0.000000  0.000000  0.000000  0.982600\n",
      "fake pepper  0.000000  0.000000  0.000000  0.000000  0.994700\n",
      "fake grape   0.000000  0.000000  0.000000  0.000000  0.985400\n",
      "total        0.298871  0.344286  0.381329  0.320357  0.979686\n",
      "total(-bg)   0.189983  0.239100  0.281917  0.211550  0.983383\n",
      "\n",
      "Epoch: [205][0/16]\tTime 0.528 (0.528)\tETA 0:00:08\tTraining Loss 1.1885 (1.1885)\n",
      "\n",
      "Epoch: [205][1/16]\tTime 0.190 (0.718)\tETA 0:00:02\tTraining Loss 1.1904 (1.1894)\n",
      "\n",
      "Epoch: [205][2/16]\tTime 0.187 (0.905)\tETA 0:00:02\tTraining Loss 1.1908 (1.1899)\n",
      "\n",
      "Epoch: [205][3/16]\tTime 0.190 (1.095)\tETA 0:00:02\tTraining Loss 1.1902 (1.1900)\n",
      "\n",
      "Epoch: [205][4/16]\tTime 0.184 (1.279)\tETA 0:00:02\tTraining Loss 1.1917 (1.1903)\n",
      "\n",
      "Epoch: [205][5/16]\tTime 0.182 (1.460)\tETA 0:00:01\tTraining Loss 1.1924 (1.1907)\n",
      "\n",
      "Epoch: [205][6/16]\tTime 0.191 (1.651)\tETA 0:00:01\tTraining Loss 1.1902 (1.1906)\n",
      "\n",
      "Epoch: [205][7/16]\tTime 0.208 (1.859)\tETA 0:00:01\tTraining Loss 1.1900 (1.1905)\n",
      "\n",
      "Epoch: [205][8/16]\tTime 0.189 (2.048)\tETA 0:00:01\tTraining Loss 1.1902 (1.1905)\n",
      "\n",
      "Epoch: [205][9/16]\tTime 0.188 (2.236)\tETA 0:00:01\tTraining Loss 1.1913 (1.1906)\n",
      "\n",
      "Epoch: [205][10/16]\tTime 0.191 (2.428)\tETA 0:00:01\tTraining Loss 1.1946 (1.1909)\n",
      "\n",
      "Epoch: [205][11/16]\tTime 0.184 (2.611)\tETA 0:00:00\tTraining Loss 1.1889 (1.1908)\n",
      "\n",
      "Epoch: [205][12/16]\tTime 0.180 (2.791)\tETA 0:00:00\tTraining Loss 1.1888 (1.1906)\n",
      "\n",
      "Epoch: [205][13/16]\tTime 0.187 (2.978)\tETA 0:00:00\tTraining Loss 1.1888 (1.1905)\n",
      "\n",
      "Epoch: [205][14/16]\tTime 0.193 (3.171)\tETA 0:00:00\tTraining Loss 1.1898 (1.1904)\n",
      "\n",
      "Epoch: [205][15/16]\tTime 0.115 (3.286)\tETA 0:00:00\tTraining Loss 1.1901 (1.1904)\n",
      "_\n",
      "Validation stats                    IoU        F1      Prec    recall       Acc\n",
      "bg,          0.958600  0.978800  0.977400  0.980300  0.963200\n",
      "real apple   0.498300  0.665100  0.884400  0.533000  0.964700\n",
      "real pepper  0.000000  0.000000  0.000000  0.000000  1.000000\n",
      "real grape   0.679700  0.809200  0.877400  0.751000  0.977100\n",
      "fake apple   0.000000  0.000000  0.000000  0.000000  0.986400\n",
      "fake pepper  0.000000  0.000000  0.000000  0.000000  0.997400\n",
      "fake grape   0.000000  0.000000  0.000000  0.000000  0.983300\n",
      "total        0.305229  0.350443  0.391314  0.323471  0.981729\n",
      "total(-bg)   0.196333  0.245717  0.293633  0.214000  0.984817\n",
      "\n",
      "Epoch: [206][0/16]\tTime 0.409 (0.409)\tETA 0:00:06\tTraining Loss 1.1925 (1.1925)\n",
      "\n",
      "Epoch: [206][1/16]\tTime 0.185 (0.594)\tETA 0:00:02\tTraining Loss 1.1875 (1.1900)\n",
      "\n",
      "Epoch: [206][2/16]\tTime 0.194 (0.787)\tETA 0:00:02\tTraining Loss 1.1912 (1.1904)\n",
      "\n",
      "Epoch: [206][3/16]\tTime 0.194 (0.982)\tETA 0:00:02\tTraining Loss 1.1876 (1.1897)\n",
      "\n",
      "Epoch: [206][4/16]\tTime 0.191 (1.173)\tETA 0:00:02\tTraining Loss 1.1916 (1.1901)\n",
      "\n",
      "Epoch: [206][5/16]\tTime 0.189 (1.362)\tETA 0:00:02\tTraining Loss 1.1889 (1.1899)\n",
      "\n",
      "Epoch: [206][6/16]\tTime 0.195 (1.557)\tETA 0:00:01\tTraining Loss 1.1949 (1.1906)\n",
      "\n",
      "Epoch: [206][7/16]\tTime 0.192 (1.750)\tETA 0:00:01\tTraining Loss 1.1900 (1.1905)\n",
      "\n",
      "Epoch: [206][8/16]\tTime 0.189 (1.939)\tETA 0:00:01\tTraining Loss 1.1887 (1.1903)\n",
      "\n",
      "Epoch: [206][9/16]\tTime 0.190 (2.129)\tETA 0:00:01\tTraining Loss 1.1881 (1.1901)\n",
      "\n",
      "Epoch: [206][10/16]\tTime 0.188 (2.316)\tETA 0:00:01\tTraining Loss 1.1907 (1.1902)\n",
      "\n",
      "Epoch: [206][11/16]\tTime 0.205 (2.522)\tETA 0:00:01\tTraining Loss 1.1902 (1.1902)\n",
      "\n",
      "Epoch: [206][12/16]\tTime 0.193 (2.715)\tETA 0:00:00\tTraining Loss 1.1886 (1.1900)\n",
      "\n",
      "Epoch: [206][13/16]\tTime 0.185 (2.900)\tETA 0:00:00\tTraining Loss 1.1909 (1.1901)\n",
      "\n",
      "Epoch: [206][14/16]\tTime 0.186 (3.087)\tETA 0:00:00\tTraining Loss 1.1893 (1.1900)\n",
      "\n",
      "Epoch: [206][15/16]\tTime 0.117 (3.204)\tETA 0:00:00\tTraining Loss 1.1877 (1.1900)\n",
      "_\n",
      "Validation stats                    IoU        F1      Prec    recall       Acc\n",
      "bg,          0.953500  0.976100  0.977400  0.975000  0.958700\n",
      "real apple   0.455200  0.625500  0.836400  0.499700  0.960700\n",
      "real pepper  0.000000  0.000000  0.000000  0.000000  1.000000\n",
      "real grape   0.682100  0.810900  0.876200  0.754800  0.977200\n",
      "fake apple   0.000000  0.000000  0.000000  0.000000  0.983700\n",
      "fake pepper  0.000000  0.000000  0.000000  0.000000  0.995300\n",
      "fake grape   0.000000  0.000000  0.000000  0.000000  0.983400\n",
      "total        0.298686  0.344643  0.384286  0.318500  0.979857\n",
      "total(-bg)   0.189550  0.239400  0.285433  0.209083  0.983383\n",
      "\n",
      "Epoch: [207][0/16]\tTime 0.467 (0.467)\tETA 0:00:07\tTraining Loss 1.1891 (1.1891)\n",
      "\n",
      "Epoch: [207][1/16]\tTime 0.174 (0.640)\tETA 0:00:02\tTraining Loss 1.1903 (1.1897)\n",
      "\n",
      "Epoch: [207][2/16]\tTime 0.194 (0.834)\tETA 0:00:02\tTraining Loss 1.1913 (1.1902)\n",
      "\n",
      "Epoch: [207][3/16]\tTime 0.187 (1.022)\tETA 0:00:02\tTraining Loss 1.1888 (1.1899)\n",
      "\n",
      "Epoch: [207][4/16]\tTime 0.189 (1.211)\tETA 0:00:02\tTraining Loss 1.1881 (1.1895)\n",
      "\n",
      "Epoch: [207][5/16]\tTime 0.186 (1.397)\tETA 0:00:02\tTraining Loss 1.1875 (1.1892)\n",
      "\n",
      "Epoch: [207][6/16]\tTime 0.185 (1.582)\tETA 0:00:01\tTraining Loss 1.1902 (1.1893)\n",
      "\n",
      "Epoch: [207][7/16]\tTime 0.181 (1.763)\tETA 0:00:01\tTraining Loss 1.1912 (1.1896)\n",
      "\n",
      "Epoch: [207][8/16]\tTime 0.188 (1.951)\tETA 0:00:01\tTraining Loss 1.1896 (1.1896)\n",
      "\n",
      "Epoch: [207][9/16]\tTime 0.183 (2.134)\tETA 0:00:01\tTraining Loss 1.1905 (1.1897)\n",
      "\n",
      "Epoch: [207][10/16]\tTime 0.183 (2.317)\tETA 0:00:01\tTraining Loss 1.1910 (1.1898)\n",
      "\n",
      "Epoch: [207][11/16]\tTime 0.185 (2.502)\tETA 0:00:00\tTraining Loss 1.1872 (1.1896)\n",
      "\n",
      "Epoch: [207][12/16]\tTime 0.183 (2.685)\tETA 0:00:00\tTraining Loss 1.1900 (1.1896)\n",
      "\n",
      "Epoch: [207][13/16]\tTime 0.188 (2.874)\tETA 0:00:00\tTraining Loss 1.1931 (1.1899)\n",
      "\n",
      "Epoch: [207][14/16]\tTime 0.180 (3.054)\tETA 0:00:00\tTraining Loss 1.1869 (1.1897)\n",
      "\n",
      "Epoch: [207][15/16]\tTime 0.115 (3.169)\tETA 0:00:00\tTraining Loss 1.1913 (1.1897)\n",
      "_\n",
      "Validation stats                  IoU        F1      Prec    recall     Acc\n",
      "bg,          0.9532  0.976000  0.976800  0.975200  0.9584\n",
      "real apple   0.5672  0.723800  0.882000  0.613800  0.9692\n",
      "real pepper  0.0000  0.000000  0.000000  0.000000  1.0000\n",
      "real grape   0.7672  0.868200  0.901900  0.837000  0.9836\n",
      "fake apple   0.0000  0.000000  0.000000  0.000000  0.9909\n",
      "fake pepper  0.0000  0.000000  0.000000  0.000000  0.9955\n",
      "fake grape   0.0000  0.000000  0.000000  0.000000  0.9876\n",
      "total        0.3268  0.366857  0.394386  0.346571  0.9836\n",
      "total(-bg)   0.2224  0.265333  0.297317  0.241800  0.9878\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: [208][0/16]\tTime 0.481 (0.481)\tETA 0:00:07\tTraining Loss 1.1882 (1.1882)\n",
      "\n",
      "Epoch: [208][1/16]\tTime 0.185 (0.666)\tETA 0:00:02\tTraining Loss 1.1930 (1.1906)\n",
      "\n",
      "Epoch: [208][2/16]\tTime 0.185 (0.851)\tETA 0:00:02\tTraining Loss 1.1876 (1.1896)\n",
      "\n",
      "Epoch: [208][3/16]\tTime 0.189 (1.040)\tETA 0:00:02\tTraining Loss 1.1889 (1.1894)\n",
      "\n",
      "Epoch: [208][4/16]\tTime 0.182 (1.222)\tETA 0:00:02\tTraining Loss 1.1914 (1.1898)\n",
      "\n",
      "Epoch: [208][5/16]\tTime 0.180 (1.402)\tETA 0:00:01\tTraining Loss 1.1892 (1.1897)\n",
      "\n",
      "Epoch: [208][6/16]\tTime 0.186 (1.588)\tETA 0:00:01\tTraining Loss 1.1902 (1.1898)\n",
      "\n",
      "Epoch: [208][7/16]\tTime 0.189 (1.777)\tETA 0:00:01\tTraining Loss 1.1872 (1.1895)\n",
      "\n",
      "Epoch: [208][8/16]\tTime 0.182 (1.959)\tETA 0:00:01\tTraining Loss 1.1911 (1.1897)\n",
      "\n",
      "Epoch: [208][9/16]\tTime 0.187 (2.146)\tETA 0:00:01\tTraining Loss 1.1904 (1.1897)\n",
      "\n",
      "Epoch: [208][10/16]\tTime 0.194 (2.339)\tETA 0:00:01\tTraining Loss 1.1898 (1.1897)\n",
      "\n",
      "Epoch: [208][11/16]\tTime 0.191 (2.530)\tETA 0:00:00\tTraining Loss 1.1874 (1.1895)\n",
      "\n",
      "Epoch: [208][12/16]\tTime 0.189 (2.719)\tETA 0:00:00\tTraining Loss 1.1874 (1.1894)\n",
      "\n",
      "Epoch: [208][13/16]\tTime 0.184 (2.903)\tETA 0:00:00\tTraining Loss 1.1879 (1.1893)\n",
      "\n",
      "Epoch: [208][14/16]\tTime 0.185 (3.088)\tETA 0:00:00\tTraining Loss 1.1904 (1.1893)\n",
      "\n",
      "Epoch: [208][15/16]\tTime 0.113 (3.200)\tETA 0:00:00\tTraining Loss 1.1899 (1.1894)\n",
      "_\n",
      "Validation stats                    IoU        F1      Prec    recall       Acc\n",
      "bg,          0.952400  0.975500  0.976800  0.974400  0.957600\n",
      "real apple   0.523200  0.686900  0.879100  0.563700  0.966200\n",
      "real pepper  0.000000  0.000000  0.000000  0.000000  1.000000\n",
      "real grape   0.778900  0.875700  0.895600  0.856700  0.984300\n",
      "fake apple   0.000000  0.000000  0.000000  0.000000  0.987000\n",
      "fake pepper  0.000000  0.000000  0.000000  0.000000  0.995300\n",
      "fake grape   0.000000  0.000000  0.000000  0.000000  0.989100\n",
      "total        0.322071  0.362586  0.393071  0.342114  0.982786\n",
      "total(-bg)   0.217017  0.260433  0.295783  0.236733  0.986983\n",
      "\n",
      "Epoch: [209][0/16]\tTime 0.379 (0.379)\tETA 0:00:06\tTraining Loss 1.1893 (1.1893)\n",
      "\n",
      "Epoch: [209][1/16]\tTime 0.180 (0.559)\tETA 0:00:02\tTraining Loss 1.1884 (1.1889)\n",
      "\n",
      "Epoch: [209][2/16]\tTime 0.183 (0.742)\tETA 0:00:02\tTraining Loss 1.1885 (1.1888)\n",
      "\n",
      "Epoch: [209][3/16]\tTime 0.180 (0.922)\tETA 0:00:02\tTraining Loss 1.1910 (1.1893)\n",
      "\n",
      "Epoch: [209][4/16]\tTime 0.180 (1.102)\tETA 0:00:02\tTraining Loss 1.1912 (1.1897)\n",
      "\n",
      "Epoch: [209][5/16]\tTime 0.183 (1.285)\tETA 0:00:02\tTraining Loss 1.1884 (1.1895)\n",
      "\n",
      "Epoch: [209][6/16]\tTime 0.187 (1.472)\tETA 0:00:01\tTraining Loss 1.1884 (1.1893)\n",
      "\n",
      "Epoch: [209][7/16]\tTime 0.185 (1.657)\tETA 0:00:01\tTraining Loss 1.1903 (1.1894)\n",
      "\n",
      "Epoch: [209][8/16]\tTime 0.181 (1.838)\tETA 0:00:01\tTraining Loss 1.1907 (1.1896)\n",
      "\n",
      "Epoch: [209][9/16]\tTime 0.185 (2.023)\tETA 0:00:01\tTraining Loss 1.1892 (1.1895)\n",
      "\n",
      "Epoch: [209][10/16]\tTime 0.182 (2.204)\tETA 0:00:01\tTraining Loss 1.1887 (1.1895)\n",
      "\n",
      "Epoch: [209][11/16]\tTime 0.186 (2.390)\tETA 0:00:00\tTraining Loss 1.1891 (1.1894)\n",
      "\n",
      "Epoch: [209][12/16]\tTime 0.193 (2.583)\tETA 0:00:00\tTraining Loss 1.1876 (1.1893)\n",
      "\n",
      "Epoch: [209][13/16]\tTime 0.182 (2.766)\tETA 0:00:00\tTraining Loss 1.1869 (1.1891)\n",
      "\n",
      "Epoch: [209][14/16]\tTime 0.186 (2.951)\tETA 0:00:00\tTraining Loss 1.1907 (1.1892)\n",
      "\n",
      "Epoch: [209][15/16]\tTime 0.113 (3.064)\tETA 0:00:00\tTraining Loss 1.1971 (1.1895)\n",
      "_\n",
      "Validation stats                    IoU        F1      Prec    recall       Acc\n",
      "bg,          0.958500  0.978700  0.978200  0.979400  0.963100\n",
      "real apple   0.507200  0.673000  0.909100  0.534200  0.965900\n",
      "real pepper  0.000000  0.000000  0.000000  0.000000  1.000000\n",
      "real grape   0.661800  0.796400  0.869200  0.735000  0.975700\n",
      "fake apple   0.000000  0.000000  0.000000  0.000000  0.985800\n",
      "fake pepper  0.000000  0.000000  0.000000  0.000000  0.996700\n",
      "fake grape   0.000000  0.000000  0.000000  0.000000  0.981400\n",
      "total        0.303929  0.349729  0.393786  0.321229  0.981229\n",
      "total(-bg)   0.194833  0.244900  0.296383  0.211533  0.984250\n",
      "\n",
      "Epoch: [210][0/16]\tTime 0.511 (0.511)\tETA 0:00:08\tTraining Loss 1.1897 (1.1897)\n",
      "\n",
      "Epoch: [210][1/16]\tTime 0.185 (0.696)\tETA 0:00:02\tTraining Loss 1.1899 (1.1898)\n",
      "\n",
      "Epoch: [210][2/16]\tTime 0.186 (0.882)\tETA 0:00:02\tTraining Loss 1.1887 (1.1894)\n",
      "\n",
      "Epoch: [210][3/16]\tTime 0.197 (1.079)\tETA 0:00:02\tTraining Loss 1.1895 (1.1895)\n",
      "\n",
      "Epoch: [210][4/16]\tTime 0.180 (1.259)\tETA 0:00:02\tTraining Loss 1.1910 (1.1898)\n",
      "\n",
      "Epoch: [210][5/16]\tTime 0.200 (1.459)\tETA 0:00:02\tTraining Loss 1.1890 (1.1896)\n",
      "\n",
      "Epoch: [210][6/16]\tTime 0.184 (1.643)\tETA 0:00:01\tTraining Loss 1.1873 (1.1893)\n",
      "\n",
      "Epoch: [210][7/16]\tTime 0.199 (1.842)\tETA 0:00:01\tTraining Loss 1.1946 (1.1900)\n",
      "\n",
      "Epoch: [210][8/16]\tTime 0.216 (2.058)\tETA 0:00:01\tTraining Loss 1.1871 (1.1896)\n",
      "\n",
      "Epoch: [210][9/16]\tTime 0.186 (2.244)\tETA 0:00:01\tTraining Loss 1.1881 (1.1895)\n",
      "\n",
      "Epoch: [210][10/16]\tTime 0.192 (2.437)\tETA 0:00:01\tTraining Loss 1.1880 (1.1893)\n",
      "\n",
      "Epoch: [210][11/16]\tTime 0.182 (2.618)\tETA 0:00:00\tTraining Loss 1.1866 (1.1891)\n",
      "\n",
      "Epoch: [210][12/16]\tTime 0.194 (2.812)\tETA 0:00:00\tTraining Loss 1.1879 (1.1890)\n",
      "\n",
      "Epoch: [210][13/16]\tTime 0.192 (3.004)\tETA 0:00:00\tTraining Loss 1.1916 (1.1892)\n",
      "\n",
      "Epoch: [210][14/16]\tTime 0.185 (3.189)\tETA 0:00:00\tTraining Loss 1.1881 (1.1891)\n",
      "\n",
      "Epoch: [210][15/16]\tTime 0.113 (3.301)\tETA 0:00:00\tTraining Loss 1.1879 (1.1891)\n",
      "_\n",
      "Validation stats                    IoU        F1      Prec    recall       Acc\n",
      "bg,          0.950900  0.974800  0.978000  0.971600  0.956400\n",
      "real apple   0.360600  0.530000  0.830400  0.389300  0.954600\n",
      "real pepper  0.000000  0.000000  0.000000  0.000000  1.000000\n",
      "real grape   0.728800  0.843100  0.866500  0.820900  0.980200\n",
      "fake apple   0.000000  0.000000  0.000000  0.000000  0.975700\n",
      "fake pepper  0.000000  0.000000  0.000000  0.000000  0.993400\n",
      "fake grape   0.000000  0.000000  0.000000  0.000000  0.986900\n",
      "total        0.291471  0.335414  0.382129  0.311686  0.978171\n",
      "total(-bg)   0.181567  0.228850  0.282817  0.201700  0.981800\n",
      "\n",
      "Epoch: [211][0/16]\tTime 0.472 (0.472)\tETA 0:00:07\tTraining Loss 1.1874 (1.1874)\n",
      "\n",
      "Epoch: [211][1/16]\tTime 0.182 (0.655)\tETA 0:00:02\tTraining Loss 1.1862 (1.1868)\n",
      "\n",
      "Epoch: [211][2/16]\tTime 0.190 (0.845)\tETA 0:00:02\tTraining Loss 1.1866 (1.1868)\n",
      "\n",
      "Epoch: [211][3/16]\tTime 0.183 (1.027)\tETA 0:00:02\tTraining Loss 1.1871 (1.1868)\n",
      "\n",
      "Epoch: [211][4/16]\tTime 0.187 (1.215)\tETA 0:00:02\tTraining Loss 1.1886 (1.1872)\n",
      "\n",
      "Epoch: [211][5/16]\tTime 0.188 (1.402)\tETA 0:00:02\tTraining Loss 1.1886 (1.1874)\n",
      "\n",
      "Epoch: [211][6/16]\tTime 0.184 (1.587)\tETA 0:00:01\tTraining Loss 1.1891 (1.1877)\n",
      "\n",
      "Epoch: [211][7/16]\tTime 0.186 (1.772)\tETA 0:00:01\tTraining Loss 1.1905 (1.1880)\n",
      "\n",
      "Epoch: [211][8/16]\tTime 0.186 (1.958)\tETA 0:00:01\tTraining Loss 1.1883 (1.1880)\n",
      "\n",
      "Epoch: [211][9/16]\tTime 0.183 (2.141)\tETA 0:00:01\tTraining Loss 1.1915 (1.1884)\n",
      "\n",
      "Epoch: [211][10/16]\tTime 0.189 (2.330)\tETA 0:00:01\tTraining Loss 1.1869 (1.1883)\n",
      "\n",
      "Epoch: [211][11/16]\tTime 0.188 (2.518)\tETA 0:00:00\tTraining Loss 1.1877 (1.1882)\n",
      "\n",
      "Epoch: [211][12/16]\tTime 0.198 (2.716)\tETA 0:00:00\tTraining Loss 1.1904 (1.1884)\n",
      "\n",
      "Epoch: [211][13/16]\tTime 0.184 (2.900)\tETA 0:00:00\tTraining Loss 1.1956 (1.1889)\n",
      "\n",
      "Epoch: [211][14/16]\tTime 0.187 (3.087)\tETA 0:00:00\tTraining Loss 1.1876 (1.1888)\n",
      "\n",
      "Epoch: [211][15/16]\tTime 0.113 (3.200)\tETA 0:00:00\tTraining Loss 1.1873 (1.1888)\n",
      "_\n",
      "Validation stats                    IoU        F1      Prec    recall       Acc\n",
      "bg,          0.954900  0.976900  0.977200  0.976600  0.959900\n",
      "real apple   0.367300  0.537200  0.812500  0.401300  0.954600\n",
      "real pepper  0.000000  0.000000  0.000000  0.000000  1.000000\n",
      "real grape   0.678600  0.808500  0.873500  0.752600  0.976900\n",
      "fake apple   0.000000  0.000000  0.000000  0.000000  0.977800\n",
      "fake pepper  0.000000  0.000000  0.000000  0.000000  0.996900\n",
      "fake grape   0.000000  0.000000  0.000000  0.000000  0.982500\n",
      "total        0.285829  0.331800  0.380457  0.304357  0.978371\n",
      "total(-bg)   0.174317  0.224283  0.281000  0.192317  0.981450\n",
      "\n",
      "Epoch: [212][0/16]\tTime 0.519 (0.519)\tETA 0:00:08\tTraining Loss 1.1874 (1.1874)\n",
      "\n",
      "Epoch: [212][1/16]\tTime 0.188 (0.707)\tETA 0:00:02\tTraining Loss 1.1865 (1.1870)\n",
      "\n",
      "Epoch: [212][2/16]\tTime 0.193 (0.900)\tETA 0:00:02\tTraining Loss 1.1884 (1.1875)\n",
      "\n",
      "Epoch: [212][3/16]\tTime 0.190 (1.090)\tETA 0:00:02\tTraining Loss 1.1887 (1.1878)\n",
      "\n",
      "Epoch: [212][4/16]\tTime 0.189 (1.279)\tETA 0:00:02\tTraining Loss 1.1884 (1.1879)\n",
      "\n",
      "Epoch: [212][5/16]\tTime 0.183 (1.462)\tETA 0:00:02\tTraining Loss 1.1884 (1.1880)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: [212][6/16]\tTime 0.202 (1.664)\tETA 0:00:02\tTraining Loss 1.1885 (1.1880)\n",
      "\n",
      "Epoch: [212][7/16]\tTime 0.192 (1.856)\tETA 0:00:01\tTraining Loss 1.1886 (1.1881)\n",
      "\n",
      "Epoch: [212][8/16]\tTime 0.193 (2.048)\tETA 0:00:01\tTraining Loss 1.1882 (1.1881)\n",
      "\n",
      "Epoch: [212][9/16]\tTime 0.198 (2.246)\tETA 0:00:01\tTraining Loss 1.1858 (1.1879)\n",
      "\n",
      "Epoch: [212][10/16]\tTime 0.184 (2.430)\tETA 0:00:01\tTraining Loss 1.1887 (1.1880)\n",
      "\n",
      "Epoch: [212][11/16]\tTime 0.202 (2.632)\tETA 0:00:01\tTraining Loss 1.1902 (1.1882)\n",
      "\n",
      "Epoch: [212][12/16]\tTime 0.195 (2.827)\tETA 0:00:00\tTraining Loss 1.1870 (1.1881)\n",
      "\n",
      "Epoch: [212][13/16]\tTime 0.179 (3.005)\tETA 0:00:00\tTraining Loss 1.1877 (1.1880)\n",
      "\n",
      "Epoch: [212][14/16]\tTime 0.186 (3.191)\tETA 0:00:00\tTraining Loss 1.1921 (1.1883)\n",
      "\n",
      "Epoch: [212][15/16]\tTime 0.115 (3.306)\tETA 0:00:00\tTraining Loss 1.1938 (1.1885)\n",
      "_\n",
      "Validation stats                    IoU       F1      Prec    recall       Acc\n",
      "bg,          0.954300  0.97660  0.978100  0.975100  0.959400\n",
      "real apple   0.372800  0.54310  0.810100  0.408500  0.954800\n",
      "real pepper  0.000000  0.00000  0.000000  0.000000  1.000000\n",
      "real grape   0.695600  0.82040  0.880100  0.768400  0.978200\n",
      "fake apple   0.000000  0.00000  0.000000  0.000000  0.976700\n",
      "fake pepper  0.000000  0.00000  0.000000  0.000000  0.995600\n",
      "fake grape   0.000000  0.00000  0.000000  0.000000  0.984200\n",
      "total        0.288957  0.33430  0.381186  0.307429  0.978414\n",
      "total(-bg)   0.178067  0.22725  0.281700  0.196150  0.981583\n",
      "\n",
      "Epoch: [213][0/16]\tTime 0.494 (0.494)\tETA 0:00:07\tTraining Loss 1.1857 (1.1857)\n",
      "\n",
      "Epoch: [213][1/16]\tTime 0.179 (0.673)\tETA 0:00:02\tTraining Loss 1.1892 (1.1875)\n",
      "\n",
      "Epoch: [213][2/16]\tTime 0.188 (0.860)\tETA 0:00:02\tTraining Loss 1.1894 (1.1881)\n",
      "\n",
      "Epoch: [213][3/16]\tTime 0.185 (1.045)\tETA 0:00:02\tTraining Loss 1.1877 (1.1880)\n",
      "\n",
      "Epoch: [213][4/16]\tTime 0.192 (1.237)\tETA 0:00:02\tTraining Loss 1.1887 (1.1881)\n",
      "\n",
      "Epoch: [213][5/16]\tTime 0.185 (1.422)\tETA 0:00:02\tTraining Loss 1.1868 (1.1879)\n",
      "\n",
      "Epoch: [213][6/16]\tTime 0.187 (1.609)\tETA 0:00:01\tTraining Loss 1.1915 (1.1884)\n",
      "\n",
      "Epoch: [213][7/16]\tTime 0.191 (1.800)\tETA 0:00:01\tTraining Loss 1.1879 (1.1884)\n",
      "\n",
      "Epoch: [213][8/16]\tTime 0.187 (1.987)\tETA 0:00:01\tTraining Loss 1.1865 (1.1882)\n",
      "\n",
      "Epoch: [213][9/16]\tTime 0.190 (2.177)\tETA 0:00:01\tTraining Loss 1.1876 (1.1881)\n",
      "\n",
      "Epoch: [213][10/16]\tTime 0.185 (2.362)\tETA 0:00:01\tTraining Loss 1.1942 (1.1887)\n",
      "\n",
      "Epoch: [213][11/16]\tTime 0.191 (2.553)\tETA 0:00:00\tTraining Loss 1.1884 (1.1886)\n",
      "\n",
      "Epoch: [213][12/16]\tTime 0.188 (2.741)\tETA 0:00:00\tTraining Loss 1.1872 (1.1885)\n",
      "\n",
      "Epoch: [213][13/16]\tTime 0.185 (2.926)\tETA 0:00:00\tTraining Loss 1.1873 (1.1884)\n",
      "\n",
      "Epoch: [213][14/16]\tTime 0.185 (3.112)\tETA 0:00:00\tTraining Loss 1.1870 (1.1883)\n",
      "\n",
      "Epoch: [213][15/16]\tTime 0.114 (3.225)\tETA 0:00:00\tTraining Loss 1.1887 (1.1884)\n",
      "_\n",
      "Validation stats                    IoU        F1      Prec    recall       Acc\n",
      "bg,          0.953600  0.976200  0.978200  0.974300  0.958800\n",
      "real apple   0.411100  0.582700  0.805100  0.456600  0.957000\n",
      "real pepper  0.000000  0.000000  0.000000  0.000000  1.000000\n",
      "real grape   0.723600  0.839600  0.869800  0.811500  0.979900\n",
      "fake apple   0.000000  0.000000  0.000000  0.000000  0.980100\n",
      "fake pepper  0.000000  0.000000  0.000000  0.000000  0.997500\n",
      "fake grape   0.000000  0.000000  0.000000  0.000000  0.986100\n",
      "total        0.298329  0.342643  0.379014  0.320343  0.979914\n",
      "total(-bg)   0.189117  0.237050  0.279150  0.211350  0.983433\n",
      "\n",
      "Epoch: [214][0/16]\tTime 0.511 (0.511)\tETA 0:00:08\tTraining Loss 1.1871 (1.1871)\n",
      "\n",
      "Epoch: [214][1/16]\tTime 0.198 (0.708)\tETA 0:00:02\tTraining Loss 1.1867 (1.1869)\n",
      "\n",
      "Epoch: [214][2/16]\tTime 0.186 (0.894)\tETA 0:00:02\tTraining Loss 1.1865 (1.1868)\n",
      "\n",
      "Epoch: [214][3/16]\tTime 0.195 (1.089)\tETA 0:00:02\tTraining Loss 1.1852 (1.1864)\n",
      "\n",
      "Epoch: [214][4/16]\tTime 0.190 (1.279)\tETA 0:00:02\tTraining Loss 1.1869 (1.1865)\n",
      "\n",
      "Epoch: [214][5/16]\tTime 0.184 (1.463)\tETA 0:00:02\tTraining Loss 1.1900 (1.1871)\n",
      "\n",
      "Epoch: [214][6/16]\tTime 0.203 (1.667)\tETA 0:00:02\tTraining Loss 1.1879 (1.1872)\n",
      "\n",
      "Epoch: [214][7/16]\tTime 0.191 (1.858)\tETA 0:00:01\tTraining Loss 1.1875 (1.1872)\n",
      "\n",
      "Epoch: [214][8/16]\tTime 0.205 (2.063)\tETA 0:00:01\tTraining Loss 1.1888 (1.1874)\n",
      "\n",
      "Epoch: [214][9/16]\tTime 0.190 (2.253)\tETA 0:00:01\tTraining Loss 1.1920 (1.1879)\n",
      "\n",
      "Epoch: [214][10/16]\tTime 0.189 (2.443)\tETA 0:00:01\tTraining Loss 1.1888 (1.1880)\n",
      "\n",
      "Epoch: [214][11/16]\tTime 0.189 (2.632)\tETA 0:00:00\tTraining Loss 1.1903 (1.1882)\n",
      "\n",
      "Epoch: [214][12/16]\tTime 0.183 (2.814)\tETA 0:00:00\tTraining Loss 1.1857 (1.1880)\n",
      "\n",
      "Epoch: [214][13/16]\tTime 0.188 (3.002)\tETA 0:00:00\tTraining Loss 1.1879 (1.1880)\n",
      "\n",
      "Epoch: [214][14/16]\tTime 0.184 (3.187)\tETA 0:00:00\tTraining Loss 1.1881 (1.1880)\n",
      "\n",
      "Epoch: [214][15/16]\tTime 0.116 (3.303)\tETA 0:00:00\tTraining Loss 1.1891 (1.1880)\n",
      "_\n",
      "Validation stats                    IoU        F1      Prec    recall       Acc\n",
      "bg,          0.957000  0.978000  0.979000  0.977000  0.961800\n",
      "real apple   0.502300  0.668600  0.881500  0.538700  0.964900\n",
      "real pepper  0.000000  0.000000  0.000000  0.000000  0.999900\n",
      "real grape   0.754700  0.860200  0.882900  0.838700  0.982400\n",
      "fake apple   0.000000  0.000000  0.000000  0.000000  0.985400\n",
      "fake pepper  0.000000  0.000000  0.000000  0.000000  0.997500\n",
      "fake grape   0.000000  0.000000  0.000000  0.000000  0.986700\n",
      "total        0.316286  0.358114  0.391914  0.336343  0.982657\n",
      "total(-bg)   0.209500  0.254800  0.294067  0.229567  0.986133\n",
      "\n",
      "Epoch: [215][0/16]\tTime 0.422 (0.422)\tETA 0:00:06\tTraining Loss 1.1872 (1.1872)\n",
      "\n",
      "Epoch: [215][1/16]\tTime 0.283 (0.705)\tETA 0:00:04\tTraining Loss 1.1863 (1.1868)\n",
      "\n",
      "Epoch: [215][2/16]\tTime 0.186 (0.891)\tETA 0:00:02\tTraining Loss 1.1871 (1.1869)\n",
      "\n",
      "Epoch: [215][3/16]\tTime 0.182 (1.072)\tETA 0:00:02\tTraining Loss 1.1862 (1.1867)\n",
      "\n",
      "Epoch: [215][4/16]\tTime 0.196 (1.268)\tETA 0:00:02\tTraining Loss 1.1889 (1.1872)\n",
      "\n",
      "Epoch: [215][5/16]\tTime 0.191 (1.459)\tETA 0:00:02\tTraining Loss 1.1883 (1.1873)\n",
      "\n",
      "Epoch: [215][6/16]\tTime 0.184 (1.643)\tETA 0:00:01\tTraining Loss 1.1864 (1.1872)\n",
      "\n",
      "Epoch: [215][7/16]\tTime 0.196 (1.839)\tETA 0:00:01\tTraining Loss 1.1892 (1.1875)\n",
      "\n",
      "Epoch: [215][8/16]\tTime 0.184 (2.023)\tETA 0:00:01\tTraining Loss 1.1862 (1.1873)\n",
      "\n",
      "Epoch: [215][9/16]\tTime 0.193 (2.216)\tETA 0:00:01\tTraining Loss 1.1877 (1.1874)\n",
      "\n",
      "Epoch: [215][10/16]\tTime 0.194 (2.410)\tETA 0:00:01\tTraining Loss 1.1906 (1.1876)\n",
      "\n",
      "Epoch: [215][11/16]\tTime 0.190 (2.600)\tETA 0:00:00\tTraining Loss 1.1907 (1.1879)\n",
      "\n",
      "Epoch: [215][12/16]\tTime 0.184 (2.784)\tETA 0:00:00\tTraining Loss 1.1921 (1.1882)\n",
      "\n",
      "Epoch: [215][13/16]\tTime 0.189 (2.973)\tETA 0:00:00\tTraining Loss 1.1888 (1.1883)\n",
      "\n",
      "Epoch: [215][14/16]\tTime 0.194 (3.167)\tETA 0:00:00\tTraining Loss 1.1875 (1.1882)\n",
      "\n",
      "Epoch: [215][15/16]\tTime 0.117 (3.283)\tETA 0:00:00\tTraining Loss 1.1954 (1.1884)\n",
      "_\n",
      "Validation stats                    IoU        F1      Prec    recall       Acc\n",
      "bg,          0.957100  0.978000  0.976200  0.980000  0.961800\n",
      "real apple   0.557300  0.715700  0.930000  0.581700  0.969600\n",
      "real pepper  0.000000  0.000000  0.000000  0.000000  1.000000\n",
      "real grape   0.776700  0.874300  0.877800  0.870900  0.983800\n",
      "fake apple   0.000000  0.000000  0.000000  0.000000  0.989500\n",
      "fake pepper  0.000000  0.000000  0.000000  0.000000  0.997900\n",
      "fake grape   0.000000  0.000000  0.000000  0.000000  0.990800\n",
      "total        0.327300  0.366857  0.397714  0.347514  0.984771\n",
      "total(-bg)   0.222333  0.265000  0.301300  0.242100  0.988600\n",
      "\n",
      "Epoch: [216][0/16]\tTime 0.436 (0.436)\tETA 0:00:06\tTraining Loss 1.1866 (1.1866)\n",
      "\n",
      "Epoch: [216][1/16]\tTime 0.190 (0.626)\tETA 0:00:02\tTraining Loss 1.1875 (1.1871)\n",
      "\n",
      "Epoch: [216][2/16]\tTime 0.184 (0.810)\tETA 0:00:02\tTraining Loss 1.1862 (1.1868)\n",
      "\n",
      "Epoch: [216][3/16]\tTime 0.180 (0.989)\tETA 0:00:02\tTraining Loss 1.1941 (1.1886)\n",
      "\n",
      "Epoch: [216][4/16]\tTime 0.190 (1.179)\tETA 0:00:02\tTraining Loss 1.1887 (1.1886)\n",
      "\n",
      "Epoch: [216][5/16]\tTime 0.187 (1.366)\tETA 0:00:02\tTraining Loss 1.1869 (1.1883)\n",
      "\n",
      "Epoch: [216][6/16]\tTime 0.188 (1.554)\tETA 0:00:01\tTraining Loss 1.1895 (1.1885)\n",
      "\n",
      "Epoch: [216][7/16]\tTime 0.190 (1.744)\tETA 0:00:01\tTraining Loss 1.1884 (1.1885)\n",
      "\n",
      "Epoch: [216][8/16]\tTime 0.185 (1.929)\tETA 0:00:01\tTraining Loss 1.1876 (1.1884)\n",
      "\n",
      "Epoch: [216][9/16]\tTime 0.183 (2.111)\tETA 0:00:01\tTraining Loss 1.1892 (1.1885)\n",
      "\n",
      "Epoch: [216][10/16]\tTime 0.187 (2.299)\tETA 0:00:01\tTraining Loss 1.1947 (1.1890)\n",
      "\n",
      "Epoch: [216][11/16]\tTime 0.180 (2.479)\tETA 0:00:00\tTraining Loss 1.1877 (1.1889)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: [216][12/16]\tTime 0.199 (2.677)\tETA 0:00:00\tTraining Loss 1.1881 (1.1889)\n",
      "\n",
      "Epoch: [216][13/16]\tTime 0.181 (2.859)\tETA 0:00:00\tTraining Loss 1.1874 (1.1888)\n",
      "\n",
      "Epoch: [216][14/16]\tTime 0.188 (3.047)\tETA 0:00:00\tTraining Loss 1.1878 (1.1887)\n",
      "\n",
      "Epoch: [216][15/16]\tTime 0.114 (3.161)\tETA 0:00:00\tTraining Loss 1.1865 (1.1886)\n",
      "_\n",
      "Validation stats                    IoU        F1      Prec    recall     Acc\n",
      "bg,          0.952100  0.975400  0.978900  0.972100  0.9575\n",
      "real apple   0.421900  0.593300  0.794500  0.473500  0.9574\n",
      "real pepper  0.000000  0.000000  0.000000  0.000000  0.9990\n",
      "real grape   0.662800  0.797200  0.857500  0.744900  0.9755\n",
      "fake apple   0.000000  0.000000  0.000000  0.000000  0.9816\n",
      "fake pepper  0.000000  0.000000  0.000000  0.000000  0.9960\n",
      "fake grape   0.000000  0.000000  0.000000  0.000000  0.9825\n",
      "total        0.290971  0.337986  0.375843  0.312929  0.9785\n",
      "total(-bg)   0.180783  0.231750  0.275333  0.203067  0.9820\n",
      "\n",
      "Epoch: [217][0/16]\tTime 0.493 (0.493)\tETA 0:00:07\tTraining Loss 1.1896 (1.1896)\n",
      "\n",
      "Epoch: [217][1/16]\tTime 0.179 (0.672)\tETA 0:00:02\tTraining Loss 1.1872 (1.1884)\n",
      "\n",
      "Epoch: [217][2/16]\tTime 0.191 (0.862)\tETA 0:00:02\tTraining Loss 1.1895 (1.1888)\n",
      "\n",
      "Epoch: [217][3/16]\tTime 0.189 (1.051)\tETA 0:00:02\tTraining Loss 1.1869 (1.1883)\n",
      "\n",
      "Epoch: [217][4/16]\tTime 0.193 (1.244)\tETA 0:00:02\tTraining Loss 1.1864 (1.1879)\n",
      "\n",
      "Epoch: [217][5/16]\tTime 0.187 (1.431)\tETA 0:00:02\tTraining Loss 1.1889 (1.1881)\n",
      "\n",
      "Epoch: [217][6/16]\tTime 0.190 (1.621)\tETA 0:00:01\tTraining Loss 1.1915 (1.1886)\n",
      "\n",
      "Epoch: [217][7/16]\tTime 0.179 (1.800)\tETA 0:00:01\tTraining Loss 1.1887 (1.1886)\n",
      "\n",
      "Epoch: [217][8/16]\tTime 0.189 (1.989)\tETA 0:00:01\tTraining Loss 1.1874 (1.1885)\n",
      "\n",
      "Epoch: [217][9/16]\tTime 0.187 (2.176)\tETA 0:00:01\tTraining Loss 1.1882 (1.1884)\n",
      "\n",
      "Epoch: [217][10/16]\tTime 0.185 (2.361)\tETA 0:00:01\tTraining Loss 1.1882 (1.1884)\n",
      "\n",
      "Epoch: [217][11/16]\tTime 0.179 (2.540)\tETA 0:00:00\tTraining Loss 1.1861 (1.1882)\n",
      "\n",
      "Epoch: [217][12/16]\tTime 0.191 (2.731)\tETA 0:00:00\tTraining Loss 1.1876 (1.1882)\n",
      "\n",
      "Epoch: [217][13/16]\tTime 0.181 (2.912)\tETA 0:00:00\tTraining Loss 1.1872 (1.1881)\n",
      "\n",
      "Epoch: [217][14/16]\tTime 0.185 (3.097)\tETA 0:00:00\tTraining Loss 1.1876 (1.1881)\n",
      "\n",
      "Epoch: [217][15/16]\tTime 0.115 (3.212)\tETA 0:00:00\tTraining Loss 1.1916 (1.1882)\n",
      "_\n",
      "Validation stats                    IoU        F1      Prec    recall       Acc\n",
      "bg,          0.948300  0.973400  0.975600  0.971300  0.953900\n",
      "real apple   0.598000  0.748400  0.885100  0.648400  0.971400\n",
      "real pepper  0.000000  0.000000  0.000000  0.000000  0.999900\n",
      "real grape   0.726800  0.841700  0.895400  0.794200  0.980700\n",
      "fake apple   0.000000  0.000000  0.000000  0.000000  0.994800\n",
      "fake pepper  0.000000  0.000000  0.000000  0.000000  0.995800\n",
      "fake grape   0.000000  0.000000  0.000000  0.000000  0.980800\n",
      "total        0.324729  0.366214  0.393729  0.344843  0.982471\n",
      "total(-bg)   0.220800  0.265017  0.296750  0.240433  0.987233\n",
      "\n",
      "Epoch: [218][0/16]\tTime 0.492 (0.492)\tETA 0:00:07\tTraining Loss 1.1857 (1.1857)\n",
      "\n",
      "Epoch: [218][1/16]\tTime 0.187 (0.680)\tETA 0:00:02\tTraining Loss 1.1877 (1.1867)\n",
      "\n",
      "Epoch: [218][2/16]\tTime 0.187 (0.867)\tETA 0:00:02\tTraining Loss 1.1897 (1.1877)\n",
      "\n",
      "Epoch: [218][3/16]\tTime 0.189 (1.055)\tETA 0:00:02\tTraining Loss 1.1912 (1.1886)\n",
      "\n",
      "Epoch: [218][4/16]\tTime 0.188 (1.244)\tETA 0:00:02\tTraining Loss 1.1883 (1.1885)\n",
      "\n",
      "Epoch: [218][5/16]\tTime 0.186 (1.429)\tETA 0:00:02\tTraining Loss 1.1864 (1.1882)\n",
      "\n",
      "Epoch: [218][6/16]\tTime 0.195 (1.624)\tETA 0:00:01\tTraining Loss 1.1877 (1.1881)\n",
      "\n",
      "Epoch: [218][7/16]\tTime 0.185 (1.809)\tETA 0:00:01\tTraining Loss 1.1856 (1.1878)\n",
      "\n",
      "Epoch: [218][8/16]\tTime 0.193 (2.002)\tETA 0:00:01\tTraining Loss 1.1862 (1.1876)\n",
      "\n",
      "Epoch: [218][9/16]\tTime 0.189 (2.192)\tETA 0:00:01\tTraining Loss 1.1878 (1.1876)\n",
      "\n",
      "Epoch: [218][10/16]\tTime 0.189 (2.381)\tETA 0:00:01\tTraining Loss 1.1872 (1.1876)\n",
      "\n",
      "Epoch: [218][11/16]\tTime 0.182 (2.563)\tETA 0:00:00\tTraining Loss 1.1884 (1.1876)\n",
      "\n",
      "Epoch: [218][12/16]\tTime 0.201 (2.764)\tETA 0:00:00\tTraining Loss 1.1886 (1.1877)\n",
      "\n",
      "Epoch: [218][13/16]\tTime 0.186 (2.950)\tETA 0:00:00\tTraining Loss 1.1902 (1.1879)\n",
      "\n",
      "Epoch: [218][14/16]\tTime 0.187 (3.137)\tETA 0:00:00\tTraining Loss 1.1881 (1.1879)\n",
      "\n",
      "Epoch: [218][15/16]\tTime 0.115 (3.252)\tETA 0:00:00\tTraining Loss 1.1871 (1.1879)\n",
      "_\n",
      "Validation stats                    IoU        F1      Prec    recall       Acc\n",
      "bg,          0.957500  0.978200  0.978900  0.977700  0.962200\n",
      "real apple   0.391300  0.562400  0.865200  0.416600  0.957400\n",
      "real pepper  0.000000  0.000000  0.000000  0.000000  1.000000\n",
      "real grape   0.720800  0.837700  0.883500  0.796500  0.980000\n",
      "fake apple   0.000000  0.000000  0.000000  0.000000  0.975200\n",
      "fake pepper  0.000000  0.000000  0.000000  0.000000  0.998000\n",
      "fake grape   0.000000  0.000000  0.000000  0.000000  0.985300\n",
      "total        0.295657  0.339757  0.389657  0.312971  0.979729\n",
      "total(-bg)   0.185350  0.233350  0.291450  0.202183  0.982650\n",
      "\n",
      "Epoch: [219][0/16]\tTime 0.483 (0.483)\tETA 0:00:07\tTraining Loss 1.1894 (1.1894)\n",
      "\n",
      "Epoch: [219][1/16]\tTime 0.210 (0.693)\tETA 0:00:03\tTraining Loss 1.1909 (1.1901)\n",
      "\n",
      "Epoch: [219][2/16]\tTime 0.163 (0.857)\tETA 0:00:02\tTraining Loss 1.1871 (1.1891)\n",
      "\n",
      "Epoch: [219][3/16]\tTime 0.198 (1.055)\tETA 0:00:02\tTraining Loss 1.1874 (1.1887)\n",
      "\n",
      "Epoch: [219][4/16]\tTime 0.187 (1.243)\tETA 0:00:02\tTraining Loss 1.1920 (1.1894)\n",
      "\n",
      "Epoch: [219][5/16]\tTime 0.180 (1.422)\tETA 0:00:01\tTraining Loss 1.1868 (1.1889)\n",
      "\n",
      "Epoch: [219][6/16]\tTime 0.197 (1.620)\tETA 0:00:01\tTraining Loss 1.1868 (1.1886)\n",
      "\n",
      "Epoch: [219][7/16]\tTime 0.199 (1.819)\tETA 0:00:01\tTraining Loss 1.1884 (1.1886)\n",
      "\n",
      "Epoch: [219][8/16]\tTime 0.193 (2.012)\tETA 0:00:01\tTraining Loss 1.1857 (1.1883)\n",
      "\n",
      "Epoch: [219][9/16]\tTime 0.198 (2.210)\tETA 0:00:01\tTraining Loss 1.1875 (1.1882)\n",
      "\n",
      "Epoch: [219][10/16]\tTime 0.181 (2.391)\tETA 0:00:01\tTraining Loss 1.1863 (1.1880)\n",
      "\n",
      "Epoch: [219][11/16]\tTime 0.196 (2.587)\tETA 0:00:00\tTraining Loss 1.1887 (1.1881)\n",
      "\n",
      "Epoch: [219][12/16]\tTime 0.196 (2.782)\tETA 0:00:00\tTraining Loss 1.1862 (1.1880)\n",
      "\n",
      "Epoch: [219][13/16]\tTime 0.182 (2.964)\tETA 0:00:00\tTraining Loss 1.1861 (1.1878)\n",
      "\n",
      "Epoch: [219][14/16]\tTime 0.195 (3.159)\tETA 0:00:00\tTraining Loss 1.1879 (1.1878)\n",
      "\n",
      "Epoch: [219][15/16]\tTime 0.119 (3.278)\tETA 0:00:00\tTraining Loss 1.1856 (1.1878)\n",
      "_\n",
      "Validation stats                    IoU        F1      Prec    recall       Acc\n",
      "bg,          0.954100  0.976500  0.976800  0.976200  0.959200\n",
      "real apple   0.443100  0.614100  0.910600  0.463300  0.961700\n",
      "real pepper  0.000000  0.000000  0.000000  0.000000  0.999800\n",
      "real grape   0.689500  0.816200  0.884400  0.757900  0.977900\n",
      "fake apple   0.000000  0.000000  0.000000  0.000000  0.980500\n",
      "fake pepper  0.000000  0.000000  0.000000  0.000000  0.997200\n",
      "fake grape   0.000000  0.000000  0.000000  0.000000  0.980400\n",
      "total        0.298100  0.343829  0.395971  0.313914  0.979529\n",
      "total(-bg)   0.188767  0.238383  0.299167  0.203533  0.982917\n",
      "\n",
      "Epoch: [220][0/16]\tTime 0.405 (0.405)\tETA 0:00:06\tTraining Loss 1.1872 (1.1872)\n",
      "\n",
      "Epoch: [220][1/16]\tTime 0.191 (0.595)\tETA 0:00:02\tTraining Loss 1.1871 (1.1871)\n",
      "\n",
      "Epoch: [220][2/16]\tTime 0.188 (0.784)\tETA 0:00:02\tTraining Loss 1.1870 (1.1871)\n",
      "\n",
      "Epoch: [220][3/16]\tTime 0.182 (0.966)\tETA 0:00:02\tTraining Loss 1.1923 (1.1884)\n",
      "\n",
      "Epoch: [220][4/16]\tTime 0.185 (1.151)\tETA 0:00:02\tTraining Loss 1.1858 (1.1879)\n",
      "\n",
      "Epoch: [220][5/16]\tTime 0.193 (1.343)\tETA 0:00:02\tTraining Loss 1.1864 (1.1876)\n",
      "\n",
      "Epoch: [220][6/16]\tTime 0.190 (1.533)\tETA 0:00:01\tTraining Loss 1.1854 (1.1873)\n",
      "\n",
      "Epoch: [220][7/16]\tTime 0.183 (1.716)\tETA 0:00:01\tTraining Loss 1.1869 (1.1873)\n",
      "\n",
      "Epoch: [220][8/16]\tTime 0.180 (1.896)\tETA 0:00:01\tTraining Loss 1.1854 (1.1870)\n",
      "\n",
      "Epoch: [220][9/16]\tTime 0.186 (2.081)\tETA 0:00:01\tTraining Loss 1.1885 (1.1872)\n",
      "\n",
      "Epoch: [220][10/16]\tTime 0.183 (2.265)\tETA 0:00:01\tTraining Loss 1.1869 (1.1872)\n",
      "\n",
      "Epoch: [220][11/16]\tTime 0.200 (2.464)\tETA 0:00:00\tTraining Loss 1.1858 (1.1870)\n",
      "\n",
      "Epoch: [220][12/16]\tTime 0.199 (2.663)\tETA 0:00:00\tTraining Loss 1.1897 (1.1872)\n",
      "\n",
      "Epoch: [220][13/16]\tTime 0.193 (2.856)\tETA 0:00:00\tTraining Loss 1.1859 (1.1872)\n",
      "\n",
      "Epoch: [220][14/16]\tTime 0.189 (3.045)\tETA 0:00:00\tTraining Loss 1.1875 (1.1872)\n",
      "\n",
      "Epoch: [220][15/16]\tTime 0.115 (3.160)\tETA 0:00:00\tTraining Loss 1.1887 (1.1872)\n",
      "_\n",
      "Validation stats                    IoU        F1      Prec    recall       Acc\n",
      "bg,          0.956800  0.977900  0.977400  0.978400  0.961600\n",
      "real apple   0.402200  0.573600  0.855800  0.431400  0.957900\n",
      "real pepper  0.000000  0.000000  0.000000  0.000000  1.000000\n",
      "real grape   0.749500  0.856800  0.888600  0.827300  0.982100\n",
      "fake apple   0.000000  0.000000  0.000000  0.000000  0.979500\n",
      "fake pepper  0.000000  0.000000  0.000000  0.000000  0.996100\n",
      "fake grape   0.000000  0.000000  0.000000  0.000000  0.988300\n",
      "total        0.301214  0.344043  0.388829  0.319586  0.980786\n",
      "total(-bg)   0.191950  0.238400  0.290733  0.209783  0.983983\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: [221][0/16]\tTime 0.505 (0.505)\tETA 0:00:08\tTraining Loss 1.1868 (1.1868)\n",
      "\n",
      "Epoch: [221][1/16]\tTime 0.180 (0.686)\tETA 0:00:02\tTraining Loss 1.1893 (1.1880)\n",
      "\n",
      "Epoch: [221][2/16]\tTime 0.196 (0.882)\tETA 0:00:02\tTraining Loss 1.1891 (1.1884)\n",
      "\n",
      "Epoch: [221][3/16]\tTime 0.180 (1.062)\tETA 0:00:02\tTraining Loss 1.1856 (1.1877)\n",
      "\n",
      "Epoch: [221][4/16]\tTime 0.191 (1.253)\tETA 0:00:02\tTraining Loss 1.1847 (1.1871)\n",
      "\n",
      "Epoch: [221][5/16]\tTime 0.180 (1.433)\tETA 0:00:01\tTraining Loss 1.1875 (1.1871)\n",
      "\n",
      "Epoch: [221][6/16]\tTime 0.190 (1.623)\tETA 0:00:01\tTraining Loss 1.1891 (1.1874)\n",
      "\n",
      "Epoch: [221][7/16]\tTime 0.186 (1.810)\tETA 0:00:01\tTraining Loss 1.1861 (1.1873)\n",
      "\n",
      "Epoch: [221][8/16]\tTime 0.188 (1.997)\tETA 0:00:01\tTraining Loss 1.1847 (1.1870)\n",
      "\n",
      "Epoch: [221][9/16]\tTime 0.186 (2.183)\tETA 0:00:01\tTraining Loss 1.1857 (1.1869)\n",
      "\n",
      "Epoch: [221][10/16]\tTime 0.192 (2.375)\tETA 0:00:01\tTraining Loss 1.1858 (1.1868)\n",
      "\n",
      "Epoch: [221][11/16]\tTime 0.188 (2.563)\tETA 0:00:00\tTraining Loss 1.1861 (1.1867)\n",
      "\n",
      "Epoch: [221][12/16]\tTime 0.187 (2.750)\tETA 0:00:00\tTraining Loss 1.1851 (1.1866)\n",
      "\n",
      "Epoch: [221][13/16]\tTime 0.191 (2.941)\tETA 0:00:00\tTraining Loss 1.1869 (1.1866)\n",
      "\n",
      "Epoch: [221][14/16]\tTime 0.195 (3.136)\tETA 0:00:00\tTraining Loss 1.1886 (1.1867)\n",
      "\n",
      "Epoch: [221][15/16]\tTime 0.120 (3.255)\tETA 0:00:00\tTraining Loss 1.1871 (1.1867)\n",
      "_\n",
      "Validation stats                    IoU        F1      Prec    recall      Acc\n",
      "bg,          0.951800  0.975300  0.978500  0.972200  0.95720\n",
      "real apple   0.432800  0.604000  0.837000  0.472600  0.95930\n",
      "real pepper  0.000000  0.000000  0.000000  0.000000  0.99990\n",
      "real grape   0.752300  0.858600  0.873700  0.844000  0.98200\n",
      "fake apple   0.000000  0.000000  0.000000  0.000000  0.98140\n",
      "fake pepper  0.000000  0.000000  0.000000  0.000000  0.99400\n",
      "fake grape   0.000000  0.000000  0.000000  0.000000  0.98830\n",
      "total        0.305271  0.348271  0.384171  0.326971  0.98030\n",
      "total(-bg)   0.197517  0.243767  0.285117  0.219433  0.98415\n",
      "\n",
      "Epoch: [222][0/16]\tTime 0.535 (0.535)\tETA 0:00:08\tTraining Loss 1.1857 (1.1857)\n",
      "\n",
      "Epoch: [222][1/16]\tTime 0.198 (0.733)\tETA 0:00:02\tTraining Loss 1.1859 (1.1858)\n",
      "\n",
      "Epoch: [222][2/16]\tTime 0.186 (0.919)\tETA 0:00:02\tTraining Loss 1.1882 (1.1866)\n",
      "\n",
      "Epoch: [222][3/16]\tTime 0.198 (1.117)\tETA 0:00:02\tTraining Loss 1.1842 (1.1860)\n",
      "\n",
      "Epoch: [222][4/16]\tTime 0.186 (1.303)\tETA 0:00:02\tTraining Loss 1.1863 (1.1861)\n",
      "\n",
      "Epoch: [222][5/16]\tTime 0.193 (1.497)\tETA 0:00:02\tTraining Loss 1.1849 (1.1859)\n",
      "\n",
      "Epoch: [222][6/16]\tTime 0.197 (1.694)\tETA 0:00:01\tTraining Loss 1.1855 (1.1858)\n",
      "\n",
      "Epoch: [222][7/16]\tTime 0.187 (1.880)\tETA 0:00:01\tTraining Loss 1.1892 (1.1862)\n",
      "\n",
      "Epoch: [222][8/16]\tTime 0.194 (2.075)\tETA 0:00:01\tTraining Loss 1.1840 (1.1860)\n",
      "\n",
      "Epoch: [222][9/16]\tTime 0.185 (2.260)\tETA 0:00:01\tTraining Loss 1.1893 (1.1863)\n",
      "\n",
      "Epoch: [222][10/16]\tTime 0.207 (2.467)\tETA 0:00:01\tTraining Loss 1.1859 (1.1863)\n",
      "\n",
      "Epoch: [222][11/16]\tTime 0.187 (2.654)\tETA 0:00:00\tTraining Loss 1.1844 (1.1861)\n",
      "\n",
      "Epoch: [222][12/16]\tTime 0.193 (2.846)\tETA 0:00:00\tTraining Loss 1.1851 (1.1860)\n",
      "\n",
      "Epoch: [222][13/16]\tTime 0.189 (3.036)\tETA 0:00:00\tTraining Loss 1.1843 (1.1859)\n",
      "\n",
      "Epoch: [222][14/16]\tTime 0.200 (3.235)\tETA 0:00:00\tTraining Loss 1.1875 (1.1860)\n",
      "\n",
      "Epoch: [222][15/16]\tTime 0.112 (3.348)\tETA 0:00:00\tTraining Loss 1.1875 (1.1861)\n",
      "_\n",
      "Validation stats                    IoU        F1      Prec    recall       Acc\n",
      "bg,          0.952300  0.975500  0.977800  0.973300  0.957600\n",
      "real apple   0.533900  0.696100  0.849000  0.590000  0.966200\n",
      "real pepper  0.000000  0.000000  0.000000  0.000000  1.000000\n",
      "real grape   0.756100  0.861100  0.885900  0.837800  0.982500\n",
      "fake apple   0.000000  0.000000  0.000000  0.000000  0.988800\n",
      "fake pepper  0.000000  0.000000  0.000000  0.000000  0.996400\n",
      "fake grape   0.000000  0.000000  0.000000  0.000000  0.987200\n",
      "total        0.320329  0.361814  0.387529  0.343014  0.982671\n",
      "total(-bg)   0.215000  0.259533  0.289150  0.237967  0.986850\n",
      "\n",
      "Epoch: [223][0/16]\tTime 0.411 (0.411)\tETA 0:00:06\tTraining Loss 1.1852 (1.1852)\n",
      "\n",
      "Epoch: [223][1/16]\tTime 0.184 (0.594)\tETA 0:00:02\tTraining Loss 1.1849 (1.1850)\n",
      "\n",
      "Epoch: [223][2/16]\tTime 0.201 (0.795)\tETA 0:00:02\tTraining Loss 1.1847 (1.1849)\n",
      "\n",
      "Epoch: [223][3/16]\tTime 0.178 (0.973)\tETA 0:00:02\tTraining Loss 1.1849 (1.1849)\n",
      "\n",
      "Epoch: [223][4/16]\tTime 0.194 (1.168)\tETA 0:00:02\tTraining Loss 1.1840 (1.1847)\n",
      "\n",
      "Epoch: [223][5/16]\tTime 0.180 (1.347)\tETA 0:00:01\tTraining Loss 1.1844 (1.1847)\n",
      "\n",
      "Epoch: [223][6/16]\tTime 0.205 (1.552)\tETA 0:00:02\tTraining Loss 1.1873 (1.1850)\n",
      "\n",
      "Epoch: [223][7/16]\tTime 0.195 (1.747)\tETA 0:00:01\tTraining Loss 1.1852 (1.1851)\n",
      "\n",
      "Epoch: [223][8/16]\tTime 0.180 (1.927)\tETA 0:00:01\tTraining Loss 1.1858 (1.1852)\n",
      "\n",
      "Epoch: [223][9/16]\tTime 0.189 (2.116)\tETA 0:00:01\tTraining Loss 1.1852 (1.1852)\n",
      "\n",
      "Epoch: [223][10/16]\tTime 0.190 (2.307)\tETA 0:00:01\tTraining Loss 1.1860 (1.1852)\n",
      "\n",
      "Epoch: [223][11/16]\tTime 0.182 (2.489)\tETA 0:00:00\tTraining Loss 1.1836 (1.1851)\n",
      "\n",
      "Epoch: [223][12/16]\tTime 0.186 (2.674)\tETA 0:00:00\tTraining Loss 1.1936 (1.1857)\n",
      "\n",
      "Epoch: [223][13/16]\tTime 0.179 (2.853)\tETA 0:00:00\tTraining Loss 1.1871 (1.1858)\n",
      "\n",
      "Epoch: [223][14/16]\tTime 0.191 (3.045)\tETA 0:00:00\tTraining Loss 1.1884 (1.1860)\n",
      "\n",
      "Epoch: [223][15/16]\tTime 0.113 (3.158)\tETA 0:00:00\tTraining Loss 1.1855 (1.1860)\n",
      "_\n",
      "Validation stats                    IoU        F1      Prec    recall       Acc\n",
      "bg,          0.952000  0.975400  0.978400  0.972500  0.957400\n",
      "real apple   0.557100  0.715500  0.835600  0.625600  0.967300\n",
      "real pepper  0.000000  0.000000  0.000000  0.000000  0.999800\n",
      "real grape   0.763200  0.865600  0.881700  0.850200  0.982900\n",
      "fake apple   0.000000  0.000000  0.000000  0.000000  0.991300\n",
      "fake pepper  0.000000  0.000000  0.000000  0.000000  0.996900\n",
      "fake grape   0.000000  0.000000  0.000000  0.000000  0.988000\n",
      "total        0.324614  0.365214  0.385100  0.349757  0.983371\n",
      "total(-bg)   0.220050  0.263517  0.286217  0.245967  0.987700\n",
      "\n",
      "Epoch: [224][0/16]\tTime 0.434 (0.434)\tETA 0:00:06\tTraining Loss 1.1847 (1.1847)\n",
      "\n",
      "Epoch: [224][1/16]\tTime 0.189 (0.623)\tETA 0:00:02\tTraining Loss 1.1835 (1.1841)\n",
      "\n",
      "Epoch: [224][2/16]\tTime 0.187 (0.810)\tETA 0:00:02\tTraining Loss 1.1889 (1.1857)\n",
      "\n",
      "Epoch: [224][3/16]\tTime 0.193 (1.003)\tETA 0:00:02\tTraining Loss 1.1862 (1.1858)\n",
      "\n",
      "Epoch: [224][4/16]\tTime 0.176 (1.179)\tETA 0:00:02\tTraining Loss 1.1852 (1.1857)\n",
      "\n",
      "Epoch: [224][5/16]\tTime 0.182 (1.361)\tETA 0:00:02\tTraining Loss 1.1850 (1.1856)\n",
      "\n",
      "Epoch: [224][6/16]\tTime 0.186 (1.548)\tETA 0:00:01\tTraining Loss 1.1842 (1.1854)\n",
      "\n",
      "Epoch: [224][7/16]\tTime 0.190 (1.738)\tETA 0:00:01\tTraining Loss 1.1877 (1.1857)\n",
      "\n",
      "Epoch: [224][8/16]\tTime 0.190 (1.928)\tETA 0:00:01\tTraining Loss 1.1848 (1.1856)\n",
      "\n",
      "Epoch: [224][9/16]\tTime 0.181 (2.109)\tETA 0:00:01\tTraining Loss 1.1879 (1.1858)\n",
      "\n",
      "Epoch: [224][10/16]\tTime 0.187 (2.296)\tETA 0:00:01\tTraining Loss 1.1839 (1.1857)\n",
      "\n",
      "Epoch: [224][11/16]\tTime 0.184 (2.480)\tETA 0:00:00\tTraining Loss 1.1870 (1.1858)\n",
      "\n",
      "Epoch: [224][12/16]\tTime 0.196 (2.676)\tETA 0:00:00\tTraining Loss 1.1856 (1.1858)\n",
      "\n",
      "Epoch: [224][13/16]\tTime 0.186 (2.862)\tETA 0:00:00\tTraining Loss 1.1858 (1.1858)\n",
      "\n",
      "Epoch: [224][14/16]\tTime 0.186 (3.048)\tETA 0:00:00\tTraining Loss 1.1845 (1.1857)\n",
      "\n",
      "Epoch: [224][15/16]\tTime 0.114 (3.162)\tETA 0:00:00\tTraining Loss 1.1848 (1.1856)\n",
      "_\n",
      "Validation stats                    IoU        F1      Prec    recall       Acc\n",
      "bg,          0.955000  0.976900  0.977000  0.977000  0.960000\n",
      "real apple   0.481600  0.650100  0.841400  0.529700  0.962500\n",
      "real pepper  0.000000  0.000000  0.000000  0.000000  1.000000\n",
      "real grape   0.732900  0.845800  0.890700  0.805300  0.981000\n",
      "fake apple   0.000000  0.000000  0.000000  0.000000  0.986600\n",
      "fake pepper  0.000000  0.000000  0.000000  0.000000  0.996000\n",
      "fake grape   0.000000  0.000000  0.000000  0.000000  0.986900\n",
      "total        0.309929  0.353257  0.387014  0.330286  0.981857\n",
      "total(-bg)   0.202417  0.249317  0.288683  0.222500  0.985500\n",
      "\n",
      "Epoch: [225][0/16]\tTime 0.477 (0.477)\tETA 0:00:07\tTraining Loss 1.1843 (1.1843)\n",
      "\n",
      "Epoch: [225][1/16]\tTime 0.174 (0.652)\tETA 0:00:02\tTraining Loss 1.1840 (1.1842)\n",
      "\n",
      "Epoch: [225][2/16]\tTime 0.194 (0.845)\tETA 0:00:02\tTraining Loss 1.1844 (1.1842)\n",
      "\n",
      "Epoch: [225][3/16]\tTime 0.186 (1.031)\tETA 0:00:02\tTraining Loss 1.1853 (1.1845)\n",
      "\n",
      "Epoch: [225][4/16]\tTime 0.188 (1.219)\tETA 0:00:02\tTraining Loss 1.1852 (1.1846)\n",
      "\n",
      "Epoch: [225][5/16]\tTime 0.182 (1.401)\tETA 0:00:02\tTraining Loss 1.1859 (1.1848)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: [225][6/16]\tTime 0.186 (1.587)\tETA 0:00:01\tTraining Loss 1.1858 (1.1850)\n",
      "\n",
      "Epoch: [225][7/16]\tTime 0.201 (1.788)\tETA 0:00:01\tTraining Loss 1.1860 (1.1851)\n",
      "\n",
      "Epoch: [225][8/16]\tTime 0.184 (1.972)\tETA 0:00:01\tTraining Loss 1.1846 (1.1851)\n",
      "\n",
      "Epoch: [225][9/16]\tTime 0.180 (2.152)\tETA 0:00:01\tTraining Loss 1.1829 (1.1848)\n",
      "\n",
      "Epoch: [225][10/16]\tTime 0.186 (2.338)\tETA 0:00:01\tTraining Loss 1.1848 (1.1848)\n",
      "\n",
      "Epoch: [225][11/16]\tTime 0.181 (2.519)\tETA 0:00:00\tTraining Loss 1.1874 (1.1850)\n",
      "\n",
      "Epoch: [225][12/16]\tTime 0.192 (2.711)\tETA 0:00:00\tTraining Loss 1.1874 (1.1852)\n",
      "\n",
      "Epoch: [225][13/16]\tTime 0.177 (2.888)\tETA 0:00:00\tTraining Loss 1.1864 (1.1853)\n",
      "\n",
      "Epoch: [225][14/16]\tTime 0.187 (3.075)\tETA 0:00:00\tTraining Loss 1.1865 (1.1854)\n",
      "\n",
      "Epoch: [225][15/16]\tTime 0.116 (3.191)\tETA 0:00:00\tTraining Loss 1.1927 (1.1856)\n",
      "_\n",
      "Validation stats                    IoU        F1      Prec    recall       Acc\n",
      "bg,          0.951400  0.975100  0.977900  0.972400  0.956800\n",
      "real apple   0.471800  0.641100  0.818800  0.526800  0.961200\n",
      "real pepper  0.000000  0.000000  0.000000  0.000000  1.000000\n",
      "real grape   0.745700  0.854300  0.874400  0.835200  0.981600\n",
      "fake apple   0.000000  0.000000  0.000000  0.000000  0.985200\n",
      "fake pepper  0.000000  0.000000  0.000000  0.000000  0.994800\n",
      "fake grape   0.000000  0.000000  0.000000  0.000000  0.988800\n",
      "total        0.309843  0.352929  0.381586  0.333486  0.981200\n",
      "total(-bg)   0.202917  0.249233  0.282200  0.227000  0.985267\n",
      "\n",
      "Epoch: [226][0/16]\tTime 0.522 (0.522)\tETA 0:00:08\tTraining Loss 1.1839 (1.1839)\n",
      "\n",
      "Epoch: [226][1/16]\tTime 0.182 (0.704)\tETA 0:00:02\tTraining Loss 1.1868 (1.1853)\n",
      "\n",
      "Epoch: [226][2/16]\tTime 0.192 (0.895)\tETA 0:00:02\tTraining Loss 1.1892 (1.1866)\n",
      "\n",
      "Epoch: [226][3/16]\tTime 0.187 (1.082)\tETA 0:00:02\tTraining Loss 1.1831 (1.1857)\n",
      "\n",
      "Epoch: [226][4/16]\tTime 0.190 (1.273)\tETA 0:00:02\tTraining Loss 1.1861 (1.1858)\n",
      "\n",
      "Epoch: [226][5/16]\tTime 0.190 (1.462)\tETA 0:00:02\tTraining Loss 1.1839 (1.1855)\n",
      "\n",
      "Epoch: [226][6/16]\tTime 0.192 (1.654)\tETA 0:00:01\tTraining Loss 1.1864 (1.1856)\n",
      "\n",
      "Epoch: [226][7/16]\tTime 0.196 (1.850)\tETA 0:00:01\tTraining Loss 1.1857 (1.1856)\n",
      "\n",
      "Epoch: [226][8/16]\tTime 0.185 (2.035)\tETA 0:00:01\tTraining Loss 1.1843 (1.1855)\n",
      "\n",
      "Epoch: [226][9/16]\tTime 0.191 (2.227)\tETA 0:00:01\tTraining Loss 1.1850 (1.1855)\n",
      "\n",
      "Epoch: [226][10/16]\tTime 0.184 (2.411)\tETA 0:00:01\tTraining Loss 1.1859 (1.1855)\n",
      "\n",
      "Epoch: [226][11/16]\tTime 0.195 (2.606)\tETA 0:00:00\tTraining Loss 1.1840 (1.1854)\n",
      "\n",
      "Epoch: [226][12/16]\tTime 0.202 (2.808)\tETA 0:00:00\tTraining Loss 1.1883 (1.1856)\n",
      "\n",
      "Epoch: [226][13/16]\tTime 0.195 (3.003)\tETA 0:00:00\tTraining Loss 1.1840 (1.1855)\n",
      "\n",
      "Epoch: [226][14/16]\tTime 0.185 (3.188)\tETA 0:00:00\tTraining Loss 1.1839 (1.1854)\n",
      "\n",
      "Epoch: [226][15/16]\tTime 0.114 (3.303)\tETA 0:00:00\tTraining Loss 1.1865 (1.1854)\n",
      "_\n",
      "Validation stats                    IoU        F1      Prec    recall       Acc\n",
      "bg,          0.955700  0.977300  0.978400  0.976200  0.960600\n",
      "real apple   0.497500  0.664400  0.871900  0.536700  0.964400\n",
      "real pepper  0.000000  0.000000  0.000000  0.000000  1.000000\n",
      "real grape   0.670300  0.802600  0.855000  0.756300  0.975900\n",
      "fake apple   0.000000  0.000000  0.000000  0.000000  0.986700\n",
      "fake pepper  0.000000  0.000000  0.000000  0.000000  0.996700\n",
      "fake grape   0.000000  0.000000  0.000000  0.000000  0.981900\n",
      "total        0.303357  0.349186  0.386471  0.324171  0.980886\n",
      "total(-bg)   0.194633  0.244500  0.287817  0.215500  0.984267\n",
      "\n",
      "Epoch: [227][0/16]\tTime 0.496 (0.496)\tETA 0:00:07\tTraining Loss 1.1843 (1.1843)\n",
      "\n",
      "Epoch: [227][1/16]\tTime 0.185 (0.681)\tETA 0:00:02\tTraining Loss 1.1857 (1.1850)\n",
      "\n",
      "Epoch: [227][2/16]\tTime 0.192 (0.873)\tETA 0:00:02\tTraining Loss 1.1878 (1.1859)\n",
      "\n",
      "Epoch: [227][3/16]\tTime 0.185 (1.058)\tETA 0:00:02\tTraining Loss 1.1846 (1.1856)\n",
      "\n",
      "Epoch: [227][4/16]\tTime 0.185 (1.243)\tETA 0:00:02\tTraining Loss 1.1857 (1.1856)\n",
      "\n",
      "Epoch: [227][5/16]\tTime 0.185 (1.428)\tETA 0:00:02\tTraining Loss 1.1833 (1.1852)\n",
      "\n",
      "Epoch: [227][6/16]\tTime 0.189 (1.617)\tETA 0:00:01\tTraining Loss 1.1835 (1.1850)\n",
      "\n",
      "Epoch: [227][7/16]\tTime 0.184 (1.802)\tETA 0:00:01\tTraining Loss 1.1858 (1.1851)\n",
      "\n",
      "Epoch: [227][8/16]\tTime 0.191 (1.993)\tETA 0:00:01\tTraining Loss 1.1834 (1.1849)\n",
      "\n",
      "Epoch: [227][9/16]\tTime 0.289 (2.282)\tETA 0:00:02\tTraining Loss 1.1844 (1.1848)\n",
      "\n",
      "Epoch: [227][10/16]\tTime 0.180 (2.461)\tETA 0:00:01\tTraining Loss 1.1838 (1.1848)\n",
      "\n",
      "Epoch: [227][11/16]\tTime 0.180 (2.641)\tETA 0:00:00\tTraining Loss 1.1873 (1.1850)\n",
      "\n",
      "Epoch: [227][12/16]\tTime 0.189 (2.830)\tETA 0:00:00\tTraining Loss 1.1843 (1.1849)\n",
      "\n",
      "Epoch: [227][13/16]\tTime 0.186 (3.017)\tETA 0:00:00\tTraining Loss 1.1839 (1.1848)\n",
      "\n",
      "Epoch: [227][14/16]\tTime 0.193 (3.210)\tETA 0:00:00\tTraining Loss 1.1838 (1.1848)\n",
      "\n",
      "Epoch: [227][15/16]\tTime 0.114 (3.324)\tETA 0:00:00\tTraining Loss 1.1863 (1.1848)\n",
      "_\n",
      "Validation stats                    IoU        F1      Prec    recall       Acc\n",
      "bg,          0.956500  0.977700  0.978000  0.977600  0.961400\n",
      "real apple   0.580100  0.734200  0.893200  0.623300  0.970300\n",
      "real pepper  0.000000  0.000000  0.000000  0.000000  1.000000\n",
      "real grape   0.784500  0.879200  0.905700  0.854200  0.984800\n",
      "fake apple   0.000000  0.000000  0.000000  0.000000  0.991200\n",
      "fake pepper  0.000000  0.000000  0.000000  0.000000  0.996900\n",
      "fake grape   0.000000  0.000000  0.000000  0.000000  0.988000\n",
      "total        0.331586  0.370157  0.396700  0.350729  0.984657\n",
      "total(-bg)   0.227433  0.268900  0.299817  0.246250  0.988533\n",
      "\n",
      "Epoch: [228][0/16]\tTime 0.490 (0.490)\tETA 0:00:07\tTraining Loss 1.1842 (1.1842)\n",
      "\n",
      "Epoch: [228][1/16]\tTime 0.186 (0.676)\tETA 0:00:02\tTraining Loss 1.1832 (1.1837)\n",
      "\n",
      "Epoch: [228][2/16]\tTime 0.188 (0.864)\tETA 0:00:02\tTraining Loss 1.1837 (1.1837)\n",
      "\n",
      "Epoch: [228][3/16]\tTime 0.184 (1.048)\tETA 0:00:02\tTraining Loss 1.1869 (1.1845)\n",
      "\n",
      "Epoch: [228][4/16]\tTime 0.189 (1.236)\tETA 0:00:02\tTraining Loss 1.1836 (1.1843)\n",
      "\n",
      "Epoch: [228][5/16]\tTime 0.191 (1.427)\tETA 0:00:02\tTraining Loss 1.1852 (1.1844)\n",
      "\n",
      "Epoch: [228][6/16]\tTime 0.184 (1.611)\tETA 0:00:01\tTraining Loss 1.1861 (1.1847)\n",
      "\n",
      "Epoch: [228][7/16]\tTime 0.182 (1.794)\tETA 0:00:01\tTraining Loss 1.1838 (1.1846)\n",
      "\n",
      "Epoch: [228][8/16]\tTime 0.184 (1.977)\tETA 0:00:01\tTraining Loss 1.1829 (1.1844)\n",
      "\n",
      "Epoch: [228][9/16]\tTime 0.189 (2.167)\tETA 0:00:01\tTraining Loss 1.1837 (1.1843)\n",
      "\n",
      "Epoch: [228][10/16]\tTime 0.188 (2.355)\tETA 0:00:01\tTraining Loss 1.1852 (1.1844)\n",
      "\n",
      "Epoch: [228][11/16]\tTime 0.187 (2.542)\tETA 0:00:00\tTraining Loss 1.1836 (1.1843)\n",
      "\n",
      "Epoch: [228][12/16]\tTime 0.187 (2.729)\tETA 0:00:00\tTraining Loss 1.1832 (1.1842)\n",
      "\n",
      "Epoch: [228][13/16]\tTime 0.190 (2.919)\tETA 0:00:00\tTraining Loss 1.1840 (1.1842)\n",
      "\n",
      "Epoch: [228][14/16]\tTime 0.187 (3.106)\tETA 0:00:00\tTraining Loss 1.1884 (1.1845)\n",
      "\n",
      "Epoch: [228][15/16]\tTime 0.113 (3.219)\tETA 0:00:00\tTraining Loss 1.1832 (1.1845)\n",
      "_\n",
      "Validation stats                    IoU        F1      Prec    recall       Acc\n",
      "bg,          0.956700  0.977800  0.979000  0.976700  0.961500\n",
      "real apple   0.582900  0.736500  0.877800  0.634400  0.970200\n",
      "real pepper  0.000000  0.000000  0.000000  0.000000  1.000000\n",
      "real grape   0.807700  0.893600  0.891500  0.895700  0.986200\n",
      "fake apple   0.000000  0.000000  0.000000  0.000000  0.990900\n",
      "fake pepper  0.000000  0.000000  0.000000  0.000000  0.999100\n",
      "fake grape   0.000000  0.000000  0.000000  0.000000  0.990100\n",
      "total        0.335329  0.372557  0.392614  0.358114  0.985429\n",
      "total(-bg)   0.231767  0.271683  0.294883  0.255017  0.989417\n",
      "\n",
      "Epoch: [229][0/16]\tTime 0.372 (0.372)\tETA 0:00:05\tTraining Loss 1.1899 (1.1899)\n",
      "\n",
      "Epoch: [229][1/16]\tTime 0.182 (0.553)\tETA 0:00:02\tTraining Loss 1.1835 (1.1867)\n",
      "\n",
      "Epoch: [229][2/16]\tTime 0.186 (0.739)\tETA 0:00:02\tTraining Loss 1.1832 (1.1855)\n",
      "\n",
      "Epoch: [229][3/16]\tTime 0.192 (0.932)\tETA 0:00:02\tTraining Loss 1.1848 (1.1853)\n",
      "\n",
      "Epoch: [229][4/16]\tTime 0.183 (1.114)\tETA 0:00:02\tTraining Loss 1.1856 (1.1854)\n",
      "\n",
      "Epoch: [229][5/16]\tTime 0.188 (1.302)\tETA 0:00:02\tTraining Loss 1.1847 (1.1853)\n",
      "\n",
      "Epoch: [229][6/16]\tTime 0.185 (1.487)\tETA 0:00:01\tTraining Loss 1.1845 (1.1852)\n",
      "\n",
      "Epoch: [229][7/16]\tTime 0.187 (1.674)\tETA 0:00:01\tTraining Loss 1.1825 (1.1848)\n",
      "\n",
      "Epoch: [229][8/16]\tTime 0.181 (1.855)\tETA 0:00:01\tTraining Loss 1.1827 (1.1846)\n",
      "\n",
      "Epoch: [229][9/16]\tTime 0.184 (2.039)\tETA 0:00:01\tTraining Loss 1.1856 (1.1847)\n",
      "\n",
      "Epoch: [229][10/16]\tTime 0.192 (2.231)\tETA 0:00:01\tTraining Loss 1.1837 (1.1846)\n",
      "\n",
      "Epoch: [229][11/16]\tTime 0.183 (2.414)\tETA 0:00:00\tTraining Loss 1.1841 (1.1846)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: [229][12/16]\tTime 0.189 (2.603)\tETA 0:00:00\tTraining Loss 1.1845 (1.1845)\n",
      "\n",
      "Epoch: [229][13/16]\tTime 0.186 (2.789)\tETA 0:00:00\tTraining Loss 1.1837 (1.1845)\n",
      "\n",
      "Epoch: [229][14/16]\tTime 0.190 (2.978)\tETA 0:00:00\tTraining Loss 1.1838 (1.1844)\n",
      "\n",
      "Epoch: [229][15/16]\tTime 0.116 (3.095)\tETA 0:00:00\tTraining Loss 1.1852 (1.1845)\n",
      "_\n",
      "Validation stats                    IoU       F1      Prec    recall       Acc\n",
      "bg,          0.959400  0.97920  0.977400  0.981100  0.963900\n",
      "real apple   0.488500  0.65640  0.889600  0.520100  0.964200\n",
      "real pepper  0.000000  0.00000  0.000000  0.000000  1.000000\n",
      "real grape   0.718400  0.83610  0.899000  0.781400  0.980200\n",
      "fake apple   0.000000  0.00000  0.000000  0.000000  0.984900\n",
      "fake pepper  0.000000  0.00000  0.000000  0.000000  0.997800\n",
      "fake grape   0.000000  0.00000  0.000000  0.000000  0.984700\n",
      "total        0.309471  0.35310  0.395143  0.326086  0.982243\n",
      "total(-bg)   0.201150  0.24875  0.298100  0.216917  0.985300\n",
      "\n",
      "Epoch: [230][0/16]\tTime 0.490 (0.490)\tETA 0:00:07\tTraining Loss 1.1839 (1.1839)\n",
      "\n",
      "Epoch: [230][1/16]\tTime 0.184 (0.675)\tETA 0:00:02\tTraining Loss 1.1830 (1.1835)\n",
      "\n",
      "Epoch: [230][2/16]\tTime 0.196 (0.870)\tETA 0:00:02\tTraining Loss 1.1840 (1.1836)\n",
      "\n",
      "Epoch: [230][3/16]\tTime 0.186 (1.056)\tETA 0:00:02\tTraining Loss 1.1855 (1.1841)\n",
      "\n",
      "Epoch: [230][4/16]\tTime 0.179 (1.235)\tETA 0:00:02\tTraining Loss 1.1824 (1.1838)\n",
      "\n",
      "Epoch: [230][5/16]\tTime 0.193 (1.428)\tETA 0:00:02\tTraining Loss 1.1823 (1.1835)\n",
      "\n",
      "Epoch: [230][6/16]\tTime 0.194 (1.622)\tETA 0:00:01\tTraining Loss 1.1870 (1.1840)\n",
      "\n",
      "Epoch: [230][7/16]\tTime 0.189 (1.811)\tETA 0:00:01\tTraining Loss 1.1906 (1.1848)\n",
      "\n",
      "Epoch: [230][8/16]\tTime 0.187 (1.998)\tETA 0:00:01\tTraining Loss 1.1824 (1.1846)\n",
      "\n",
      "Epoch: [230][9/16]\tTime 0.199 (2.197)\tETA 0:00:01\tTraining Loss 1.1840 (1.1845)\n",
      "\n",
      "Epoch: [230][10/16]\tTime 0.299 (2.496)\tETA 0:00:01\tTraining Loss 1.1850 (1.1845)\n",
      "\n",
      "Epoch: [230][11/16]\tTime 0.188 (2.684)\tETA 0:00:00\tTraining Loss 1.1827 (1.1844)\n",
      "\n",
      "Epoch: [230][12/16]\tTime 0.187 (2.871)\tETA 0:00:00\tTraining Loss 1.1833 (1.1843)\n",
      "\n",
      "Epoch: [230][13/16]\tTime 0.175 (3.046)\tETA 0:00:00\tTraining Loss 1.1828 (1.1842)\n",
      "\n",
      "Epoch: [230][14/16]\tTime 0.190 (3.236)\tETA 0:00:00\tTraining Loss 1.1823 (1.1841)\n",
      "\n",
      "Epoch: [230][15/16]\tTime 0.114 (3.349)\tETA 0:00:00\tTraining Loss 1.1835 (1.1841)\n",
      "_\n",
      "Validation stats                  IoU        F1      Prec    recall       Acc\n",
      "bg,          0.9527  0.975700  0.977300  0.974200  0.957900\n",
      "real apple   0.5799  0.734000  0.875500  0.632000  0.969900\n",
      "real pepper  0.0000  0.000000  0.000000  0.000000  1.000000\n",
      "real grape   0.7893  0.882200  0.897100  0.867900  0.985000\n",
      "fake apple   0.0000  0.000000  0.000000  0.000000  0.992300\n",
      "fake pepper  0.0000  0.000000  0.000000  0.000000  0.995200\n",
      "fake grape   0.0000  0.000000  0.000000  0.000000  0.989400\n",
      "total        0.3317  0.370271  0.392843  0.353443  0.984243\n",
      "total(-bg)   0.2282  0.269367  0.295433  0.249983  0.988633\n",
      "\n",
      "Epoch: [231][0/16]\tTime 0.518 (0.518)\tETA 0:00:08\tTraining Loss 1.1833 (1.1833)\n",
      "\n",
      "Epoch: [231][1/16]\tTime 0.184 (0.701)\tETA 0:00:02\tTraining Loss 1.1833 (1.1833)\n",
      "\n",
      "Epoch: [231][2/16]\tTime 0.194 (0.896)\tETA 0:00:02\tTraining Loss 1.1829 (1.1832)\n",
      "\n",
      "Epoch: [231][3/16]\tTime 0.186 (1.082)\tETA 0:00:02\tTraining Loss 1.1824 (1.1830)\n",
      "\n",
      "Epoch: [231][4/16]\tTime 0.196 (1.278)\tETA 0:00:02\tTraining Loss 1.1813 (1.1826)\n",
      "\n",
      "Epoch: [231][5/16]\tTime 0.186 (1.464)\tETA 0:00:02\tTraining Loss 1.1832 (1.1827)\n",
      "\n",
      "Epoch: [231][6/16]\tTime 0.197 (1.661)\tETA 0:00:01\tTraining Loss 1.1829 (1.1827)\n",
      "\n",
      "Epoch: [231][7/16]\tTime 0.193 (1.853)\tETA 0:00:01\tTraining Loss 1.1878 (1.1834)\n",
      "\n",
      "Epoch: [231][8/16]\tTime 0.191 (2.044)\tETA 0:00:01\tTraining Loss 1.1833 (1.1834)\n",
      "\n",
      "Epoch: [231][9/16]\tTime 0.188 (2.232)\tETA 0:00:01\tTraining Loss 1.1862 (1.1836)\n",
      "\n",
      "Epoch: [231][10/16]\tTime 0.187 (2.419)\tETA 0:00:01\tTraining Loss 1.1868 (1.1839)\n",
      "\n",
      "Epoch: [231][11/16]\tTime 0.192 (2.611)\tETA 0:00:00\tTraining Loss 1.1835 (1.1839)\n",
      "\n",
      "Epoch: [231][12/16]\tTime 0.199 (2.810)\tETA 0:00:00\tTraining Loss 1.1851 (1.1840)\n",
      "\n",
      "Epoch: [231][13/16]\tTime 0.188 (2.998)\tETA 0:00:00\tTraining Loss 1.1833 (1.1839)\n",
      "\n",
      "Epoch: [231][14/16]\tTime 0.186 (3.184)\tETA 0:00:00\tTraining Loss 1.1823 (1.1838)\n",
      "\n",
      "Epoch: [231][15/16]\tTime 0.113 (3.297)\tETA 0:00:00\tTraining Loss 1.1838 (1.1838)\n",
      "_\n",
      "Validation stats                    IoU        F1      Prec    recall       Acc\n",
      "bg,          0.957600  0.978300  0.978700  0.977900  0.962300\n",
      "real apple   0.559800  0.717700  0.898100  0.597700  0.969100\n",
      "real pepper  0.000000  0.000000  0.000000  0.000000  1.000000\n",
      "real grape   0.795900  0.886300  0.891600  0.881100  0.985400\n",
      "fake apple   0.000000  0.000000  0.000000  0.000000  0.988800\n",
      "fake pepper  0.000000  0.000000  0.000000  0.000000  0.997800\n",
      "fake grape   0.000000  0.000000  0.000000  0.000000  0.989900\n",
      "total        0.330471  0.368900  0.395486  0.350957  0.984757\n",
      "total(-bg)   0.225950  0.267333  0.298283  0.246467  0.988500\n",
      "\n",
      "Epoch: [232][0/16]\tTime 0.484 (0.484)\tETA 0:00:07\tTraining Loss 1.1814 (1.1814)\n",
      "\n",
      "Epoch: [232][1/16]\tTime 0.174 (0.658)\tETA 0:00:02\tTraining Loss 1.1830 (1.1822)\n",
      "\n",
      "Epoch: [232][2/16]\tTime 0.195 (0.853)\tETA 0:00:02\tTraining Loss 1.1842 (1.1829)\n",
      "\n",
      "Epoch: [232][3/16]\tTime 0.182 (1.034)\tETA 0:00:02\tTraining Loss 1.1822 (1.1827)\n",
      "\n",
      "Epoch: [232][4/16]\tTime 0.184 (1.218)\tETA 0:00:02\tTraining Loss 1.1830 (1.1828)\n",
      "\n",
      "Epoch: [232][5/16]\tTime 0.183 (1.401)\tETA 0:00:02\tTraining Loss 1.1837 (1.1829)\n",
      "\n",
      "Epoch: [232][6/16]\tTime 0.197 (1.597)\tETA 0:00:01\tTraining Loss 1.1845 (1.1831)\n",
      "\n",
      "Epoch: [232][7/16]\tTime 0.185 (1.782)\tETA 0:00:01\tTraining Loss 1.1842 (1.1833)\n",
      "\n",
      "Epoch: [232][8/16]\tTime 0.187 (1.969)\tETA 0:00:01\tTraining Loss 1.1830 (1.1832)\n",
      "\n",
      "Epoch: [232][9/16]\tTime 0.185 (2.154)\tETA 0:00:01\tTraining Loss 1.1832 (1.1832)\n",
      "\n",
      "Epoch: [232][10/16]\tTime 0.184 (2.338)\tETA 0:00:01\tTraining Loss 1.1849 (1.1834)\n",
      "\n",
      "Epoch: [232][11/16]\tTime 0.178 (2.516)\tETA 0:00:00\tTraining Loss 1.1830 (1.1834)\n",
      "\n",
      "Epoch: [232][12/16]\tTime 0.186 (2.702)\tETA 0:00:00\tTraining Loss 1.1820 (1.1833)\n",
      "\n",
      "Epoch: [232][13/16]\tTime 0.184 (2.886)\tETA 0:00:00\tTraining Loss 1.1840 (1.1833)\n",
      "\n",
      "Epoch: [232][14/16]\tTime 0.183 (3.069)\tETA 0:00:00\tTraining Loss 1.1826 (1.1833)\n",
      "\n",
      "Epoch: [232][15/16]\tTime 0.113 (3.182)\tETA 0:00:00\tTraining Loss 1.1839 (1.1833)\n",
      "_\n",
      "Validation stats                    IoU        F1      Prec    recall       Acc\n",
      "bg,          0.957200  0.978100  0.977900  0.978300  0.962000\n",
      "real apple   0.575500  0.730500  0.912200  0.609200  0.970500\n",
      "real pepper  0.000000  0.000000  0.000000  0.000000  1.000000\n",
      "real grape   0.788300  0.881600  0.887000  0.876300  0.984800\n",
      "fake apple   0.000000  0.000000  0.000000  0.000000  0.990700\n",
      "fake pepper  0.000000  0.000000  0.000000  0.000000  0.997900\n",
      "fake grape   0.000000  0.000000  0.000000  0.000000  0.989100\n",
      "total        0.331571  0.370029  0.396729  0.351971  0.985000\n",
      "total(-bg)   0.227300  0.268683  0.299867  0.247583  0.988833\n",
      "\n",
      "Epoch: [233][0/16]\tTime 0.528 (0.528)\tETA 0:00:08\tTraining Loss 1.1825 (1.1825)\n",
      "\n",
      "Epoch: [233][1/16]\tTime 0.188 (0.716)\tETA 0:00:02\tTraining Loss 1.1835 (1.1830)\n",
      "\n",
      "Epoch: [233][2/16]\tTime 0.190 (0.906)\tETA 0:00:02\tTraining Loss 1.1862 (1.1841)\n",
      "\n",
      "Epoch: [233][3/16]\tTime 0.187 (1.094)\tETA 0:00:02\tTraining Loss 1.1821 (1.1836)\n",
      "\n",
      "Epoch: [233][4/16]\tTime 0.195 (1.288)\tETA 0:00:02\tTraining Loss 1.1820 (1.1833)\n",
      "\n",
      "Epoch: [233][5/16]\tTime 0.184 (1.473)\tETA 0:00:02\tTraining Loss 1.1823 (1.1831)\n",
      "\n",
      "Epoch: [233][6/16]\tTime 0.196 (1.669)\tETA 0:00:01\tTraining Loss 1.1843 (1.1833)\n",
      "\n",
      "Epoch: [233][7/16]\tTime 0.197 (1.866)\tETA 0:00:01\tTraining Loss 1.1845 (1.1834)\n",
      "\n",
      "Epoch: [233][8/16]\tTime 0.189 (2.055)\tETA 0:00:01\tTraining Loss 1.1878 (1.1839)\n",
      "\n",
      "Epoch: [233][9/16]\tTime 0.187 (2.242)\tETA 0:00:01\tTraining Loss 1.1823 (1.1838)\n",
      "\n",
      "Epoch: [233][10/16]\tTime 0.191 (2.433)\tETA 0:00:01\tTraining Loss 1.1835 (1.1837)\n",
      "\n",
      "Epoch: [233][11/16]\tTime 0.183 (2.616)\tETA 0:00:00\tTraining Loss 1.1830 (1.1837)\n",
      "\n",
      "Epoch: [233][12/16]\tTime 0.202 (2.819)\tETA 0:00:00\tTraining Loss 1.1826 (1.1836)\n",
      "\n",
      "Epoch: [233][13/16]\tTime 0.190 (3.009)\tETA 0:00:00\tTraining Loss 1.1832 (1.1836)\n",
      "\n",
      "Epoch: [233][14/16]\tTime 0.183 (3.192)\tETA 0:00:00\tTraining Loss 1.1816 (1.1834)\n",
      "\n",
      "Epoch: [233][15/16]\tTime 0.117 (3.309)\tETA 0:00:00\tTraining Loss 1.1818 (1.1834)\n",
      "_\n",
      "Validation stats                   IoU        F1      Prec    recall       Acc\n",
      "bg,          0.95940  0.979200  0.978000  0.980500  0.963900\n",
      "real apple   0.47750  0.646300  0.881300  0.510300  0.963300\n",
      "real pepper  0.00000  0.000000  0.000000  0.000000  1.000000\n",
      "real grape   0.77020  0.870200  0.888300  0.852800  0.983500\n",
      "fake apple   0.00000  0.000000  0.000000  0.000000  0.984400\n",
      "fake pepper  0.00000  0.000000  0.000000  0.000000  0.998000\n",
      "fake grape   0.00000  0.000000  0.000000  0.000000  0.989500\n",
      "total        0.31530  0.356529  0.392514  0.334800  0.983229\n",
      "total(-bg)   0.20795  0.252750  0.294933  0.227183  0.986450\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: [234][0/16]\tTime 0.401 (0.401)\tETA 0:00:06\tTraining Loss 1.1828 (1.1828)\n",
      "\n",
      "Epoch: [234][1/16]\tTime 0.185 (0.585)\tETA 0:00:02\tTraining Loss 1.1830 (1.1829)\n",
      "\n",
      "Epoch: [234][2/16]\tTime 0.189 (0.775)\tETA 0:00:02\tTraining Loss 1.1829 (1.1829)\n",
      "\n",
      "Epoch: [234][3/16]\tTime 0.189 (0.964)\tETA 0:00:02\tTraining Loss 1.1835 (1.1830)\n",
      "\n",
      "Epoch: [234][4/16]\tTime 0.193 (1.157)\tETA 0:00:02\tTraining Loss 1.1828 (1.1830)\n",
      "\n",
      "Epoch: [234][5/16]\tTime 0.188 (1.345)\tETA 0:00:02\tTraining Loss 1.1834 (1.1831)\n",
      "\n",
      "Epoch: [234][6/16]\tTime 0.191 (1.536)\tETA 0:00:01\tTraining Loss 1.1852 (1.1834)\n",
      "\n",
      "Epoch: [234][7/16]\tTime 0.189 (1.725)\tETA 0:00:01\tTraining Loss 1.1823 (1.1832)\n",
      "\n",
      "Epoch: [234][8/16]\tTime 0.189 (1.913)\tETA 0:00:01\tTraining Loss 1.1837 (1.1833)\n",
      "\n",
      "Epoch: [234][9/16]\tTime 0.184 (2.097)\tETA 0:00:01\tTraining Loss 1.1820 (1.1832)\n",
      "\n",
      "Epoch: [234][10/16]\tTime 0.188 (2.286)\tETA 0:00:01\tTraining Loss 1.1827 (1.1831)\n",
      "\n",
      "Epoch: [234][11/16]\tTime 0.184 (2.470)\tETA 0:00:00\tTraining Loss 1.1878 (1.1835)\n",
      "\n",
      "Epoch: [234][12/16]\tTime 0.194 (2.664)\tETA 0:00:00\tTraining Loss 1.1816 (1.1834)\n",
      "\n",
      "Epoch: [234][13/16]\tTime 0.181 (2.845)\tETA 0:00:00\tTraining Loss 1.1823 (1.1833)\n",
      "\n",
      "Epoch: [234][14/16]\tTime 0.197 (3.043)\tETA 0:00:00\tTraining Loss 1.1813 (1.1832)\n",
      "\n",
      "Epoch: [234][15/16]\tTime 0.115 (3.157)\tETA 0:00:00\tTraining Loss 1.1825 (1.1831)\n",
      "_\n",
      "Validation stats                    IoU        F1      Prec    recall       Acc\n",
      "bg,          0.957600  0.978300  0.978200  0.978500  0.962300\n",
      "real apple   0.471700  0.641000  0.874700  0.505900  0.962800\n",
      "real pepper  0.000000  0.000000  0.000000  0.000000  1.000000\n",
      "real grape   0.754300  0.859900  0.878300  0.842300  0.982200\n",
      "fake apple   0.000000  0.000000  0.000000  0.000000  0.983800\n",
      "fake pepper  0.000000  0.000000  0.000000  0.000000  0.997700\n",
      "fake grape   0.000000  0.000000  0.000000  0.000000  0.988400\n",
      "total        0.311943  0.354171  0.390171  0.332386  0.982457\n",
      "total(-bg)   0.204333  0.250150  0.292167  0.224700  0.985817\n",
      "\n",
      "Epoch: [235][0/16]\tTime 0.365 (0.365)\tETA 0:00:05\tTraining Loss 1.1833 (1.1833)\n",
      "\n",
      "Epoch: [235][1/16]\tTime 0.187 (0.552)\tETA 0:00:02\tTraining Loss 1.1807 (1.1820)\n",
      "\n",
      "Epoch: [235][2/16]\tTime 0.182 (0.734)\tETA 0:00:02\tTraining Loss 1.1829 (1.1823)\n",
      "\n",
      "Epoch: [235][3/16]\tTime 0.178 (0.912)\tETA 0:00:02\tTraining Loss 1.1856 (1.1832)\n",
      "\n",
      "Epoch: [235][4/16]\tTime 0.184 (1.096)\tETA 0:00:02\tTraining Loss 1.1826 (1.1830)\n",
      "\n",
      "Epoch: [235][5/16]\tTime 0.192 (1.288)\tETA 0:00:02\tTraining Loss 1.1828 (1.1830)\n",
      "\n",
      "Epoch: [235][6/16]\tTime 0.184 (1.472)\tETA 0:00:01\tTraining Loss 1.1827 (1.1830)\n",
      "\n",
      "Epoch: [235][7/16]\tTime 0.178 (1.651)\tETA 0:00:01\tTraining Loss 1.1824 (1.1829)\n",
      "\n",
      "Epoch: [235][8/16]\tTime 0.187 (1.837)\tETA 0:00:01\tTraining Loss 1.1823 (1.1828)\n",
      "\n",
      "Epoch: [235][9/16]\tTime 0.182 (2.019)\tETA 0:00:01\tTraining Loss 1.1822 (1.1828)\n",
      "\n",
      "Epoch: [235][10/16]\tTime 0.183 (2.202)\tETA 0:00:01\tTraining Loss 1.1851 (1.1830)\n",
      "\n",
      "Epoch: [235][11/16]\tTime 0.198 (2.401)\tETA 0:00:00\tTraining Loss 1.1838 (1.1830)\n",
      "\n",
      "Epoch: [235][12/16]\tTime 0.185 (2.586)\tETA 0:00:00\tTraining Loss 1.1827 (1.1830)\n",
      "\n",
      "Epoch: [235][13/16]\tTime 0.207 (2.792)\tETA 0:00:00\tTraining Loss 1.1840 (1.1831)\n",
      "\n",
      "Epoch: [235][14/16]\tTime 0.165 (2.957)\tETA 0:00:00\tTraining Loss 1.1823 (1.1830)\n",
      "\n",
      "Epoch: [235][15/16]\tTime 0.117 (3.074)\tETA 0:00:00\tTraining Loss 1.1825 (1.1830)\n",
      "_\n",
      "Validation stats                    IoU        F1      Prec    recall       Acc\n",
      "bg,          0.953100  0.976000  0.978800  0.973300  0.958400\n",
      "real apple   0.438900  0.610000  0.825500  0.483700  0.959400\n",
      "real pepper  0.000000  0.000000  0.000000  0.000000  0.999800\n",
      "real grape   0.737700  0.849000  0.867000  0.831900  0.980900\n",
      "fake apple   0.000000  0.000000  0.000000  0.000000  0.981800\n",
      "fake pepper  0.000000  0.000000  0.000000  0.000000  0.995600\n",
      "fake grape   0.000000  0.000000  0.000000  0.000000  0.988100\n",
      "total        0.304243  0.347857  0.381614  0.326986  0.980571\n",
      "total(-bg)   0.196100  0.243167  0.282083  0.219267  0.984267\n",
      "\n",
      "Epoch: [236][0/16]\tTime 0.432 (0.432)\tETA 0:00:06\tTraining Loss 1.1819 (1.1819)\n",
      "\n",
      "Epoch: [236][1/16]\tTime 0.191 (0.622)\tETA 0:00:02\tTraining Loss 1.1822 (1.1820)\n",
      "\n",
      "Epoch: [236][2/16]\tTime 0.189 (0.811)\tETA 0:00:02\tTraining Loss 1.1825 (1.1822)\n",
      "\n",
      "Epoch: [236][3/16]\tTime 0.184 (0.995)\tETA 0:00:02\tTraining Loss 1.1827 (1.1823)\n",
      "\n",
      "Epoch: [236][4/16]\tTime 0.186 (1.181)\tETA 0:00:02\tTraining Loss 1.1821 (1.1823)\n",
      "\n",
      "Epoch: [236][5/16]\tTime 0.189 (1.370)\tETA 0:00:02\tTraining Loss 1.1812 (1.1821)\n",
      "\n",
      "Epoch: [236][6/16]\tTime 0.184 (1.553)\tETA 0:00:01\tTraining Loss 1.1817 (1.1821)\n",
      "\n",
      "Epoch: [236][7/16]\tTime 0.183 (1.737)\tETA 0:00:01\tTraining Loss 1.1833 (1.1822)\n",
      "\n",
      "Epoch: [236][8/16]\tTime 0.183 (1.919)\tETA 0:00:01\tTraining Loss 1.1843 (1.1824)\n",
      "\n",
      "Epoch: [236][9/16]\tTime 0.186 (2.105)\tETA 0:00:01\tTraining Loss 1.1841 (1.1826)\n",
      "\n",
      "Epoch: [236][10/16]\tTime 0.186 (2.291)\tETA 0:00:01\tTraining Loss 1.1833 (1.1827)\n",
      "\n",
      "Epoch: [236][11/16]\tTime 0.180 (2.471)\tETA 0:00:00\tTraining Loss 1.1807 (1.1825)\n",
      "\n",
      "Epoch: [236][12/16]\tTime 0.185 (2.656)\tETA 0:00:00\tTraining Loss 1.1830 (1.1825)\n",
      "\n",
      "Epoch: [236][13/16]\tTime 0.185 (2.841)\tETA 0:00:00\tTraining Loss 1.1831 (1.1826)\n",
      "\n",
      "Epoch: [236][14/16]\tTime 0.190 (3.031)\tETA 0:00:00\tTraining Loss 1.1831 (1.1826)\n",
      "\n",
      "Epoch: [236][15/16]\tTime 0.115 (3.146)\tETA 0:00:00\tTraining Loss 1.1843 (1.1827)\n",
      "_\n",
      "Validation stats                    IoU        F1      Prec    recall       Acc\n",
      "bg,          0.953200  0.976000  0.977400  0.974700  0.958400\n",
      "real apple   0.525800  0.689200  0.857500  0.576200  0.965900\n",
      "real pepper  0.000000  0.000000  0.000000  0.000000  0.999800\n",
      "real grape   0.784400  0.879100  0.904600  0.855100  0.984800\n",
      "fake apple   0.000000  0.000000  0.000000  0.000000  0.989100\n",
      "fake pepper  0.000000  0.000000  0.000000  0.000000  0.994800\n",
      "fake grape   0.000000  0.000000  0.000000  0.000000  0.988800\n",
      "total        0.323343  0.363471  0.391357  0.343714  0.983086\n",
      "total(-bg)   0.218367  0.261383  0.293683  0.238550  0.987200\n",
      "\n",
      "Epoch: [237][0/16]\tTime 0.484 (0.484)\tETA 0:00:07\tTraining Loss 1.1826 (1.1826)\n",
      "\n",
      "Epoch: [237][1/16]\tTime 0.184 (0.669)\tETA 0:00:02\tTraining Loss 1.1863 (1.1844)\n",
      "\n",
      "Epoch: [237][2/16]\tTime 0.186 (0.855)\tETA 0:00:02\tTraining Loss 1.1811 (1.1833)\n",
      "\n",
      "Epoch: [237][3/16]\tTime 0.181 (1.036)\tETA 0:00:02\tTraining Loss 1.1824 (1.1831)\n",
      "\n",
      "Epoch: [237][4/16]\tTime 0.181 (1.217)\tETA 0:00:02\tTraining Loss 1.1814 (1.1827)\n",
      "\n",
      "Epoch: [237][5/16]\tTime 0.183 (1.400)\tETA 0:00:02\tTraining Loss 1.1813 (1.1825)\n",
      "\n",
      "Epoch: [237][6/16]\tTime 0.177 (1.577)\tETA 0:00:01\tTraining Loss 1.1822 (1.1825)\n",
      "\n",
      "Epoch: [237][7/16]\tTime 0.191 (1.767)\tETA 0:00:01\tTraining Loss 1.1835 (1.1826)\n",
      "\n",
      "Epoch: [237][8/16]\tTime 0.187 (1.955)\tETA 0:00:01\tTraining Loss 1.1823 (1.1826)\n",
      "\n",
      "Epoch: [237][9/16]\tTime 0.195 (2.150)\tETA 0:00:01\tTraining Loss 1.1838 (1.1827)\n",
      "\n",
      "Epoch: [237][10/16]\tTime 0.183 (2.332)\tETA 0:00:01\tTraining Loss 1.1812 (1.1826)\n",
      "\n",
      "Epoch: [237][11/16]\tTime 0.195 (2.528)\tETA 0:00:00\tTraining Loss 1.1806 (1.1824)\n",
      "\n",
      "Epoch: [237][12/16]\tTime 0.189 (2.716)\tETA 0:00:00\tTraining Loss 1.1822 (1.1824)\n",
      "\n",
      "Epoch: [237][13/16]\tTime 0.181 (2.897)\tETA 0:00:00\tTraining Loss 1.1812 (1.1823)\n",
      "\n",
      "Epoch: [237][14/16]\tTime 0.190 (3.088)\tETA 0:00:00\tTraining Loss 1.1813 (1.1822)\n",
      "\n",
      "Epoch: [237][15/16]\tTime 0.113 (3.201)\tETA 0:00:00\tTraining Loss 1.1804 (1.1822)\n",
      "_\n",
      "Validation stats                    IoU        F1      Prec    recall       Acc\n",
      "bg,          0.958600  0.978800  0.977700  0.980000  0.963200\n",
      "real apple   0.481400  0.649900  0.884800  0.513600  0.963600\n",
      "real pepper  0.000000  0.000000  0.000000  0.000000  1.000000\n",
      "real grape   0.739300  0.850100  0.888300  0.815100  0.981400\n",
      "fake apple   0.000000  0.000000  0.000000  0.000000  0.985100\n",
      "fake pepper  0.000000  0.000000  0.000000  0.000000  0.996900\n",
      "fake grape   0.000000  0.000000  0.000000  0.000000  0.987200\n",
      "total        0.311329  0.354114  0.392971  0.329814  0.982486\n",
      "total(-bg)   0.203450  0.250000  0.295517  0.221450  0.985700\n",
      "\n",
      "Epoch: [238][0/16]\tTime 0.477 (0.477)\tETA 0:00:07\tTraining Loss 1.1816 (1.1816)\n",
      "\n",
      "Epoch: [238][1/16]\tTime 0.178 (0.655)\tETA 0:00:02\tTraining Loss 1.1833 (1.1824)\n",
      "\n",
      "Epoch: [238][2/16]\tTime 0.187 (0.842)\tETA 0:00:02\tTraining Loss 1.1836 (1.1828)\n",
      "\n",
      "Epoch: [238][3/16]\tTime 0.181 (1.023)\tETA 0:00:02\tTraining Loss 1.1826 (1.1828)\n",
      "\n",
      "Epoch: [238][4/16]\tTime 0.183 (1.205)\tETA 0:00:02\tTraining Loss 1.1834 (1.1829)\n",
      "\n",
      "Epoch: [238][5/16]\tTime 0.183 (1.389)\tETA 0:00:02\tTraining Loss 1.1805 (1.1825)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: [238][6/16]\tTime 0.180 (1.569)\tETA 0:00:01\tTraining Loss 1.1808 (1.1823)\n",
      "\n",
      "Epoch: [238][7/16]\tTime 0.185 (1.754)\tETA 0:00:01\tTraining Loss 1.1824 (1.1823)\n",
      "\n",
      "Epoch: [238][8/16]\tTime 0.183 (1.937)\tETA 0:00:01\tTraining Loss 1.1809 (1.1821)\n",
      "\n",
      "Epoch: [238][9/16]\tTime 0.185 (2.122)\tETA 0:00:01\tTraining Loss 1.1816 (1.1821)\n",
      "\n",
      "Epoch: [238][10/16]\tTime 0.184 (2.306)\tETA 0:00:01\tTraining Loss 1.1843 (1.1823)\n",
      "\n",
      "Epoch: [238][11/16]\tTime 0.182 (2.488)\tETA 0:00:00\tTraining Loss 1.1827 (1.1823)\n",
      "\n",
      "Epoch: [238][12/16]\tTime 0.182 (2.670)\tETA 0:00:00\tTraining Loss 1.1821 (1.1823)\n",
      "\n",
      "Epoch: [238][13/16]\tTime 0.183 (2.853)\tETA 0:00:00\tTraining Loss 1.1823 (1.1823)\n",
      "\n",
      "Epoch: [238][14/16]\tTime 0.182 (3.035)\tETA 0:00:00\tTraining Loss 1.1815 (1.1822)\n",
      "\n",
      "Epoch: [238][15/16]\tTime 0.115 (3.150)\tETA 0:00:00\tTraining Loss 1.1820 (1.1822)\n",
      "_\n",
      "Validation stats                    IoU        F1      Prec    recall       Acc\n",
      "bg,          0.952900  0.975800  0.978500  0.973200  0.958100\n",
      "real apple   0.505300  0.671300  0.845400  0.556800  0.964200\n",
      "real pepper  0.000000  0.000000  0.000000  0.000000  1.000000\n",
      "real grape   0.769700  0.869800  0.894500  0.846500  0.983600\n",
      "fake apple   0.000000  0.000000  0.000000  0.000000  0.986000\n",
      "fake pepper  0.000000  0.000000  0.000000  0.000000  0.995200\n",
      "fake grape   0.000000  0.000000  0.000000  0.000000  0.988200\n",
      "total        0.318271  0.359557  0.388343  0.339500  0.982186\n",
      "total(-bg)   0.212500  0.256850  0.289983  0.233883  0.986200\n",
      "\n",
      "Epoch: [239][0/16]\tTime 0.514 (0.514)\tETA 0:00:08\tTraining Loss 1.1823 (1.1823)\n",
      "\n",
      "Epoch: [239][1/16]\tTime 0.189 (0.703)\tETA 0:00:02\tTraining Loss 1.1821 (1.1822)\n",
      "\n",
      "Epoch: [239][2/16]\tTime 0.182 (0.885)\tETA 0:00:02\tTraining Loss 1.1811 (1.1818)\n",
      "\n",
      "Epoch: [239][3/16]\tTime 0.187 (1.073)\tETA 0:00:02\tTraining Loss 1.1826 (1.1820)\n",
      "\n",
      "Epoch: [239][4/16]\tTime 0.190 (1.262)\tETA 0:00:02\tTraining Loss 1.1832 (1.1823)\n",
      "\n",
      "Epoch: [239][5/16]\tTime 0.182 (1.445)\tETA 0:00:02\tTraining Loss 1.1815 (1.1821)\n",
      "\n",
      "Epoch: [239][6/16]\tTime 0.189 (1.634)\tETA 0:00:01\tTraining Loss 1.1880 (1.1830)\n",
      "\n",
      "Epoch: [239][7/16]\tTime 0.191 (1.825)\tETA 0:00:01\tTraining Loss 1.1818 (1.1828)\n",
      "\n",
      "Epoch: [239][8/16]\tTime 0.182 (2.007)\tETA 0:00:01\tTraining Loss 1.1825 (1.1828)\n",
      "\n",
      "Epoch: [239][9/16]\tTime 0.197 (2.203)\tETA 0:00:01\tTraining Loss 1.1807 (1.1826)\n",
      "\n",
      "Epoch: [239][10/16]\tTime 0.290 (2.494)\tETA 0:00:01\tTraining Loss 1.1823 (1.1826)\n",
      "\n",
      "Epoch: [239][11/16]\tTime 0.192 (2.686)\tETA 0:00:00\tTraining Loss 1.1806 (1.1824)\n",
      "\n",
      "Epoch: [239][12/16]\tTime 0.193 (2.879)\tETA 0:00:00\tTraining Loss 1.1818 (1.1824)\n",
      "\n",
      "Epoch: [239][13/16]\tTime 0.182 (3.061)\tETA 0:00:00\tTraining Loss 1.1807 (1.1822)\n",
      "\n",
      "Epoch: [239][14/16]\tTime 0.184 (3.245)\tETA 0:00:00\tTraining Loss 1.1834 (1.1823)\n",
      "\n",
      "Epoch: [239][15/16]\tTime 0.112 (3.357)\tETA 0:00:00\tTraining Loss 1.1813 (1.1823)\n",
      "_\n",
      "Validation stats                    IoU        F1      Prec    recall       Acc\n",
      "bg,          0.954700  0.976800  0.977600  0.976100  0.959800\n",
      "real apple   0.297800  0.458800  0.766400  0.327500  0.949200\n",
      "real pepper  0.000000  0.000000  0.000000  0.000000  1.000000\n",
      "real grape   0.764900  0.866800  0.871300  0.862400  0.982800\n",
      "fake apple   0.000000  0.000000  0.000000  0.000000  0.971900\n",
      "fake pepper  0.000000  0.000000  0.000000  0.000000  0.998200\n",
      "fake grape   0.000000  0.000000  0.000000  0.000000  0.990300\n",
      "total        0.288200  0.328914  0.373614  0.309429  0.978886\n",
      "total(-bg)   0.177117  0.220933  0.272950  0.198317  0.982067\n",
      "\n",
      "Epoch: [240][0/16]\tTime 0.461 (0.461)\tETA 0:00:07\tTraining Loss 1.1824 (1.1824)\n",
      "\n",
      "Epoch: [240][1/16]\tTime 0.174 (0.635)\tETA 0:00:02\tTraining Loss 1.1829 (1.1827)\n",
      "\n",
      "Epoch: [240][2/16]\tTime 0.192 (0.827)\tETA 0:00:02\tTraining Loss 1.1820 (1.1824)\n",
      "\n",
      "Epoch: [240][3/16]\tTime 0.182 (1.009)\tETA 0:00:02\tTraining Loss 1.1842 (1.1829)\n",
      "\n",
      "Epoch: [240][4/16]\tTime 0.192 (1.201)\tETA 0:00:02\tTraining Loss 1.1813 (1.1826)\n",
      "\n",
      "Epoch: [240][5/16]\tTime 0.197 (1.398)\tETA 0:00:02\tTraining Loss 1.1874 (1.1834)\n",
      "\n",
      "Epoch: [240][6/16]\tTime 0.180 (1.578)\tETA 0:00:01\tTraining Loss 1.1812 (1.1831)\n",
      "\n",
      "Epoch: [240][7/16]\tTime 0.183 (1.761)\tETA 0:00:01\tTraining Loss 1.1813 (1.1828)\n",
      "\n",
      "Epoch: [240][8/16]\tTime 0.184 (1.945)\tETA 0:00:01\tTraining Loss 1.1810 (1.1826)\n",
      "\n",
      "Epoch: [240][9/16]\tTime 0.188 (2.133)\tETA 0:00:01\tTraining Loss 1.1925 (1.1836)\n",
      "\n",
      "Epoch: [240][10/16]\tTime 0.193 (2.325)\tETA 0:00:01\tTraining Loss 1.1814 (1.1834)\n",
      "\n",
      "Epoch: [240][11/16]\tTime 0.188 (2.513)\tETA 0:00:00\tTraining Loss 1.1868 (1.1837)\n",
      "\n",
      "Epoch: [240][12/16]\tTime 0.192 (2.705)\tETA 0:00:00\tTraining Loss 1.1971 (1.1847)\n",
      "\n",
      "Epoch: [240][13/16]\tTime 0.182 (2.887)\tETA 0:00:00\tTraining Loss 1.1910 (1.1852)\n",
      "\n",
      "Epoch: [240][14/16]\tTime 0.191 (3.078)\tETA 0:00:00\tTraining Loss 1.1837 (1.1851)\n",
      "\n",
      "Epoch: [240][15/16]\tTime 0.113 (3.191)\tETA 0:00:00\tTraining Loss 1.1878 (1.1852)\n",
      "_\n",
      "Validation stats                    IoU        F1      Prec    recall       Acc\n",
      "bg,          0.941300  0.969700  0.978400  0.961300  0.947900\n",
      "real apple   0.502800  0.669100  0.819700  0.565400  0.963300\n",
      "real pepper  0.000000  0.000000  0.000000  0.000000  0.999700\n",
      "real grape   0.624500  0.768800  0.910400  0.665400  0.974100\n",
      "fake apple   0.000000  0.000000  0.000000  0.000000  0.990300\n",
      "fake pepper  0.000000  0.000000  0.000000  0.000000  0.991300\n",
      "fake grape   0.000000  0.000000  0.000000  0.000000  0.965600\n",
      "total        0.295514  0.343943  0.386929  0.313157  0.976029\n",
      "total(-bg)   0.187883  0.239650  0.288350  0.205133  0.980717\n",
      "\n",
      "Epoch: [241][0/16]\tTime 0.458 (0.458)\tETA 0:00:07\tTraining Loss 1.1974 (1.1974)\n",
      "\n",
      "Epoch: [241][1/16]\tTime 0.180 (0.638)\tETA 0:00:02\tTraining Loss 1.1908 (1.1941)\n",
      "\n",
      "Epoch: [241][2/16]\tTime 0.181 (0.818)\tETA 0:00:02\tTraining Loss 1.1864 (1.1915)\n",
      "\n",
      "Epoch: [241][3/16]\tTime 0.186 (1.004)\tETA 0:00:02\tTraining Loss 1.1881 (1.1907)\n",
      "\n",
      "Epoch: [241][4/16]\tTime 0.194 (1.199)\tETA 0:00:02\tTraining Loss 1.1879 (1.1901)\n",
      "\n",
      "Epoch: [241][5/16]\tTime 0.181 (1.380)\tETA 0:00:01\tTraining Loss 1.1939 (1.1907)\n",
      "\n",
      "Epoch: [241][6/16]\tTime 0.187 (1.567)\tETA 0:00:01\tTraining Loss 1.1859 (1.1901)\n",
      "\n",
      "Epoch: [241][7/16]\tTime 0.188 (1.755)\tETA 0:00:01\tTraining Loss 1.1881 (1.1898)\n",
      "\n",
      "Epoch: [241][8/16]\tTime 0.180 (1.935)\tETA 0:00:01\tTraining Loss 1.1891 (1.1897)\n",
      "\n",
      "Epoch: [241][9/16]\tTime 0.197 (2.132)\tETA 0:00:01\tTraining Loss 1.1905 (1.1898)\n",
      "\n",
      "Epoch: [241][10/16]\tTime 0.187 (2.319)\tETA 0:00:01\tTraining Loss 1.1919 (1.1900)\n",
      "\n",
      "Epoch: [241][11/16]\tTime 0.193 (2.512)\tETA 0:00:00\tTraining Loss 1.1870 (1.1897)\n",
      "\n",
      "Epoch: [241][12/16]\tTime 0.191 (2.704)\tETA 0:00:00\tTraining Loss 1.1880 (1.1896)\n",
      "\n",
      "Epoch: [241][13/16]\tTime 0.185 (2.888)\tETA 0:00:00\tTraining Loss 1.2114 (1.1912)\n",
      "\n",
      "Epoch: [241][14/16]\tTime 0.187 (3.075)\tETA 0:00:00\tTraining Loss 1.1867 (1.1909)\n",
      "\n",
      "Epoch: [241][15/16]\tTime 0.113 (3.188)\tETA 0:00:00\tTraining Loss 1.2091 (1.1915)\n",
      "_\n",
      "Validation stats                    IoU        F1      Prec    recall       Acc\n",
      "bg,          0.945200  0.971800  0.973800  0.969900  0.951100\n",
      "real apple   0.334200  0.501000  0.878900  0.350400  0.954100\n",
      "real pepper  0.000000  0.000000  0.000000  0.000000  1.000000\n",
      "real grape   0.220700  0.361600  0.910600  0.225600  0.948400\n",
      "fake apple   0.000000  0.000000  0.000000  0.000000  0.991800\n",
      "fake pepper  0.000000  0.000000  0.000000  0.000000  0.974900\n",
      "fake grape   0.000000  0.000000  0.000000  0.000000  0.941700\n",
      "total        0.214300  0.262057  0.394757  0.220843  0.966000\n",
      "total(-bg)   0.092483  0.143767  0.298250  0.096000  0.968483\n",
      "\n",
      "Epoch: [242][0/16]\tTime 0.382 (0.382)\tETA 0:00:06\tTraining Loss 1.1982 (1.1982)\n",
      "\n",
      "Epoch: [242][1/16]\tTime 0.178 (0.560)\tETA 0:00:02\tTraining Loss 1.1996 (1.1989)\n",
      "\n",
      "Epoch: [242][2/16]\tTime 0.184 (0.743)\tETA 0:00:02\tTraining Loss 1.1937 (1.1972)\n",
      "\n",
      "Epoch: [242][3/16]\tTime 0.188 (0.931)\tETA 0:00:02\tTraining Loss 1.2022 (1.1984)\n",
      "\n",
      "Epoch: [242][4/16]\tTime 0.191 (1.122)\tETA 0:00:02\tTraining Loss 1.1985 (1.1985)\n",
      "\n",
      "Epoch: [242][5/16]\tTime 0.184 (1.306)\tETA 0:00:02\tTraining Loss 1.2007 (1.1988)\n",
      "\n",
      "Epoch: [242][6/16]\tTime 0.184 (1.490)\tETA 0:00:01\tTraining Loss 1.2206 (1.2019)\n",
      "\n",
      "Epoch: [242][7/16]\tTime 0.194 (1.684)\tETA 0:00:01\tTraining Loss 1.2022 (1.2020)\n",
      "\n",
      "Epoch: [242][8/16]\tTime 0.192 (1.876)\tETA 0:00:01\tTraining Loss 1.1948 (1.2012)\n",
      "\n",
      "Epoch: [242][9/16]\tTime 0.184 (2.060)\tETA 0:00:01\tTraining Loss 1.2055 (1.2016)\n",
      "\n",
      "Epoch: [242][10/16]\tTime 0.183 (2.243)\tETA 0:00:01\tTraining Loss 1.2151 (1.2028)\n",
      "\n",
      "Epoch: [242][11/16]\tTime 0.191 (2.434)\tETA 0:00:00\tTraining Loss 1.2180 (1.2041)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: [242][12/16]\tTime 0.187 (2.621)\tETA 0:00:00\tTraining Loss 1.2024 (1.2040)\n",
      "\n",
      "Epoch: [242][13/16]\tTime 0.182 (2.803)\tETA 0:00:00\tTraining Loss 1.2094 (1.2043)\n",
      "\n",
      "Epoch: [242][14/16]\tTime 0.183 (2.986)\tETA 0:00:00\tTraining Loss 1.2158 (1.2051)\n",
      "\n",
      "Epoch: [242][15/16]\tTime 0.128 (3.114)\tETA 0:00:00\tTraining Loss 1.2171 (1.2055)\n",
      "_\n",
      "Validation stats                    IoU        F1      Prec    recall       Acc\n",
      "bg,          0.953900  0.976300  0.976000  0.976800  0.958900\n",
      "real apple   0.606100  0.754700  0.909500  0.645000  0.972500\n",
      "real pepper  0.000000  0.000000  0.000000  0.000000  0.990300\n",
      "real grape   0.636900  0.778100  0.870200  0.703800  0.974000\n",
      "fake apple   0.000000  0.000000  0.000000  0.000000  0.983900\n",
      "fake pepper  0.000000  0.000000  0.000000  0.000000  0.996100\n",
      "fake grape   0.000000  0.000000  0.000000  0.000000  0.998900\n",
      "total        0.313843  0.358443  0.393671  0.332229  0.982086\n",
      "total(-bg)   0.207167  0.255467  0.296617  0.224800  0.985950\n",
      "\n",
      "Epoch: [243][0/16]\tTime 0.361 (0.361)\tETA 0:00:05\tTraining Loss 1.2033 (1.2033)\n",
      "\n",
      "Epoch: [243][1/16]\tTime 0.187 (0.548)\tETA 0:00:02\tTraining Loss 1.2073 (1.2053)\n",
      "\n",
      "Epoch: [243][2/16]\tTime 0.187 (0.735)\tETA 0:00:02\tTraining Loss 1.2019 (1.2041)\n",
      "\n",
      "Epoch: [243][3/16]\tTime 0.192 (0.927)\tETA 0:00:02\tTraining Loss 1.1997 (1.2030)\n",
      "\n",
      "Epoch: [243][4/16]\tTime 0.189 (1.116)\tETA 0:00:02\tTraining Loss 1.2189 (1.2062)\n",
      "\n",
      "Epoch: [243][5/16]\tTime 0.183 (1.299)\tETA 0:00:02\tTraining Loss 1.1976 (1.2048)\n",
      "\n",
      "Epoch: [243][6/16]\tTime 0.185 (1.484)\tETA 0:00:01\tTraining Loss 1.1969 (1.2036)\n",
      "\n",
      "Epoch: [243][7/16]\tTime 0.188 (1.671)\tETA 0:00:01\tTraining Loss 1.1989 (1.2031)\n",
      "\n",
      "Epoch: [243][8/16]\tTime 0.189 (1.860)\tETA 0:00:01\tTraining Loss 1.2152 (1.2044)\n",
      "\n",
      "Epoch: [243][9/16]\tTime 0.190 (2.050)\tETA 0:00:01\tTraining Loss 1.2096 (1.2049)\n",
      "\n",
      "Epoch: [243][10/16]\tTime 0.189 (2.240)\tETA 0:00:01\tTraining Loss 1.2041 (1.2048)\n",
      "\n",
      "Epoch: [243][11/16]\tTime 0.293 (2.533)\tETA 0:00:01\tTraining Loss 1.1953 (1.2041)\n",
      "\n",
      "Epoch: [243][12/16]\tTime 0.197 (2.730)\tETA 0:00:00\tTraining Loss 1.1935 (1.2032)\n",
      "\n",
      "Epoch: [243][13/16]\tTime 0.185 (2.916)\tETA 0:00:00\tTraining Loss 1.2078 (1.2036)\n",
      "\n",
      "Epoch: [243][14/16]\tTime 0.185 (3.101)\tETA 0:00:00\tTraining Loss 1.2002 (1.2033)\n",
      "\n",
      "Epoch: [243][15/16]\tTime 0.117 (3.218)\tETA 0:00:00\tTraining Loss 1.1956 (1.2031)\n",
      "_\n",
      "Validation stats                    IoU        F1    Prec    recall       Acc\n",
      "bg,          0.923600  0.960200  0.9740  0.946900  0.931900\n",
      "real apple   0.259600  0.412100  0.8677  0.270300  0.949300\n",
      "real pepper  0.000000  0.000000  0.0000  0.000000  0.995300\n",
      "real grape   0.723300  0.839400  0.9149  0.775400  0.980800\n",
      "fake apple   0.000000  0.000000  0.0000  0.000000  0.970800\n",
      "fake pepper  0.000000  0.000000  0.0000  0.000000  0.993500\n",
      "fake grape   0.000000  0.000000  0.0000  0.000000  0.961100\n",
      "total        0.272357  0.315957  0.3938  0.284657  0.968957\n",
      "total(-bg)   0.163817  0.208583  0.2971  0.174283  0.975133\n",
      "\n",
      "Epoch: [244][0/16]\tTime 0.500 (0.500)\tETA 0:00:07\tTraining Loss 1.1981 (1.1981)\n",
      "\n",
      "Epoch: [244][1/16]\tTime 0.180 (0.680)\tETA 0:00:02\tTraining Loss 1.2016 (1.1999)\n",
      "\n",
      "Epoch: [244][2/16]\tTime 0.188 (0.867)\tETA 0:00:02\tTraining Loss 1.1925 (1.1974)\n",
      "\n",
      "Epoch: [244][3/16]\tTime 0.190 (1.057)\tETA 0:00:02\tTraining Loss 1.2005 (1.1982)\n",
      "\n",
      "Epoch: [244][4/16]\tTime 0.188 (1.245)\tETA 0:00:02\tTraining Loss 1.2112 (1.2008)\n",
      "\n",
      "Epoch: [244][5/16]\tTime 0.185 (1.429)\tETA 0:00:02\tTraining Loss 1.1944 (1.1997)\n",
      "\n",
      "Epoch: [244][6/16]\tTime 0.190 (1.619)\tETA 0:00:01\tTraining Loss 1.2118 (1.2014)\n",
      "\n",
      "Epoch: [244][7/16]\tTime 0.186 (1.805)\tETA 0:00:01\tTraining Loss 1.1922 (1.2003)\n",
      "\n",
      "Epoch: [244][8/16]\tTime 0.195 (2.000)\tETA 0:00:01\tTraining Loss 1.1953 (1.1997)\n",
      "\n",
      "Epoch: [244][9/16]\tTime 0.186 (2.186)\tETA 0:00:01\tTraining Loss 1.1953 (1.1993)\n",
      "\n",
      "Epoch: [244][10/16]\tTime 0.187 (2.373)\tETA 0:00:01\tTraining Loss 1.1999 (1.1993)\n",
      "\n",
      "Epoch: [244][11/16]\tTime 0.188 (2.561)\tETA 0:00:00\tTraining Loss 1.1948 (1.1990)\n",
      "\n",
      "Epoch: [244][12/16]\tTime 0.186 (2.748)\tETA 0:00:00\tTraining Loss 1.1939 (1.1986)\n",
      "\n",
      "Epoch: [244][13/16]\tTime 0.183 (2.930)\tETA 0:00:00\tTraining Loss 1.1967 (1.1984)\n",
      "\n",
      "Epoch: [244][14/16]\tTime 0.190 (3.120)\tETA 0:00:00\tTraining Loss 1.2002 (1.1985)\n",
      "\n",
      "Epoch: [244][15/16]\tTime 0.116 (3.236)\tETA 0:00:00\tTraining Loss 1.1874 (1.1982)\n",
      "_\n",
      "Validation stats                    IoU        F1      Prec    recall       Acc\n",
      "bg,          0.938300  0.968100  0.977400  0.959100  0.945200\n",
      "real apple   0.518700  0.683000  0.825100  0.582800  0.964500\n",
      "real pepper  0.000000  0.000000  0.000000  0.000000  0.999600\n",
      "real grape   0.717400  0.835400  0.871500  0.802300  0.979500\n",
      "fake apple   0.000000  0.000000  0.000000  0.000000  0.989500\n",
      "fake pepper  0.000000  0.000000  0.000000  0.000000  0.985100\n",
      "fake grape   0.000000  0.000000  0.000000  0.000000  0.985000\n",
      "total        0.310629  0.355214  0.382000  0.334886  0.978343\n",
      "total(-bg)   0.206017  0.253067  0.282767  0.230850  0.983867\n",
      "\n",
      "Epoch: [245][0/16]\tTime 0.461 (0.461)\tETA 0:00:07\tTraining Loss 1.1979 (1.1979)\n",
      "\n",
      "Epoch: [245][1/16]\tTime 0.180 (0.640)\tETA 0:00:02\tTraining Loss 1.1888 (1.1934)\n",
      "\n",
      "Epoch: [245][2/16]\tTime 0.186 (0.826)\tETA 0:00:02\tTraining Loss 1.1911 (1.1926)\n",
      "\n",
      "Epoch: [245][3/16]\tTime 0.188 (1.014)\tETA 0:00:02\tTraining Loss 1.1906 (1.1921)\n",
      "\n",
      "Epoch: [245][4/16]\tTime 0.184 (1.199)\tETA 0:00:02\tTraining Loss 1.1934 (1.1924)\n",
      "\n",
      "Epoch: [245][5/16]\tTime 0.181 (1.380)\tETA 0:00:01\tTraining Loss 1.1988 (1.1934)\n",
      "\n",
      "Epoch: [245][6/16]\tTime 0.193 (1.573)\tETA 0:00:01\tTraining Loss 1.1962 (1.1938)\n",
      "\n",
      "Epoch: [245][7/16]\tTime 0.187 (1.760)\tETA 0:00:01\tTraining Loss 1.1917 (1.1936)\n",
      "\n",
      "Epoch: [245][8/16]\tTime 0.187 (1.947)\tETA 0:00:01\tTraining Loss 1.1951 (1.1937)\n",
      "\n",
      "Epoch: [245][9/16]\tTime 0.188 (2.134)\tETA 0:00:01\tTraining Loss 1.1909 (1.1935)\n",
      "\n",
      "Epoch: [245][10/16]\tTime 0.198 (2.332)\tETA 0:00:01\tTraining Loss 1.1909 (1.1932)\n",
      "\n",
      "Epoch: [245][11/16]\tTime 0.185 (2.517)\tETA 0:00:00\tTraining Loss 1.1873 (1.1927)\n",
      "\n",
      "Epoch: [245][12/16]\tTime 0.188 (2.705)\tETA 0:00:00\tTraining Loss 1.1904 (1.1925)\n",
      "\n",
      "Epoch: [245][13/16]\tTime 0.193 (2.898)\tETA 0:00:00\tTraining Loss 1.1990 (1.1930)\n",
      "\n",
      "Epoch: [245][14/16]\tTime 0.183 (3.081)\tETA 0:00:00\tTraining Loss 1.1968 (1.1933)\n",
      "\n",
      "Epoch: [245][15/16]\tTime 0.117 (3.198)\tETA 0:00:00\tTraining Loss 1.1945 (1.1933)\n",
      "_\n",
      "Validation stats                    IoU        F1      Prec    recall       Acc\n",
      "bg,          0.958000  0.978500  0.977900  0.979200  0.962700\n",
      "real apple   0.441300  0.612300  0.864300  0.474100  0.960500\n",
      "real pepper  0.000000  0.000000  0.000000  0.000000  0.998500\n",
      "real grape   0.416000  0.587500  0.842600  0.451000  0.959000\n",
      "fake apple   0.000000  0.000000  0.000000  0.000000  0.983200\n",
      "fake pepper  0.000000  0.000000  0.000000  0.000000  0.996900\n",
      "fake grape   0.000000  0.000000  0.000000  0.000000  0.962800\n",
      "total        0.259329  0.311186  0.383543  0.272043  0.974800\n",
      "total(-bg)   0.142883  0.199967  0.284483  0.154183  0.976817\n",
      "\n",
      "Epoch: [246][0/16]\tTime 0.526 (0.526)\tETA 0:00:08\tTraining Loss 1.1898 (1.1898)\n",
      "\n",
      "Epoch: [246][1/16]\tTime 0.186 (0.713)\tETA 0:00:02\tTraining Loss 1.1842 (1.1870)\n",
      "\n",
      "Epoch: [246][2/16]\tTime 0.194 (0.907)\tETA 0:00:02\tTraining Loss 1.1944 (1.1895)\n",
      "\n",
      "Epoch: [246][3/16]\tTime 0.190 (1.097)\tETA 0:00:02\tTraining Loss 1.1873 (1.1889)\n",
      "\n",
      "Epoch: [246][4/16]\tTime 0.196 (1.292)\tETA 0:00:02\tTraining Loss 1.1876 (1.1887)\n",
      "\n",
      "Epoch: [246][5/16]\tTime 0.193 (1.485)\tETA 0:00:02\tTraining Loss 1.1912 (1.1891)\n",
      "\n",
      "Epoch: [246][6/16]\tTime 0.189 (1.674)\tETA 0:00:01\tTraining Loss 1.1863 (1.1887)\n",
      "\n",
      "Epoch: [246][7/16]\tTime 0.191 (1.865)\tETA 0:00:01\tTraining Loss 1.1873 (1.1885)\n",
      "\n",
      "Epoch: [246][8/16]\tTime 0.189 (2.054)\tETA 0:00:01\tTraining Loss 1.1879 (1.1884)\n",
      "\n",
      "Epoch: [246][9/16]\tTime 0.196 (2.249)\tETA 0:00:01\tTraining Loss 1.1860 (1.1882)\n",
      "\n",
      "Epoch: [246][10/16]\tTime 0.190 (2.440)\tETA 0:00:01\tTraining Loss 1.1911 (1.1885)\n",
      "\n",
      "Epoch: [246][11/16]\tTime 0.211 (2.651)\tETA 0:00:01\tTraining Loss 1.1897 (1.1886)\n",
      "\n",
      "Epoch: [246][12/16]\tTime 0.183 (2.834)\tETA 0:00:00\tTraining Loss 1.1854 (1.1883)\n",
      "\n",
      "Epoch: [246][13/16]\tTime 0.189 (3.023)\tETA 0:00:00\tTraining Loss 1.1852 (1.1881)\n",
      "\n",
      "Epoch: [246][14/16]\tTime 0.187 (3.210)\tETA 0:00:00\tTraining Loss 1.1851 (1.1879)\n",
      "\n",
      "Epoch: [246][15/16]\tTime 0.115 (3.325)\tETA 0:00:00\tTraining Loss 1.1962 (1.1882)\n",
      "_\n",
      "Validation stats                    IoU        F1      Prec    recall       Acc\n",
      "bg,          0.953900  0.976400  0.978800  0.974100  0.959100\n",
      "real apple   0.476900  0.645800  0.879900  0.510100  0.963200\n",
      "real pepper  0.000000  0.000000  0.000000  0.000000  1.000000\n",
      "real grape   0.630200  0.773100  0.839300  0.716700  0.972800\n",
      "fake apple   0.000000  0.000000  0.000000  0.000000  0.976500\n",
      "fake pepper  0.000000  0.000000  0.000000  0.000000  0.994900\n",
      "fake grape   0.000000  0.000000  0.000000  0.000000  0.987400\n",
      "total        0.294429  0.342186  0.385429  0.314414  0.979129\n",
      "total(-bg)   0.184517  0.236483  0.286533  0.204467  0.982467\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: [247][0/16]\tTime 0.382 (0.382)\tETA 0:00:06\tTraining Loss 1.1833 (1.1833)\n",
      "\n",
      "Epoch: [247][1/16]\tTime 0.191 (0.572)\tETA 0:00:02\tTraining Loss 1.1842 (1.1837)\n",
      "\n",
      "Epoch: [247][2/16]\tTime 0.188 (0.761)\tETA 0:00:02\tTraining Loss 1.1858 (1.1844)\n",
      "\n",
      "Epoch: [247][3/16]\tTime 0.203 (0.963)\tETA 0:00:02\tTraining Loss 1.1856 (1.1847)\n",
      "\n",
      "Epoch: [247][4/16]\tTime 0.176 (1.140)\tETA 0:00:02\tTraining Loss 1.1850 (1.1848)\n",
      "\n",
      "Epoch: [247][5/16]\tTime 0.188 (1.328)\tETA 0:00:02\tTraining Loss 1.1856 (1.1849)\n",
      "\n",
      "Epoch: [247][6/16]\tTime 0.186 (1.514)\tETA 0:00:01\tTraining Loss 1.1976 (1.1867)\n",
      "\n",
      "Epoch: [247][7/16]\tTime 0.190 (1.705)\tETA 0:00:01\tTraining Loss 1.1865 (1.1867)\n",
      "\n",
      "Epoch: [247][8/16]\tTime 0.185 (1.890)\tETA 0:00:01\tTraining Loss 1.1933 (1.1874)\n",
      "\n",
      "Epoch: [247][9/16]\tTime 0.191 (2.081)\tETA 0:00:01\tTraining Loss 1.1896 (1.1877)\n",
      "\n",
      "Epoch: [247][10/16]\tTime 0.201 (2.281)\tETA 0:00:01\tTraining Loss 1.1859 (1.1875)\n",
      "\n",
      "Epoch: [247][11/16]\tTime 0.192 (2.473)\tETA 0:00:00\tTraining Loss 1.1887 (1.1876)\n",
      "\n",
      "Epoch: [247][12/16]\tTime 0.184 (2.657)\tETA 0:00:00\tTraining Loss 1.1901 (1.1878)\n",
      "\n",
      "Epoch: [247][13/16]\tTime 0.186 (2.844)\tETA 0:00:00\tTraining Loss 1.1849 (1.1876)\n",
      "\n",
      "Epoch: [247][14/16]\tTime 0.181 (3.025)\tETA 0:00:00\tTraining Loss 1.1855 (1.1874)\n",
      "\n",
      "Epoch: [247][15/16]\tTime 0.116 (3.141)\tETA 0:00:00\tTraining Loss 1.1851 (1.1874)\n",
      "_\n",
      "Validation stats                    IoU        F1      Prec    recall       Acc\n",
      "bg,          0.951800  0.975300  0.977200  0.973500  0.957200\n",
      "real apple   0.455000  0.625400  0.887200  0.482900  0.962000\n",
      "real pepper  0.000000  0.000000  0.000000  0.000000  0.999900\n",
      "real grape   0.600700  0.750500  0.886800  0.650600  0.972000\n",
      "fake apple   0.000000  0.000000  0.000000  0.000000  0.981900\n",
      "fake pepper  0.000000  0.000000  0.000000  0.000000  0.996200\n",
      "fake grape   0.000000  0.000000  0.000000  0.000000  0.971600\n",
      "total        0.286786  0.335886  0.393029  0.301000  0.977257\n",
      "total(-bg)   0.175950  0.229317  0.295667  0.188917  0.980600\n",
      "\n",
      "Epoch: [248][0/16]\tTime 0.474 (0.474)\tETA 0:00:07\tTraining Loss 1.1842 (1.1842)\n",
      "\n",
      "Epoch: [248][1/16]\tTime 0.193 (0.666)\tETA 0:00:02\tTraining Loss 1.1828 (1.1835)\n",
      "\n",
      "Epoch: [248][2/16]\tTime 0.181 (0.847)\tETA 0:00:02\tTraining Loss 1.1865 (1.1845)\n",
      "\n",
      "Epoch: [248][3/16]\tTime 0.187 (1.034)\tETA 0:00:02\tTraining Loss 1.1831 (1.1841)\n",
      "\n",
      "Epoch: [248][4/16]\tTime 0.188 (1.222)\tETA 0:00:02\tTraining Loss 1.1895 (1.1852)\n",
      "\n",
      "Epoch: [248][5/16]\tTime 0.185 (1.407)\tETA 0:00:02\tTraining Loss 1.1823 (1.1847)\n",
      "\n",
      "Epoch: [248][6/16]\tTime 0.181 (1.588)\tETA 0:00:01\tTraining Loss 1.1834 (1.1845)\n",
      "\n",
      "Epoch: [248][7/16]\tTime 0.191 (1.779)\tETA 0:00:01\tTraining Loss 1.1834 (1.1844)\n",
      "\n",
      "Epoch: [248][8/16]\tTime 0.184 (1.963)\tETA 0:00:01\tTraining Loss 1.1840 (1.1844)\n",
      "\n",
      "Epoch: [248][9/16]\tTime 0.184 (2.147)\tETA 0:00:01\tTraining Loss 1.1826 (1.1842)\n",
      "\n",
      "Epoch: [248][10/16]\tTime 0.193 (2.340)\tETA 0:00:01\tTraining Loss 1.1827 (1.1840)\n",
      "\n",
      "Epoch: [248][11/16]\tTime 0.191 (2.532)\tETA 0:00:00\tTraining Loss 1.1832 (1.1840)\n",
      "\n",
      "Epoch: [248][12/16]\tTime 0.184 (2.715)\tETA 0:00:00\tTraining Loss 1.1836 (1.1839)\n",
      "\n",
      "Epoch: [248][13/16]\tTime 0.190 (2.905)\tETA 0:00:00\tTraining Loss 1.1821 (1.1838)\n",
      "\n",
      "Epoch: [248][14/16]\tTime 0.187 (3.092)\tETA 0:00:00\tTraining Loss 1.1823 (1.1837)\n",
      "\n",
      "Epoch: [248][15/16]\tTime 0.110 (3.202)\tETA 0:00:00\tTraining Loss 1.1844 (1.1837)\n",
      "_\n",
      "Validation stats                    IoU        F1      Prec    recall       Acc\n",
      "bg,          0.953100  0.975900  0.976400  0.975500  0.958200\n",
      "real apple   0.545300  0.705700  0.885700  0.586600  0.967900\n",
      "real pepper  0.000000  0.000000  0.000000  0.000000  1.000000\n",
      "real grape   0.404800  0.576300  0.814300  0.446000  0.957500\n",
      "fake apple   0.000000  0.000000  0.000000  0.000000  0.989900\n",
      "fake pepper  0.000000  0.000000  0.000000  0.000000  0.994600\n",
      "fake grape   0.000000  0.000000  0.000000  0.000000  0.963300\n",
      "total        0.271886  0.322557  0.382343  0.286871  0.975914\n",
      "total(-bg)   0.158350  0.213667  0.283333  0.172100  0.978867\n",
      "\n",
      "Epoch: [249][0/16]\tTime 0.519 (0.519)\tETA 0:00:08\tTraining Loss 1.1820 (1.1820)\n",
      "\n",
      "Epoch: [249][1/16]\tTime 0.191 (0.710)\tETA 0:00:02\tTraining Loss 1.1826 (1.1823)\n",
      "\n",
      "Epoch: [249][2/16]\tTime 0.190 (0.900)\tETA 0:00:02\tTraining Loss 1.1822 (1.1823)\n",
      "\n",
      "Epoch: [249][3/16]\tTime 0.184 (1.084)\tETA 0:00:02\tTraining Loss 1.1833 (1.1825)\n",
      "\n",
      "Epoch: [249][4/16]\tTime 0.202 (1.286)\tETA 0:00:02\tTraining Loss 1.1830 (1.1826)\n",
      "\n",
      "Epoch: [249][5/16]\tTime 0.187 (1.473)\tETA 0:00:02\tTraining Loss 1.1815 (1.1824)\n",
      "\n",
      "Epoch: [249][6/16]\tTime 0.193 (1.666)\tETA 0:00:01\tTraining Loss 1.1842 (1.1827)\n",
      "\n",
      "Epoch: [249][7/16]\tTime 0.193 (1.859)\tETA 0:00:01\tTraining Loss 1.1819 (1.1826)\n",
      "\n",
      "Epoch: [249][8/16]\tTime 0.196 (2.055)\tETA 0:00:01\tTraining Loss 1.1863 (1.1830)\n",
      "\n",
      "Epoch: [249][9/16]\tTime 0.186 (2.241)\tETA 0:00:01\tTraining Loss 1.1829 (1.1830)\n",
      "\n",
      "Epoch: [249][10/16]\tTime 0.188 (2.429)\tETA 0:00:01\tTraining Loss 1.1876 (1.1834)\n",
      "\n",
      "Epoch: [249][11/16]\tTime 0.192 (2.622)\tETA 0:00:00\tTraining Loss 1.1812 (1.1832)\n",
      "\n",
      "Epoch: [249][12/16]\tTime 0.193 (2.815)\tETA 0:00:00\tTraining Loss 1.1841 (1.1833)\n",
      "\n",
      "Epoch: [249][13/16]\tTime 0.202 (3.016)\tETA 0:00:00\tTraining Loss 1.1853 (1.1834)\n",
      "\n",
      "Epoch: [249][14/16]\tTime 0.196 (3.213)\tETA 0:00:00\tTraining Loss 1.1839 (1.1835)\n",
      "\n",
      "Epoch: [249][15/16]\tTime 0.115 (3.328)\tETA 0:00:00\tTraining Loss 1.1820 (1.1834)\n",
      "_\n",
      "Validation stats                    IoU        F1      Prec    recall       Acc\n",
      "bg,          0.960000  0.979600  0.977100  0.982100  0.964500\n",
      "real apple   0.390500  0.561600  0.971200  0.395100  0.959500\n",
      "real pepper  0.000000  0.000000  0.000000  0.000000  0.998300\n",
      "real grape   0.254600  0.405800  0.853700  0.266200  0.949500\n",
      "fake apple   0.000000  0.000000  0.000000  0.000000  0.971100\n",
      "fake pepper  0.000000  0.000000  0.000000  0.000000  1.000000\n",
      "fake grape   0.000000  0.000000  0.000000  0.000000  0.951500\n",
      "total        0.229300  0.278143  0.400286  0.234771  0.970629\n",
      "total(-bg)   0.107517  0.161233  0.304150  0.110217  0.971650\n",
      "\n",
      "Epoch: [250][0/16]\tTime 0.471 (0.471)\tETA 0:00:07\tTraining Loss 1.1892 (1.1892)\n",
      "\n",
      "Epoch: [250][1/16]\tTime 0.176 (0.646)\tETA 0:00:02\tTraining Loss 1.1834 (1.1863)\n",
      "\n",
      "Epoch: [250][2/16]\tTime 0.182 (0.828)\tETA 0:00:02\tTraining Loss 1.1832 (1.1853)\n",
      "\n",
      "Epoch: [250][3/16]\tTime 0.187 (1.015)\tETA 0:00:02\tTraining Loss 1.1831 (1.1847)\n",
      "\n",
      "Epoch: [250][4/16]\tTime 0.183 (1.198)\tETA 0:00:02\tTraining Loss 1.1833 (1.1845)\n",
      "\n",
      "Epoch: [250][5/16]\tTime 0.188 (1.386)\tETA 0:00:02\tTraining Loss 1.1842 (1.1844)\n",
      "\n",
      "Epoch: [250][6/16]\tTime 0.194 (1.580)\tETA 0:00:01\tTraining Loss 1.1808 (1.1839)\n",
      "\n",
      "Epoch: [250][7/16]\tTime 0.186 (1.766)\tETA 0:00:01\tTraining Loss 1.1813 (1.1836)\n",
      "\n",
      "Epoch: [250][8/16]\tTime 0.192 (1.958)\tETA 0:00:01\tTraining Loss 1.1838 (1.1836)\n",
      "\n",
      "Epoch: [250][9/16]\tTime 0.186 (2.143)\tETA 0:00:01\tTraining Loss 1.1817 (1.1834)\n",
      "\n",
      "Epoch: [250][10/16]\tTime 0.187 (2.330)\tETA 0:00:01\tTraining Loss 1.1846 (1.1835)\n",
      "\n",
      "Epoch: [250][11/16]\tTime 0.183 (2.513)\tETA 0:00:00\tTraining Loss 1.1820 (1.1834)\n",
      "\n",
      "Epoch: [250][12/16]\tTime 0.197 (2.711)\tETA 0:00:00\tTraining Loss 1.1812 (1.1832)\n",
      "\n",
      "Epoch: [250][13/16]\tTime 0.183 (2.893)\tETA 0:00:00\tTraining Loss 1.1803 (1.1830)\n",
      "\n",
      "Epoch: [250][14/16]\tTime 0.187 (3.080)\tETA 0:00:00\tTraining Loss 1.1821 (1.1829)\n",
      "\n",
      "Epoch: [250][15/16]\tTime 0.112 (3.191)\tETA 0:00:00\tTraining Loss 1.1801 (1.1828)\n",
      "_\n",
      "Validation stats                    IoU        F1      Prec    recall       Acc\n",
      "bg,          0.951300  0.975000  0.975800  0.974300  0.956600\n",
      "real apple   0.582900  0.736500  0.900200  0.623200  0.970700\n",
      "real pepper  0.000000  0.000000  0.000000  0.000000  1.000000\n",
      "real grape   0.597100  0.747700  0.909700  0.634700  0.972300\n",
      "fake apple   0.000000  0.000000  0.000000  0.000000  0.984900\n",
      "fake pepper  0.000000  0.000000  0.000000  0.000000  0.989700\n",
      "fake grape   0.000000  0.000000  0.000000  0.000000  0.984300\n",
      "total        0.304471  0.351314  0.397957  0.318886  0.979786\n",
      "total(-bg)   0.196667  0.247367  0.301650  0.209650  0.983650\n",
      "\n",
      "Epoch: [251][0/16]\tTime 0.499 (0.499)\tETA 0:00:07\tTraining Loss 1.1807 (1.1807)\n",
      "\n",
      "Epoch: [251][1/16]\tTime 0.171 (0.669)\tETA 0:00:02\tTraining Loss 1.1817 (1.1812)\n",
      "\n",
      "Epoch: [251][2/16]\tTime 0.182 (0.852)\tETA 0:00:02\tTraining Loss 1.1848 (1.1824)\n",
      "\n",
      "Epoch: [251][3/16]\tTime 0.186 (1.038)\tETA 0:00:02\tTraining Loss 1.1803 (1.1819)\n",
      "\n",
      "Epoch: [251][4/16]\tTime 0.186 (1.224)\tETA 0:00:02\tTraining Loss 1.1808 (1.1817)\n",
      "\n",
      "Epoch: [251][5/16]\tTime 0.184 (1.407)\tETA 0:00:02\tTraining Loss 1.1802 (1.1814)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: [251][6/16]\tTime 0.191 (1.599)\tETA 0:00:01\tTraining Loss 1.1809 (1.1814)\n",
      "\n",
      "Epoch: [251][7/16]\tTime 0.195 (1.794)\tETA 0:00:01\tTraining Loss 1.1871 (1.1821)\n",
      "\n",
      "Epoch: [251][8/16]\tTime 0.185 (1.978)\tETA 0:00:01\tTraining Loss 1.1811 (1.1820)\n",
      "\n",
      "Epoch: [251][9/16]\tTime 0.194 (2.172)\tETA 0:00:01\tTraining Loss 1.1799 (1.1818)\n",
      "\n",
      "Epoch: [251][10/16]\tTime 0.182 (2.354)\tETA 0:00:01\tTraining Loss 1.1815 (1.1817)\n",
      "\n",
      "Epoch: [251][11/16]\tTime 0.184 (2.538)\tETA 0:00:00\tTraining Loss 1.1837 (1.1819)\n",
      "\n",
      "Epoch: [251][12/16]\tTime 0.184 (2.722)\tETA 0:00:00\tTraining Loss 1.1798 (1.1817)\n",
      "\n",
      "Epoch: [251][13/16]\tTime 0.181 (2.903)\tETA 0:00:00\tTraining Loss 1.1797 (1.1816)\n",
      "\n",
      "Epoch: [251][14/16]\tTime 0.190 (3.094)\tETA 0:00:00\tTraining Loss 1.1927 (1.1823)\n",
      "\n",
      "Epoch: [251][15/16]\tTime 0.113 (3.207)\tETA 0:00:00\tTraining Loss 1.1833 (1.1824)\n",
      "_\n",
      "Validation stats                    IoU        F1      Prec    recall       Acc\n",
      "bg,          0.952500  0.975600  0.977000  0.974400  0.957800\n",
      "real apple   0.384700  0.555600  0.818900  0.420500  0.955800\n",
      "real pepper  0.000000  0.000000  0.000000  0.000000  1.000000\n",
      "real grape   0.606800  0.755300  0.882500  0.660200  0.972300\n",
      "fake apple   0.000000  0.000000  0.000000  0.000000  0.978400\n",
      "fake pepper  0.000000  0.000000  0.000000  0.000000  0.994800\n",
      "fake grape   0.000000  0.000000  0.000000  0.000000  0.976200\n",
      "total        0.277714  0.326643  0.382629  0.293586  0.976471\n",
      "total(-bg)   0.165250  0.218483  0.283567  0.180117  0.979583\n",
      "\n",
      "Epoch: [252][0/16]\tTime 0.473 (0.473)\tETA 0:00:07\tTraining Loss 1.1815 (1.1815)\n",
      "\n",
      "Epoch: [252][1/16]\tTime 0.189 (0.662)\tETA 0:00:02\tTraining Loss 1.1830 (1.1822)\n",
      "\n",
      "Epoch: [252][2/16]\tTime 0.183 (0.845)\tETA 0:00:02\tTraining Loss 1.1799 (1.1815)\n",
      "\n",
      "Epoch: [252][3/16]\tTime 0.188 (1.033)\tETA 0:00:02\tTraining Loss 1.1809 (1.1813)\n",
      "\n",
      "Epoch: [252][4/16]\tTime 0.182 (1.215)\tETA 0:00:02\tTraining Loss 1.1804 (1.1812)\n",
      "\n",
      "Epoch: [252][5/16]\tTime 0.182 (1.397)\tETA 0:00:02\tTraining Loss 1.1803 (1.1810)\n",
      "\n",
      "Epoch: [252][6/16]\tTime 0.187 (1.584)\tETA 0:00:01\tTraining Loss 1.1804 (1.1809)\n",
      "\n",
      "Epoch: [252][7/16]\tTime 0.186 (1.770)\tETA 0:00:01\tTraining Loss 1.1810 (1.1809)\n",
      "\n",
      "Epoch: [252][8/16]\tTime 0.187 (1.957)\tETA 0:00:01\tTraining Loss 1.1825 (1.1811)\n",
      "\n",
      "Epoch: [252][9/16]\tTime 0.186 (2.142)\tETA 0:00:01\tTraining Loss 1.1804 (1.1810)\n",
      "\n",
      "Epoch: [252][10/16]\tTime 0.186 (2.328)\tETA 0:00:01\tTraining Loss 1.1821 (1.1811)\n",
      "\n",
      "Epoch: [252][11/16]\tTime 0.188 (2.516)\tETA 0:00:00\tTraining Loss 1.1823 (1.1812)\n",
      "\n",
      "Epoch: [252][12/16]\tTime 0.190 (2.706)\tETA 0:00:00\tTraining Loss 1.1837 (1.1814)\n",
      "\n",
      "Epoch: [252][13/16]\tTime 0.178 (2.884)\tETA 0:00:00\tTraining Loss 1.1831 (1.1815)\n",
      "\n",
      "Epoch: [252][14/16]\tTime 0.192 (3.076)\tETA 0:00:00\tTraining Loss 1.1806 (1.1815)\n",
      "\n",
      "Epoch: [252][15/16]\tTime 0.115 (3.191)\tETA 0:00:00\tTraining Loss 1.1829 (1.1815)\n",
      "_\n",
      "Validation stats                    IoU        F1      Prec    recall       Acc\n",
      "bg,          0.955200  0.977000  0.978000  0.976200  0.960200\n",
      "real apple   0.489400  0.657100  0.874100  0.526500  0.963900\n",
      "real pepper  0.000000  0.000000  0.000000  0.000000  0.999700\n",
      "real grape   0.474300  0.643400  0.845500  0.519300  0.962700\n",
      "fake apple   0.000000  0.000000  0.000000  0.000000  0.983500\n",
      "fake pepper  0.000000  0.000000  0.000000  0.000000  0.996800\n",
      "fake grape   0.000000  0.000000  0.000000  0.000000  0.967200\n",
      "total        0.274129  0.325357  0.385371  0.288857  0.976286\n",
      "total(-bg)   0.160617  0.216750  0.286600  0.174300  0.978967\n",
      "\n",
      "Epoch: [253][0/16]\tTime 0.377 (0.377)\tETA 0:00:06\tTraining Loss 1.1803 (1.1803)\n",
      "\n",
      "Epoch: [253][1/16]\tTime 0.180 (0.557)\tETA 0:00:02\tTraining Loss 1.1797 (1.1800)\n",
      "\n",
      "Epoch: [253][2/16]\tTime 0.196 (0.753)\tETA 0:00:02\tTraining Loss 1.1809 (1.1803)\n",
      "\n",
      "Epoch: [253][3/16]\tTime 0.176 (0.930)\tETA 0:00:02\tTraining Loss 1.1800 (1.1802)\n",
      "\n",
      "Epoch: [253][4/16]\tTime 0.186 (1.116)\tETA 0:00:02\tTraining Loss 1.1807 (1.1803)\n",
      "\n",
      "Epoch: [253][5/16]\tTime 0.190 (1.306)\tETA 0:00:02\tTraining Loss 1.1858 (1.1812)\n",
      "\n",
      "Epoch: [253][6/16]\tTime 0.191 (1.497)\tETA 0:00:01\tTraining Loss 1.1835 (1.1815)\n",
      "\n",
      "Epoch: [253][7/16]\tTime 0.199 (1.696)\tETA 0:00:01\tTraining Loss 1.1790 (1.1812)\n",
      "\n",
      "Epoch: [253][8/16]\tTime 0.182 (1.878)\tETA 0:00:01\tTraining Loss 1.1829 (1.1814)\n",
      "\n",
      "Epoch: [253][9/16]\tTime 0.187 (2.065)\tETA 0:00:01\tTraining Loss 1.1815 (1.1814)\n",
      "\n",
      "Epoch: [253][10/16]\tTime 0.181 (2.246)\tETA 0:00:01\tTraining Loss 1.1802 (1.1813)\n",
      "\n",
      "Epoch: [253][11/16]\tTime 0.181 (2.427)\tETA 0:00:00\tTraining Loss 1.1801 (1.1812)\n",
      "\n",
      "Epoch: [253][12/16]\tTime 0.186 (2.613)\tETA 0:00:00\tTraining Loss 1.1800 (1.1811)\n",
      "\n",
      "Epoch: [253][13/16]\tTime 0.188 (2.802)\tETA 0:00:00\tTraining Loss 1.1824 (1.1812)\n",
      "\n",
      "Epoch: [253][14/16]\tTime 0.181 (2.982)\tETA 0:00:00\tTraining Loss 1.1803 (1.1811)\n",
      "\n",
      "Epoch: [253][15/16]\tTime 0.115 (3.098)\tETA 0:00:00\tTraining Loss 1.1850 (1.1813)\n",
      "_\n",
      "Validation stats                    IoU        F1      Prec    recall       Acc\n",
      "bg,          0.951300  0.975000  0.977600  0.972400  0.956700\n",
      "real apple   0.630100  0.773000  0.866200  0.698000  0.973100\n",
      "real pepper  0.000000  0.000000  0.000000  0.000000  1.000000\n",
      "real grape   0.717900  0.835700  0.892800  0.785700  0.980000\n",
      "fake apple   0.000000  0.000000  0.000000  0.000000  0.995300\n",
      "fake pepper  0.000000  0.000000  0.000000  0.000000  0.993300\n",
      "fake grape   0.000000  0.000000  0.000000  0.000000  0.986200\n",
      "total        0.328471  0.369100  0.390943  0.350871  0.983514\n",
      "total(-bg)   0.224667  0.268117  0.293167  0.247283  0.987983\n",
      "\n",
      "Epoch: [254][0/16]\tTime 0.531 (0.531)\tETA 0:00:08\tTraining Loss 1.1805 (1.1805)\n",
      "\n",
      "Epoch: [254][1/16]\tTime 0.182 (0.714)\tETA 0:00:02\tTraining Loss 1.1814 (1.1810)\n",
      "\n",
      "Epoch: [254][2/16]\tTime 0.191 (0.905)\tETA 0:00:02\tTraining Loss 1.1793 (1.1804)\n",
      "\n",
      "Epoch: [254][3/16]\tTime 0.199 (1.104)\tETA 0:00:02\tTraining Loss 1.1807 (1.1805)\n",
      "\n",
      "Epoch: [254][4/16]\tTime 0.185 (1.289)\tETA 0:00:02\tTraining Loss 1.1799 (1.1804)\n",
      "\n",
      "Epoch: [254][5/16]\tTime 0.185 (1.474)\tETA 0:00:02\tTraining Loss 1.1807 (1.1804)\n",
      "\n",
      "Epoch: [254][6/16]\tTime 0.196 (1.669)\tETA 0:00:01\tTraining Loss 1.1800 (1.1804)\n",
      "\n",
      "Epoch: [254][7/16]\tTime 0.185 (1.854)\tETA 0:00:01\tTraining Loss 1.1793 (1.1802)\n",
      "\n",
      "Epoch: [254][8/16]\tTime 0.187 (2.041)\tETA 0:00:01\tTraining Loss 1.1790 (1.1801)\n",
      "\n",
      "Epoch: [254][9/16]\tTime 0.190 (2.231)\tETA 0:00:01\tTraining Loss 1.1794 (1.1800)\n",
      "\n",
      "Epoch: [254][10/16]\tTime 0.196 (2.427)\tETA 0:00:01\tTraining Loss 1.1840 (1.1804)\n",
      "\n",
      "Epoch: [254][11/16]\tTime 0.198 (2.625)\tETA 0:00:00\tTraining Loss 1.1804 (1.1804)\n",
      "\n",
      "Epoch: [254][12/16]\tTime 0.195 (2.820)\tETA 0:00:00\tTraining Loss 1.1826 (1.1805)\n",
      "\n",
      "Epoch: [254][13/16]\tTime 0.194 (3.014)\tETA 0:00:00\tTraining Loss 1.1805 (1.1805)\n",
      "\n",
      "Epoch: [254][14/16]\tTime 0.187 (3.200)\tETA 0:00:00\tTraining Loss 1.1829 (1.1807)\n",
      "\n",
      "Epoch: [254][15/16]\tTime 0.119 (3.319)\tETA 0:00:00\tTraining Loss 1.1808 (1.1807)\n",
      "_\n",
      "Validation stats                    IoU        F1      Prec    recall       Acc\n",
      "bg,          0.954800  0.976800  0.977900  0.975800  0.959900\n",
      "real apple   0.646000  0.784900  0.896400  0.698200  0.974900\n",
      "real pepper  0.000000  0.000000  0.000000  0.000000  0.999900\n",
      "real grape   0.750900  0.857700  0.876900  0.839400  0.982000\n",
      "fake apple   0.000000  0.000000  0.000000  0.000000  0.993900\n",
      "fake pepper  0.000000  0.000000  0.000000  0.000000  0.996000\n",
      "fake grape   0.000000  0.000000  0.000000  0.000000  0.991000\n",
      "total        0.335957  0.374200  0.393029  0.359057  0.985371\n",
      "total(-bg)   0.232817  0.273767  0.295550  0.256267  0.989617\n",
      "\n",
      "Epoch: [255][0/16]\tTime 0.454 (0.454)\tETA 0:00:07\tTraining Loss 1.1813 (1.1813)\n",
      "\n",
      "Epoch: [255][1/16]\tTime 0.182 (0.636)\tETA 0:00:02\tTraining Loss 1.1787 (1.1800)\n",
      "\n",
      "Epoch: [255][2/16]\tTime 0.184 (0.821)\tETA 0:00:02\tTraining Loss 1.1793 (1.1798)\n",
      "\n",
      "Epoch: [255][3/16]\tTime 0.183 (1.004)\tETA 0:00:02\tTraining Loss 1.1795 (1.1797)\n",
      "\n",
      "Epoch: [255][4/16]\tTime 0.185 (1.189)\tETA 0:00:02\tTraining Loss 1.1804 (1.1798)\n",
      "\n",
      "Epoch: [255][5/16]\tTime 0.181 (1.370)\tETA 0:00:01\tTraining Loss 1.1806 (1.1800)\n",
      "\n",
      "Epoch: [255][6/16]\tTime 0.188 (1.558)\tETA 0:00:01\tTraining Loss 1.1786 (1.1798)\n",
      "\n",
      "Epoch: [255][7/16]\tTime 0.202 (1.760)\tETA 0:00:01\tTraining Loss 1.1803 (1.1798)\n",
      "\n",
      "Epoch: [255][8/16]\tTime 0.181 (1.941)\tETA 0:00:01\tTraining Loss 1.1804 (1.1799)\n",
      "\n",
      "Epoch: [255][9/16]\tTime 0.188 (2.129)\tETA 0:00:01\tTraining Loss 1.1800 (1.1799)\n",
      "\n",
      "Epoch: [255][10/16]\tTime 0.184 (2.313)\tETA 0:00:01\tTraining Loss 1.1806 (1.1800)\n",
      "\n",
      "Epoch: [255][11/16]\tTime 0.192 (2.504)\tETA 0:00:00\tTraining Loss 1.1796 (1.1799)\n",
      "\n",
      "Epoch: [255][12/16]\tTime 0.182 (2.686)\tETA 0:00:00\tTraining Loss 1.1793 (1.1799)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: [255][13/16]\tTime 0.187 (2.873)\tETA 0:00:00\tTraining Loss 1.1797 (1.1799)\n",
      "\n",
      "Epoch: [255][14/16]\tTime 0.188 (3.061)\tETA 0:00:00\tTraining Loss 1.1820 (1.1800)\n",
      "\n",
      "Epoch: [255][15/16]\tTime 0.115 (3.176)\tETA 0:00:00\tTraining Loss 1.1801 (1.1800)\n",
      "_\n",
      "Validation stats                    IoU        F1      Prec    recall       Acc\n",
      "bg,          0.951700  0.975200  0.977400  0.973200  0.957100\n",
      "real apple   0.618300  0.764100  0.866800  0.683200  0.972300\n",
      "real pepper  0.000000  0.000000  0.000000  0.000000  1.000000\n",
      "real grape   0.647500  0.786000  0.924900  0.683400  0.975900\n",
      "fake apple   0.000000  0.000000  0.000000  0.000000  0.992500\n",
      "fake pepper  0.000000  0.000000  0.000000  0.000000  0.995300\n",
      "fake grape   0.000000  0.000000  0.000000  0.000000  0.977600\n",
      "total        0.316786  0.360757  0.395586  0.334257  0.981529\n",
      "total(-bg)   0.210967  0.258350  0.298617  0.227767  0.985600\n",
      "\n",
      "Epoch: [256][0/16]\tTime 0.507 (0.507)\tETA 0:00:08\tTraining Loss 1.1793 (1.1793)\n",
      "\n",
      "Epoch: [256][1/16]\tTime 0.184 (0.691)\tETA 0:00:02\tTraining Loss 1.1783 (1.1788)\n",
      "\n",
      "Epoch: [256][2/16]\tTime 0.193 (0.884)\tETA 0:00:02\tTraining Loss 1.1817 (1.1798)\n",
      "\n",
      "Epoch: [256][3/16]\tTime 0.278 (1.162)\tETA 0:00:03\tTraining Loss 1.1792 (1.1796)\n",
      "\n",
      "Epoch: [256][4/16]\tTime 0.184 (1.346)\tETA 0:00:02\tTraining Loss 1.1810 (1.1799)\n",
      "\n",
      "Epoch: [256][5/16]\tTime 0.190 (1.536)\tETA 0:00:02\tTraining Loss 1.1804 (1.1800)\n",
      "\n",
      "Epoch: [256][6/16]\tTime 0.186 (1.722)\tETA 0:00:01\tTraining Loss 1.1829 (1.1804)\n",
      "\n",
      "Epoch: [256][7/16]\tTime 0.191 (1.913)\tETA 0:00:01\tTraining Loss 1.1797 (1.1803)\n",
      "\n",
      "Epoch: [256][8/16]\tTime 0.183 (2.096)\tETA 0:00:01\tTraining Loss 1.1797 (1.1802)\n",
      "\n",
      "Epoch: [256][9/16]\tTime 0.189 (2.285)\tETA 0:00:01\tTraining Loss 1.1816 (1.1804)\n",
      "\n",
      "Epoch: [256][10/16]\tTime 0.184 (2.469)\tETA 0:00:01\tTraining Loss 1.1796 (1.1803)\n",
      "\n",
      "Epoch: [256][11/16]\tTime 0.189 (2.658)\tETA 0:00:00\tTraining Loss 1.1808 (1.1804)\n",
      "\n",
      "Epoch: [256][12/16]\tTime 0.184 (2.841)\tETA 0:00:00\tTraining Loss 1.1807 (1.1804)\n",
      "\n",
      "Epoch: [256][13/16]\tTime 0.191 (3.033)\tETA 0:00:00\tTraining Loss 1.1797 (1.1803)\n",
      "\n",
      "Epoch: [256][14/16]\tTime 0.190 (3.223)\tETA 0:00:00\tTraining Loss 1.1795 (1.1803)\n",
      "\n",
      "Epoch: [256][15/16]\tTime 0.115 (3.338)\tETA 0:00:00\tTraining Loss 1.1816 (1.1803)\n",
      "_\n",
      "Validation stats                    IoU        F1      Prec    recall       Acc\n",
      "bg,          0.959300  0.979200  0.977800  0.980600  0.963800\n",
      "real apple   0.501000  0.667500  0.882800  0.536700  0.964900\n",
      "real pepper  0.000000  0.000000  0.000000  0.000000  0.999600\n",
      "real grape   0.747300  0.855300  0.908700  0.807900  0.982300\n",
      "fake apple   0.000000  0.000000  0.000000  0.000000  0.985100\n",
      "fake pepper  0.000000  0.000000  0.000000  0.000000  0.998000\n",
      "fake grape   0.000000  0.000000  0.000000  0.000000  0.986900\n",
      "total        0.315371  0.357429  0.395614  0.332171  0.982943\n",
      "total(-bg)   0.208050  0.253800  0.298583  0.224100  0.986133\n",
      "\n",
      "Epoch: [257][0/16]\tTime 0.474 (0.474)\tETA 0:00:07\tTraining Loss 1.1869 (1.1869)\n",
      "\n",
      "Epoch: [257][1/16]\tTime 0.186 (0.660)\tETA 0:00:02\tTraining Loss 1.1781 (1.1825)\n",
      "\n",
      "Epoch: [257][2/16]\tTime 0.182 (0.842)\tETA 0:00:02\tTraining Loss 1.1787 (1.1812)\n",
      "\n",
      "Epoch: [257][3/16]\tTime 0.185 (1.027)\tETA 0:00:02\tTraining Loss 1.1784 (1.1805)\n",
      "\n",
      "Epoch: [257][4/16]\tTime 0.179 (1.206)\tETA 0:00:02\tTraining Loss 1.1785 (1.1801)\n",
      "\n",
      "Epoch: [257][5/16]\tTime 0.188 (1.394)\tETA 0:00:02\tTraining Loss 1.1807 (1.1802)\n",
      "\n",
      "Epoch: [257][6/16]\tTime 0.188 (1.582)\tETA 0:00:01\tTraining Loss 1.1791 (1.1801)\n",
      "\n",
      "Epoch: [257][7/16]\tTime 0.194 (1.776)\tETA 0:00:01\tTraining Loss 1.1790 (1.1799)\n",
      "\n",
      "Epoch: [257][8/16]\tTime 0.182 (1.958)\tETA 0:00:01\tTraining Loss 1.1793 (1.1799)\n",
      "\n",
      "Epoch: [257][9/16]\tTime 0.199 (2.157)\tETA 0:00:01\tTraining Loss 1.1808 (1.1800)\n",
      "\n",
      "Epoch: [257][10/16]\tTime 0.192 (2.349)\tETA 0:00:01\tTraining Loss 1.1809 (1.1800)\n",
      "\n",
      "Epoch: [257][11/16]\tTime 0.192 (2.541)\tETA 0:00:00\tTraining Loss 1.1808 (1.1801)\n",
      "\n",
      "Epoch: [257][12/16]\tTime 0.191 (2.732)\tETA 0:00:00\tTraining Loss 1.1840 (1.1804)\n",
      "\n",
      "Epoch: [257][13/16]\tTime 0.186 (2.917)\tETA 0:00:00\tTraining Loss 1.1800 (1.1804)\n",
      "\n",
      "Epoch: [257][14/16]\tTime 0.198 (3.115)\tETA 0:00:00\tTraining Loss 1.1788 (1.1803)\n",
      "\n",
      "Epoch: [257][15/16]\tTime 0.112 (3.227)\tETA 0:00:00\tTraining Loss 1.1790 (1.1802)\n",
      "_\n",
      "Validation stats                    IoU        F1      Prec    recall       Acc\n",
      "bg,          0.953500  0.976100  0.977900  0.974400  0.958600\n",
      "real apple   0.643300  0.782900  0.863800  0.715900  0.973900\n",
      "real pepper  0.000000  0.000000  0.000000  0.000000  1.000000\n",
      "real grape   0.759600  0.863400  0.907100  0.823700  0.983100\n",
      "fake apple   0.000000  0.000000  0.000000  0.000000  0.994600\n",
      "fake pepper  0.000000  0.000000  0.000000  0.000000  0.997200\n",
      "fake grape   0.000000  0.000000  0.000000  0.000000  0.987900\n",
      "total        0.336629  0.374629  0.392686  0.359143  0.985043\n",
      "total(-bg)   0.233817  0.274383  0.295150  0.256600  0.989450\n",
      "\n",
      "Epoch: [258][0/16]\tTime 0.536 (0.536)\tETA 0:00:08\tTraining Loss 1.1838 (1.1838)\n",
      "\n",
      "Epoch: [258][1/16]\tTime 0.192 (0.728)\tETA 0:00:02\tTraining Loss 1.1803 (1.1821)\n",
      "\n",
      "Epoch: [258][2/16]\tTime 0.191 (0.918)\tETA 0:00:02\tTraining Loss 1.1784 (1.1808)\n",
      "\n",
      "Epoch: [258][3/16]\tTime 0.184 (1.102)\tETA 0:00:02\tTraining Loss 1.1789 (1.1803)\n",
      "\n",
      "Epoch: [258][4/16]\tTime 0.193 (1.295)\tETA 0:00:02\tTraining Loss 1.1812 (1.1805)\n",
      "\n",
      "Epoch: [258][5/16]\tTime 0.190 (1.485)\tETA 0:00:02\tTraining Loss 1.1812 (1.1806)\n",
      "\n",
      "Epoch: [258][6/16]\tTime 0.215 (1.700)\tETA 0:00:02\tTraining Loss 1.1778 (1.1802)\n",
      "\n",
      "Epoch: [258][7/16]\tTime 0.191 (1.890)\tETA 0:00:01\tTraining Loss 1.1856 (1.1809)\n",
      "\n",
      "Epoch: [258][8/16]\tTime 0.189 (2.079)\tETA 0:00:01\tTraining Loss 1.1785 (1.1806)\n",
      "\n",
      "Epoch: [258][9/16]\tTime 0.189 (2.267)\tETA 0:00:01\tTraining Loss 1.1794 (1.1805)\n",
      "\n",
      "Epoch: [258][10/16]\tTime 0.183 (2.451)\tETA 0:00:01\tTraining Loss 1.1830 (1.1807)\n",
      "\n",
      "Epoch: [258][11/16]\tTime 0.180 (2.630)\tETA 0:00:00\tTraining Loss 1.1790 (1.1806)\n",
      "\n",
      "Epoch: [258][12/16]\tTime 0.188 (2.819)\tETA 0:00:00\tTraining Loss 1.1789 (1.1805)\n",
      "\n",
      "Epoch: [258][13/16]\tTime 0.181 (2.999)\tETA 0:00:00\tTraining Loss 1.1790 (1.1804)\n",
      "\n",
      "Epoch: [258][14/16]\tTime 0.192 (3.191)\tETA 0:00:00\tTraining Loss 1.1784 (1.1802)\n",
      "\n",
      "Epoch: [258][15/16]\tTime 0.113 (3.304)\tETA 0:00:00\tTraining Loss 1.1846 (1.1804)\n",
      "_\n",
      "Validation stats                    IoU        F1      Prec    recall       Acc\n",
      "bg,          0.957000  0.978000  0.978200  0.977900  0.961800\n",
      "real apple   0.660800  0.795700  0.902400  0.711600  0.976000\n",
      "real pepper  0.000000  0.000000  0.000000  0.000000  1.000000\n",
      "real grape   0.773400  0.872200  0.912500  0.835400  0.984200\n",
      "fake apple   0.000000  0.000000  0.000000  0.000000  0.994000\n",
      "fake pepper  0.000000  0.000000  0.000000  0.000000  0.998600\n",
      "fake grape   0.000000  0.000000  0.000000  0.000000  0.987700\n",
      "total        0.341600  0.377986  0.399014  0.360700  0.986043\n",
      "total(-bg)   0.239033  0.277983  0.302483  0.257833  0.990083\n",
      "\n",
      "Epoch: [259][0/16]\tTime 0.494 (0.494)\tETA 0:00:07\tTraining Loss 1.1782 (1.1782)\n",
      "\n",
      "Epoch: [259][1/16]\tTime 0.184 (0.678)\tETA 0:00:02\tTraining Loss 1.1788 (1.1785)\n",
      "\n",
      "Epoch: [259][2/16]\tTime 0.187 (0.865)\tETA 0:00:02\tTraining Loss 1.1801 (1.1791)\n",
      "\n",
      "Epoch: [259][3/16]\tTime 0.185 (1.051)\tETA 0:00:02\tTraining Loss 1.1807 (1.1795)\n",
      "\n",
      "Epoch: [259][4/16]\tTime 0.191 (1.242)\tETA 0:00:02\tTraining Loss 1.1782 (1.1792)\n",
      "\n",
      "Epoch: [259][5/16]\tTime 0.188 (1.430)\tETA 0:00:02\tTraining Loss 1.1788 (1.1792)\n",
      "\n",
      "Epoch: [259][6/16]\tTime 0.188 (1.618)\tETA 0:00:01\tTraining Loss 1.1793 (1.1792)\n",
      "\n",
      "Epoch: [259][7/16]\tTime 0.188 (1.806)\tETA 0:00:01\tTraining Loss 1.1786 (1.1791)\n",
      "\n",
      "Epoch: [259][8/16]\tTime 0.185 (1.991)\tETA 0:00:01\tTraining Loss 1.1799 (1.1792)\n",
      "\n",
      "Epoch: [259][9/16]\tTime 0.191 (2.182)\tETA 0:00:01\tTraining Loss 1.1811 (1.1794)\n",
      "\n",
      "Epoch: [259][10/16]\tTime 0.191 (2.374)\tETA 0:00:01\tTraining Loss 1.1784 (1.1793)\n",
      "\n",
      "Epoch: [259][11/16]\tTime 0.185 (2.559)\tETA 0:00:00\tTraining Loss 1.1797 (1.1793)\n",
      "\n",
      "Epoch: [259][12/16]\tTime 0.196 (2.755)\tETA 0:00:00\tTraining Loss 1.1807 (1.1794)\n",
      "\n",
      "Epoch: [259][13/16]\tTime 0.183 (2.939)\tETA 0:00:00\tTraining Loss 1.1798 (1.1795)\n",
      "\n",
      "Epoch: [259][14/16]\tTime 0.189 (3.127)\tETA 0:00:00\tTraining Loss 1.1790 (1.1794)\n",
      "\n",
      "Epoch: [259][15/16]\tTime 0.112 (3.240)\tETA 0:00:00\tTraining Loss 1.1787 (1.1794)\n",
      "_\n",
      "Validation stats                    IoU        F1      Prec    recall       Acc\n",
      "bg,          0.957200  0.978100  0.977600  0.978600  0.961900\n",
      "real apple   0.659400  0.794700  0.907600  0.706900  0.976000\n",
      "real pepper  0.000000  0.000000  0.000000  0.000000  1.000000\n",
      "real grape   0.711800  0.831600  0.925400  0.755200  0.980200\n",
      "fake apple   0.000000  0.000000  0.000000  0.000000  0.993500\n",
      "fake pepper  0.000000  0.000000  0.000000  0.000000  0.998600\n",
      "fake grape   0.000000  0.000000  0.000000  0.000000  0.982300\n",
      "total        0.332629  0.372057  0.401514  0.348671  0.984643\n",
      "total(-bg)   0.228533  0.271050  0.305500  0.243683  0.988433\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: [260][0/16]\tTime 0.536 (0.536)\tETA 0:00:08\tTraining Loss 1.1788 (1.1788)\n",
      "\n",
      "Epoch: [260][1/16]\tTime 0.175 (0.711)\tETA 0:00:02\tTraining Loss 1.1795 (1.1792)\n",
      "\n",
      "Epoch: [260][2/16]\tTime 0.206 (0.917)\tETA 0:00:02\tTraining Loss 1.1791 (1.1792)\n",
      "\n",
      "Epoch: [260][3/16]\tTime 0.188 (1.105)\tETA 0:00:02\tTraining Loss 1.1782 (1.1789)\n",
      "\n",
      "Epoch: [260][4/16]\tTime 0.189 (1.293)\tETA 0:00:02\tTraining Loss 1.1780 (1.1787)\n",
      "\n",
      "Epoch: [260][5/16]\tTime 0.193 (1.486)\tETA 0:00:02\tTraining Loss 1.1779 (1.1786)\n",
      "\n",
      "Epoch: [260][6/16]\tTime 0.214 (1.700)\tETA 0:00:02\tTraining Loss 1.1794 (1.1787)\n",
      "\n",
      "Epoch: [260][7/16]\tTime 0.185 (1.885)\tETA 0:00:01\tTraining Loss 1.1801 (1.1789)\n",
      "\n",
      "Epoch: [260][8/16]\tTime 0.185 (2.070)\tETA 0:00:01\tTraining Loss 1.1774 (1.1787)\n",
      "\n",
      "Epoch: [260][9/16]\tTime 0.195 (2.264)\tETA 0:00:01\tTraining Loss 1.1794 (1.1788)\n",
      "\n",
      "Epoch: [260][10/16]\tTime 0.189 (2.453)\tETA 0:00:01\tTraining Loss 1.1795 (1.1789)\n",
      "\n",
      "Epoch: [260][11/16]\tTime 0.189 (2.642)\tETA 0:00:00\tTraining Loss 1.1824 (1.1792)\n",
      "\n",
      "Epoch: [260][12/16]\tTime 0.187 (2.828)\tETA 0:00:00\tTraining Loss 1.1777 (1.1790)\n",
      "\n",
      "Epoch: [260][13/16]\tTime 0.189 (3.017)\tETA 0:00:00\tTraining Loss 1.1793 (1.1791)\n",
      "\n",
      "Epoch: [260][14/16]\tTime 0.189 (3.206)\tETA 0:00:00\tTraining Loss 1.1775 (1.1790)\n",
      "\n",
      "Epoch: [260][15/16]\tTime 0.111 (3.317)\tETA 0:00:00\tTraining Loss 1.1873 (1.1792)\n",
      "_\n",
      "Validation stats                    IoU        F1      Prec    recall       Acc\n",
      "bg,          0.956200  0.977500  0.978200  0.977000  0.961100\n",
      "real apple   0.502500  0.668800  0.862500  0.546200  0.964500\n",
      "real pepper  0.000000  0.000000  0.000000  0.000000  0.999700\n",
      "real grape   0.719800  0.837000  0.887800  0.791800  0.980000\n",
      "fake apple   0.000000  0.000000  0.000000  0.000000  0.988500\n",
      "fake pepper  0.000000  0.000000  0.000000  0.000000  0.995800\n",
      "fake grape   0.000000  0.000000  0.000000  0.000000  0.983900\n",
      "total        0.311214  0.354757  0.389786  0.330714  0.981929\n",
      "total(-bg)   0.203717  0.250967  0.291717  0.223000  0.985400\n",
      "\n",
      "Epoch: [261][0/16]\tTime 0.409 (0.409)\tETA 0:00:06\tTraining Loss 1.1790 (1.1790)\n",
      "\n",
      "Epoch: [261][1/16]\tTime 0.298 (0.707)\tETA 0:00:04\tTraining Loss 1.1790 (1.1790)\n",
      "\n",
      "Epoch: [261][2/16]\tTime 0.188 (0.895)\tETA 0:00:02\tTraining Loss 1.1784 (1.1788)\n",
      "\n",
      "Epoch: [261][3/16]\tTime 0.193 (1.087)\tETA 0:00:02\tTraining Loss 1.1783 (1.1787)\n",
      "\n",
      "Epoch: [261][4/16]\tTime 0.186 (1.273)\tETA 0:00:02\tTraining Loss 1.1782 (1.1786)\n",
      "\n",
      "Epoch: [261][5/16]\tTime 0.201 (1.474)\tETA 0:00:02\tTraining Loss 1.1811 (1.1790)\n",
      "\n",
      "Epoch: [261][6/16]\tTime 0.196 (1.670)\tETA 0:00:01\tTraining Loss 1.1783 (1.1789)\n",
      "\n",
      "Epoch: [261][7/16]\tTime 0.189 (1.859)\tETA 0:00:01\tTraining Loss 1.1777 (1.1788)\n",
      "\n",
      "Epoch: [261][8/16]\tTime 0.298 (2.157)\tETA 0:00:02\tTraining Loss 1.1775 (1.1786)\n",
      "\n",
      "Epoch: [261][9/16]\tTime 0.185 (2.342)\tETA 0:00:01\tTraining Loss 1.1778 (1.1785)\n",
      "\n",
      "Epoch: [261][10/16]\tTime 0.191 (2.533)\tETA 0:00:01\tTraining Loss 1.1802 (1.1787)\n",
      "\n",
      "Epoch: [261][11/16]\tTime 0.214 (2.747)\tETA 0:00:01\tTraining Loss 1.1820 (1.1790)\n",
      "\n",
      "Epoch: [261][12/16]\tTime 0.187 (2.934)\tETA 0:00:00\tTraining Loss 1.1788 (1.1789)\n",
      "\n",
      "Epoch: [261][13/16]\tTime 0.184 (3.118)\tETA 0:00:00\tTraining Loss 1.1784 (1.1789)\n",
      "\n",
      "Epoch: [261][14/16]\tTime 0.190 (3.308)\tETA 0:00:00\tTraining Loss 1.1789 (1.1789)\n",
      "\n",
      "Epoch: [261][15/16]\tTime 0.117 (3.425)\tETA 0:00:00\tTraining Loss 1.1828 (1.1790)\n",
      "_\n",
      "Validation stats                    IoU        F1      Prec    recall       Acc\n",
      "bg,          0.954300  0.976600  0.978700  0.974500  0.959400\n",
      "real apple   0.491600  0.659100  0.849600  0.538400  0.963400\n",
      "real pepper  0.000000  0.000000  0.000000  0.000000  0.999900\n",
      "real grape   0.744900  0.853700  0.889100  0.821100  0.981800\n",
      "fake apple   0.000000  0.000000  0.000000  0.000000  0.984000\n",
      "fake pepper  0.000000  0.000000  0.000000  0.000000  0.997100\n",
      "fake grape   0.000000  0.000000  0.000000  0.000000  0.986300\n",
      "total        0.312971  0.355629  0.388200  0.333429  0.981700\n",
      "total(-bg)   0.206083  0.252133  0.289783  0.226583  0.985417\n",
      "\n",
      "Epoch: [262][0/16]\tTime 0.478 (0.478)\tETA 0:00:07\tTraining Loss 1.1781 (1.1781)\n",
      "\n",
      "Epoch: [262][1/16]\tTime 0.175 (0.653)\tETA 0:00:02\tTraining Loss 1.1788 (1.1784)\n",
      "\n",
      "Epoch: [262][2/16]\tTime 0.187 (0.840)\tETA 0:00:02\tTraining Loss 1.1776 (1.1781)\n",
      "\n",
      "Epoch: [262][3/16]\tTime 0.186 (1.026)\tETA 0:00:02\tTraining Loss 1.1784 (1.1782)\n",
      "\n",
      "Epoch: [262][4/16]\tTime 0.186 (1.212)\tETA 0:00:02\tTraining Loss 1.1793 (1.1784)\n",
      "\n",
      "Epoch: [262][5/16]\tTime 0.186 (1.398)\tETA 0:00:02\tTraining Loss 1.1776 (1.1783)\n",
      "\n",
      "Epoch: [262][6/16]\tTime 0.196 (1.594)\tETA 0:00:01\tTraining Loss 1.1791 (1.1784)\n",
      "\n",
      "Epoch: [262][7/16]\tTime 0.190 (1.783)\tETA 0:00:01\tTraining Loss 1.1785 (1.1784)\n",
      "\n",
      "Epoch: [262][8/16]\tTime 0.194 (1.978)\tETA 0:00:01\tTraining Loss 1.1796 (1.1785)\n",
      "\n",
      "Epoch: [262][9/16]\tTime 0.186 (2.164)\tETA 0:00:01\tTraining Loss 1.1812 (1.1788)\n",
      "\n",
      "Epoch: [262][10/16]\tTime 0.186 (2.350)\tETA 0:00:01\tTraining Loss 1.1796 (1.1789)\n",
      "\n",
      "Epoch: [262][11/16]\tTime 0.183 (2.534)\tETA 0:00:00\tTraining Loss 1.1795 (1.1789)\n",
      "\n",
      "Epoch: [262][12/16]\tTime 0.184 (2.717)\tETA 0:00:00\tTraining Loss 1.1790 (1.1789)\n",
      "\n",
      "Epoch: [262][13/16]\tTime 0.189 (2.907)\tETA 0:00:00\tTraining Loss 1.1804 (1.1790)\n",
      "\n",
      "Epoch: [262][14/16]\tTime 0.185 (3.092)\tETA 0:00:00\tTraining Loss 1.1785 (1.1790)\n",
      "\n",
      "Epoch: [262][15/16]\tTime 0.115 (3.207)\tETA 0:00:00\tTraining Loss 1.1804 (1.1790)\n",
      "_\n",
      "Validation stats                    IoU        F1     Prec    recall       Acc\n",
      "bg,          0.952500  0.975600  0.97760  0.973700  0.957800\n",
      "real apple   0.633500  0.775600  0.86370  0.703900  0.973200\n",
      "real pepper  0.000000  0.000000  0.00000  0.000000  1.000000\n",
      "real grape   0.727900  0.842500  0.90900  0.785100  0.981000\n",
      "fake apple   0.000000  0.000000  0.00000  0.000000  0.991900\n",
      "fake pepper  0.000000  0.000000  0.00000  0.000000  0.997100\n",
      "fake grape   0.000000  0.000000  0.00000  0.000000  0.986500\n",
      "total        0.330557  0.370529  0.39290  0.351814  0.983929\n",
      "total(-bg)   0.226900  0.269683  0.29545  0.248167  0.988283\n",
      "\n",
      "Epoch: [263][0/16]\tTime 0.451 (0.451)\tETA 0:00:07\tTraining Loss 1.1775 (1.1775)\n",
      "\n",
      "Epoch: [263][1/16]\tTime 0.179 (0.630)\tETA 0:00:02\tTraining Loss 1.1789 (1.1782)\n",
      "\n",
      "Epoch: [263][2/16]\tTime 0.185 (0.815)\tETA 0:00:02\tTraining Loss 1.1777 (1.1780)\n",
      "\n",
      "Epoch: [263][3/16]\tTime 0.192 (1.007)\tETA 0:00:02\tTraining Loss 1.1811 (1.1788)\n",
      "\n",
      "Epoch: [263][4/16]\tTime 0.191 (1.198)\tETA 0:00:02\tTraining Loss 1.1796 (1.1790)\n",
      "\n",
      "Epoch: [263][5/16]\tTime 0.185 (1.383)\tETA 0:00:02\tTraining Loss 1.1821 (1.1795)\n",
      "\n",
      "Epoch: [263][6/16]\tTime 0.200 (1.583)\tETA 0:00:02\tTraining Loss 1.1790 (1.1794)\n",
      "\n",
      "Epoch: [263][7/16]\tTime 0.186 (1.769)\tETA 0:00:01\tTraining Loss 1.1778 (1.1792)\n",
      "\n",
      "Epoch: [263][8/16]\tTime 0.194 (1.963)\tETA 0:00:01\tTraining Loss 1.1791 (1.1792)\n",
      "\n",
      "Epoch: [263][9/16]\tTime 0.188 (2.150)\tETA 0:00:01\tTraining Loss 1.1824 (1.1795)\n",
      "\n",
      "Epoch: [263][10/16]\tTime 0.187 (2.337)\tETA 0:00:01\tTraining Loss 1.1781 (1.1794)\n",
      "\n",
      "Epoch: [263][11/16]\tTime 0.194 (2.531)\tETA 0:00:00\tTraining Loss 1.1773 (1.1792)\n",
      "\n",
      "Epoch: [263][12/16]\tTime 0.198 (2.729)\tETA 0:00:00\tTraining Loss 1.1790 (1.1792)\n",
      "\n",
      "Epoch: [263][13/16]\tTime 0.190 (2.919)\tETA 0:00:00\tTraining Loss 1.1776 (1.1791)\n",
      "\n",
      "Epoch: [263][14/16]\tTime 0.187 (3.106)\tETA 0:00:00\tTraining Loss 1.1773 (1.1790)\n",
      "\n",
      "Epoch: [263][15/16]\tTime 0.113 (3.219)\tETA 0:00:00\tTraining Loss 1.1786 (1.1790)\n",
      "_\n",
      "Validation stats                    IoU        F1      Prec    recall       Acc\n",
      "bg,          0.955800  0.977400  0.978300  0.976500  0.960700\n",
      "real apple   0.489200  0.656900  0.839300  0.539700  0.963000\n",
      "real pepper  0.000000  0.000000  0.000000  0.000000  0.999600\n",
      "real grape   0.772700  0.871700  0.906300  0.839800  0.984000\n",
      "fake apple   0.000000  0.000000  0.000000  0.000000  0.987700\n",
      "fake pepper  0.000000  0.000000  0.000000  0.000000  0.996000\n",
      "fake grape   0.000000  0.000000  0.000000  0.000000  0.986900\n",
      "total        0.316814  0.358000  0.389129  0.336571  0.982557\n",
      "total(-bg)   0.210317  0.254767  0.290933  0.229917  0.986200\n",
      "\n",
      "Epoch: [264][0/16]\tTime 0.424 (0.424)\tETA 0:00:06\tTraining Loss 1.1782 (1.1782)\n",
      "\n",
      "Epoch: [264][1/16]\tTime 0.183 (0.607)\tETA 0:00:02\tTraining Loss 1.1777 (1.1780)\n",
      "\n",
      "Epoch: [264][2/16]\tTime 0.195 (0.802)\tETA 0:00:02\tTraining Loss 1.1796 (1.1785)\n",
      "\n",
      "Epoch: [264][3/16]\tTime 0.181 (0.983)\tETA 0:00:02\tTraining Loss 1.1801 (1.1789)\n",
      "\n",
      "Epoch: [264][4/16]\tTime 0.183 (1.166)\tETA 0:00:02\tTraining Loss 1.1799 (1.1791)\n",
      "\n",
      "Epoch: [264][5/16]\tTime 0.189 (1.355)\tETA 0:00:02\tTraining Loss 1.1782 (1.1790)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: [264][6/16]\tTime 0.188 (1.543)\tETA 0:00:01\tTraining Loss 1.1777 (1.1788)\n",
      "\n",
      "Epoch: [264][7/16]\tTime 0.191 (1.734)\tETA 0:00:01\tTraining Loss 1.1784 (1.1787)\n",
      "\n",
      "Epoch: [264][8/16]\tTime 0.185 (1.920)\tETA 0:00:01\tTraining Loss 1.1815 (1.1790)\n",
      "\n",
      "Epoch: [264][9/16]\tTime 0.177 (2.097)\tETA 0:00:01\tTraining Loss 1.1780 (1.1789)\n",
      "\n",
      "Epoch: [264][10/16]\tTime 0.194 (2.290)\tETA 0:00:01\tTraining Loss 1.1780 (1.1788)\n",
      "\n",
      "Epoch: [264][11/16]\tTime 0.179 (2.470)\tETA 0:00:00\tTraining Loss 1.1785 (1.1788)\n",
      "\n",
      "Epoch: [264][12/16]\tTime 0.183 (2.652)\tETA 0:00:00\tTraining Loss 1.1803 (1.1789)\n",
      "\n",
      "Epoch: [264][13/16]\tTime 0.181 (2.833)\tETA 0:00:00\tTraining Loss 1.1775 (1.1788)\n",
      "\n",
      "Epoch: [264][14/16]\tTime 0.308 (3.141)\tETA 0:00:00\tTraining Loss 1.1780 (1.1788)\n",
      "\n",
      "Epoch: [264][15/16]\tTime 0.115 (3.256)\tETA 0:00:00\tTraining Loss 1.1796 (1.1788)\n",
      "_\n",
      "Validation stats                    IoU        F1      Prec    recall       Acc\n",
      "bg,          0.956100  0.977500  0.978400  0.976700  0.961000\n",
      "real apple   0.655800  0.792100  0.897500  0.708800  0.975500\n",
      "real pepper  0.000000  0.000000  0.000000  0.000000  0.999900\n",
      "real grape   0.774200  0.872700  0.913400  0.835500  0.984200\n",
      "fake apple   0.000000  0.000000  0.000000  0.000000  0.992800\n",
      "fake pepper  0.000000  0.000000  0.000000  0.000000  0.997700\n",
      "fake grape   0.000000  0.000000  0.000000  0.000000  0.988700\n",
      "total        0.340871  0.377471  0.398471  0.360143  0.985686\n",
      "total(-bg)   0.238333  0.277467  0.301817  0.257383  0.989800\n",
      "\n",
      "Epoch: [265][0/16]\tTime 0.352 (0.352)\tETA 0:00:05\tTraining Loss 1.1783 (1.1783)\n",
      "\n",
      "Epoch: [265][1/16]\tTime 0.190 (0.542)\tETA 0:00:02\tTraining Loss 1.1777 (1.1780)\n",
      "\n",
      "Epoch: [265][2/16]\tTime 0.180 (0.722)\tETA 0:00:02\tTraining Loss 1.1812 (1.1790)\n",
      "\n",
      "Epoch: [265][3/16]\tTime 0.193 (0.915)\tETA 0:00:02\tTraining Loss 1.1785 (1.1789)\n",
      "\n",
      "Epoch: [265][4/16]\tTime 0.190 (1.105)\tETA 0:00:02\tTraining Loss 1.1798 (1.1791)\n",
      "\n",
      "Epoch: [265][5/16]\tTime 0.184 (1.288)\tETA 0:00:02\tTraining Loss 1.1783 (1.1789)\n",
      "\n",
      "Epoch: [265][6/16]\tTime 0.184 (1.472)\tETA 0:00:01\tTraining Loss 1.1815 (1.1793)\n",
      "\n",
      "Epoch: [265][7/16]\tTime 0.190 (1.661)\tETA 0:00:01\tTraining Loss 1.1770 (1.1790)\n",
      "\n",
      "Epoch: [265][8/16]\tTime 0.189 (1.851)\tETA 0:00:01\tTraining Loss 1.1779 (1.1789)\n",
      "\n",
      "Epoch: [265][9/16]\tTime 0.180 (2.031)\tETA 0:00:01\tTraining Loss 1.1772 (1.1787)\n",
      "\n",
      "Epoch: [265][10/16]\tTime 0.185 (2.216)\tETA 0:00:01\tTraining Loss 1.1779 (1.1786)\n",
      "\n",
      "Epoch: [265][11/16]\tTime 0.195 (2.411)\tETA 0:00:00\tTraining Loss 1.1802 (1.1788)\n",
      "\n",
      "Epoch: [265][12/16]\tTime 0.188 (2.599)\tETA 0:00:00\tTraining Loss 1.1807 (1.1789)\n",
      "\n",
      "Epoch: [265][13/16]\tTime 0.189 (2.788)\tETA 0:00:00\tTraining Loss 1.1774 (1.1788)\n",
      "\n",
      "Epoch: [265][14/16]\tTime 0.194 (2.981)\tETA 0:00:00\tTraining Loss 1.1779 (1.1787)\n",
      "\n",
      "Epoch: [265][15/16]\tTime 0.112 (3.093)\tETA 0:00:00\tTraining Loss 1.1795 (1.1788)\n",
      "_\n",
      "Validation stats                    IoU        F1      Prec    recall       Acc\n",
      "bg,          0.957500  0.978200  0.978100  0.978400  0.962200\n",
      "real apple   0.500100  0.666700  0.880500  0.536500  0.964800\n",
      "real pepper  0.000000  0.000000  0.000000  0.000000  0.999800\n",
      "real grape   0.774400  0.872800  0.894900  0.851900  0.983900\n",
      "fake apple   0.000000  0.000000  0.000000  0.000000  0.984000\n",
      "fake pepper  0.000000  0.000000  0.000000  0.000000  0.997900\n",
      "fake grape   0.000000  0.000000  0.000000  0.000000  0.989700\n",
      "total        0.318857  0.359671  0.393357  0.338114  0.983186\n",
      "total(-bg)   0.212417  0.256583  0.295900  0.231400  0.986683\n",
      "\n",
      "Epoch: [266][0/16]\tTime 0.467 (0.467)\tETA 0:00:07\tTraining Loss 1.1770 (1.1770)\n",
      "\n",
      "Epoch: [266][1/16]\tTime 0.187 (0.654)\tETA 0:00:02\tTraining Loss 1.1783 (1.1776)\n",
      "\n",
      "Epoch: [266][2/16]\tTime 0.188 (0.842)\tETA 0:00:02\tTraining Loss 1.1797 (1.1783)\n",
      "\n",
      "Epoch: [266][3/16]\tTime 0.192 (1.034)\tETA 0:00:02\tTraining Loss 1.1799 (1.1787)\n",
      "\n",
      "Epoch: [266][4/16]\tTime 0.185 (1.218)\tETA 0:00:02\tTraining Loss 1.1776 (1.1785)\n",
      "\n",
      "Epoch: [266][5/16]\tTime 0.191 (1.409)\tETA 0:00:02\tTraining Loss 1.1778 (1.1784)\n",
      "\n",
      "Epoch: [266][6/16]\tTime 0.179 (1.588)\tETA 0:00:01\tTraining Loss 1.1774 (1.1782)\n",
      "\n",
      "Epoch: [266][7/16]\tTime 0.182 (1.769)\tETA 0:00:01\tTraining Loss 1.1780 (1.1782)\n",
      "\n",
      "Epoch: [266][8/16]\tTime 0.181 (1.950)\tETA 0:00:01\tTraining Loss 1.1777 (1.1781)\n",
      "\n",
      "Epoch: [266][9/16]\tTime 0.191 (2.141)\tETA 0:00:01\tTraining Loss 1.1773 (1.1781)\n",
      "\n",
      "Epoch: [266][10/16]\tTime 0.193 (2.334)\tETA 0:00:01\tTraining Loss 1.1783 (1.1781)\n",
      "\n",
      "Epoch: [266][11/16]\tTime 0.183 (2.518)\tETA 0:00:00\tTraining Loss 1.1793 (1.1782)\n",
      "\n",
      "Epoch: [266][12/16]\tTime 0.187 (2.705)\tETA 0:00:00\tTraining Loss 1.1787 (1.1782)\n",
      "\n",
      "Epoch: [266][13/16]\tTime 0.188 (2.894)\tETA 0:00:00\tTraining Loss 1.1767 (1.1781)\n",
      "\n",
      "Epoch: [266][14/16]\tTime 0.179 (3.072)\tETA 0:00:00\tTraining Loss 1.1767 (1.1780)\n",
      "\n",
      "Epoch: [266][15/16]\tTime 0.115 (3.187)\tETA 0:00:00\tTraining Loss 1.1771 (1.1780)\n",
      "_\n",
      "Validation stats                    IoU        F1      Prec    recall       Acc\n",
      "bg,          0.955300  0.977100  0.977600  0.976700  0.960300\n",
      "real apple   0.484700  0.652900  0.843500  0.532600  0.962800\n",
      "real pepper  0.000000  0.000000  0.000000  0.000000  0.999900\n",
      "real grape   0.761100  0.864300  0.895800  0.835000  0.983000\n",
      "fake apple   0.000000  0.000000  0.000000  0.000000  0.986800\n",
      "fake pepper  0.000000  0.000000  0.000000  0.000000  0.996900\n",
      "fake grape   0.000000  0.000000  0.000000  0.000000  0.987000\n",
      "total        0.314443  0.356329  0.388129  0.334900  0.982386\n",
      "total(-bg)   0.207633  0.252867  0.289883  0.227933  0.986067\n",
      "\n",
      "Epoch: [267][0/16]\tTime 0.480 (0.480)\tETA 0:00:07\tTraining Loss 1.1789 (1.1789)\n",
      "\n",
      "Epoch: [267][1/16]\tTime 0.177 (0.658)\tETA 0:00:02\tTraining Loss 1.1767 (1.1778)\n",
      "\n",
      "Epoch: [267][2/16]\tTime 0.181 (0.839)\tETA 0:00:02\tTraining Loss 1.1771 (1.1776)\n",
      "\n",
      "Epoch: [267][3/16]\tTime 0.188 (1.027)\tETA 0:00:02\tTraining Loss 1.1778 (1.1776)\n",
      "\n",
      "Epoch: [267][4/16]\tTime 0.185 (1.212)\tETA 0:00:02\tTraining Loss 1.1765 (1.1774)\n",
      "\n",
      "Epoch: [267][5/16]\tTime 0.179 (1.390)\tETA 0:00:01\tTraining Loss 1.1801 (1.1779)\n",
      "\n",
      "Epoch: [267][6/16]\tTime 0.189 (1.580)\tETA 0:00:01\tTraining Loss 1.1789 (1.1780)\n",
      "\n",
      "Epoch: [267][7/16]\tTime 0.182 (1.762)\tETA 0:00:01\tTraining Loss 1.1773 (1.1779)\n",
      "\n",
      "Epoch: [267][8/16]\tTime 0.190 (1.951)\tETA 0:00:01\tTraining Loss 1.1782 (1.1779)\n",
      "\n",
      "Epoch: [267][9/16]\tTime 0.185 (2.136)\tETA 0:00:01\tTraining Loss 1.1766 (1.1778)\n",
      "\n",
      "Epoch: [267][10/16]\tTime 0.191 (2.327)\tETA 0:00:01\tTraining Loss 1.1776 (1.1778)\n",
      "\n",
      "Epoch: [267][11/16]\tTime 0.193 (2.520)\tETA 0:00:00\tTraining Loss 1.1775 (1.1778)\n",
      "\n",
      "Epoch: [267][12/16]\tTime 0.193 (2.713)\tETA 0:00:00\tTraining Loss 1.1772 (1.1777)\n",
      "\n",
      "Epoch: [267][13/16]\tTime 0.190 (2.903)\tETA 0:00:00\tTraining Loss 1.1778 (1.1777)\n",
      "\n",
      "Epoch: [267][14/16]\tTime 0.189 (3.092)\tETA 0:00:00\tTraining Loss 1.1781 (1.1778)\n",
      "\n",
      "Epoch: [267][15/16]\tTime 0.118 (3.211)\tETA 0:00:00\tTraining Loss 1.1810 (1.1779)\n",
      "_\n",
      "Validation stats                    IoU        F1      Prec    recall       Acc\n",
      "bg,          0.956900  0.977900  0.978800  0.977100  0.961700\n",
      "real apple   0.496700  0.663700  0.868600  0.537000  0.964200\n",
      "real pepper  0.000000  0.000000  0.000000  0.000000  0.999900\n",
      "real grape   0.778700  0.875500  0.893800  0.858000  0.984200\n",
      "fake apple   0.000000  0.000000  0.000000  0.000000  0.984300\n",
      "fake pepper  0.000000  0.000000  0.000000  0.000000  0.997100\n",
      "fake grape   0.000000  0.000000  0.000000  0.000000  0.989500\n",
      "total        0.318900  0.359586  0.391600  0.338871  0.982986\n",
      "total(-bg)   0.212567  0.256533  0.293733  0.232500  0.986533\n",
      "\n",
      "Epoch: [268][0/16]\tTime 0.446 (0.446)\tETA 0:00:07\tTraining Loss 1.1777 (1.1777)\n",
      "\n",
      "Epoch: [268][1/16]\tTime 0.190 (0.637)\tETA 0:00:02\tTraining Loss 1.1760 (1.1769)\n",
      "\n",
      "Epoch: [268][2/16]\tTime 0.184 (0.820)\tETA 0:00:02\tTraining Loss 1.1773 (1.1770)\n",
      "\n",
      "Epoch: [268][3/16]\tTime 0.186 (1.006)\tETA 0:00:02\tTraining Loss 1.1773 (1.1771)\n",
      "\n",
      "Epoch: [268][4/16]\tTime 0.189 (1.194)\tETA 0:00:02\tTraining Loss 1.1790 (1.1775)\n",
      "\n",
      "Epoch: [268][5/16]\tTime 0.187 (1.381)\tETA 0:00:02\tTraining Loss 1.1786 (1.1776)\n",
      "\n",
      "Epoch: [268][6/16]\tTime 0.183 (1.564)\tETA 0:00:01\tTraining Loss 1.1759 (1.1774)\n",
      "\n",
      "Epoch: [268][7/16]\tTime 0.186 (1.750)\tETA 0:00:01\tTraining Loss 1.1766 (1.1773)\n",
      "\n",
      "Epoch: [268][8/16]\tTime 0.183 (1.933)\tETA 0:00:01\tTraining Loss 1.1780 (1.1774)\n",
      "\n",
      "Epoch: [268][9/16]\tTime 0.188 (2.121)\tETA 0:00:01\tTraining Loss 1.1767 (1.1773)\n",
      "\n",
      "Epoch: [268][10/16]\tTime 0.182 (2.303)\tETA 0:00:01\tTraining Loss 1.1790 (1.1775)\n",
      "\n",
      "Epoch: [268][11/16]\tTime 0.188 (2.491)\tETA 0:00:00\tTraining Loss 1.1797 (1.1777)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: [268][12/16]\tTime 0.189 (2.680)\tETA 0:00:00\tTraining Loss 1.1769 (1.1776)\n",
      "\n",
      "Epoch: [268][13/16]\tTime 0.184 (2.864)\tETA 0:00:00\tTraining Loss 1.1769 (1.1775)\n",
      "\n",
      "Epoch: [268][14/16]\tTime 0.188 (3.052)\tETA 0:00:00\tTraining Loss 1.1780 (1.1776)\n",
      "\n",
      "Epoch: [268][15/16]\tTime 0.113 (3.165)\tETA 0:00:00\tTraining Loss 1.1769 (1.1776)\n",
      "_\n",
      "Validation stats                    IoU        F1      Prec    recall       Acc\n",
      "bg,          0.952500  0.975600  0.977500  0.973900  0.957800\n",
      "real apple   0.480200  0.648800  0.870600  0.517100  0.963200\n",
      "real pepper  0.000000  0.000000  0.000000  0.000000  0.999700\n",
      "real grape   0.745800  0.854400  0.882900  0.827700  0.981700\n",
      "fake apple   0.000000  0.000000  0.000000  0.000000  0.987100\n",
      "fake pepper  0.000000  0.000000  0.000000  0.000000  0.992600\n",
      "fake grape   0.000000  0.000000  0.000000  0.000000  0.986500\n",
      "total        0.311214  0.354114  0.390143  0.331243  0.981229\n",
      "total(-bg)   0.204333  0.250533  0.292250  0.224133  0.985133\n",
      "\n",
      "Epoch: [269][0/16]\tTime 0.471 (0.471)\tETA 0:00:07\tTraining Loss 1.1782 (1.1782)\n",
      "\n",
      "Epoch: [269][1/16]\tTime 0.193 (0.665)\tETA 0:00:02\tTraining Loss 1.1777 (1.1779)\n",
      "\n",
      "Epoch: [269][2/16]\tTime 0.177 (0.842)\tETA 0:00:02\tTraining Loss 1.1780 (1.1779)\n",
      "\n",
      "Epoch: [269][3/16]\tTime 0.180 (1.021)\tETA 0:00:02\tTraining Loss 1.1767 (1.1776)\n",
      "\n",
      "Epoch: [269][4/16]\tTime 0.183 (1.205)\tETA 0:00:02\tTraining Loss 1.1788 (1.1779)\n",
      "\n",
      "Epoch: [269][5/16]\tTime 0.191 (1.396)\tETA 0:00:02\tTraining Loss 1.1765 (1.1777)\n",
      "\n",
      "Epoch: [269][6/16]\tTime 0.193 (1.589)\tETA 0:00:01\tTraining Loss 1.1776 (1.1776)\n",
      "\n",
      "Epoch: [269][7/16]\tTime 0.190 (1.779)\tETA 0:00:01\tTraining Loss 1.1768 (1.1775)\n",
      "\n",
      "Epoch: [269][8/16]\tTime 0.188 (1.967)\tETA 0:00:01\tTraining Loss 1.1768 (1.1775)\n",
      "\n",
      "Epoch: [269][9/16]\tTime 0.186 (2.152)\tETA 0:00:01\tTraining Loss 1.1800 (1.1777)\n",
      "\n",
      "Epoch: [269][10/16]\tTime 0.185 (2.338)\tETA 0:00:01\tTraining Loss 1.1760 (1.1776)\n",
      "\n",
      "Epoch: [269][11/16]\tTime 0.182 (2.520)\tETA 0:00:00\tTraining Loss 1.1769 (1.1775)\n",
      "\n",
      "Epoch: [269][12/16]\tTime 0.184 (2.703)\tETA 0:00:00\tTraining Loss 1.1770 (1.1775)\n",
      "\n",
      "Epoch: [269][13/16]\tTime 0.187 (2.891)\tETA 0:00:00\tTraining Loss 1.1797 (1.1776)\n",
      "\n",
      "Epoch: [269][14/16]\tTime 0.189 (3.080)\tETA 0:00:00\tTraining Loss 1.1783 (1.1777)\n",
      "\n",
      "Epoch: [269][15/16]\tTime 0.116 (3.196)\tETA 0:00:00\tTraining Loss 1.1838 (1.1779)\n",
      "_\n",
      "Validation stats                    IoU        F1      Prec    recall       Acc\n",
      "bg,          0.952400  0.975600  0.977600  0.973700  0.957700\n",
      "real apple   0.642900  0.782600  0.880300  0.704400  0.974300\n",
      "real pepper  0.000000  0.000000  0.000000  0.000000  1.000000\n",
      "real grape   0.744100  0.853200  0.920100  0.795500  0.982300\n",
      "fake apple   0.000000  0.000000  0.000000  0.000000  0.992800\n",
      "fake pepper  0.000000  0.000000  0.000000  0.000000  0.995200\n",
      "fake grape   0.000000  0.000000  0.000000  0.000000  0.986700\n",
      "total        0.334200  0.373057  0.396857  0.353371  0.984143\n",
      "total(-bg)   0.231167  0.272633  0.300067  0.249983  0.988550\n",
      "\n",
      "Epoch: [270][0/16]\tTime 0.485 (0.485)\tETA 0:00:07\tTraining Loss 1.1785 (1.1785)\n",
      "\n",
      "Epoch: [270][1/16]\tTime 0.179 (0.664)\tETA 0:00:02\tTraining Loss 1.1766 (1.1776)\n",
      "\n",
      "Epoch: [270][2/16]\tTime 0.188 (0.852)\tETA 0:00:02\tTraining Loss 1.1779 (1.1777)\n",
      "\n",
      "Epoch: [270][3/16]\tTime 0.189 (1.041)\tETA 0:00:02\tTraining Loss 1.1779 (1.1777)\n",
      "\n",
      "Epoch: [270][4/16]\tTime 0.186 (1.226)\tETA 0:00:02\tTraining Loss 1.1779 (1.1778)\n",
      "\n",
      "Epoch: [270][5/16]\tTime 0.186 (1.412)\tETA 0:00:02\tTraining Loss 1.1772 (1.1777)\n",
      "\n",
      "Epoch: [270][6/16]\tTime 0.194 (1.606)\tETA 0:00:01\tTraining Loss 1.1770 (1.1776)\n",
      "\n",
      "Epoch: [270][7/16]\tTime 0.185 (1.791)\tETA 0:00:01\tTraining Loss 1.1783 (1.1777)\n",
      "\n",
      "Epoch: [270][8/16]\tTime 0.193 (1.984)\tETA 0:00:01\tTraining Loss 1.1770 (1.1776)\n",
      "\n",
      "Epoch: [270][9/16]\tTime 0.188 (2.172)\tETA 0:00:01\tTraining Loss 1.1770 (1.1775)\n",
      "\n",
      "Epoch: [270][10/16]\tTime 0.183 (2.355)\tETA 0:00:01\tTraining Loss 1.1772 (1.1775)\n",
      "\n",
      "Epoch: [270][11/16]\tTime 0.192 (2.546)\tETA 0:00:00\tTraining Loss 1.1767 (1.1774)\n",
      "\n",
      "Epoch: [270][12/16]\tTime 0.200 (2.746)\tETA 0:00:00\tTraining Loss 1.1763 (1.1774)\n",
      "\n",
      "Epoch: [270][13/16]\tTime 0.191 (2.937)\tETA 0:00:00\tTraining Loss 1.1775 (1.1774)\n",
      "\n",
      "Epoch: [270][14/16]\tTime 0.186 (3.123)\tETA 0:00:00\tTraining Loss 1.1776 (1.1774)\n",
      "\n",
      "Epoch: [270][15/16]\tTime 0.112 (3.235)\tETA 0:00:00\tTraining Loss 1.1770 (1.1774)\n",
      "_\n",
      "Validation stats                    IoU        F1      Prec    recall       Acc\n",
      "bg,          0.955400  0.977100  0.978100  0.976300  0.960400\n",
      "real apple   0.641600  0.781600  0.874200  0.706900  0.974100\n",
      "real pepper  0.000000  0.000000  0.000000  0.000000  1.000000\n",
      "real grape   0.733400  0.846100  0.918700  0.784300  0.981500\n",
      "fake apple   0.000000  0.000000  0.000000  0.000000  0.995000\n",
      "fake pepper  0.000000  0.000000  0.000000  0.000000  0.996900\n",
      "fake grape   0.000000  0.000000  0.000000  0.000000  0.984400\n",
      "total        0.332914  0.372114  0.395857  0.352500  0.984614\n",
      "total(-bg)   0.229167  0.271283  0.298817  0.248533  0.988650\n",
      "\n",
      "Epoch: [271][0/16]\tTime 0.540 (0.540)\tETA 0:00:08\tTraining Loss 1.1785 (1.1785)\n",
      "\n",
      "Epoch: [271][1/16]\tTime 0.197 (0.736)\tETA 0:00:02\tTraining Loss 1.1771 (1.1778)\n",
      "\n",
      "Epoch: [271][2/16]\tTime 0.187 (0.924)\tETA 0:00:02\tTraining Loss 1.1766 (1.1774)\n",
      "\n",
      "Epoch: [271][3/16]\tTime 0.190 (1.113)\tETA 0:00:02\tTraining Loss 1.1766 (1.1772)\n",
      "\n",
      "Epoch: [271][4/16]\tTime 0.195 (1.309)\tETA 0:00:02\tTraining Loss 1.1781 (1.1774)\n",
      "\n",
      "Epoch: [271][5/16]\tTime 0.191 (1.499)\tETA 0:00:02\tTraining Loss 1.1766 (1.1772)\n",
      "\n",
      "Epoch: [271][6/16]\tTime 0.192 (1.691)\tETA 0:00:01\tTraining Loss 1.1775 (1.1773)\n",
      "\n",
      "Epoch: [271][7/16]\tTime 0.191 (1.883)\tETA 0:00:01\tTraining Loss 1.1775 (1.1773)\n",
      "\n",
      "Epoch: [271][8/16]\tTime 0.198 (2.080)\tETA 0:00:01\tTraining Loss 1.1774 (1.1773)\n",
      "\n",
      "Epoch: [271][9/16]\tTime 0.212 (2.292)\tETA 0:00:01\tTraining Loss 1.1758 (1.1772)\n",
      "\n",
      "Epoch: [271][10/16]\tTime 0.191 (2.484)\tETA 0:00:01\tTraining Loss 1.1815 (1.1776)\n",
      "\n",
      "Epoch: [271][11/16]\tTime 0.188 (2.671)\tETA 0:00:00\tTraining Loss 1.1764 (1.1775)\n",
      "\n",
      "Epoch: [271][12/16]\tTime 0.183 (2.854)\tETA 0:00:00\tTraining Loss 1.1767 (1.1774)\n",
      "\n",
      "Epoch: [271][13/16]\tTime 0.192 (3.046)\tETA 0:00:00\tTraining Loss 1.1780 (1.1774)\n",
      "\n",
      "Epoch: [271][14/16]\tTime 0.189 (3.235)\tETA 0:00:00\tTraining Loss 1.1765 (1.1774)\n",
      "\n",
      "Epoch: [271][15/16]\tTime 0.113 (3.349)\tETA 0:00:00\tTraining Loss 1.1808 (1.1775)\n",
      "_\n",
      "Validation stats                    IoU        F1      Prec    recall       Acc\n",
      "bg,          0.957700  0.978400  0.977900  0.978900  0.962400\n",
      "real apple   0.655800  0.792100  0.896500  0.709500  0.975500\n",
      "real pepper  0.000000  0.000000  0.000000  0.000000  1.000000\n",
      "real grape   0.749000  0.856400  0.916700  0.803700  0.982600\n",
      "fake apple   0.000000  0.000000  0.000000  0.000000  0.994500\n",
      "fake pepper  0.000000  0.000000  0.000000  0.000000  0.998600\n",
      "fake grape   0.000000  0.000000  0.000000  0.000000  0.986100\n",
      "total        0.337500  0.375271  0.398729  0.356014  0.985671\n",
      "total(-bg)   0.234133  0.274750  0.302200  0.252200  0.989550\n",
      "\n",
      "Epoch: [272][0/16]\tTime 0.412 (0.412)\tETA 0:00:06\tTraining Loss 1.1760 (1.1760)\n",
      "\n",
      "Epoch: [272][1/16]\tTime 0.197 (0.609)\tETA 0:00:02\tTraining Loss 1.1757 (1.1758)\n",
      "\n",
      "Epoch: [272][2/16]\tTime 0.187 (0.796)\tETA 0:00:02\tTraining Loss 1.1765 (1.1760)\n",
      "\n",
      "Epoch: [272][3/16]\tTime 0.192 (0.988)\tETA 0:00:02\tTraining Loss 1.1766 (1.1762)\n",
      "\n",
      "Epoch: [272][4/16]\tTime 0.187 (1.175)\tETA 0:00:02\tTraining Loss 1.1773 (1.1764)\n",
      "\n",
      "Epoch: [272][5/16]\tTime 0.197 (1.371)\tETA 0:00:02\tTraining Loss 1.1769 (1.1765)\n",
      "\n",
      "Epoch: [272][6/16]\tTime 0.192 (1.563)\tETA 0:00:01\tTraining Loss 1.1765 (1.1765)\n",
      "\n",
      "Epoch: [272][7/16]\tTime 0.187 (1.750)\tETA 0:00:01\tTraining Loss 1.1772 (1.1766)\n",
      "\n",
      "Epoch: [272][8/16]\tTime 0.186 (1.936)\tETA 0:00:01\tTraining Loss 1.1916 (1.1782)\n",
      "\n",
      "Epoch: [272][9/16]\tTime 0.189 (2.125)\tETA 0:00:01\tTraining Loss 1.1780 (1.1782)\n",
      "\n",
      "Epoch: [272][10/16]\tTime 0.189 (2.314)\tETA 0:00:01\tTraining Loss 1.1767 (1.1781)\n",
      "\n",
      "Epoch: [272][11/16]\tTime 0.190 (2.503)\tETA 0:00:00\tTraining Loss 1.1764 (1.1779)\n",
      "\n",
      "Epoch: [272][12/16]\tTime 0.195 (2.698)\tETA 0:00:00\tTraining Loss 1.1773 (1.1779)\n",
      "\n",
      "Epoch: [272][13/16]\tTime 0.186 (2.884)\tETA 0:00:00\tTraining Loss 1.1760 (1.1778)\n",
      "\n",
      "Epoch: [272][14/16]\tTime 0.192 (3.075)\tETA 0:00:00\tTraining Loss 1.1766 (1.1777)\n",
      "\n",
      "Epoch: [272][15/16]\tTime 0.114 (3.190)\tETA 0:00:00\tTraining Loss 1.1791 (1.1777)\n",
      "_\n",
      "Validation stats                    IoU        F1      Prec    recall       Acc\n",
      "bg,          0.958400  0.978700  0.978200  0.979300  0.963000\n",
      "real apple   0.508200  0.673900  0.897000  0.539700  0.965700\n",
      "real pepper  0.000000  0.000000  0.000000  0.000000  0.999900\n",
      "real grape   0.769300  0.869600  0.866400  0.872900  0.983100\n",
      "fake apple   0.000000  0.000000  0.000000  0.000000  0.985800\n",
      "fake pepper  0.000000  0.000000  0.000000  0.000000  0.998700\n",
      "fake grape   0.000000  0.000000  0.000000  0.000000  0.990800\n",
      "total        0.319414  0.360314  0.391657  0.341700  0.983857\n",
      "total(-bg)   0.212917  0.257250  0.293900  0.235433  0.987333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: [273][0/16]\tTime 0.462 (0.462)\tETA 0:00:07\tTraining Loss 1.1762 (1.1762)\n",
      "\n",
      "Epoch: [273][1/16]\tTime 0.192 (0.654)\tETA 0:00:02\tTraining Loss 1.1774 (1.1768)\n",
      "\n",
      "Epoch: [273][2/16]\tTime 0.183 (0.837)\tETA 0:00:02\tTraining Loss 1.1759 (1.1765)\n",
      "\n",
      "Epoch: [273][3/16]\tTime 0.188 (1.025)\tETA 0:00:02\tTraining Loss 1.1785 (1.1770)\n",
      "\n",
      "Epoch: [273][4/16]\tTime 0.184 (1.209)\tETA 0:00:02\tTraining Loss 1.1785 (1.1773)\n",
      "\n",
      "Epoch: [273][5/16]\tTime 0.183 (1.392)\tETA 0:00:02\tTraining Loss 1.1789 (1.1776)\n",
      "\n",
      "Epoch: [273][6/16]\tTime 0.197 (1.589)\tETA 0:00:01\tTraining Loss 1.1772 (1.1775)\n",
      "\n",
      "Epoch: [273][7/16]\tTime 0.186 (1.774)\tETA 0:00:01\tTraining Loss 1.1784 (1.1776)\n",
      "\n",
      "Epoch: [273][8/16]\tTime 0.191 (1.966)\tETA 0:00:01\tTraining Loss 1.1766 (1.1775)\n",
      "\n",
      "Epoch: [273][9/16]\tTime 0.187 (2.153)\tETA 0:00:01\tTraining Loss 1.1766 (1.1774)\n",
      "\n",
      "Epoch: [273][10/16]\tTime 0.187 (2.340)\tETA 0:00:01\tTraining Loss 1.1766 (1.1774)\n",
      "\n",
      "Epoch: [273][11/16]\tTime 0.196 (2.536)\tETA 0:00:00\tTraining Loss 1.1771 (1.1773)\n",
      "\n",
      "Epoch: [273][12/16]\tTime 0.190 (2.725)\tETA 0:00:00\tTraining Loss 1.1769 (1.1773)\n",
      "\n",
      "Epoch: [273][13/16]\tTime 0.190 (2.915)\tETA 0:00:00\tTraining Loss 1.1781 (1.1774)\n",
      "\n",
      "Epoch: [273][14/16]\tTime 0.190 (3.105)\tETA 0:00:00\tTraining Loss 1.1757 (1.1772)\n",
      "\n",
      "Epoch: [273][15/16]\tTime 0.115 (3.220)\tETA 0:00:00\tTraining Loss 1.1777 (1.1773)\n",
      "_\n",
      "Validation stats                    IoU        F1      Prec    recall       Acc\n",
      "bg,          0.956900  0.977900  0.977700  0.978300  0.961700\n",
      "real apple   0.656300  0.792500  0.902600  0.706400  0.975700\n",
      "real pepper  0.000000  0.000000  0.000000  0.000000  1.000000\n",
      "real grape   0.721100  0.837900  0.897500  0.785800  0.980300\n",
      "fake apple   0.000000  0.000000  0.000000  0.000000  0.991100\n",
      "fake pepper  0.000000  0.000000  0.000000  0.000000  0.999100\n",
      "fake grape   0.000000  0.000000  0.000000  0.000000  0.988100\n",
      "total        0.333471  0.372614  0.396829  0.352929  0.985143\n",
      "total(-bg)   0.229567  0.271733  0.300017  0.248700  0.989050\n",
      "\n",
      "Epoch: [274][0/16]\tTime 0.373 (0.373)\tETA 0:00:05\tTraining Loss 1.1761 (1.1761)\n",
      "\n",
      "Epoch: [274][1/16]\tTime 0.191 (0.565)\tETA 0:00:02\tTraining Loss 1.1768 (1.1765)\n",
      "\n",
      "Epoch: [274][2/16]\tTime 0.185 (0.749)\tETA 0:00:02\tTraining Loss 1.1760 (1.1763)\n",
      "\n",
      "Epoch: [274][3/16]\tTime 0.184 (0.933)\tETA 0:00:02\tTraining Loss 1.1789 (1.1770)\n",
      "\n",
      "Epoch: [274][4/16]\tTime 0.180 (1.113)\tETA 0:00:02\tTraining Loss 1.1788 (1.1773)\n",
      "\n",
      "Epoch: [274][5/16]\tTime 0.187 (1.300)\tETA 0:00:02\tTraining Loss 1.1785 (1.1775)\n",
      "\n",
      "Epoch: [274][6/16]\tTime 0.189 (1.489)\tETA 0:00:01\tTraining Loss 1.1768 (1.1774)\n",
      "\n",
      "Epoch: [274][7/16]\tTime 0.192 (1.681)\tETA 0:00:01\tTraining Loss 1.1770 (1.1774)\n",
      "\n",
      "Epoch: [274][8/16]\tTime 0.199 (1.880)\tETA 0:00:01\tTraining Loss 1.1767 (1.1773)\n",
      "\n",
      "Epoch: [274][9/16]\tTime 0.185 (2.065)\tETA 0:00:01\tTraining Loss 1.1761 (1.1772)\n",
      "\n",
      "Epoch: [274][10/16]\tTime 0.189 (2.254)\tETA 0:00:01\tTraining Loss 1.1773 (1.1772)\n",
      "\n",
      "Epoch: [274][11/16]\tTime 0.183 (2.438)\tETA 0:00:00\tTraining Loss 1.1762 (1.1771)\n",
      "\n",
      "Epoch: [274][12/16]\tTime 0.202 (2.639)\tETA 0:00:00\tTraining Loss 1.1782 (1.1772)\n",
      "\n",
      "Epoch: [274][13/16]\tTime 0.184 (2.823)\tETA 0:00:00\tTraining Loss 1.1773 (1.1772)\n",
      "\n",
      "Epoch: [274][14/16]\tTime 0.187 (3.010)\tETA 0:00:00\tTraining Loss 1.1761 (1.1771)\n",
      "\n",
      "Epoch: [274][15/16]\tTime 0.112 (3.122)\tETA 0:00:00\tTraining Loss 1.1800 (1.1772)\n",
      "_\n",
      "Validation stats                    IoU        F1      Prec    recall       Acc\n",
      "bg,          0.956400  0.977700  0.978200  0.977200  0.961300\n",
      "real apple   0.631600  0.774200  0.896800  0.681100  0.973900\n",
      "real pepper  0.000000  0.000000  0.000000  0.000000  1.000000\n",
      "real grape   0.733200  0.846000  0.910400  0.790300  0.981400\n",
      "fake apple   0.000000  0.000000  0.000000  0.000000  0.990200\n",
      "fake pepper  0.000000  0.000000  0.000000  0.000000  0.998400\n",
      "fake grape   0.000000  0.000000  0.000000  0.000000  0.986100\n",
      "total        0.331600  0.371129  0.397914  0.349800  0.984471\n",
      "total(-bg)   0.227467  0.270033  0.301200  0.245233  0.988333\n",
      "\n",
      "Epoch: [275][0/16]\tTime 0.473 (0.473)\tETA 0:00:07\tTraining Loss 1.1793 (1.1793)\n",
      "\n",
      "Epoch: [275][1/16]\tTime 0.184 (0.658)\tETA 0:00:02\tTraining Loss 1.1773 (1.1783)\n",
      "\n",
      "Epoch: [275][2/16]\tTime 0.186 (0.844)\tETA 0:00:02\tTraining Loss 1.1766 (1.1777)\n",
      "\n",
      "Epoch: [275][3/16]\tTime 0.186 (1.029)\tETA 0:00:02\tTraining Loss 1.1762 (1.1773)\n",
      "\n",
      "Epoch: [275][4/16]\tTime 0.182 (1.212)\tETA 0:00:02\tTraining Loss 1.1768 (1.1772)\n",
      "\n",
      "Epoch: [275][5/16]\tTime 0.186 (1.398)\tETA 0:00:02\tTraining Loss 1.1772 (1.1772)\n",
      "\n",
      "Epoch: [275][6/16]\tTime 0.187 (1.585)\tETA 0:00:01\tTraining Loss 1.1770 (1.1772)\n",
      "\n",
      "Epoch: [275][7/16]\tTime 0.184 (1.769)\tETA 0:00:01\tTraining Loss 1.1763 (1.1771)\n",
      "\n",
      "Epoch: [275][8/16]\tTime 0.186 (1.956)\tETA 0:00:01\tTraining Loss 1.1792 (1.1773)\n",
      "\n",
      "Epoch: [275][9/16]\tTime 0.184 (2.140)\tETA 0:00:01\tTraining Loss 1.1763 (1.1772)\n",
      "\n",
      "Epoch: [275][10/16]\tTime 0.192 (2.332)\tETA 0:00:01\tTraining Loss 1.1799 (1.1775)\n",
      "\n",
      "Epoch: [275][11/16]\tTime 0.182 (2.514)\tETA 0:00:00\tTraining Loss 1.1753 (1.1773)\n",
      "\n",
      "Epoch: [275][12/16]\tTime 0.182 (2.696)\tETA 0:00:00\tTraining Loss 1.1767 (1.1772)\n",
      "\n",
      "Epoch: [275][13/16]\tTime 0.180 (2.876)\tETA 0:00:00\tTraining Loss 1.1768 (1.1772)\n",
      "\n",
      "Epoch: [275][14/16]\tTime 0.193 (3.069)\tETA 0:00:00\tTraining Loss 1.1758 (1.1771)\n",
      "\n",
      "Epoch: [275][15/16]\tTime 0.114 (3.183)\tETA 0:00:00\tTraining Loss 1.1786 (1.1772)\n",
      "_\n",
      "Validation stats                    IoU        F1      Prec    recall       Acc\n",
      "bg,          0.957900  0.978400  0.978000  0.979000  0.962600\n",
      "real apple   0.660500  0.795500  0.911000  0.706100  0.976200\n",
      "real pepper  0.000000  0.000000  0.000000  0.000000  1.000000\n",
      "real grape   0.757600  0.862100  0.908400  0.820300  0.983000\n",
      "fake apple   0.000000  0.000000  0.000000  0.000000  0.993200\n",
      "fake pepper  0.000000  0.000000  0.000000  0.000000  0.997500\n",
      "fake grape   0.000000  0.000000  0.000000  0.000000  0.989100\n",
      "total        0.339429  0.376571  0.399629  0.357914  0.985943\n",
      "total(-bg)   0.236350  0.276267  0.303233  0.254400  0.989833\n",
      "\n",
      "Epoch: [276][0/16]\tTime 0.479 (0.479)\tETA 0:00:07\tTraining Loss 1.1774 (1.1774)\n",
      "\n",
      "Epoch: [276][1/16]\tTime 0.185 (0.665)\tETA 0:00:02\tTraining Loss 1.1757 (1.1766)\n",
      "\n",
      "Epoch: [276][2/16]\tTime 0.183 (0.848)\tETA 0:00:02\tTraining Loss 1.1761 (1.1764)\n",
      "\n",
      "Epoch: [276][3/16]\tTime 0.188 (1.036)\tETA 0:00:02\tTraining Loss 1.1764 (1.1764)\n",
      "\n",
      "Epoch: [276][4/16]\tTime 0.186 (1.222)\tETA 0:00:02\tTraining Loss 1.1783 (1.1768)\n",
      "\n",
      "Epoch: [276][5/16]\tTime 0.185 (1.407)\tETA 0:00:02\tTraining Loss 1.1757 (1.1766)\n",
      "\n",
      "Epoch: [276][6/16]\tTime 0.185 (1.592)\tETA 0:00:01\tTraining Loss 1.1777 (1.1768)\n",
      "\n",
      "Epoch: [276][7/16]\tTime 0.184 (1.776)\tETA 0:00:01\tTraining Loss 1.1756 (1.1766)\n",
      "\n",
      "Epoch: [276][8/16]\tTime 0.184 (1.960)\tETA 0:00:01\tTraining Loss 1.1771 (1.1767)\n",
      "\n",
      "Epoch: [276][9/16]\tTime 0.190 (2.149)\tETA 0:00:01\tTraining Loss 1.1767 (1.1767)\n",
      "\n",
      "Epoch: [276][10/16]\tTime 0.187 (2.336)\tETA 0:00:01\tTraining Loss 1.1773 (1.1767)\n",
      "\n",
      "Epoch: [276][11/16]\tTime 0.193 (2.529)\tETA 0:00:00\tTraining Loss 1.1762 (1.1767)\n",
      "\n",
      "Epoch: [276][12/16]\tTime 0.185 (2.714)\tETA 0:00:00\tTraining Loss 1.1759 (1.1766)\n",
      "\n",
      "Epoch: [276][13/16]\tTime 0.182 (2.896)\tETA 0:00:00\tTraining Loss 1.1762 (1.1766)\n",
      "\n",
      "Epoch: [276][14/16]\tTime 0.186 (3.082)\tETA 0:00:00\tTraining Loss 1.1770 (1.1766)\n",
      "\n",
      "Epoch: [276][15/16]\tTime 0.115 (3.197)\tETA 0:00:00\tTraining Loss 1.1780 (1.1767)\n",
      "_\n",
      "Validation stats                    IoU        F1      Prec    recall       Acc\n",
      "bg,          0.957300  0.978100  0.978400  0.977900  0.962100\n",
      "real apple   0.497900  0.664800  0.872600  0.536900  0.964400\n",
      "real pepper  0.000000  0.000000  0.000000  0.000000  0.999800\n",
      "real grape   0.773700  0.872300  0.890900  0.854600  0.983800\n",
      "fake apple   0.000000  0.000000  0.000000  0.000000  0.986500\n",
      "fake pepper  0.000000  0.000000  0.000000  0.000000  0.996600\n",
      "fake grape   0.000000  0.000000  0.000000  0.000000  0.988800\n",
      "total        0.318414  0.359314  0.391700  0.338486  0.983143\n",
      "total(-bg)   0.211933  0.256183  0.293917  0.231917  0.986650\n",
      "\n",
      "Epoch: [277][0/16]\tTime 0.454 (0.454)\tETA 0:00:07\tTraining Loss 1.1759 (1.1759)\n",
      "\n",
      "Epoch: [277][1/16]\tTime 0.179 (0.634)\tETA 0:00:02\tTraining Loss 1.1783 (1.1771)\n",
      "\n",
      "Epoch: [277][2/16]\tTime 0.192 (0.826)\tETA 0:00:02\tTraining Loss 1.1763 (1.1768)\n",
      "\n",
      "Epoch: [277][3/16]\tTime 0.190 (1.016)\tETA 0:00:02\tTraining Loss 1.1759 (1.1766)\n",
      "\n",
      "Epoch: [277][4/16]\tTime 0.190 (1.206)\tETA 0:00:02\tTraining Loss 1.1754 (1.1764)\n",
      "\n",
      "Epoch: [277][5/16]\tTime 0.200 (1.406)\tETA 0:00:02\tTraining Loss 1.1751 (1.1762)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: [277][6/16]\tTime 0.190 (1.596)\tETA 0:00:01\tTraining Loss 1.1790 (1.1766)\n",
      "\n",
      "Epoch: [277][7/16]\tTime 0.188 (1.785)\tETA 0:00:01\tTraining Loss 1.1762 (1.1765)\n",
      "\n",
      "Epoch: [277][8/16]\tTime 0.196 (1.981)\tETA 0:00:01\tTraining Loss 1.1769 (1.1766)\n",
      "\n",
      "Epoch: [277][9/16]\tTime 0.187 (2.168)\tETA 0:00:01\tTraining Loss 1.1768 (1.1766)\n",
      "\n",
      "Epoch: [277][10/16]\tTime 0.188 (2.355)\tETA 0:00:01\tTraining Loss 1.1776 (1.1767)\n",
      "\n",
      "Epoch: [277][11/16]\tTime 0.187 (2.543)\tETA 0:00:00\tTraining Loss 1.1763 (1.1766)\n",
      "\n",
      "Epoch: [277][12/16]\tTime 0.291 (2.834)\tETA 0:00:01\tTraining Loss 1.1766 (1.1766)\n",
      "\n",
      "Epoch: [277][13/16]\tTime 0.190 (3.024)\tETA 0:00:00\tTraining Loss 1.1766 (1.1766)\n",
      "\n",
      "Epoch: [277][14/16]\tTime 0.191 (3.215)\tETA 0:00:00\tTraining Loss 1.1771 (1.1767)\n",
      "\n",
      "Epoch: [277][15/16]\tTime 0.115 (3.330)\tETA 0:00:00\tTraining Loss 1.1800 (1.1768)\n",
      "_\n",
      "Validation stats                    IoU        F1      Prec    recall       Acc\n",
      "bg,          0.955700  0.977300  0.978600  0.976000  0.960600\n",
      "real apple   0.453300  0.623700  0.862600  0.488500  0.961300\n",
      "real pepper  0.000000  0.000000  0.000000  0.000000  0.999700\n",
      "real grape   0.765100  0.866900  0.887100  0.847600  0.983100\n",
      "fake apple   0.000000  0.000000  0.000000  0.000000  0.982300\n",
      "fake pepper  0.000000  0.000000  0.000000  0.000000  0.996100\n",
      "fake grape   0.000000  0.000000  0.000000  0.000000  0.988300\n",
      "total        0.310586  0.352557  0.389757  0.330300  0.981629\n",
      "total(-bg)   0.203067  0.248433  0.291617  0.222683  0.985133\n",
      "\n",
      "Epoch: [278][0/16]\tTime 0.470 (0.470)\tETA 0:00:07\tTraining Loss 1.1855 (1.1855)\n",
      "\n",
      "Epoch: [278][1/16]\tTime 0.188 (0.658)\tETA 0:00:02\tTraining Loss 1.1766 (1.1810)\n",
      "\n",
      "Epoch: [278][2/16]\tTime 0.182 (0.840)\tETA 0:00:02\tTraining Loss 1.1769 (1.1796)\n",
      "\n",
      "Epoch: [278][3/16]\tTime 0.190 (1.031)\tETA 0:00:02\tTraining Loss 1.1754 (1.1786)\n",
      "\n",
      "Epoch: [278][4/16]\tTime 0.184 (1.215)\tETA 0:00:02\tTraining Loss 1.1767 (1.1782)\n",
      "\n",
      "Epoch: [278][5/16]\tTime 0.176 (1.390)\tETA 0:00:01\tTraining Loss 1.1753 (1.1777)\n",
      "\n",
      "Epoch: [278][6/16]\tTime 0.192 (1.582)\tETA 0:00:01\tTraining Loss 1.1767 (1.1776)\n",
      "\n",
      "Epoch: [278][7/16]\tTime 0.186 (1.768)\tETA 0:00:01\tTraining Loss 1.1759 (1.1774)\n",
      "\n",
      "Epoch: [278][8/16]\tTime 0.181 (1.950)\tETA 0:00:01\tTraining Loss 1.1753 (1.1771)\n",
      "\n",
      "Epoch: [278][9/16]\tTime 0.187 (2.136)\tETA 0:00:01\tTraining Loss 1.1758 (1.1770)\n",
      "\n",
      "Epoch: [278][10/16]\tTime 0.186 (2.322)\tETA 0:00:01\tTraining Loss 1.1768 (1.1770)\n",
      "\n",
      "Epoch: [278][11/16]\tTime 0.189 (2.512)\tETA 0:00:00\tTraining Loss 1.1761 (1.1769)\n",
      "\n",
      "Epoch: [278][12/16]\tTime 0.198 (2.710)\tETA 0:00:00\tTraining Loss 1.1751 (1.1768)\n",
      "\n",
      "Epoch: [278][13/16]\tTime 0.195 (2.905)\tETA 0:00:00\tTraining Loss 1.1758 (1.1767)\n",
      "\n",
      "Epoch: [278][14/16]\tTime 0.197 (3.101)\tETA 0:00:00\tTraining Loss 1.1759 (1.1766)\n",
      "\n",
      "Epoch: [278][15/16]\tTime 0.118 (3.220)\tETA 0:00:00\tTraining Loss 1.1793 (1.1767)\n",
      "_\n",
      "Validation stats                    IoU        F1      Prec    recall       Acc\n",
      "bg,          0.956800  0.977900  0.978500  0.977400  0.961700\n",
      "real apple   0.468700  0.638200  0.870800  0.503700  0.962500\n",
      "real pepper  0.000000  0.000000  0.000000  0.000000  0.999700\n",
      "real grape   0.759300  0.863100  0.892400  0.835700  0.982800\n",
      "fake apple   0.000000  0.000000  0.000000  0.000000  0.983500\n",
      "fake pepper  0.000000  0.000000  0.000000  0.000000  0.996800\n",
      "fake grape   0.000000  0.000000  0.000000  0.000000  0.987300\n",
      "total        0.312114  0.354171  0.391671  0.330971  0.982043\n",
      "total(-bg)   0.204667  0.250217  0.293867  0.223233  0.985433\n",
      "\n",
      "Epoch: [279][0/16]\tTime 0.500 (0.500)\tETA 0:00:07\tTraining Loss 1.1766 (1.1766)\n",
      "\n",
      "Epoch: [279][1/16]\tTime 0.174 (0.673)\tETA 0:00:02\tTraining Loss 1.1776 (1.1771)\n",
      "\n",
      "Epoch: [279][2/16]\tTime 0.190 (0.863)\tETA 0:00:02\tTraining Loss 1.1755 (1.1766)\n",
      "\n",
      "Epoch: [279][3/16]\tTime 0.187 (1.050)\tETA 0:00:02\tTraining Loss 1.1757 (1.1764)\n",
      "\n",
      "Epoch: [279][4/16]\tTime 0.181 (1.231)\tETA 0:00:02\tTraining Loss 1.1751 (1.1761)\n",
      "\n",
      "Epoch: [279][5/16]\tTime 0.202 (1.433)\tETA 0:00:02\tTraining Loss 1.1763 (1.1761)\n",
      "\n",
      "Epoch: [279][6/16]\tTime 0.196 (1.629)\tETA 0:00:01\tTraining Loss 1.1775 (1.1763)\n",
      "\n",
      "Epoch: [279][7/16]\tTime 0.188 (1.816)\tETA 0:00:01\tTraining Loss 1.1756 (1.1762)\n",
      "\n",
      "Epoch: [279][8/16]\tTime 0.189 (2.005)\tETA 0:00:01\tTraining Loss 1.1760 (1.1762)\n",
      "\n",
      "Epoch: [279][9/16]\tTime 0.191 (2.196)\tETA 0:00:01\tTraining Loss 1.1755 (1.1761)\n",
      "\n",
      "Epoch: [279][10/16]\tTime 0.187 (2.383)\tETA 0:00:01\tTraining Loss 1.1797 (1.1765)\n",
      "\n",
      "Epoch: [279][11/16]\tTime 0.190 (2.573)\tETA 0:00:00\tTraining Loss 1.1753 (1.1764)\n",
      "\n",
      "Epoch: [279][12/16]\tTime 0.182 (2.756)\tETA 0:00:00\tTraining Loss 1.1806 (1.1767)\n",
      "\n",
      "Epoch: [279][13/16]\tTime 0.194 (2.950)\tETA 0:00:00\tTraining Loss 1.1758 (1.1766)\n",
      "\n",
      "Epoch: [279][14/16]\tTime 0.188 (3.138)\tETA 0:00:00\tTraining Loss 1.1774 (1.1767)\n",
      "\n",
      "Epoch: [279][15/16]\tTime 0.118 (3.256)\tETA 0:00:00\tTraining Loss 1.1755 (1.1766)\n",
      "_\n",
      "Validation stats                    IoU        F1      Prec    recall       Acc\n",
      "bg,          0.956000  0.977400  0.978400  0.976600  0.960900\n",
      "real apple   0.454100  0.624600  0.871700  0.486600  0.961600\n",
      "real pepper  0.000000  0.000000  0.000000  0.000000  0.999900\n",
      "real grape   0.739000  0.849900  0.881300  0.820700  0.981200\n",
      "fake apple   0.000000  0.000000  0.000000  0.000000  0.982200\n",
      "fake pepper  0.000000  0.000000  0.000000  0.000000  0.996700\n",
      "fake grape   0.000000  0.000000  0.000000  0.000000  0.986200\n",
      "total        0.307014  0.350271  0.390200  0.326271  0.981243\n",
      "total(-bg)   0.198850  0.245750  0.292167  0.217883  0.984633\n",
      "\n",
      "Epoch: [280][0/16]\tTime 0.463 (0.463)\tETA 0:00:07\tTraining Loss 1.1758 (1.1758)\n",
      "\n",
      "Epoch: [280][1/16]\tTime 0.188 (0.651)\tETA 0:00:02\tTraining Loss 1.1755 (1.1756)\n",
      "\n",
      "Epoch: [280][2/16]\tTime 0.185 (0.836)\tETA 0:00:02\tTraining Loss 1.1762 (1.1758)\n",
      "\n",
      "Epoch: [280][3/16]\tTime 0.184 (1.019)\tETA 0:00:02\tTraining Loss 1.1761 (1.1759)\n",
      "\n",
      "Epoch: [280][4/16]\tTime 0.191 (1.210)\tETA 0:00:02\tTraining Loss 1.1755 (1.1758)\n",
      "\n",
      "Epoch: [280][5/16]\tTime 0.188 (1.398)\tETA 0:00:02\tTraining Loss 1.1756 (1.1758)\n",
      "\n",
      "Epoch: [280][6/16]\tTime 0.196 (1.594)\tETA 0:00:01\tTraining Loss 1.1760 (1.1758)\n",
      "\n",
      "Epoch: [280][7/16]\tTime 0.189 (1.783)\tETA 0:00:01\tTraining Loss 1.1751 (1.1757)\n",
      "\n",
      "Epoch: [280][8/16]\tTime 0.194 (1.976)\tETA 0:00:01\tTraining Loss 1.1795 (1.1762)\n",
      "\n",
      "Epoch: [280][9/16]\tTime 0.186 (2.162)\tETA 0:00:01\tTraining Loss 1.1766 (1.1762)\n",
      "\n",
      "Epoch: [280][10/16]\tTime 0.188 (2.350)\tETA 0:00:01\tTraining Loss 1.1762 (1.1762)\n",
      "\n",
      "Epoch: [280][11/16]\tTime 0.192 (2.542)\tETA 0:00:00\tTraining Loss 1.1760 (1.1762)\n",
      "\n",
      "Epoch: [280][12/16]\tTime 0.201 (2.743)\tETA 0:00:00\tTraining Loss 1.1798 (1.1765)\n",
      "\n",
      "Epoch: [280][13/16]\tTime 0.185 (2.928)\tETA 0:00:00\tTraining Loss 1.1757 (1.1764)\n",
      "\n",
      "Epoch: [280][14/16]\tTime 0.190 (3.118)\tETA 0:00:00\tTraining Loss 1.1757 (1.1764)\n",
      "\n",
      "Epoch: [280][15/16]\tTime 0.114 (3.232)\tETA 0:00:00\tTraining Loss 1.1793 (1.1765)\n",
      "_\n",
      "Validation stats                    IoU        F1     Prec    recall       Acc\n",
      "bg,          0.958500  0.978800  0.97850  0.979200  0.963200\n",
      "real apple   0.672600  0.804200  0.91870  0.715100  0.977100\n",
      "real pepper  0.000000  0.000000  0.00000  0.000000  1.000000\n",
      "real grape   0.774500  0.872900  0.89720  0.850000  0.984000\n",
      "fake apple   0.000000  0.000000  0.00000  0.000000  0.993700\n",
      "fake pepper  0.000000  0.000000  0.00000  0.000000  0.998800\n",
      "fake grape   0.000000  0.000000  0.00000  0.000000  0.990200\n",
      "total        0.343657  0.379414  0.39920  0.363471  0.986714\n",
      "total(-bg)   0.241183  0.279517  0.30265  0.260850  0.990633\n",
      "\n",
      "Epoch: [281][0/16]\tTime 0.538 (0.538)\tETA 0:00:08\tTraining Loss 1.1763 (1.1763)\n",
      "\n",
      "Epoch: [281][1/16]\tTime 0.182 (0.720)\tETA 0:00:02\tTraining Loss 1.1770 (1.1767)\n",
      "\n",
      "Epoch: [281][2/16]\tTime 0.197 (0.916)\tETA 0:00:02\tTraining Loss 1.1808 (1.1780)\n",
      "\n",
      "Epoch: [281][3/16]\tTime 0.190 (1.106)\tETA 0:00:02\tTraining Loss 1.1759 (1.1775)\n",
      "\n",
      "Epoch: [281][4/16]\tTime 0.193 (1.300)\tETA 0:00:02\tTraining Loss 1.1783 (1.1777)\n",
      "\n",
      "Epoch: [281][5/16]\tTime 0.189 (1.488)\tETA 0:00:02\tTraining Loss 1.1763 (1.1774)\n",
      "\n",
      "Epoch: [281][6/16]\tTime 0.208 (1.696)\tETA 0:00:02\tTraining Loss 1.1761 (1.1773)\n",
      "\n",
      "Epoch: [281][7/16]\tTime 0.196 (1.891)\tETA 0:00:01\tTraining Loss 1.1751 (1.1770)\n",
      "\n",
      "Epoch: [281][8/16]\tTime 0.181 (2.073)\tETA 0:00:01\tTraining Loss 1.1767 (1.1770)\n",
      "\n",
      "Epoch: [281][9/16]\tTime 0.195 (2.268)\tETA 0:00:01\tTraining Loss 1.1760 (1.1769)\n",
      "\n",
      "Epoch: [281][10/16]\tTime 0.183 (2.451)\tETA 0:00:01\tTraining Loss 1.1754 (1.1767)\n",
      "\n",
      "Epoch: [281][11/16]\tTime 0.186 (2.637)\tETA 0:00:00\tTraining Loss 1.1747 (1.1766)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: [281][12/16]\tTime 0.190 (2.826)\tETA 0:00:00\tTraining Loss 1.1779 (1.1767)\n",
      "\n",
      "Epoch: [281][13/16]\tTime 0.181 (3.007)\tETA 0:00:00\tTraining Loss 1.1754 (1.1766)\n",
      "\n",
      "Epoch: [281][14/16]\tTime 0.194 (3.201)\tETA 0:00:00\tTraining Loss 1.1749 (1.1765)\n",
      "\n",
      "Epoch: [281][15/16]\tTime 0.114 (3.315)\tETA 0:00:00\tTraining Loss 1.1796 (1.1766)\n",
      "_\n",
      "Validation stats                    IoU        F1      Prec    recall       Acc\n",
      "bg,          0.956200  0.977600  0.978800  0.976500  0.961100\n",
      "real apple   0.496800  0.663700  0.848700  0.545000  0.963700\n",
      "real pepper  0.000000  0.000000  0.000000  0.000000  0.999800\n",
      "real grape   0.778500  0.875400  0.887700  0.863600  0.984100\n",
      "fake apple   0.000000  0.000000  0.000000  0.000000  0.984900\n",
      "fake pepper  0.000000  0.000000  0.000000  0.000000  0.998800\n",
      "fake grape   0.000000  0.000000  0.000000  0.000000  0.989100\n",
      "total        0.318786  0.359529  0.387886  0.340729  0.983071\n",
      "total(-bg)   0.212550  0.256517  0.289400  0.234767  0.986733\n",
      "\n",
      "Epoch: [282][0/16]\tTime 0.503 (0.503)\tETA 0:00:08\tTraining Loss 1.1767 (1.1767)\n",
      "\n",
      "Epoch: [282][1/16]\tTime 0.180 (0.683)\tETA 0:00:02\tTraining Loss 1.1757 (1.1762)\n",
      "\n",
      "Epoch: [282][2/16]\tTime 0.192 (0.875)\tETA 0:00:02\tTraining Loss 1.1757 (1.1761)\n",
      "\n",
      "Epoch: [282][3/16]\tTime 0.187 (1.062)\tETA 0:00:02\tTraining Loss 1.1748 (1.1758)\n",
      "\n",
      "Epoch: [282][4/16]\tTime 0.186 (1.248)\tETA 0:00:02\tTraining Loss 1.1763 (1.1759)\n",
      "\n",
      "Epoch: [282][5/16]\tTime 0.183 (1.431)\tETA 0:00:02\tTraining Loss 1.1751 (1.1757)\n",
      "\n",
      "Epoch: [282][6/16]\tTime 0.201 (1.632)\tETA 0:00:02\tTraining Loss 1.1762 (1.1758)\n",
      "\n",
      "Epoch: [282][7/16]\tTime 0.189 (1.820)\tETA 0:00:01\tTraining Loss 1.1760 (1.1758)\n",
      "\n",
      "Epoch: [282][8/16]\tTime 0.192 (2.012)\tETA 0:00:01\tTraining Loss 1.1773 (1.1760)\n",
      "\n",
      "Epoch: [282][9/16]\tTime 0.191 (2.203)\tETA 0:00:01\tTraining Loss 1.1774 (1.1761)\n",
      "\n",
      "Epoch: [282][10/16]\tTime 0.189 (2.392)\tETA 0:00:01\tTraining Loss 1.1754 (1.1760)\n",
      "\n",
      "Epoch: [282][11/16]\tTime 0.190 (2.582)\tETA 0:00:00\tTraining Loss 1.1757 (1.1760)\n",
      "\n",
      "Epoch: [282][12/16]\tTime 0.309 (2.891)\tETA 0:00:01\tTraining Loss 1.1755 (1.1760)\n",
      "\n",
      "Epoch: [282][13/16]\tTime 0.196 (3.087)\tETA 0:00:00\tTraining Loss 1.1761 (1.1760)\n",
      "\n",
      "Epoch: [282][14/16]\tTime 0.177 (3.264)\tETA 0:00:00\tTraining Loss 1.1759 (1.1760)\n",
      "\n",
      "Epoch: [282][15/16]\tTime 0.113 (3.377)\tETA 0:00:00\tTraining Loss 1.1752 (1.1760)\n",
      "_\n",
      "Validation stats                    IoU        F1      Prec    recall       Acc\n",
      "bg,          0.958600  0.978800  0.978600  0.979100  0.963200\n",
      "real apple   0.667800  0.800800  0.902500  0.719800  0.976500\n",
      "real pepper  0.000000  0.000000  0.000000  0.000000  1.000000\n",
      "real grape   0.758100  0.862300  0.891500  0.835200  0.982700\n",
      "fake apple   0.000000  0.000000  0.000000  0.000000  0.994000\n",
      "fake pepper  0.000000  0.000000  0.000000  0.000000  0.999000\n",
      "fake grape   0.000000  0.000000  0.000000  0.000000  0.990000\n",
      "total        0.340643  0.377414  0.396086  0.362014  0.986486\n",
      "total(-bg)   0.237650  0.277183  0.299000  0.259167  0.990367\n",
      "\n",
      "Epoch: [283][0/16]\tTime 0.475 (0.475)\tETA 0:00:07\tTraining Loss 1.1784 (1.1784)\n",
      "\n",
      "Epoch: [283][1/16]\tTime 0.182 (0.657)\tETA 0:00:02\tTraining Loss 1.1780 (1.1782)\n",
      "\n",
      "Epoch: [283][2/16]\tTime 0.189 (0.846)\tETA 0:00:02\tTraining Loss 1.1746 (1.1770)\n",
      "\n",
      "Epoch: [283][3/16]\tTime 0.288 (1.134)\tETA 0:00:03\tTraining Loss 1.1759 (1.1767)\n",
      "\n",
      "Epoch: [283][4/16]\tTime 0.183 (1.317)\tETA 0:00:02\tTraining Loss 1.1750 (1.1764)\n",
      "\n",
      "Epoch: [283][5/16]\tTime 0.193 (1.510)\tETA 0:00:02\tTraining Loss 1.1754 (1.1762)\n",
      "\n",
      "Epoch: [283][6/16]\tTime 0.190 (1.700)\tETA 0:00:01\tTraining Loss 1.1765 (1.1763)\n",
      "\n",
      "Epoch: [283][7/16]\tTime 0.183 (1.884)\tETA 0:00:01\tTraining Loss 1.1754 (1.1762)\n",
      "\n",
      "Epoch: [283][8/16]\tTime 0.186 (2.069)\tETA 0:00:01\tTraining Loss 1.1755 (1.1761)\n",
      "\n",
      "Epoch: [283][9/16]\tTime 0.181 (2.251)\tETA 0:00:01\tTraining Loss 1.1763 (1.1761)\n",
      "\n",
      "Epoch: [283][10/16]\tTime 0.184 (2.435)\tETA 0:00:01\tTraining Loss 1.1754 (1.1760)\n",
      "\n",
      "Epoch: [283][11/16]\tTime 0.191 (2.626)\tETA 0:00:00\tTraining Loss 1.1749 (1.1759)\n",
      "\n",
      "Epoch: [283][12/16]\tTime 0.184 (2.809)\tETA 0:00:00\tTraining Loss 1.1743 (1.1758)\n",
      "\n",
      "Epoch: [283][13/16]\tTime 0.189 (2.998)\tETA 0:00:00\tTraining Loss 1.1750 (1.1758)\n",
      "\n",
      "Epoch: [283][14/16]\tTime 0.190 (3.188)\tETA 0:00:00\tTraining Loss 1.1812 (1.1761)\n",
      "\n",
      "Epoch: [283][15/16]\tTime 0.116 (3.304)\tETA 0:00:00\tTraining Loss 1.1774 (1.1762)\n",
      "_\n",
      "Validation stats                    IoU        F1      Prec    recall       Acc\n",
      "bg,          0.957200  0.978100  0.977900  0.978300  0.962000\n",
      "real apple   0.466700  0.636300  0.879700  0.498500  0.962600\n",
      "real pepper  0.000000  0.000000  0.000000  0.000000  0.999700\n",
      "real grape   0.759200  0.863000  0.891100  0.836800  0.982800\n",
      "fake apple   0.000000  0.000000  0.000000  0.000000  0.983500\n",
      "fake pepper  0.000000  0.000000  0.000000  0.000000  0.996600\n",
      "fake grape   0.000000  0.000000  0.000000  0.000000  0.988100\n",
      "total        0.311871  0.353914  0.392671  0.330514  0.982186\n",
      "total(-bg)   0.204317  0.249883  0.295133  0.222550  0.985550\n",
      "\n",
      "Epoch: [284][0/16]\tTime 0.475 (0.475)\tETA 0:00:07\tTraining Loss 1.1775 (1.1775)\n",
      "\n",
      "Epoch: [284][1/16]\tTime 0.185 (0.659)\tETA 0:00:02\tTraining Loss 1.1751 (1.1763)\n",
      "\n",
      "Epoch: [284][2/16]\tTime 0.185 (0.844)\tETA 0:00:02\tTraining Loss 1.1755 (1.1760)\n",
      "\n",
      "Epoch: [284][3/16]\tTime 0.195 (1.039)\tETA 0:00:02\tTraining Loss 1.1759 (1.1760)\n",
      "\n",
      "Epoch: [284][4/16]\tTime 0.181 (1.220)\tETA 0:00:02\tTraining Loss 1.1756 (1.1759)\n",
      "\n",
      "Epoch: [284][5/16]\tTime 0.186 (1.406)\tETA 0:00:02\tTraining Loss 1.1767 (1.1760)\n",
      "\n",
      "Epoch: [284][6/16]\tTime 0.181 (1.587)\tETA 0:00:01\tTraining Loss 1.1749 (1.1759)\n",
      "\n",
      "Epoch: [284][7/16]\tTime 0.187 (1.775)\tETA 0:00:01\tTraining Loss 1.1746 (1.1757)\n",
      "\n",
      "Epoch: [284][8/16]\tTime 0.188 (1.963)\tETA 0:00:01\tTraining Loss 1.1755 (1.1757)\n",
      "\n",
      "Epoch: [284][9/16]\tTime 0.188 (2.151)\tETA 0:00:01\tTraining Loss 1.1765 (1.1758)\n",
      "\n",
      "Epoch: [284][10/16]\tTime 0.202 (2.353)\tETA 0:00:01\tTraining Loss 1.1747 (1.1757)\n",
      "\n",
      "Epoch: [284][11/16]\tTime 0.190 (2.543)\tETA 0:00:00\tTraining Loss 1.1777 (1.1759)\n",
      "\n",
      "Epoch: [284][12/16]\tTime 0.187 (2.729)\tETA 0:00:00\tTraining Loss 1.1746 (1.1758)\n",
      "\n",
      "Epoch: [284][13/16]\tTime 0.186 (2.915)\tETA 0:00:00\tTraining Loss 1.1799 (1.1761)\n",
      "\n",
      "Epoch: [284][14/16]\tTime 0.183 (3.099)\tETA 0:00:00\tTraining Loss 1.1765 (1.1761)\n",
      "\n",
      "Epoch: [284][15/16]\tTime 0.113 (3.212)\tETA 0:00:00\tTraining Loss 1.1758 (1.1761)\n",
      "_\n",
      "Validation stats                    IoU        F1      Prec    recall       Acc\n",
      "bg,          0.955400  0.977100  0.979000  0.975400  0.960400\n",
      "real apple   0.482200  0.650600  0.860000  0.523300  0.963100\n",
      "real pepper  0.000000  0.000000  0.000000  0.000000  0.999800\n",
      "real grape   0.763100  0.865600  0.878100  0.853500  0.982800\n",
      "fake apple   0.000000  0.000000  0.000000  0.000000  0.984700\n",
      "fake pepper  0.000000  0.000000  0.000000  0.000000  0.996300\n",
      "fake grape   0.000000  0.000000  0.000000  0.000000  0.988400\n",
      "total        0.314386  0.356186  0.388157  0.336029  0.982214\n",
      "total(-bg)   0.207550  0.252700  0.289683  0.229467  0.985850\n",
      "\n",
      "Epoch: [285][0/16]\tTime 0.472 (0.472)\tETA 0:00:07\tTraining Loss 1.1755 (1.1755)\n",
      "\n",
      "Epoch: [285][1/16]\tTime 0.188 (0.660)\tETA 0:00:02\tTraining Loss 1.1760 (1.1758)\n",
      "\n",
      "Epoch: [285][2/16]\tTime 0.188 (0.848)\tETA 0:00:02\tTraining Loss 1.1765 (1.1760)\n",
      "\n",
      "Epoch: [285][3/16]\tTime 0.187 (1.035)\tETA 0:00:02\tTraining Loss 1.1770 (1.1763)\n",
      "\n",
      "Epoch: [285][4/16]\tTime 0.181 (1.216)\tETA 0:00:02\tTraining Loss 1.1758 (1.1762)\n",
      "\n",
      "Epoch: [285][5/16]\tTime 0.179 (1.395)\tETA 0:00:01\tTraining Loss 1.1747 (1.1759)\n",
      "\n",
      "Epoch: [285][6/16]\tTime 0.187 (1.582)\tETA 0:00:01\tTraining Loss 1.1742 (1.1757)\n",
      "\n",
      "Epoch: [285][7/16]\tTime 0.191 (1.773)\tETA 0:00:01\tTraining Loss 1.1760 (1.1757)\n",
      "\n",
      "Epoch: [285][8/16]\tTime 0.184 (1.957)\tETA 0:00:01\tTraining Loss 1.1747 (1.1756)\n",
      "\n",
      "Epoch: [285][9/16]\tTime 0.180 (2.136)\tETA 0:00:01\tTraining Loss 1.1752 (1.1756)\n",
      "\n",
      "Epoch: [285][10/16]\tTime 0.193 (2.330)\tETA 0:00:01\tTraining Loss 1.1764 (1.1756)\n",
      "\n",
      "Epoch: [285][11/16]\tTime 0.188 (2.518)\tETA 0:00:00\tTraining Loss 1.1753 (1.1756)\n",
      "\n",
      "Epoch: [285][12/16]\tTime 0.196 (2.714)\tETA 0:00:00\tTraining Loss 1.1789 (1.1759)\n",
      "\n",
      "Epoch: [285][13/16]\tTime 0.174 (2.888)\tETA 0:00:00\tTraining Loss 1.1755 (1.1758)\n",
      "\n",
      "Epoch: [285][14/16]\tTime 0.185 (3.073)\tETA 0:00:00\tTraining Loss 1.1749 (1.1758)\n",
      "\n",
      "Epoch: [285][15/16]\tTime 0.114 (3.187)\tETA 0:00:00\tTraining Loss 1.1754 (1.1758)\n",
      "_\n",
      "Validation stats                    IoU        F1      Prec   recall     Acc\n",
      "bg,          0.955700  0.977300  0.979400  0.97530  0.9607\n",
      "real apple   0.494200  0.661400  0.867100  0.53470  0.9640\n",
      "real pepper  0.000000  0.000000  0.000000  0.00000  0.9997\n",
      "real grape   0.756600  0.861400  0.877200  0.84620  0.9824\n",
      "fake apple   0.000000  0.000000  0.000000  0.00000  0.9847\n",
      "fake pepper  0.000000  0.000000  0.000000  0.00000  0.9969\n",
      "fake grape   0.000000  0.000000  0.000000  0.00000  0.9877\n",
      "total        0.315214  0.357157  0.389100  0.33660  0.9823\n",
      "total(-bg)   0.208467  0.253800  0.290717  0.23015  0.9859\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: [286][0/16]\tTime 0.485 (0.485)\tETA 0:00:07\tTraining Loss 1.1759 (1.1759)\n",
      "\n",
      "Epoch: [286][1/16]\tTime 0.192 (0.677)\tETA 0:00:02\tTraining Loss 1.1751 (1.1755)\n",
      "\n",
      "Epoch: [286][2/16]\tTime 0.191 (0.867)\tETA 0:00:02\tTraining Loss 1.1757 (1.1756)\n",
      "\n",
      "Epoch: [286][3/16]\tTime 0.182 (1.049)\tETA 0:00:02\tTraining Loss 1.1749 (1.1754)\n",
      "\n",
      "Epoch: [286][4/16]\tTime 0.186 (1.236)\tETA 0:00:02\tTraining Loss 1.1763 (1.1756)\n",
      "\n",
      "Epoch: [286][5/16]\tTime 0.184 (1.419)\tETA 0:00:02\tTraining Loss 1.1750 (1.1755)\n",
      "\n",
      "Epoch: [286][6/16]\tTime 0.188 (1.607)\tETA 0:00:01\tTraining Loss 1.1747 (1.1754)\n",
      "\n",
      "Epoch: [286][7/16]\tTime 0.185 (1.792)\tETA 0:00:01\tTraining Loss 1.1764 (1.1755)\n",
      "\n",
      "Epoch: [286][8/16]\tTime 0.188 (1.980)\tETA 0:00:01\tTraining Loss 1.1753 (1.1755)\n",
      "\n",
      "Epoch: [286][9/16]\tTime 0.300 (2.279)\tETA 0:00:02\tTraining Loss 1.1751 (1.1754)\n",
      "\n",
      "Epoch: [286][10/16]\tTime 0.189 (2.468)\tETA 0:00:01\tTraining Loss 1.1756 (1.1755)\n",
      "\n",
      "Epoch: [286][11/16]\tTime 0.183 (2.651)\tETA 0:00:00\tTraining Loss 1.1756 (1.1755)\n",
      "\n",
      "Epoch: [286][12/16]\tTime 0.183 (2.834)\tETA 0:00:00\tTraining Loss 1.1746 (1.1754)\n",
      "\n",
      "Epoch: [286][13/16]\tTime 0.188 (3.022)\tETA 0:00:00\tTraining Loss 1.1756 (1.1754)\n",
      "\n",
      "Epoch: [286][14/16]\tTime 0.191 (3.213)\tETA 0:00:00\tTraining Loss 1.1752 (1.1754)\n",
      "\n",
      "Epoch: [286][15/16]\tTime 0.114 (3.327)\tETA 0:00:00\tTraining Loss 1.1758 (1.1754)\n",
      "_\n",
      "Validation stats                    IoU        F1      Prec    recall       Acc\n",
      "bg,          0.958000  0.978500  0.978500  0.978500  0.962700\n",
      "real apple   0.497600  0.664500  0.862400  0.540500  0.964100\n",
      "real pepper  0.000000  0.000000  0.000000  0.000000  0.999700\n",
      "real grape   0.770400  0.870300  0.896500  0.845600  0.983700\n",
      "fake apple   0.000000  0.000000  0.000000  0.000000  0.985800\n",
      "fake pepper  0.000000  0.000000  0.000000  0.000000  0.998400\n",
      "fake grape   0.000000  0.000000  0.000000  0.000000  0.988000\n",
      "total        0.318000  0.359043  0.391057  0.337800  0.983200\n",
      "total(-bg)   0.211333  0.255800  0.293150  0.231017  0.986617\n",
      "\n",
      "Epoch: [287][0/16]\tTime 0.476 (0.476)\tETA 0:00:07\tTraining Loss 1.1775 (1.1775)\n",
      "\n",
      "Epoch: [287][1/16]\tTime 0.186 (0.662)\tETA 0:00:02\tTraining Loss 1.1790 (1.1782)\n",
      "\n",
      "Epoch: [287][2/16]\tTime 0.193 (0.855)\tETA 0:00:02\tTraining Loss 1.1756 (1.1774)\n",
      "\n",
      "Epoch: [287][3/16]\tTime 0.181 (1.036)\tETA 0:00:02\tTraining Loss 1.1763 (1.1771)\n",
      "\n",
      "Epoch: [287][4/16]\tTime 0.189 (1.225)\tETA 0:00:02\tTraining Loss 1.1758 (1.1768)\n",
      "\n",
      "Epoch: [287][5/16]\tTime 0.184 (1.409)\tETA 0:00:02\tTraining Loss 1.1748 (1.1765)\n",
      "\n",
      "Epoch: [287][6/16]\tTime 0.186 (1.594)\tETA 0:00:01\tTraining Loss 1.1765 (1.1765)\n",
      "\n",
      "Epoch: [287][7/16]\tTime 0.187 (1.781)\tETA 0:00:01\tTraining Loss 1.1763 (1.1765)\n",
      "\n",
      "Epoch: [287][8/16]\tTime 0.182 (1.963)\tETA 0:00:01\tTraining Loss 1.1751 (1.1763)\n",
      "\n",
      "Epoch: [287][9/16]\tTime 0.192 (2.155)\tETA 0:00:01\tTraining Loss 1.1747 (1.1762)\n",
      "\n",
      "Epoch: [287][10/16]\tTime 0.185 (2.339)\tETA 0:00:01\tTraining Loss 1.1747 (1.1760)\n",
      "\n",
      "Epoch: [287][11/16]\tTime 0.190 (2.529)\tETA 0:00:00\tTraining Loss 1.1761 (1.1760)\n",
      "\n",
      "Epoch: [287][12/16]\tTime 0.194 (2.722)\tETA 0:00:00\tTraining Loss 1.1750 (1.1760)\n",
      "\n",
      "Epoch: [287][13/16]\tTime 0.185 (2.908)\tETA 0:00:00\tTraining Loss 1.1742 (1.1758)\n",
      "\n",
      "Epoch: [287][14/16]\tTime 0.187 (3.094)\tETA 0:00:00\tTraining Loss 1.1748 (1.1758)\n",
      "\n",
      "Epoch: [287][15/16]\tTime 0.118 (3.212)\tETA 0:00:00\tTraining Loss 1.1752 (1.1757)\n",
      "_\n",
      "Validation stats                    IoU        F1      Prec    recall       Acc\n",
      "bg,          0.959500  0.979300  0.979200  0.979400  0.964000\n",
      "real apple   0.509600  0.675100  0.893500  0.542600  0.965700\n",
      "real pepper  0.000000  0.000000  0.000000  0.000000  1.000000\n",
      "real grape   0.781100  0.877100  0.882600  0.871700  0.984200\n",
      "fake apple   0.000000  0.000000  0.000000  0.000000  0.984300\n",
      "fake pepper  0.000000  0.000000  0.000000  0.000000  0.998600\n",
      "fake grape   0.000000  0.000000  0.000000  0.000000  0.990600\n",
      "total        0.321457  0.361643  0.393614  0.341957  0.983914\n",
      "total(-bg)   0.215117  0.258700  0.296017  0.235717  0.987233\n",
      "\n",
      "Epoch: [288][0/16]\tTime 0.491 (0.491)\tETA 0:00:07\tTraining Loss 1.1749 (1.1749)\n",
      "\n",
      "Epoch: [288][1/16]\tTime 0.183 (0.674)\tETA 0:00:02\tTraining Loss 1.1755 (1.1752)\n",
      "\n",
      "Epoch: [288][2/16]\tTime 0.188 (0.862)\tETA 0:00:02\tTraining Loss 1.1746 (1.1750)\n",
      "\n",
      "Epoch: [288][3/16]\tTime 0.182 (1.044)\tETA 0:00:02\tTraining Loss 1.1746 (1.1749)\n",
      "\n",
      "Epoch: [288][4/16]\tTime 0.181 (1.225)\tETA 0:00:02\tTraining Loss 1.1744 (1.1748)\n",
      "\n",
      "Epoch: [288][5/16]\tTime 0.189 (1.415)\tETA 0:00:02\tTraining Loss 1.1747 (1.1748)\n",
      "\n",
      "Epoch: [288][6/16]\tTime 0.186 (1.601)\tETA 0:00:01\tTraining Loss 1.1769 (1.1751)\n",
      "\n",
      "Epoch: [288][7/16]\tTime 0.189 (1.790)\tETA 0:00:01\tTraining Loss 1.1749 (1.1751)\n",
      "\n",
      "Epoch: [288][8/16]\tTime 0.181 (1.972)\tETA 0:00:01\tTraining Loss 1.1759 (1.1752)\n",
      "\n",
      "Epoch: [288][9/16]\tTime 0.185 (2.157)\tETA 0:00:01\tTraining Loss 1.1743 (1.1751)\n",
      "\n",
      "Epoch: [288][10/16]\tTime 0.188 (2.345)\tETA 0:00:01\tTraining Loss 1.1758 (1.1751)\n",
      "\n",
      "Epoch: [288][11/16]\tTime 0.184 (2.530)\tETA 0:00:00\tTraining Loss 1.1751 (1.1751)\n",
      "\n",
      "Epoch: [288][12/16]\tTime 0.184 (2.713)\tETA 0:00:00\tTraining Loss 1.1757 (1.1752)\n",
      "\n",
      "Epoch: [288][13/16]\tTime 0.185 (2.899)\tETA 0:00:00\tTraining Loss 1.1749 (1.1752)\n",
      "\n",
      "Epoch: [288][14/16]\tTime 0.183 (3.082)\tETA 0:00:00\tTraining Loss 1.1771 (1.1753)\n",
      "\n",
      "Epoch: [288][15/16]\tTime 0.114 (3.196)\tETA 0:00:00\tTraining Loss 1.1740 (1.1752)\n",
      "_\n",
      "Validation stats                    IoU        F1    Prec    recall       Acc\n",
      "bg,          0.958600  0.978800  0.9778  0.980000  0.963200\n",
      "real apple   0.668500  0.801200  0.9209  0.709200  0.976900\n",
      "real pepper  0.000000  0.000000  0.0000  0.000000  1.000000\n",
      "real grape   0.723700  0.839600  0.9181  0.773700  0.980900\n",
      "fake apple   0.000000  0.000000  0.0000  0.000000  0.991800\n",
      "fake pepper  0.000000  0.000000  0.0000  0.000000  0.998500\n",
      "fake grape   0.000000  0.000000  0.0000  0.000000  0.986300\n",
      "total        0.335829  0.374229  0.4024  0.351843  0.985371\n",
      "total(-bg)   0.232033  0.273467  0.3065  0.247150  0.989067\n",
      "\n",
      "Epoch: [289][0/16]\tTime 0.537 (0.537)\tETA 0:00:08\tTraining Loss 1.1743 (1.1743)\n",
      "\n",
      "Epoch: [289][1/16]\tTime 0.195 (0.733)\tETA 0:00:02\tTraining Loss 1.1841 (1.1792)\n",
      "\n",
      "Epoch: [289][2/16]\tTime 0.193 (0.925)\tETA 0:00:02\tTraining Loss 1.1743 (1.1776)\n",
      "\n",
      "Epoch: [289][3/16]\tTime 0.187 (1.113)\tETA 0:00:02\tTraining Loss 1.1743 (1.1767)\n",
      "\n",
      "Epoch: [289][4/16]\tTime 0.188 (1.300)\tETA 0:00:02\tTraining Loss 1.1746 (1.1763)\n",
      "\n",
      "Epoch: [289][5/16]\tTime 0.193 (1.494)\tETA 0:00:02\tTraining Loss 1.1744 (1.1760)\n",
      "\n",
      "Epoch: [289][6/16]\tTime 0.201 (1.695)\tETA 0:00:02\tTraining Loss 1.1761 (1.1760)\n",
      "\n",
      "Epoch: [289][7/16]\tTime 0.188 (1.883)\tETA 0:00:01\tTraining Loss 1.1752 (1.1759)\n",
      "\n",
      "Epoch: [289][8/16]\tTime 0.195 (2.078)\tETA 0:00:01\tTraining Loss 1.1750 (1.1758)\n",
      "\n",
      "Epoch: [289][9/16]\tTime 0.190 (2.268)\tETA 0:00:01\tTraining Loss 1.1743 (1.1757)\n",
      "\n",
      "Epoch: [289][10/16]\tTime 0.197 (2.465)\tETA 0:00:01\tTraining Loss 1.1751 (1.1756)\n",
      "\n",
      "Epoch: [289][11/16]\tTime 0.188 (2.653)\tETA 0:00:00\tTraining Loss 1.1752 (1.1756)\n",
      "\n",
      "Epoch: [289][12/16]\tTime 0.208 (2.861)\tETA 0:00:00\tTraining Loss 1.1742 (1.1755)\n",
      "\n",
      "Epoch: [289][13/16]\tTime 0.184 (3.045)\tETA 0:00:00\tTraining Loss 1.1758 (1.1755)\n",
      "\n",
      "Epoch: [289][14/16]\tTime 0.186 (3.232)\tETA 0:00:00\tTraining Loss 1.1747 (1.1754)\n",
      "\n",
      "Epoch: [289][15/16]\tTime 0.112 (3.343)\tETA 0:00:00\tTraining Loss 1.1845 (1.1757)\n",
      "_\n",
      "Validation stats                    IoU        F1      Prec    recall     Acc\n",
      "bg,          0.957000  0.978000  0.978500  0.977600  0.9618\n",
      "real apple   0.451000  0.621600  0.862200  0.486100  0.9611\n",
      "real pepper  0.000000  0.000000  0.000000  0.000000  0.9998\n",
      "real grape   0.777600  0.874900  0.890300  0.860000  0.9841\n",
      "fake apple   0.000000  0.000000  0.000000  0.000000  0.9819\n",
      "fake pepper  0.000000  0.000000  0.000000  0.000000  0.9989\n",
      "fake grape   0.000000  0.000000  0.000000  0.000000  0.9878\n",
      "total        0.312229  0.353500  0.390143  0.331957  0.9822\n",
      "total(-bg)   0.204767  0.249417  0.292083  0.224350  0.9856\n",
      "\n",
      "Epoch: [290][0/16]\tTime 0.390 (0.390)\tETA 0:00:06\tTraining Loss 1.1752 (1.1752)\n",
      "\n",
      "Epoch: [290][1/16]\tTime 0.185 (0.575)\tETA 0:00:02\tTraining Loss 1.1744 (1.1748)\n",
      "\n",
      "Epoch: [290][2/16]\tTime 0.195 (0.770)\tETA 0:00:02\tTraining Loss 1.1742 (1.1746)\n",
      "\n",
      "Epoch: [290][3/16]\tTime 0.184 (0.953)\tETA 0:00:02\tTraining Loss 1.1755 (1.1748)\n",
      "\n",
      "Epoch: [290][4/16]\tTime 0.192 (1.145)\tETA 0:00:02\tTraining Loss 1.1748 (1.1748)\n",
      "\n",
      "Epoch: [290][5/16]\tTime 0.185 (1.331)\tETA 0:00:02\tTraining Loss 1.1739 (1.1747)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: [290][6/16]\tTime 0.192 (1.523)\tETA 0:00:01\tTraining Loss 1.1767 (1.1750)\n",
      "\n",
      "Epoch: [290][7/16]\tTime 0.189 (1.712)\tETA 0:00:01\tTraining Loss 1.1771 (1.1752)\n",
      "\n",
      "Epoch: [290][8/16]\tTime 0.192 (1.905)\tETA 0:00:01\tTraining Loss 1.1765 (1.1754)\n",
      "\n",
      "Epoch: [290][9/16]\tTime 0.192 (2.096)\tETA 0:00:01\tTraining Loss 1.1761 (1.1754)\n",
      "\n",
      "Epoch: [290][10/16]\tTime 0.194 (2.290)\tETA 0:00:01\tTraining Loss 1.1744 (1.1753)\n",
      "\n",
      "Epoch: [290][11/16]\tTime 0.192 (2.481)\tETA 0:00:00\tTraining Loss 1.1749 (1.1753)\n",
      "\n",
      "Epoch: [290][12/16]\tTime 0.187 (2.668)\tETA 0:00:00\tTraining Loss 1.1742 (1.1752)\n",
      "\n",
      "Epoch: [290][13/16]\tTime 0.183 (2.851)\tETA 0:00:00\tTraining Loss 1.1765 (1.1753)\n",
      "\n",
      "Epoch: [290][14/16]\tTime 0.187 (3.038)\tETA 0:00:00\tTraining Loss 1.1759 (1.1754)\n",
      "\n",
      "Epoch: [290][15/16]\tTime 0.113 (3.151)\tETA 0:00:00\tTraining Loss 1.1755 (1.1754)\n",
      "_\n",
      "Validation stats                    IoU      F1      Prec    recall       Acc\n",
      "bg,          0.958800  0.9789  0.978800  0.979200  0.963400\n",
      "real apple   0.672000  0.8038  0.896800  0.728300  0.976600\n",
      "real pepper  0.000000  0.0000  0.000000  0.000000  1.000000\n",
      "real grape   0.782500  0.8780  0.895100  0.861600  0.984500\n",
      "fake apple   0.000000  0.0000  0.000000  0.000000  0.993300\n",
      "fake pepper  0.000000  0.0000  0.000000  0.000000  0.998600\n",
      "fake grape   0.000000  0.0000  0.000000  0.000000  0.993800\n",
      "total        0.344757  0.3801  0.395814  0.367014  0.987171\n",
      "total(-bg)   0.242417  0.2803  0.298650  0.264983  0.991133\n",
      "\n",
      "Epoch: [291][0/16]\tTime 0.394 (0.394)\tETA 0:00:06\tTraining Loss 1.1765 (1.1765)\n",
      "\n",
      "Epoch: [291][1/16]\tTime 0.194 (0.588)\tETA 0:00:02\tTraining Loss 1.1754 (1.1760)\n",
      "\n",
      "Epoch: [291][2/16]\tTime 0.187 (0.775)\tETA 0:00:02\tTraining Loss 1.1746 (1.1755)\n",
      "\n",
      "Epoch: [291][3/16]\tTime 0.181 (0.956)\tETA 0:00:02\tTraining Loss 1.1753 (1.1754)\n",
      "\n",
      "Epoch: [291][4/16]\tTime 0.190 (1.146)\tETA 0:00:02\tTraining Loss 1.1740 (1.1752)\n",
      "\n",
      "Epoch: [291][5/16]\tTime 0.187 (1.333)\tETA 0:00:02\tTraining Loss 1.1738 (1.1749)\n",
      "\n",
      "Epoch: [291][6/16]\tTime 0.186 (1.519)\tETA 0:00:01\tTraining Loss 1.1758 (1.1751)\n",
      "\n",
      "Epoch: [291][7/16]\tTime 0.204 (1.723)\tETA 0:00:01\tTraining Loss 1.1754 (1.1751)\n",
      "\n",
      "Epoch: [291][8/16]\tTime 0.192 (1.915)\tETA 0:00:01\tTraining Loss 1.1735 (1.1749)\n",
      "\n",
      "Epoch: [291][9/16]\tTime 0.189 (2.104)\tETA 0:00:01\tTraining Loss 1.1743 (1.1749)\n",
      "\n",
      "Epoch: [291][10/16]\tTime 0.183 (2.287)\tETA 0:00:01\tTraining Loss 1.1748 (1.1749)\n",
      "\n",
      "Epoch: [291][11/16]\tTime 0.185 (2.472)\tETA 0:00:00\tTraining Loss 1.1751 (1.1749)\n",
      "\n",
      "Epoch: [291][12/16]\tTime 0.185 (2.657)\tETA 0:00:00\tTraining Loss 1.1743 (1.1748)\n",
      "\n",
      "Epoch: [291][13/16]\tTime 0.192 (2.849)\tETA 0:00:00\tTraining Loss 1.1773 (1.1750)\n",
      "\n",
      "Epoch: [291][14/16]\tTime 0.184 (3.033)\tETA 0:00:00\tTraining Loss 1.1746 (1.1750)\n",
      "\n",
      "Epoch: [291][15/16]\tTime 0.117 (3.150)\tETA 0:00:00\tTraining Loss 1.1741 (1.1749)\n",
      "_\n",
      "Validation stats                    IoU        F1      Prec    recall       Acc\n",
      "bg,          0.958900  0.979000  0.978700  0.979300  0.963500\n",
      "real apple   0.670900  0.803000  0.905900  0.721200  0.976800\n",
      "real pepper  0.000000  0.000000  0.000000  0.000000  1.000000\n",
      "real grape   0.718100  0.835900  0.915200  0.769300  0.980400\n",
      "fake apple   0.000000  0.000000  0.000000  0.000000  0.993800\n",
      "fake pepper  0.000000  0.000000  0.000000  0.000000  0.998500\n",
      "fake grape   0.000000  0.000000  0.000000  0.000000  0.984500\n",
      "total        0.335414  0.373986  0.399971  0.352829  0.985357\n",
      "total(-bg)   0.231500  0.273150  0.303517  0.248417  0.989000\n",
      "\n",
      "Epoch: [292][0/16]\tTime 0.459 (0.459)\tETA 0:00:07\tTraining Loss 1.1744 (1.1744)\n",
      "\n",
      "Epoch: [292][1/16]\tTime 0.182 (0.641)\tETA 0:00:02\tTraining Loss 1.1738 (1.1741)\n",
      "\n",
      "Epoch: [292][2/16]\tTime 0.191 (0.831)\tETA 0:00:02\tTraining Loss 1.1752 (1.1745)\n",
      "\n",
      "Epoch: [292][3/16]\tTime 0.187 (1.018)\tETA 0:00:02\tTraining Loss 1.1744 (1.1745)\n",
      "\n",
      "Epoch: [292][4/16]\tTime 0.185 (1.203)\tETA 0:00:02\tTraining Loss 1.1746 (1.1745)\n",
      "\n",
      "Epoch: [292][5/16]\tTime 0.184 (1.387)\tETA 0:00:02\tTraining Loss 1.1741 (1.1744)\n",
      "\n",
      "Epoch: [292][6/16]\tTime 0.188 (1.575)\tETA 0:00:01\tTraining Loss 1.1756 (1.1746)\n",
      "\n",
      "Epoch: [292][7/16]\tTime 0.188 (1.763)\tETA 0:00:01\tTraining Loss 1.1746 (1.1746)\n",
      "\n",
      "Epoch: [292][8/16]\tTime 0.184 (1.947)\tETA 0:00:01\tTraining Loss 1.1744 (1.1746)\n",
      "\n",
      "Epoch: [292][9/16]\tTime 0.188 (2.134)\tETA 0:00:01\tTraining Loss 1.1752 (1.1746)\n",
      "\n",
      "Epoch: [292][10/16]\tTime 0.182 (2.316)\tETA 0:00:01\tTraining Loss 1.1747 (1.1746)\n",
      "\n",
      "Epoch: [292][11/16]\tTime 0.185 (2.502)\tETA 0:00:00\tTraining Loss 1.1745 (1.1746)\n",
      "\n",
      "Epoch: [292][12/16]\tTime 0.189 (2.690)\tETA 0:00:00\tTraining Loss 1.1743 (1.1746)\n",
      "\n",
      "Epoch: [292][13/16]\tTime 0.181 (2.871)\tETA 0:00:00\tTraining Loss 1.1739 (1.1746)\n",
      "\n",
      "Epoch: [292][14/16]\tTime 0.181 (3.053)\tETA 0:00:00\tTraining Loss 1.1756 (1.1746)\n",
      "\n",
      "Epoch: [292][15/16]\tTime 0.112 (3.165)\tETA 0:00:00\tTraining Loss 1.1791 (1.1748)\n",
      "_\n",
      "Validation stats                    IoU        F1      Prec    recall       Acc\n",
      "bg,          0.957400  0.978200  0.977900  0.978600  0.962200\n",
      "real apple   0.466400  0.636000  0.879300  0.498300  0.962500\n",
      "real pepper  0.000000  0.000000  0.000000  0.000000  0.999600\n",
      "real grape   0.769200  0.869500  0.880400  0.859000  0.983300\n",
      "fake apple   0.000000  0.000000  0.000000  0.000000  0.983600\n",
      "fake pepper  0.000000  0.000000  0.000000  0.000000  0.998600\n",
      "fake grape   0.000000  0.000000  0.000000  0.000000  0.988600\n",
      "total        0.313286  0.354814  0.391086  0.333700  0.982629\n",
      "total(-bg)   0.205933  0.250917  0.293283  0.226217  0.986033\n",
      "\n",
      "Epoch: [293][0/16]\tTime 0.470 (0.470)\tETA 0:00:07\tTraining Loss 1.1743 (1.1743)\n",
      "\n",
      "Epoch: [293][1/16]\tTime 0.197 (0.667)\tETA 0:00:02\tTraining Loss 1.1743 (1.1743)\n",
      "\n",
      "Epoch: [293][2/16]\tTime 0.181 (0.848)\tETA 0:00:02\tTraining Loss 1.1756 (1.1747)\n",
      "\n",
      "Epoch: [293][3/16]\tTime 0.183 (1.031)\tETA 0:00:02\tTraining Loss 1.1749 (1.1748)\n",
      "\n",
      "Epoch: [293][4/16]\tTime 0.190 (1.222)\tETA 0:00:02\tTraining Loss 1.1739 (1.1746)\n",
      "\n",
      "Epoch: [293][5/16]\tTime 0.182 (1.404)\tETA 0:00:02\tTraining Loss 1.1747 (1.1746)\n",
      "\n",
      "Epoch: [293][6/16]\tTime 0.188 (1.592)\tETA 0:00:01\tTraining Loss 1.1744 (1.1746)\n",
      "\n",
      "Epoch: [293][7/16]\tTime 0.181 (1.773)\tETA 0:00:01\tTraining Loss 1.1750 (1.1746)\n",
      "\n",
      "Epoch: [293][8/16]\tTime 0.206 (1.978)\tETA 0:00:01\tTraining Loss 1.1741 (1.1746)\n",
      "\n",
      "Epoch: [293][9/16]\tTime 0.187 (2.165)\tETA 0:00:01\tTraining Loss 1.1741 (1.1745)\n",
      "\n",
      "Epoch: [293][10/16]\tTime 0.179 (2.344)\tETA 0:00:01\tTraining Loss 1.1767 (1.1747)\n",
      "\n",
      "Epoch: [293][11/16]\tTime 0.182 (2.526)\tETA 0:00:00\tTraining Loss 1.1742 (1.1747)\n",
      "\n",
      "Epoch: [293][12/16]\tTime 0.193 (2.719)\tETA 0:00:00\tTraining Loss 1.1763 (1.1748)\n",
      "\n",
      "Epoch: [293][13/16]\tTime 0.187 (2.906)\tETA 0:00:00\tTraining Loss 1.1752 (1.1748)\n",
      "\n",
      "Epoch: [293][14/16]\tTime 0.185 (3.091)\tETA 0:00:00\tTraining Loss 1.1743 (1.1748)\n",
      "\n",
      "Epoch: [293][15/16]\tTime 0.112 (3.203)\tETA 0:00:00\tTraining Loss 1.1751 (1.1748)\n",
      "_\n",
      "Validation stats                    IoU        F1      Prec    recall       Acc\n",
      "bg,          0.956100  0.977500  0.978400  0.976700  0.961000\n",
      "real apple   0.572400  0.728000  0.873300  0.624200  0.969400\n",
      "real pepper  0.000000  0.000000  0.000000  0.000000  1.000000\n",
      "real grape   0.747300  0.855300  0.896600  0.817700  0.982100\n",
      "fake apple   0.000000  0.000000  0.000000  0.000000  0.986000\n",
      "fake pepper  0.000000  0.000000  0.000000  0.000000  0.998700\n",
      "fake grape   0.000000  0.000000  0.000000  0.000000  0.989300\n",
      "total        0.325114  0.365829  0.392614  0.345514  0.983786\n",
      "total(-bg)   0.219950  0.263883  0.294983  0.240317  0.987583\n",
      "\n",
      "Epoch: [294][0/16]\tTime 0.462 (0.462)\tETA 0:00:07\tTraining Loss 1.1748 (1.1748)\n",
      "\n",
      "Epoch: [294][1/16]\tTime 0.174 (0.637)\tETA 0:00:02\tTraining Loss 1.1748 (1.1748)\n",
      "\n",
      "Epoch: [294][2/16]\tTime 0.191 (0.828)\tETA 0:00:02\tTraining Loss 1.1741 (1.1746)\n",
      "\n",
      "Epoch: [294][3/16]\tTime 0.186 (1.014)\tETA 0:00:02\tTraining Loss 1.1732 (1.1742)\n",
      "\n",
      "Epoch: [294][4/16]\tTime 0.192 (1.205)\tETA 0:00:02\tTraining Loss 1.1745 (1.1743)\n",
      "\n",
      "Epoch: [294][5/16]\tTime 0.185 (1.391)\tETA 0:00:02\tTraining Loss 1.1759 (1.1746)\n",
      "\n",
      "Epoch: [294][6/16]\tTime 0.191 (1.581)\tETA 0:00:01\tTraining Loss 1.1743 (1.1745)\n",
      "\n",
      "Epoch: [294][7/16]\tTime 0.176 (1.758)\tETA 0:00:01\tTraining Loss 1.1748 (1.1745)\n",
      "\n",
      "Epoch: [294][8/16]\tTime 0.188 (1.946)\tETA 0:00:01\tTraining Loss 1.1740 (1.1745)\n",
      "\n",
      "Epoch: [294][9/16]\tTime 0.185 (2.130)\tETA 0:00:01\tTraining Loss 1.1746 (1.1745)\n",
      "\n",
      "Epoch: [294][10/16]\tTime 0.181 (2.311)\tETA 0:00:01\tTraining Loss 1.1749 (1.1745)\n",
      "\n",
      "Epoch: [294][11/16]\tTime 0.198 (2.509)\tETA 0:00:00\tTraining Loss 1.1739 (1.1745)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: [294][12/16]\tTime 0.192 (2.702)\tETA 0:00:00\tTraining Loss 1.1738 (1.1744)\n",
      "\n",
      "Epoch: [294][13/16]\tTime 0.184 (2.886)\tETA 0:00:00\tTraining Loss 1.1760 (1.1745)\n",
      "\n",
      "Epoch: [294][14/16]\tTime 0.187 (3.073)\tETA 0:00:00\tTraining Loss 1.1745 (1.1745)\n",
      "\n",
      "Epoch: [294][15/16]\tTime 0.115 (3.188)\tETA 0:00:00\tTraining Loss 1.1740 (1.1745)\n",
      "_\n",
      "Validation stats                    IoU        F1      Prec    recall       Acc\n",
      "bg,          0.956600  0.977800  0.977600  0.978000  0.961400\n",
      "real apple   0.553500  0.712500  0.875100  0.601000  0.968100\n",
      "real pepper  0.000000  0.000000  0.000000  0.000000  1.000000\n",
      "real grape   0.737600  0.848900  0.900700  0.802900  0.981500\n",
      "fake apple   0.000000  0.000000  0.000000  0.000000  0.984500\n",
      "fake pepper  0.000000  0.000000  0.000000  0.000000  0.999100\n",
      "fake grape   0.000000  0.000000  0.000000  0.000000  0.989100\n",
      "total        0.321100  0.362743  0.393343  0.340271  0.983386\n",
      "total(-bg)   0.215183  0.260233  0.295967  0.233983  0.987050\n",
      "\n",
      "Epoch: [295][0/16]\tTime 0.485 (0.485)\tETA 0:00:07\tTraining Loss 1.1738 (1.1738)\n",
      "\n",
      "Epoch: [295][1/16]\tTime 0.183 (0.668)\tETA 0:00:02\tTraining Loss 1.1742 (1.1740)\n",
      "\n",
      "Epoch: [295][2/16]\tTime 0.182 (0.849)\tETA 0:00:02\tTraining Loss 1.1735 (1.1738)\n",
      "\n",
      "Epoch: [295][3/16]\tTime 0.191 (1.040)\tETA 0:00:02\tTraining Loss 1.1743 (1.1740)\n",
      "\n",
      "Epoch: [295][4/16]\tTime 0.188 (1.228)\tETA 0:00:02\tTraining Loss 1.1742 (1.1740)\n",
      "\n",
      "Epoch: [295][5/16]\tTime 0.305 (1.533)\tETA 0:00:03\tTraining Loss 1.1735 (1.1739)\n",
      "\n",
      "Epoch: [295][6/16]\tTime 0.195 (1.729)\tETA 0:00:01\tTraining Loss 1.1742 (1.1740)\n",
      "\n",
      "Epoch: [295][7/16]\tTime 0.187 (1.916)\tETA 0:00:01\tTraining Loss 1.1742 (1.1740)\n",
      "\n",
      "Epoch: [295][8/16]\tTime 0.188 (2.104)\tETA 0:00:01\tTraining Loss 1.1755 (1.1742)\n",
      "\n",
      "Epoch: [295][9/16]\tTime 0.187 (2.291)\tETA 0:00:01\tTraining Loss 1.1741 (1.1742)\n",
      "\n",
      "Epoch: [295][10/16]\tTime 0.185 (2.476)\tETA 0:00:01\tTraining Loss 1.1750 (1.1742)\n",
      "\n",
      "Epoch: [295][11/16]\tTime 0.184 (2.660)\tETA 0:00:00\tTraining Loss 1.1738 (1.1742)\n",
      "\n",
      "Epoch: [295][12/16]\tTime 0.196 (2.856)\tETA 0:00:00\tTraining Loss 1.1745 (1.1742)\n",
      "\n",
      "Epoch: [295][13/16]\tTime 0.181 (3.037)\tETA 0:00:00\tTraining Loss 1.1745 (1.1742)\n",
      "\n",
      "Epoch: [295][14/16]\tTime 0.195 (3.232)\tETA 0:00:00\tTraining Loss 1.1755 (1.1743)\n",
      "\n",
      "Epoch: [295][15/16]\tTime 0.118 (3.350)\tETA 0:00:00\tTraining Loss 1.1744 (1.1743)\n",
      "_\n",
      "Validation stats                    IoU        F1      Prec    recall     Acc\n",
      "bg,          0.958800  0.978900  0.978100  0.979900  0.9634\n",
      "real apple   0.673100  0.804600  0.925800  0.711500  0.9773\n",
      "real pepper  0.000000  0.000000  0.000000  0.000000  1.0000\n",
      "real grape   0.733700  0.846400  0.917800  0.785300  0.9815\n",
      "fake apple   0.000000  0.000000  0.000000  0.000000  0.9925\n",
      "fake pepper  0.000000  0.000000  0.000000  0.000000  0.9983\n",
      "fake grape   0.000000  0.000000  0.000000  0.000000  0.9862\n",
      "total        0.337943  0.375700  0.403100  0.353814  0.9856\n",
      "total(-bg)   0.234467  0.275167  0.307267  0.249467  0.9893\n",
      "\n",
      "Epoch: [296][0/16]\tTime 0.482 (0.482)\tETA 0:00:07\tTraining Loss 1.1741 (1.1741)\n",
      "\n",
      "Epoch: [296][1/16]\tTime 0.183 (0.665)\tETA 0:00:02\tTraining Loss 1.1745 (1.1743)\n",
      "\n",
      "Epoch: [296][2/16]\tTime 0.190 (0.855)\tETA 0:00:02\tTraining Loss 1.1775 (1.1754)\n",
      "\n",
      "Epoch: [296][3/16]\tTime 0.187 (1.042)\tETA 0:00:02\tTraining Loss 1.1750 (1.1753)\n",
      "\n",
      "Epoch: [296][4/16]\tTime 0.183 (1.226)\tETA 0:00:02\tTraining Loss 1.1732 (1.1749)\n",
      "\n",
      "Epoch: [296][5/16]\tTime 0.183 (1.409)\tETA 0:00:02\tTraining Loss 1.1749 (1.1749)\n",
      "\n",
      "Epoch: [296][6/16]\tTime 0.185 (1.594)\tETA 0:00:01\tTraining Loss 1.1740 (1.1748)\n",
      "\n",
      "Epoch: [296][7/16]\tTime 0.189 (1.783)\tETA 0:00:01\tTraining Loss 1.1736 (1.1746)\n",
      "\n",
      "Epoch: [296][8/16]\tTime 0.198 (1.981)\tETA 0:00:01\tTraining Loss 1.1763 (1.1748)\n",
      "\n",
      "Epoch: [296][9/16]\tTime 0.190 (2.171)\tETA 0:00:01\tTraining Loss 1.1758 (1.1749)\n",
      "\n",
      "Epoch: [296][10/16]\tTime 0.184 (2.355)\tETA 0:00:01\tTraining Loss 1.1742 (1.1748)\n",
      "\n",
      "Epoch: [296][11/16]\tTime 0.181 (2.536)\tETA 0:00:00\tTraining Loss 1.1742 (1.1748)\n",
      "\n",
      "Epoch: [296][12/16]\tTime 0.193 (2.729)\tETA 0:00:00\tTraining Loss 1.1735 (1.1747)\n",
      "\n",
      "Epoch: [296][13/16]\tTime 0.191 (2.920)\tETA 0:00:00\tTraining Loss 1.1740 (1.1746)\n",
      "\n",
      "Epoch: [296][14/16]\tTime 0.176 (3.095)\tETA 0:00:00\tTraining Loss 1.1755 (1.1747)\n",
      "\n",
      "Epoch: [296][15/16]\tTime 0.114 (3.209)\tETA 0:00:00\tTraining Loss 1.1739 (1.1747)\n",
      "_\n",
      "Validation stats                    IoU        F1      Prec    recall       Acc\n",
      "bg,          0.956300  0.977600  0.977500  0.977900  0.961200\n",
      "real apple   0.557700  0.716000  0.872500  0.607200  0.968400\n",
      "real pepper  0.000000  0.000000  0.000000  0.000000  1.000000\n",
      "real grape   0.775500  0.873500  0.919900  0.831700  0.984400\n",
      "fake apple   0.000000  0.000000  0.000000  0.000000  0.988100\n",
      "fake pepper  0.000000  0.000000  0.000000  0.000000  0.999100\n",
      "fake grape   0.000000  0.000000  0.000000  0.000000  0.987000\n",
      "total        0.327071  0.366729  0.395700  0.345257  0.984029\n",
      "total(-bg)   0.222200  0.264917  0.298733  0.239817  0.987833\n",
      "\n",
      "Epoch: [297][0/16]\tTime 0.371 (0.371)\tETA 0:00:05\tTraining Loss 1.1744 (1.1744)\n",
      "\n",
      "Epoch: [297][1/16]\tTime 0.182 (0.553)\tETA 0:00:02\tTraining Loss 1.1755 (1.1750)\n",
      "\n",
      "Epoch: [297][2/16]\tTime 0.194 (0.748)\tETA 0:00:02\tTraining Loss 1.1751 (1.1750)\n",
      "\n",
      "Epoch: [297][3/16]\tTime 0.187 (0.934)\tETA 0:00:02\tTraining Loss 1.1766 (1.1754)\n",
      "\n",
      "Epoch: [297][4/16]\tTime 0.189 (1.123)\tETA 0:00:02\tTraining Loss 1.1738 (1.1751)\n",
      "\n",
      "Epoch: [297][5/16]\tTime 0.185 (1.308)\tETA 0:00:02\tTraining Loss 1.1742 (1.1750)\n",
      "\n",
      "Epoch: [297][6/16]\tTime 0.184 (1.493)\tETA 0:00:01\tTraining Loss 1.1735 (1.1748)\n",
      "\n",
      "Epoch: [297][7/16]\tTime 0.183 (1.676)\tETA 0:00:01\tTraining Loss 1.1740 (1.1747)\n",
      "\n",
      "Epoch: [297][8/16]\tTime 0.176 (1.852)\tETA 0:00:01\tTraining Loss 1.1738 (1.1746)\n",
      "\n",
      "Epoch: [297][9/16]\tTime 0.189 (2.040)\tETA 0:00:01\tTraining Loss 1.1737 (1.1745)\n",
      "\n",
      "Epoch: [297][10/16]\tTime 0.189 (2.230)\tETA 0:00:01\tTraining Loss 1.1742 (1.1745)\n",
      "\n",
      "Epoch: [297][11/16]\tTime 0.187 (2.417)\tETA 0:00:00\tTraining Loss 1.1752 (1.1745)\n",
      "\n",
      "Epoch: [297][12/16]\tTime 0.191 (2.608)\tETA 0:00:00\tTraining Loss 1.1754 (1.1746)\n",
      "\n",
      "Epoch: [297][13/16]\tTime 0.187 (2.795)\tETA 0:00:00\tTraining Loss 1.1740 (1.1745)\n",
      "\n",
      "Epoch: [297][14/16]\tTime 0.187 (2.982)\tETA 0:00:00\tTraining Loss 1.1739 (1.1745)\n",
      "\n",
      "Epoch: [297][15/16]\tTime 0.118 (3.100)\tETA 0:00:00\tTraining Loss 1.1742 (1.1745)\n",
      "_\n",
      "Validation stats                    IoU        F1      Prec    recall       Acc\n",
      "bg,          0.952900  0.975800  0.978600  0.973200  0.958200\n",
      "real apple   0.560200  0.718100  0.867500  0.612600  0.968400\n",
      "real pepper  0.000000  0.000000  0.000000  0.000000  1.000000\n",
      "real grape   0.757500  0.862000  0.902700  0.824900  0.982900\n",
      "fake apple   0.000000  0.000000  0.000000  0.000000  0.985700\n",
      "fake pepper  0.000000  0.000000  0.000000  0.000000  0.998900\n",
      "fake grape   0.000000  0.000000  0.000000  0.000000  0.985800\n",
      "total        0.324371  0.365129  0.392686  0.344386  0.982843\n",
      "total(-bg)   0.219617  0.263350  0.295033  0.239583  0.986950\n",
      "\n",
      "Epoch: [298][0/16]\tTime 0.526 (0.526)\tETA 0:00:08\tTraining Loss 1.1735 (1.1735)\n",
      "\n",
      "Epoch: [298][1/16]\tTime 0.188 (0.714)\tETA 0:00:02\tTraining Loss 1.1743 (1.1739)\n",
      "\n",
      "Epoch: [298][2/16]\tTime 0.190 (0.905)\tETA 0:00:02\tTraining Loss 1.1749 (1.1742)\n",
      "\n",
      "Epoch: [298][3/16]\tTime 0.206 (1.111)\tETA 0:00:02\tTraining Loss 1.1739 (1.1742)\n",
      "\n",
      "Epoch: [298][4/16]\tTime 0.172 (1.282)\tETA 0:00:02\tTraining Loss 1.1762 (1.1746)\n",
      "\n",
      "Epoch: [298][5/16]\tTime 0.193 (1.475)\tETA 0:00:02\tTraining Loss 1.1746 (1.1746)\n",
      "\n",
      "Epoch: [298][6/16]\tTime 0.189 (1.664)\tETA 0:00:01\tTraining Loss 1.1746 (1.1746)\n",
      "\n",
      "Epoch: [298][7/16]\tTime 0.210 (1.874)\tETA 0:00:01\tTraining Loss 1.1733 (1.1744)\n",
      "\n",
      "Epoch: [298][8/16]\tTime 0.193 (2.068)\tETA 0:00:01\tTraining Loss 1.1753 (1.1745)\n",
      "\n",
      "Epoch: [298][9/16]\tTime 0.188 (2.256)\tETA 0:00:01\tTraining Loss 1.1778 (1.1749)\n",
      "\n",
      "Epoch: [298][10/16]\tTime 0.182 (2.438)\tETA 0:00:01\tTraining Loss 1.1742 (1.1748)\n",
      "\n",
      "Epoch: [298][11/16]\tTime 0.188 (2.626)\tETA 0:00:00\tTraining Loss 1.1740 (1.1747)\n",
      "\n",
      "Epoch: [298][12/16]\tTime 0.186 (2.812)\tETA 0:00:00\tTraining Loss 1.1738 (1.1746)\n",
      "\n",
      "Epoch: [298][13/16]\tTime 0.188 (3.000)\tETA 0:00:00\tTraining Loss 1.1741 (1.1746)\n",
      "\n",
      "Epoch: [298][14/16]\tTime 0.186 (3.187)\tETA 0:00:00\tTraining Loss 1.1742 (1.1746)\n",
      "\n",
      "Epoch: [298][15/16]\tTime 0.116 (3.303)\tETA 0:00:00\tTraining Loss 1.1761 (1.1746)\n",
      "_\n",
      "Validation stats                    IoU        F1      Prec    recall       Acc\n",
      "bg,          0.959700  0.979400  0.978100  0.980800  0.964100\n",
      "real apple   0.512100  0.677300  0.907900  0.540200  0.966200\n",
      "real pepper  0.000000  0.000000  0.000000  0.000000  1.000000\n",
      "real grape   0.780900  0.876900  0.884400  0.869700  0.984200\n",
      "fake apple   0.000000  0.000000  0.000000  0.000000  0.985100\n",
      "fake pepper  0.000000  0.000000  0.000000  0.000000  0.998600\n",
      "fake grape   0.000000  0.000000  0.000000  0.000000  0.991000\n",
      "total        0.321814  0.361943  0.395771  0.341529  0.984171\n",
      "total(-bg)   0.215500  0.259033  0.298717  0.234983  0.987517\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: [299][0/16]\tTime 0.475 (0.475)\tETA 0:00:07\tTraining Loss 1.1749 (1.1749)\n",
      "\n",
      "Epoch: [299][1/16]\tTime 0.187 (0.662)\tETA 0:00:02\tTraining Loss 1.1763 (1.1756)\n",
      "\n",
      "Epoch: [299][2/16]\tTime 0.175 (0.837)\tETA 0:00:02\tTraining Loss 1.1745 (1.1752)\n",
      "\n",
      "Epoch: [299][3/16]\tTime 0.195 (1.032)\tETA 0:00:02\tTraining Loss 1.1739 (1.1749)\n",
      "\n",
      "Epoch: [299][4/16]\tTime 0.187 (1.219)\tETA 0:00:02\tTraining Loss 1.1737 (1.1747)\n",
      "\n",
      "Epoch: [299][5/16]\tTime 0.184 (1.403)\tETA 0:00:02\tTraining Loss 1.1746 (1.1746)\n",
      "\n",
      "Epoch: [299][6/16]\tTime 0.185 (1.588)\tETA 0:00:01\tTraining Loss 1.1739 (1.1745)\n",
      "\n",
      "Epoch: [299][7/16]\tTime 0.188 (1.776)\tETA 0:00:01\tTraining Loss 1.1735 (1.1744)\n",
      "\n",
      "Epoch: [299][8/16]\tTime 0.183 (1.959)\tETA 0:00:01\tTraining Loss 1.1735 (1.1743)\n",
      "\n",
      "Epoch: [299][9/16]\tTime 0.188 (2.147)\tETA 0:00:01\tTraining Loss 1.1746 (1.1743)\n",
      "\n",
      "Epoch: [299][10/16]\tTime 0.189 (2.336)\tETA 0:00:01\tTraining Loss 1.1741 (1.1743)\n",
      "\n",
      "Epoch: [299][11/16]\tTime 0.188 (2.524)\tETA 0:00:00\tTraining Loss 1.1739 (1.1743)\n",
      "\n",
      "Epoch: [299][12/16]\tTime 0.192 (2.716)\tETA 0:00:00\tTraining Loss 1.1733 (1.1742)\n",
      "\n",
      "Epoch: [299][13/16]\tTime 0.187 (2.903)\tETA 0:00:00\tTraining Loss 1.1752 (1.1743)\n",
      "\n",
      "Epoch: [299][14/16]\tTime 0.185 (3.089)\tETA 0:00:00\tTraining Loss 1.1744 (1.1743)\n",
      "\n",
      "Epoch: [299][15/16]\tTime 0.114 (3.203)\tETA 0:00:00\tTraining Loss 1.1739 (1.1743)\n",
      "_\n",
      "Validation stats                    IoU        F1      Prec    recall       Acc\n",
      "bg,          0.959100  0.979100  0.979300  0.979000  0.963700\n",
      "real apple   0.514600  0.679500  0.891400  0.549000  0.966000\n",
      "real pepper  0.000000  0.000000  0.000000  0.000000  0.999900\n",
      "real grape   0.774000  0.872500  0.890500  0.855400  0.983800\n",
      "fake apple   0.000000  0.000000  0.000000  0.000000  0.984800\n",
      "fake pepper  0.000000  0.000000  0.000000  0.000000  0.997800\n",
      "fake grape   0.000000  0.000000  0.000000  0.000000  0.989500\n",
      "total        0.321100  0.361586  0.394457  0.340486  0.983643\n",
      "total(-bg)   0.214767  0.258667  0.296983  0.234067  0.986967\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "too many indices for array: array is 1-dimensional, but 2 were indexed",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_45088/2306017544.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0mans\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_id\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'.npy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mans\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mans\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: too many indices for array: array is 1-dimensional, but 2 were indexed"
     ]
    }
   ],
   "source": [
    "run_id = 'segmentation_rgb_gpu{}_n{}_bs{}_lr{}_pretrained{}_loss_{}_time_{}'.format(gpu_id, epochs, batch_size, learning_rate, train_pretrained,'cross_entropy', str(datetime.datetime.now().time())); print('\\n\\nTraining', run_id)\n",
    "save_path = run_id + '.pkl'\n",
    "\n",
    "optimizer = torch.optim.Adam(params= model.parameters(),lr=learning_rate)\n",
    "\n",
    "#optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "metrics = Metrics(train_loader.dataset.dataset.num_classes, train_loader.dataset.dataset.class_names)\n",
    "\n",
    "# Used to keep track of statistics\n",
    "class AverageMeter(object):\n",
    "    def __init__(self):\n",
    "        self.val = 0; self.avg = 0; self.sum = 0; self.count = 0\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "REPORTS_PER_EPOCH = 10\n",
    "ITER_PER_EPOCH = len(train_loader)\n",
    "ITER_PER_REPORT = ITER_PER_EPOCH//REPORTS_PER_EPOCH\n",
    "\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "\n",
    "    # Progress reporting\n",
    "    batch_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    N = len(train_loader)\n",
    "    end = time.time()\n",
    "    \n",
    "    \n",
    "    iteration_losses = []\n",
    "\n",
    "    for i, (sample) in enumerate(train_loader):\n",
    "\n",
    "        # Load a batch and send it to GPU\n",
    "        x = sample['image'].float().cuda()\n",
    "        y = sample['label'].long().cuda()\n",
    "\n",
    "        # Forward pass: compute predicted y by passing x to the model.\n",
    "        y_pred = model(x)\n",
    "\n",
    "        # Compute and print loss.\n",
    "        loss = loss_fn(y_pred, y)\n",
    "\n",
    "        # Record loss\n",
    "        losses.update(loss.data.item(), x.size(0))\n",
    "\n",
    "        # Before the backward pass, use the optimizer object to zero all of the\n",
    "        # gradients for the variables it will update (which are the learnable\n",
    "        # weights of the model).\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Backward pass: compute gradient of the loss with respect to model parameters\n",
    "        loss.backward()\n",
    "\n",
    "        # Calling the step function on an Optimizer makes an update to its parameters\n",
    "        optimizer.step()\n",
    "\n",
    "        # Measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "        eta = str(datetime.timedelta(seconds=int(batch_time.val*(N - i))))\n",
    "\n",
    "        # Log training progress\n",
    "        if i % ITER_PER_REPORT == 0:\n",
    "            print('\\nEpoch: [{0}][{1}/{2}]\\t' 'Time {batch_time.val:.3f} ({batch_time.sum:.3f})\\t' 'ETA {eta}\\t'\n",
    "             'Training Loss {loss.val:.4f} ({loss.avg:.4f})'.format(epoch, i, N, batch_time=batch_time, loss=losses, eta=eta))\n",
    "        elif i % (ITER_PER_REPORT) == 0:\n",
    "            print('.', end='')\n",
    "\n",
    "        #break # useful for quick debugging\n",
    "    torch.cuda.empty_cache(); del x, y; gc.collect()\n",
    "\n",
    "    # Validation after each epoch\n",
    "    #model.eval()\n",
    "    metrics.reset()\n",
    "    for i, (sample) in enumerate(valid_loader):\n",
    "        x, y = sample['image'].float().cuda(), sample['label'].numpy()\n",
    "        with torch.no_grad():\n",
    "            y_pred = model(x)\n",
    "            y_pred = torch.argmax(y_pred, dim=1) # get the most likely prediction\n",
    "\n",
    "        metrics.add_batch(y, y_pred.detach().cpu().numpy())\n",
    "        print('_', end='')\n",
    "    print('\\nValidation stats ', metrics.get_table())\n",
    "    # Save model\n",
    "    iteration_losses.append(losses.avg)\n",
    "    torch.save(model.state_dict(), save_path)\n",
    "    np.save(run_id, iteration_losses)\n",
    "\n",
    "ans = np.load(run_id+'.npy')\n",
    "plt.plot(ans[:,0])\n",
    "plt.plot(np.array(ans[:,1])-0.001)\n",
    "plt.show()\n",
    "\n",
    "print('\\nTraining done. Model saved ({}).'.format(save_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset size (num. batches) 16 1\n",
      "['bg,' 'real apple' 'fake apple' 'fake pepper' 'fake grape']\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Invalid shape (256, 2048, 9) for image data",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_45088/3959489633.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0msample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclass_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'label'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m9\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m9\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorchvision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_grid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'image'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnormalize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m9\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m9\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorchvision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_grid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'label'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/torch/lib/python3.9/site-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mimshow\u001b[0;34m(X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, filternorm, filterrad, resample, url, data, **kwargs)\u001b[0m\n\u001b[1;32m   2901\u001b[0m         \u001b[0mfilternorm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilterrad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresample\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2902\u001b[0m         data=None, **kwargs):\n\u001b[0;32m-> 2903\u001b[0;31m     __ret = gca().imshow(\n\u001b[0m\u001b[1;32m   2904\u001b[0m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcmap\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maspect\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maspect\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2905\u001b[0m         \u001b[0minterpolation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minterpolation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvmin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvmin\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/torch/lib/python3.9/site-packages/matplotlib/__init__.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1359\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1360\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1361\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msanitize_sequence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1362\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1363\u001b[0m         \u001b[0mbound\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_sig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/torch/lib/python3.9/site-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mimshow\u001b[0;34m(self, X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, filternorm, filterrad, resample, url, **kwargs)\u001b[0m\n\u001b[1;32m   5607\u001b[0m                               resample=resample, **kwargs)\n\u001b[1;32m   5608\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5609\u001b[0;31m         \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5610\u001b[0m         \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_alpha\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5611\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_clip_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/torch/lib/python3.9/site-packages/matplotlib/image.py\u001b[0m in \u001b[0;36mset_data\u001b[0;34m(self, A)\u001b[0m\n\u001b[1;32m    707\u001b[0m         if not (self._A.ndim == 2\n\u001b[1;32m    708\u001b[0m                 or self._A.ndim == 3 and self._A.shape[-1] in [3, 4]):\n\u001b[0;32m--> 709\u001b[0;31m             raise TypeError(\"Invalid shape {} for image data\"\n\u001b[0m\u001b[1;32m    710\u001b[0m                             .format(self._A.shape))\n\u001b[1;32m    711\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Invalid shape (256, 2048, 9) for image data"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 648x648 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_loader, valid_loader = prep_loaders(SPECIM, hyspec=False, batch_size=batch_size, workers=workers)\n",
    "import torchvision\n",
    "sample = iter(train_loader).next()\n",
    "print(np.array(class_names)[sample['label'].unique()])\n",
    "figure(figsize=(9,9)); imshow(torchvision.utils.make_grid(sample['image'], padding=0,normalize=True).permute((1, 2, 0)))\n",
    "figure(figsize=(9,9)); imshow(torchvision.utils.make_grid(sample['label'], padding=0).permute((1, 2, 0))[:,:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sample' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_36832/2824017431.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'image'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'sample' is not defined"
     ]
    }
   ],
   "source": [
    "x = sample['image'].float().cuda()\n",
    "mask = torch.argmax(model(x),dim=1).squeeze().cpu()[0]\n",
    "imshow(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(-0.5, 2065.5, 259.5, -0.5)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x1152 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x1152 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA4sAAAB+CAYAAACNpIRUAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAAdp0lEQVR4nO3d+ZPb9Z3n8af6dtttt492G7cPfIAxYCA4Ngw2GUgYIJAhBwm7VcNuJTW7tTO1+XOGZSq1P6Qqm0m2QiW72RwQIPYAwYaEy2eMjS9w++r23W33IWl/+Eh9qS+1vtJXx/OhUnVLrf7q01JL+r6+n8/n/Umk02kkSZIkSRqrLu4GSJIkSZLKj2FRkiRJkpTDsChJkiRJymFYlCRJkiTlMCxKkiRJknI0TPfDRCJhqVRJkiRJqlLpdDox1c/sWZQkSZIk5TAsSpIkSZJyGBYlSZIkSTkMi5IkSZKkHIZFSZIkSVIOw6IkSZIkKYdhUZIkSZKUw7AoSZIkScphWJQkSZIk5TAsSpIkSZJyGBYlSZIkSTkMi5IkSZKkHIZFSZIkSVKOhrgbIEkKlgPNs7ztMHAOSBevOZIkqcYZFiWpTDwDrJ3lba8A/wMYKlprJElSrTMsSlJM5gGNYy43AIlZ/m4d0EboYczqA5LRNE2RawJaCM9Yf8xtkSRpdhLp9NSDmBKJhCOcJKlIngPuGXO5kdlPJE8DgxOu+wnwRQTtUjE8BHwVOAb8Iua2SJI0Kp1OT3ms2p5FSYpJA7OfozhRYsLvprFiWXmrJzxjjTPdUJKksmFYlKQS2wIsAJbF3RBFqI3QTzwIfAykMtfPJzzj2dmoi4G/AU4QShRJklS+DIuSVEIJ4GGgK+6GKGKLgaeAq8B+RsPiQuBJRvt9OzK3+z2GRUlSuTMsSlKV6CKE0c8ZjSoqVBOwitzSQ4OER7qNsOjJ8sz1DcB6RksPLZnkdyVJqgyGRUmqAglC/9UN4CXgVrzNqSJLgBfJDXy9wMvAHcDfZ65LEIad/scJtzUsSpIqk2FRkqqEkaSYJj669YShp/Mn/Gy2z0Jr5vcHcCkNSVK5MixKkpS3duC/MfcatDuBR4APCfMXJUkqP4ZFSZLylqCwZTDqx5wlSSpPsYbF5cDmaX5+FOguUVtm1gpsZfQocppwRPhGbC2SJEmSpGKJNSx2Ao9P8/N+yi0sPsboUeAU8CmGRUmSJEnVqCRhsR1YMcn1M60ztgK4a8zlLyhlNKsHNjDak7iI3CIG6wh/3XRuEFouaS4aaWQ960kUWL4lRYrjHGd4ZEkDldJiFtNJ55Q/76aba1wrYYtmkiAsgbEcSwdJkmpVScLiHcCzc/i9rZlz1r8R+vJKYx7w7czXySQICyvP5Ajws6gaJdWcBSzgu3yXxoLmh8EtbvESL3Gd6xG1TPm4gzt4hmem/PkrvMIBDpSwRTOpJ3xyLYm7IZIkxaaoYbGe8DG7IKLttQMdQB/FLjTenjnPtcqdKscCwgGBW2CIKDuLWcxSlhbcqwhQRx3LWEYLLUDoabzEJdKkC962cjXRxCIWjVxuo23a2y9iER100E8/ffQVu3majbo6WLIEEgno7YVUKlyfSMDSpeHrpUuQTMbbTklS0RQ1LC4G/muEd/I0oazMm8C7EW1zct8E1mBYrAU7gW3AB8DvYm6LxkqQ4Ht8j046qYvgtdhIIy/y4sjla1zjZV5mkMGCt61c61jHC7wwcnmmwP81vsZX+Spv8za72V3k1mlW2trgH/8xhMJ//Ve4ciVc39oK3/8+NDXBj34EPT1xtlKSVERFDYsJQu9iVJEru53izx7JtlzVL/tcOyepHNVRR31Er8UEiXHbiiKAanr5PHfZ5yOKXmRFqL4+hMXJrq/3c1KSql1RwuIy4EuE+qHF+Ni/gzBw8H2IsBxCHWGB5HmEPtGodAB/Ryh0sxcc8haTe4CVk1y/JvN1NeF5yjoGnCh2ozTBgzzIUpYCITTMNHRR5WMhC9nO9pGwt2SOc/3Ws56GMR9NhzjEGc5E0sb8pIB3CO/hD1MTB5QaGuCRR6C5OVxubh4NhI8+Crduhe8bG8NtE4lw+54e2LMH0n6+SfnbwuRlICczRBhbVysjYsbum09nGPgTlfq4rGIVm6ddTDA4wQmOcawELRqvKGFxCbCjGBvOuB1YCxwiyrBYTyinE2VQhNFH4wLwHobFuNwBPDDNz1cw/s36FobF0rubu9nIxriboTloo40d7Ci4Z3B15pR1iUsxhsUPCe8LD1ETYbG+HrZtC8NPJ9q6Nfc6gAcfDGHxvfecuyjNySbg3lneth/4M5UaivJXBzzIzIXGblHJj8tt3MaOWSSnJMnKD4sdwG3M/vhI+VgDLAWaingfLcB9hKNCR6ACy/evJ/wVR4Dq3yVYQXi+sj4HLsfUluqWIMGd3EkzzSXtSWykkXu5l156OcWpkt1vGjgK9BDeeaI6PJUGPgN6Ke3rczGLWc1qFkd+oC1YxSqGGKKHHrpjWXn3JrAPaCTs1MW6PHF0urpCkZqxsj2G+Wpuhi1bYGgIjhyB4cr7fJNKLztOrj2P32kA7iaEo6OZrxBC1SbCPmbpw0Rh1hKWpztH6FjJWk0Yq9g8i23UMfq4QAiNnxIO+pWvLrpYylK6ZlxMMOikk/vG7ZtO7ixnucjFQps3ItJPvTsZP5CvcmwjDAMopoXAtwhHhU5SiWFxJ9BJ6G+7GXNbiu+ezDnrlxgWi6OOOp7kyZHhp6XSSivP8RyHOFTSsAiMlG/5DtGOZXgLOB3h9mZjNav5Dt8p2va/lDntZW9MYfEq8H+A+YS1daskLN5/P2zfHs222trgW9+Cmzfh1Cm4UboVkaXKlAC+SuhiyUcTYUmfFPAjQsCC8L70NKGqe6WFxb8hrKr+BuPD4peB+2e5jSYYtzTTFcLh0/IOi/dzP9uZ/fvwpsxpJq/zevmGxcqzjPAPNtNY6NrUTph3mtVMOHazAhiY4nfShB6ToaK2LB/ZOaiFPseLCXMer+MSG4rKZeAsYVRGjb8Zz2g+81nJSnrpZWDKd6BiaCA8Q/OItkL2VcJc9isRbjNmdXXQ2Rl6Gnt7w7DWjo5w/VjJJFy44BxHqSAdjL4nNRCmUzUxeX2GIYgwPESjgzBioyVzeSHj217Ifls9IYgPEv7u6h8PV0w1vH+SAL5N+Geqgbkoc/C3jD+mk32U/tMMv/c/IZbj/5PbQOi/KfQ5fozwiPyJsHiLVLhdhP+ofyb62dLV5l7u5R7u4Wf8jKMcLeE9LwP+C+E9JMrPincJZdqqKDA1NcGLL4bexR//GBYsgB/8IAxvHauvD156abRgjqQ8JQj7NukJ180nvF9NdIHQE1kuPW11wHcJgTH7vrqN0JuYVcj77QLg+4SQ/DJVdVAuBjUcFiH8I1o+fypTPTrTvXzTM/w8HlE8x1HvKEpBFUWFokpkTnHde3E+K6rs2Z9siY1EIrdncbLbScpDYsLXyX4203Vxm/i+GuV+VgL326JT42ExDk2EmZ3nCEtpVJ8dQF/m+yRhHlV/yVtxJ2Hy+NzK909tI2HIxF5CKZGYtbWFkvYTd776+uCttyBVLkcRNZUk8EdmN4UfwkffTkI5AAizn/+dMI/4UuStm1orrXyFr7Cc5SW81zhcA35LeN3/LcUthFYlli6FZ58NPY2uxShpnHsI878XxN2Q2CxnOdvYxlrWxt2UWTEsllwDYQmHE1RjWEwQ6lFlDREWDCl9WOwiDGmIWrbe7yHKIizOmwdf/nLukfveXnj77XjapLykgP153D5BWMc2GxZThFqdVyNu10yaaWYrW2mkceYbV7R+4APC8K4dGBZnoa0tLMEhSTnWMH64ae1pp51tRdlHLY4aDotp4CDwBWFeW2krMZazzYTjPcsi2FYdYQGKHsKjXXwLCFW1JpvgHaVNhEfoFOOrdxVZY2MoUZ89Wj/ZemgALS0hRJ4/DydPlqx5Kr404VDFF5nLSSp1ZalKMwR8RJhjc2fMbSnApk2wcCEsj6FHuK8PDh0KcxUrZHmNDWxgEYs4wAEGK/aVtozQkzOTc4RlolT5BoEDjFbev058w95XwJi1c0NdfUUlRYqDHOTmmHUKznI20vuo4bAIobQEwPMYFkc9wviXdSHqgccJFR8PUYq3qqWEstLFHKeeAB7OfP9bShoWW1rgqadCtcHpzJ8PX/86fPSRYbEKvRN3A2rSIPA6YSh6BYfFhx+GdbMJDkVw9Sr87ncVVQV1K1vZwAaOcayCw+JqwufiTN7FsFgtbgGvMXXt+lLaQKUurFcJ0qR5i7ciXSpjohoPi8pKEPriGpj93KnysoAQFKv0iFVTE6xYEUJgIcUhFi2C9vZwhL+nJ7LmSbXjJmGt3EbCu2a+r8d+wgGma9E2a6IVKyY/qNTSknudWM5y5k1Sqr+VVuqoYxWr6MvMxh9mmG66SZNmJStppJHznOcW5VLdtYXxn4WzPRi+kLBA+nkom79Fle8a4T2zE5eqi1YvvVzlKkNFXrDOsCgg7Pb8B2CKQY0VYBPwjcz3VVj9qqMjlKAv1P33w+OPh6Fgv/hF4duTas4Z4MeEHfB/Jv+P0S+Af4u4TZP4xjegq6v491MlnuRJNrBhyp9/j++NfH+d6/wL/0KSJM/zPEtYwk/4Ccc5XoqmzsIq4B/m8Hv3ZM7/i7CguRSF/ZnzfwbWx9yW6rKHPfyFvxT9fgyLGqeyY1Zlt35a2d7EKErOJxKWrpdqga/zvMS3NEux5Pv3JKi65VwkFcywKJWzhgZ44olQij5KK1fCt7/tnEZVjGMcYx/7OMe5uJsyR58SCk4UefhpOWtvh299KxS4eeMNGCru0KnJfIWvsHSSYZmdeUxhmMc8nuM5UqRYkCn/v5OdbGYzr/N6jHMbNwJbKHyM0A5Cabp9lGMPYyutPMET1BMKvV3mMrvZTQstPMET9NDD3iqsNj87l4DdhIJcpX99qToZFqVyVlcHmzeHuYZRam8P51OnDIuqCD30sI99cTejABehotsfgdbWMBT+xg3YtSuWsLiRjaxhTUHbaKSRe7l33HXrWU8nnexiV4xhcRlwf4HbSDA6VPAs5RgWm2lmC1tGlu05wxl2s3vkeTnJyRoOi/3U/PuMIhdpWDxDqC+6hLD8QrGcJMz6uFHE+6glmwjTjl09rIy0tMADD4TCNjNVPp3O8uXwyCOjl9cUtpNUTQYY4CM+opvuuJuiinQT2ENYe3XjmOtvEZbYSE24/cnSNCtr375wMOiOO+JZJqMGNdLIdrYzwACf8An9MawwHK11hAWwsv5K6LkqLwtYwA520EQT9dSzhCU8wiM5t7vKVQ5ykLWspYvZz+c9y1lOcCLKJhdBkvC+U8Lq7LPWRSicFPFBb5VMpGHxZOZ8J8UNi0cZXfRChXuA4j5fmoN58+BrXwvrKhaiq8siF1O4xS3+yB8ruBy+4tUPvAk8SG5Y/COxDwF7//3wdcECw2KJNNHEYzxGihTHOV4FYXFT5px1mXIMi4tYxN+NWZphOct5kidzbnec4xzkIHdwBzvZOevt72VvBYTFYeAtynOY++24dEZlK8ow1D5CoMtaBPhRJUmqPtcY/4nXR1kUCVm1KoxQaKvcGteVbA1raKGF05wmXQ7/D1VgHvPooosFLJhTMaJWWtnIRhazuAity1caOE0YI7eCSq5FP7PLhPfILqA1om1mH7/swd46Qu9lZcyu66OPoxylgw7aac/rd9OkOcMZbnKTq1wtTgMnKMqjegb46ZjL25jdcrCSJFWWY5lzmXn6aUcVxKSOOp7hGS5xiZd5mWGG425SVeikk3/ILAkyl7A49vfLw+8zX78LE+bAVpdDmXOUS2ekgN/AyEL0zcAPqZTQfYYz/JSf8gzPsJ3tef/+G7zByRJObaiMCC5JkvLj0hmxqb5lOMrHXB9bnxNpbkoSFo8CPx9z+T7g7jx//4Mxly9OdcM52wMcAb4OzI986+MNEI4mld+4f9WgbdtCAYwjR+Djj+NujSrIDW7wCq+wjnU8zMNxN0c7doShp1mTLbeTTsPu3XD+PGzdGl77qgLthDlhy2JuhzSd3cD7wFZgqveeNPAG0Ju53AA8Tdg33w2cH3Pb6YZg9hH2tYcy35enD/iA4xwfufwoj05afGkve8f1JF4ocSGjkoTFK5lzVr4DYy4TanAVTzchgn6N4ofFJCH+lu8/r2rIbbeF85UrcbdEFWaIIY5whGYKqNar6KxeDXfdNfPtssvlrI9qOJji10IoU1c30w2lGJ3OfF03w+1OwEiV8gbgq4R981PMvqr0EKETqLzXmjyfOWU9wAOT3u4MZ/hrkZPQdGIZhnoc8hrBf6ZYDRknCewlvOl+CfKccDqzPuDPhMm45VV98QAhKj8E7vbVqtWr4bHH4NKlUHJfmqXznGcXu0Yur2Ut6yOblwJHOEI33XzBF5FtU8Cnn0LfhIOWDQ2wfXthy/XMRlMT7NwZejj37y/ufSkC3YQd7+jHdQngIGG02XbCPuhc1AOPEKoxQxjF9j5h37bcHIUpKwWngetjLqcI++bzGN/tNNEw8C6ji8Ddojz/9untZz9nOZtz/flxPaqlF0tYPJE5l5cU8F7m+3UUJyy+Re7aW/E7SHjpPoBhsWatWhXOx44ZFpWXiUdGH+XRSMPip3zKB+MmIigSx46F81jNzWF911KFxSNHDIsV4Szw73E3ooodJhTJuo+5h8UGGDcd4BrwIeUZmPIpCpYihN6ZJAlTyirbQQ7G3YRJWeBmUicJR2U2Eo7WFOI6oev9GmVRTl2VbWgo7OClMgcdWlrCcLIaKmSRJs1JTjLEEBvYQH3Br1FF6SIXOchB2mhjDWvmtI3sc9xPP5e5HHELVTba2uDuu2FgAD77rKh31ZE5tUZWul+KUopw2L6V0GGR7/9pEviM0WGXNynPoKhKZFic1G5gAfDfCV3fhegGflFog6Tg5k341a9gMDOUefly+Kd/qqmwCPAmb3KVq/yQHxoWy8xfM6dNbJpzWATYzW5OcSrClqnsrFwJL7wAFy/Cyy+PHgQrgru5m8d5vGjblwqTBH6b+f4HhDUD8zFMWEriWpSNkgDD4ixM1Rs40865vYjVrcTPb9r/p6lkF7yebVl0F8gubz4/EfO9Y0S+7xVSfHzdqnwYFqd0E/jf5A5DbQKeY+Yex5vAr5l+Qq4qU7a08zlKNuG/pwdefRWGh8NQ1GJZuRJefBE++AAOHy7e/USgn35+zs9ppJFv8A0WsnBWv9dDD6/yKsMMM1TmldJq0X728wmfxD6hv2r86U9wYkyVgPO1+bjuYx9f8AVP8RTLWR53c6RpvMbM+5gJ4BmgEfh/hOGnUxWNkQpjWJxSkslL9LYwu3HgSUIZn4EI26Ty0U1JyzTdulX0OT0AtLbCxo2lua8CJUlyghM00JBX6LvFLT6j/P++WnWZyz4/UbpwoSJez8V2OXO6NVItUipX3TPfhASj+5f5rjEg5cewmLchYBej5XmnMkglvXiThJmazYQlNNoj3O6fgB6KPajic8LRuMXANmYeJlwhhofhnXdCz+JkbtyAP/wB1q6FzZtL27aIpEjxNm8zj3lsZSvLXFi6KlzgAq/xGpvZPO3cxTOc4QAHRi67REaMhodh9+5QrXQ62WqmjY1zu5+BgfC+Npz5jOzvL9lw2fd4j8Mc5h7uYRWrSnKfxXcN+ANwOzCLtTbztgp4EvgYSrwYuKaSJlT/rKccq+yruhgW85aEKizjniQUWQa4m+jCYgr4CEpQz/BC5ryWEBarRDIJH34I16aYtN7fD3v3hh2tCg2LadJ8zMcAbGCDYbFKXOYye9jDEpZMGxYvcpE9VVDyvCokk2EI+kzmz4eHH557WBwagj//OYyYKLFsafoOOqooLPYT1qKD4oTFzsz5cwyL5cRlrlQahkXlOEroCQSoI3z05Lvq1iBh5aAhSj0Q9wbh6OdtwIqS3nOkBgbgk09CCMxWPp1MSwts2gRdXaVrW5lJkeIwh1nGMjaxacriFUmSHOawc+FK7HM+p2Gaj5rTnC5haxSJ4eGwPmJTE9x1V3gfykdDA2zZAr29cPx4cdo4g9Ocpo467uIuWua8tt3k0qQ5whF66CFlr4+kCmdYVI63xnzfAKwm/7B4k1AEepqYUyS9wP8FHqeiw2J/P/zmNzPfbuFC+OY3oa6u+G0qUylSvMEbdNLJndw5ZVgcYojXeI3rXC9xC2vbvsxJVWRgAH73u/C+09WVf1hsaYFnn4UjR2ILix/zMfvZzypWFSUs7mKXB6YkVQXDomaUJv/5huVR9Hmuy57MZZuKylzL26fHnKSak07Hs0zGZPc7cd1Xl+8ooexjXSXz9iXFzrCoaSWBV8j/HyUJMS9K8CFwbJLrtwDbC9juPuAvOG+jOF7jNdpp53mez/to/2Uu82N+POXP06Tpt7S4qtWbb8K77+Ze39tbvPtMpeCXvxydu9jUBM8/H6oqjzU8DL/6FVyf0Kt/82bx2laTDgJnGC1IY2CUVDjDoqaVBs7G3Yg5uZo5T7S6wO1eI0zyVzFc5CI3uEFyVsvTjDfEEJ/73KhWTVUxudjOnRv9vqUlFMmZKJ2G7m64cqVkzapN1zPnfCeOSNLUDIuqMZ8RFrDtJL8exo+AL4BzM91QBRpkkD/wh2mLolwuQX1dSXkaGoLXX8+tkppKhXnYZeQ+7mMta1nAgribUgFOEUbVxHPouJFGHuOxklfK3sc+TnGKC44kUo0zLKrGnM+c7yS/sHgCy1SXRpIkn/BJ3M2QlK9kEvZVxvvk7dzOgzwYdzMqRA9xLhnWQAP3c3/Jg/1pTvNBFS6VJuXLsKgadRl4b8zl5cC6MZc/B7rHXC7ivJ9C3LwJ778Pt90Ga9cWvr0rV0KFwnP2oEqqXic4QZIk93Iv85gXyTaHGGI/+xlk0PnRkqqGYVE16iLw+zGXv8z4sPgp8HZJWzQn16/Dq6/CQw9FExZ7euD3v5/5dpJUwfazn0McYh3rIguLgwzyBm8YFCVVFcOiBIRSPqkJl2tUImGpe0k1IU2aFCkSmVN1GLvgVaFLRc1l8axoZZdESo37jJ5c1M9jgoTLManmJdLT7BQmEglfIaoRrcDCMZevA30xtWUOHnoIvv71wrczMACXLsGePRUz90iS5qqDDuqp51meZXWB1bL76OMlXiqDnsVmYDHwCHBfAdt5lzBXv59QCTweCRJ00EEdddPebj7zeYEXaI6oGuxVrtJPP/vZz7tMsiyNVEXS6fSUR1nsWZSA8GEY9wd8GWhuDvMf58+PuyWSVHQXuQjAAAMxtyRKA4TK3YUe8LxGOVQAT5OeVUXSNtoi7QVclDmd4lRk25QqkWFRqgbHjsErr0BnJ+zcGYaSzsW5c/DOOxa4kaRZSpPmHd6hm+4yC537gDOTXH935lxdbnKTX/PrGXsgt7CFTWyacXsf8iHHOU5vuRa4k0rEsChVg97ecO7vD2Fxrm7cgAMHomuXJNWAE5zgOMfjbsYEZ5l8bcRlVGNYHGaYQxya8XYrWDGrsNhNNwfw81AyLErV5MqV0DM40cKFcN99oz2OPT1w+HDu7Xo9giqp9hzgAGczwSpBggd4YMp1/QYY4EM+ZJjhkeuucKUUzYzIaWZX7XuyXsnKd5KTkw5XXc1qbud2eujhMIdH/h+kWmdYlKrJpUvw5pu5169aFcJi1oULk99OkmrQx3w88n2CBBvZOG1Y3MUuBhksUeuidjxzrk3HMqeJHuVRbud2LnKRN/HzUcoyLEq1IJ2GZHK0ZzE1cwlySapVycxpqp+p+qRJkyQ5qyU6pFri0hlSLWhogPb20csDA3D9emzNkaRy1k47DVMcT0+R4jKXXX+vysxjHvOZzyCDXItxqRApDtMtnWFYlCRJkqQaNV1YnL6+sCRJkiSpJhkWJUmSJEk5DIuSJEmSpByGRUmSJElSDsOiJEmSJCmHYVGSJEmSlMOwKEmSJEnKYViUJEmSJOUwLEqSJEmSchgWJUmSJEk5DIuSJEmSpByGRUmSJElSDsOiJEmSJCmHYVGSJEmSlMOwKEmSJEnKYViUJEmSJOUwLEqSJEmSchgWJUmSJEk5DIuSJEmSpByGRUmSJElSDsOiJEmSJCmHYVGSJEmSlMOwKEmSJEnKYViUJEmSJOUwLEqSJEmSchgWJUmSJEk5DIuSJEmSpByGRUmSJElSDsOiJEmSJClHIp1Ox90GSZIkSVKZsWdRkiRJkpTDsChJkiRJymFYlCRJkiTlMCxKkiRJknIYFiVJkiRJOQyLkiRJkqQc/x94Z7Wh5riJ/QAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 1152x1152 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.train()\n",
    "def decode_segmap(mask, unk_label=255):\n",
    "    \"\"\"Decode segmentation label prediction as RGB images\n",
    "    Args:\n",
    "        mask (torch.tensor): class map with dimensions (B, M,N), where the value at\n",
    "        a given location is the integer denoting the class index.\n",
    "    Returns:\n",
    "        (np.ndarray): colored image of shape (BM, BN, 3)\n",
    "    \"\"\"\n",
    "    mask[mask == unk_label] == 0\n",
    "    mask = mask.numpy()\n",
    "    cmap = get_labels()\n",
    "    cmap_exp = cmap[..., None]\n",
    "    colored = cmap[mask].squeeze()\n",
    "    grid = make_grid(torch.tensor(colored).permute(0, 3, 1, 2))\n",
    "    return np.transpose(grid, (1, 2, 0))\n",
    "#%pylab inline\n",
    "mask = torch.argmax(model(x),dim=1).cpu()\n",
    "figure(figsize=(16,16)); imshow(torchvision.utils.make_grid(sample['image'][:,:1,:,:], padding=0).permute((1, 2, 0)))\n",
    "axis('off')\n",
    "figure(figsize=(16,16)); imshow(decode_segmap(mask))\n",
    "axis('off')\n",
    "figure(figsize=(16,16)); imshow(decode_segmap(sample['label']))\n",
    "axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.reset()\n",
    "for i, (sample) in enumerate(train_loader):\n",
    "    if i>= 10:\n",
    "        break\n",
    "    x, y = sample['image'].float().cuda(), sample['label'].numpy()\n",
    "    with torch.no_grad():\n",
    "        y_pred = model(x)\n",
    "        y_pred = torch.argmax(y_pred, dim=1) # get the most likely prediction\n",
    "\n",
    "    metrics.add_batch(y, y_pred.detach().cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation stats                    IoU        F1      Prec    recall       Acc\n",
      "bg,          0.997600  0.998700  0.998700  0.998900  0.997900\n",
      "real apple   0.960600  0.979800  0.989000  0.971000  0.999200\n",
      "real pepper  0.993500  0.996700  0.996000  0.997400  0.999900\n",
      "real grape   0.978600  0.989100  0.988000  0.990400  0.999500\n",
      "fake apple   0.988400  0.994100  0.992300  0.996000  0.999700\n",
      "fake pepper  0.990400  0.995100  0.994400  0.996000  0.999800\n",
      "fake grape   0.988600  0.994200  0.993400  0.995100  0.999600\n",
      "total        0.985386  0.992529  0.993114  0.992114  0.999371\n",
      "total(-bg)   0.983350  0.991500  0.992183  0.990983  0.999617\n"
     ]
    }
   ],
   "source": [
    "print('\\nValidation stats ', metrics.get_table())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sn\n",
    "df_cm = pd.DataFrame(metrics.confusion_matrix[1:-2,1:-2], index = [i for i in class_names[1:-2]],\n",
    "                  columns = [i for i in class_names[1:-2]])\n",
    "plt.figure(figsize = (10,7))\n",
    "sn.heatmap(df_cm, annot=True, fmt='.0f',cbar=False)\n",
    "plt.show()\n",
    "# plt.savefig('confusion_matrix_rgb.pdf',dpi=300)\n",
    "# plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'epochs-%d' % epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sample' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_36832/3727203042.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msample\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'image'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'sample' is not defined"
     ]
    }
   ],
   "source": [
    "sample['image']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
